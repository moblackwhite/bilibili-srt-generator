1
00:00:00,000 --> 00:00:02,680
首先我们讲模型选择

2
00:00:02,680 --> 00:00:07,080
先介绍一下我们怎么样去学超参数

3
00:00:07,080 --> 00:00:09,519
我们从一个简单的例子开始

4
00:00:09,519 --> 00:00:12,480
就我们这里有一个例子

5
00:00:12,480 --> 00:00:16,440
就预测谁会偿还贷款

6
00:00:16,440 --> 00:00:21,199
就假设银行雇你来调查谁会还贷款

7
00:00:21,199 --> 00:00:24,760
你拿到了100个申请人的信息

8
00:00:24,760 --> 00:00:29,960
就是他所有的去申请贷款的所有的信息

9
00:00:30,480 --> 00:00:34,200
其中你发现有5个人在三年之内违约了

10
00:00:34,200 --> 00:00:36,640
就是他还不清贷款了

11
00:00:36,640 --> 00:00:40,079
所以你的任务是把这样子的人找出来

12
00:00:40,079 --> 00:00:41,560
因为对银行来说

13
00:00:41,760 --> 00:00:44,079
你不还贷款还挺麻烦的

14
00:00:44,079 --> 00:00:44,960
对吧

15
00:00:46,079 --> 00:00:49,560
然后你就去看这100个人的申请信息

16
00:00:49,960 --> 00:00:51,320
然后你发现说

17
00:00:52,519 --> 00:00:53,719
发现有5个人

18
00:00:53,719 --> 00:00:56,600
这5个人都在面试的时候

19
00:00:56,600 --> 00:00:58,679
穿了蓝色的衬衫

20
00:01:00,079 --> 00:01:02,920
在美国蓝色的衬衫

21
00:01:02,920 --> 00:01:04,400
其实是有一个隐含信号

22
00:01:04,400 --> 00:01:05,599
就是一个蓝领

23
00:01:05,599 --> 00:01:11,239
但不管是不是你的模型也发现了很强的信号

24
00:01:11,239 --> 00:01:13,240
就是说5个人都穿了蓝色衬衫

25
00:01:13,240 --> 00:01:15,319
我模型肯定会发现这个问题

26
00:01:16,439 --> 00:01:18,760
那么当然会有问题这个事情

27
00:01:19,799 --> 00:01:20,719
为什么呢

28
00:01:22,799 --> 00:01:24,920
因为你想一想

29
00:01:24,920 --> 00:01:28,159
我面试的时候穿一个蓝色衣服

30
00:01:28,479 --> 00:01:30,280
我下次如果穿一个红色衣服

31
00:01:30,280 --> 00:01:32,719
是不是你模型就不一样了

32
00:01:33,799 --> 00:01:34,359
对吧

33
00:01:34,719 --> 00:01:37,000
所以看上去挺有道理的一件事情

34
00:01:37,000 --> 00:01:38,959
你仔细想想其实是没道理的

35
00:01:39,200 --> 00:01:40,319
但模型不知道

36
00:01:40,359 --> 00:01:45,280
模型其实很容易去被这种信号给忽略掉

37
00:01:46,239 --> 00:01:49,920
所以我们这里就要研究这个问题

38
00:01:50,799 --> 00:01:53,439
就是说我们去看这个问题的话

39
00:01:53,439 --> 00:01:54,879
其实最正常的是说

40
00:01:54,879 --> 00:01:56,719
我们去看两种误差

41
00:01:57,280 --> 00:01:58,359
就是你这个误差

42
00:01:58,359 --> 00:01:59,879
就是你的损失

43
00:02:00,640 --> 00:02:01,719
比如说我的精度

44
00:02:01,959 --> 00:02:04,359
我的判断的错误

45
00:02:05,000 --> 00:02:06,439
这里有两种误差

46
00:02:06,760 --> 00:02:08,319
一种叫做训练误差

47
00:02:08,759 --> 00:02:11,719
就是我的模型在训练数据上的误差

48
00:02:13,159 --> 00:02:14,960
第二种叫做泛化误差

49
00:02:15,360 --> 00:02:18,000
就是我的模型在新的数据上的误差

50
00:02:20,039 --> 00:02:22,439
就是说我们关心的其实是泛化误差

51
00:02:22,439 --> 00:02:24,159
我们其实不关心训练误差

52
00:02:24,639 --> 00:02:25,599
举个例子

53
00:02:27,599 --> 00:02:29,159
假设说我们来

54
00:02:29,159 --> 00:02:31,280
大家如果参加过高考的话

55
00:02:31,319 --> 00:02:32,759
有模考这个事情

56
00:02:32,759 --> 00:02:33,039
对吧

57
00:02:33,039 --> 00:02:34,199
就是模拟考试

58
00:02:35,199 --> 00:02:38,120
然后大家会去根据你模拟考试的分数

59
00:02:38,120 --> 00:02:40,000
来预测未来考试的分数

60
00:02:43,039 --> 00:02:45,960
所以说在模拟考试的时候

61
00:02:46,000 --> 00:02:47,159
表现得很好

62
00:02:47,199 --> 00:02:48,840
其实是一种训练误差

63
00:02:49,560 --> 00:02:52,159
它不代表以后考试一定会好

64
00:02:53,000 --> 00:02:53,800
举个例子

65
00:02:54,400 --> 00:02:58,040
就是说模拟考试的题

66
00:02:58,040 --> 00:02:59,640
很有可能你是见过了

67
00:03:00,280 --> 00:03:03,000
就是说虽然你可能没有看过这一次的卷子

68
00:03:03,040 --> 00:03:05,360
但是你可能在老师在上课讲过

69
00:03:05,360 --> 00:03:08,400
或者是别的地方都不小心看到过

70
00:03:08,920 --> 00:03:10,520
所以如果有两个学生

71
00:03:11,000 --> 00:03:12,960
第一个学生是说我就是背他

72
00:03:13,000 --> 00:03:14,240
我就把这个题背了

73
00:03:14,439 --> 00:03:16,200
这个是大家常用的策略

74
00:03:16,520 --> 00:03:18,240
我们把这个题的答案给背了

75
00:03:18,840 --> 00:03:20,720
那么所以你如果把所有的

76
00:03:20,760 --> 00:03:22,960
过去的问题都背好了

77
00:03:23,040 --> 00:03:24,480
那么你模拟考试很有可能

78
00:03:24,480 --> 00:03:25,599
你的成绩会很好

79
00:03:26,200 --> 00:03:27,680
所以你会拿到很好的成绩

80
00:03:29,600 --> 00:03:30,840
但学生B呢

81
00:03:31,560 --> 00:03:33,400
假设我是能确实理解

82
00:03:33,400 --> 00:03:35,439
这个题的解决思路是什么样子

83
00:03:36,319 --> 00:03:38,040
所以如果学生A和B

84
00:03:38,400 --> 00:03:39,760
都拿比较好的成绩

85
00:03:40,640 --> 00:03:42,400
那么在真实的考试中

86
00:03:42,600 --> 00:03:45,319
学生A很有可能比学生B要差

87
00:03:46,280 --> 00:03:48,719
甚至是说学生B在考试中

88
00:03:48,719 --> 00:03:50,080
你可能就打个80分

89
00:03:50,080 --> 00:03:52,240
学生A如果是90分或95分

90
00:03:52,640 --> 00:03:53,920
那么你学生B

91
00:03:54,080 --> 00:03:55,120
有很有可能是说

92
00:03:55,120 --> 00:03:57,120
我大概真实水平就80%

93
00:03:57,280 --> 00:03:59,520
我真实的考试可能还是80%

94
00:03:59,680 --> 00:04:04,159
但学生A可能你会比90要低很多

95
00:04:05,040 --> 00:04:06,280
举个具体的例子

96
00:04:06,439 --> 00:04:08,280
我还曾经犯过这个例子

97
00:04:08,960 --> 00:04:10,360
在十几年前

98
00:04:10,800 --> 00:04:12,360
那时候出国要考GIE

99
00:04:12,360 --> 00:04:13,439
我不知道现在要不要

100
00:04:13,600 --> 00:04:14,400
现在应该是要的

101
00:04:14,400 --> 00:04:16,199
但是那个年代的考GIE

102
00:04:16,199 --> 00:04:17,480
跟现在可能会不一样

103
00:04:17,840 --> 00:04:19,720
那个年代考GIE主要是背单词

104
00:04:20,120 --> 00:04:22,760
我也不记得大概几千单词了

105
00:04:22,960 --> 00:04:24,320
大概就是两三千

106
00:04:24,520 --> 00:04:27,400
我其实就准备了一个月

107
00:04:27,400 --> 00:04:30,120
一个月我的记忆力是说

108
00:04:30,120 --> 00:04:31,160
我当天背完

109
00:04:31,160 --> 00:04:32,080
第二天能记住

110
00:04:32,080 --> 00:04:33,720
大概第三天也能记住

111
00:04:33,720 --> 00:04:35,080
第四天可能就不行了

112
00:04:35,360 --> 00:04:37,640
所以我就去背题

113
00:04:37,960 --> 00:04:38,720
就背GIE

114
00:04:38,720 --> 00:04:41,080
大概我大概花了两三个星期背了一遍

115
00:04:41,480 --> 00:04:42,040
背了一遍

116
00:04:42,040 --> 00:04:45,280
然后我说拿个考试来试一下

117
00:04:45,560 --> 00:04:46,560
之前的卷子试一下

118
00:04:46,720 --> 00:04:48,120
发现结果很好

119
00:04:48,840 --> 00:04:49,160
很好

120
00:04:49,160 --> 00:04:50,160
我就说不用背了

121
00:04:50,160 --> 00:04:50,920
就这样了

122
00:04:50,920 --> 00:04:51,639
挺好的

123
00:04:51,800 --> 00:04:54,319
然后我觉得自己记忆力超群

124
00:04:54,959 --> 00:04:56,600
然后我就真的去参加考试了

125
00:04:57,079 --> 00:04:58,840
结果发现比我远远的要低

126
00:04:58,840 --> 00:05:02,879
我的GIE成绩大概也就是像MIT

127
00:05:02,879 --> 00:05:04,240
CMU这种学校

128
00:05:04,319 --> 00:05:05,680
可能就好一点

129
00:05:05,680 --> 00:05:08,519
所以我最后也就升了MIT和CMU两个学校

130
00:05:08,759 --> 00:05:09,560
就是说

131
00:05:10,040 --> 00:05:11,199
因为你的

132
00:05:11,680 --> 00:05:13,600
当时候背题是用红宝书

133
00:05:13,600 --> 00:05:16,240
红宝书其实里面的单词已经是

134
00:05:16,439 --> 00:05:20,240
他那些东西已经是根据你历年GIE的

135
00:05:20,480 --> 00:05:23,400
题库各种过去的考试总结好的

136
00:05:23,920 --> 00:05:25,400
所以你把它背一遍

137
00:05:25,400 --> 00:05:26,600
就算你当时记住了

138
00:05:26,600 --> 00:05:29,120
其实你可能真的就是把题给记住了

139
00:05:31,079 --> 00:05:32,439
所以就是说

140
00:05:33,160 --> 00:05:37,000
这里训练误差是指我们在模型看到的数据上

141
00:05:37,000 --> 00:05:38,720
有标号的数据上的误差

142
00:05:39,240 --> 00:05:41,840
犯化误差是在新的数据上的误差

143
00:05:41,879 --> 00:05:44,040
我们关心的其实是犯化误差

144
00:05:44,040 --> 00:05:48,720
所以大家两个是一定不能去搞混的

145
00:05:50,480 --> 00:05:51,280
然后呢

146
00:05:52,680 --> 00:05:54,760
所以我们来怎么去

147
00:05:55,120 --> 00:05:57,840
计算我们的训练误差和犯化误差呢

148
00:05:58,320 --> 00:06:01,080
一般来说我们会有两种数据集

149
00:06:01,560 --> 00:06:03,680
一种叫做验证数据集

150
00:06:03,720 --> 00:06:06,240
一种叫做测试数据集

151
00:06:06,920 --> 00:06:09,240
就是说其实我们经常容易搞混

152
00:06:10,120 --> 00:06:11,600
所谓的验证数据集

153
00:06:11,600 --> 00:06:15,040
是说我来评估一个模型好坏的数据集

154
00:06:15,439 --> 00:06:17,840
我来看一下我选择参数会怎么样

155
00:06:18,080 --> 00:06:19,800
比如说我们昨天有讲过

156
00:06:19,840 --> 00:06:23,240
我们调多层感知机的时候

157
00:06:23,320 --> 00:06:24,600
你要取多大

158
00:06:24,720 --> 00:06:25,840
你的学习率怎么取

159
00:06:26,280 --> 00:06:27,080
这种东西

160
00:06:27,120 --> 00:06:29,920
我是通过一个验证数据集来验证的

161
00:06:30,760 --> 00:06:31,879
举个例子是说

162
00:06:31,920 --> 00:06:34,680
经常我们将训练数据集

163
00:06:35,200 --> 00:06:36,680
分成一半一半

164
00:06:37,480 --> 00:06:38,800
然后我们就把

165
00:06:38,960 --> 00:06:40,920
一半的第一半的数据集

166
00:06:40,920 --> 00:06:42,480
用来训练我们的模型

167
00:06:43,040 --> 00:06:44,960
就是训练我们的那些模型参数

168
00:06:45,680 --> 00:06:46,759
第二个

169
00:06:48,079 --> 00:06:50,199
第二半也叫做验证数据集

170
00:06:50,240 --> 00:06:52,240
我们就把我们训练好的模型

171
00:06:52,360 --> 00:06:54,319
在验证数据集上

172
00:06:54,560 --> 00:06:55,759
测一下我们的精度

173
00:06:55,800 --> 00:06:56,759
我们的误差

174
00:06:58,280 --> 00:06:59,840
我们根据精度来看

175
00:07:00,040 --> 00:07:02,199
这个超参数可能不是很行

176
00:07:02,759 --> 00:07:05,040
那么我们可能会再换一个超参数

177
00:07:05,319 --> 00:07:06,600
就是我们换一下学习率

178
00:07:06,840 --> 00:07:08,199
换一下模型的大小

179
00:07:08,199 --> 00:07:10,159
然后再在这个验证数据集上

180
00:07:10,159 --> 00:07:10,920
测一下精度

181
00:07:11,120 --> 00:07:12,680
然后我们就可以比较说

182
00:07:13,399 --> 00:07:15,719
这两个超参数谁好谁坏

183
00:07:17,120 --> 00:07:19,319
就因为是说我们的验证数据集

184
00:07:19,319 --> 00:07:20,560
没有参加训练

185
00:07:21,439 --> 00:07:23,560
所以在一定程度上

186
00:07:23,560 --> 00:07:24,919
确实能够反映出

187
00:07:24,919 --> 00:07:26,959
我们的超参数的选择好坏

188
00:07:28,719 --> 00:07:29,839
这里有一个

189
00:07:30,680 --> 00:07:32,199
大家常犯的错误

190
00:07:33,039 --> 00:07:34,759
就是说验证数据集

191
00:07:34,759 --> 00:07:37,199
一定不能跟训练数据集混在一起

192
00:07:39,199 --> 00:07:42,240
这个是不管是新手还是老手

193
00:07:42,240 --> 00:07:43,599
一直会再犯这个错误

194
00:07:43,639 --> 00:07:44,560
我举两个例子

195
00:07:46,599 --> 00:07:47,439
就是说

196
00:07:48,199 --> 00:07:49,599
第一个例子是说

197
00:07:52,680 --> 00:07:54,839
比如说我们其实是个真实的例子

198
00:07:54,839 --> 00:07:56,120
就是我们产品里面

199
00:07:56,120 --> 00:07:57,519
遇到了一个真实的例子

200
00:07:58,120 --> 00:08:00,000
然后他一个产品说

201
00:08:00,000 --> 00:08:01,560
我去训练一个

202
00:08:01,560 --> 00:08:03,399
我用了比如说imagine.net

203
00:08:03,399 --> 00:08:04,639
这个训练数据集

204
00:08:04,639 --> 00:08:05,519
我们有讲过

205
00:08:05,519 --> 00:08:07,519
去训练我一个图形分类的问题

206
00:08:08,839 --> 00:08:10,319
然后他要去验证它

207
00:08:10,319 --> 00:08:11,079
验证它的话

208
00:08:11,079 --> 00:08:13,879
我说我去找一个新的数据集

209
00:08:14,199 --> 00:08:15,199
我怎么找呢

210
00:08:15,240 --> 00:08:16,519
就imagine.net里面

211
00:08:16,519 --> 00:08:18,800
有很多什么猫狗什么东西

212
00:08:19,079 --> 00:08:20,879
然后这个人怎么想

213
00:08:21,000 --> 00:08:21,599
这个人就是说

214
00:08:21,599 --> 00:08:23,639
我就会去google去搜猫狗

215
00:08:23,759 --> 00:08:25,039
把这个东西给搜出来

216
00:08:25,079 --> 00:08:27,000
就我搜label那个词

217
00:08:27,039 --> 00:08:28,240
去google图片里面

218
00:08:28,240 --> 00:08:30,800
把图片抓下来放进去

219
00:08:31,159 --> 00:08:33,759
然后作为它的验证数据集

220
00:08:34,279 --> 00:08:36,679
发现这个模型训练出来

221
00:08:36,679 --> 00:08:37,720
结果特别好

222
00:08:37,720 --> 00:08:38,600
然后就上线了

223
00:08:38,600 --> 00:08:38,960
上线

224
00:08:38,960 --> 00:08:40,279
然后被别人看

225
00:08:40,279 --> 00:08:42,040
这个太糟糕了

226
00:08:42,639 --> 00:08:43,279
为什么

227
00:08:44,519 --> 00:08:47,480
是因为imagine.net这个数据集

228
00:08:47,519 --> 00:08:48,680
它的图片

229
00:08:48,720 --> 00:08:49,800
绝大部分

230
00:08:49,879 --> 00:08:51,440
也是从google爬过来的

231
00:08:52,639 --> 00:08:55,800
就是说你再把它所谓的爬数据

232
00:08:55,800 --> 00:08:56,120
对吧

233
00:08:56,120 --> 00:08:57,480
就是把前面截的数据

234
00:08:57,480 --> 00:08:58,600
给你截下来

235
00:08:59,160 --> 00:09:01,440
然后你再把这个词放进google

236
00:09:01,680 --> 00:09:04,639
虽然imagine.net可能是几年前去爬的

237
00:09:04,680 --> 00:09:05,519
但你现在去看

238
00:09:05,519 --> 00:09:07,680
可能图片没有发现它的变化

239
00:09:07,720 --> 00:09:09,759
所以你还是把图片下下来

240
00:09:09,759 --> 00:09:11,040
作为你的验证集

241
00:09:11,160 --> 00:09:12,519
但实际上这个验证集

242
00:09:12,519 --> 00:09:14,519
已经在imagine.net里面出现过了

243
00:09:16,920 --> 00:09:17,399
OK

244
00:09:17,399 --> 00:09:21,360
所以你会发现你的模型可能就虚高了

245
00:09:21,480 --> 00:09:22,480
这是第一个

246
00:09:22,519 --> 00:09:24,200
一个非常隐藏的

247
00:09:24,480 --> 00:09:27,600
但是很严重的一个事情

248
00:09:28,560 --> 00:09:29,680
我再举一个例子

249
00:09:29,800 --> 00:09:32,680
也是我们组的一个同学

250
00:09:32,840 --> 00:09:33,360
这个事情

251
00:09:33,360 --> 00:09:36,160
我后来还把它当做挺严重的事情处理的

252
00:09:36,399 --> 00:09:37,240
就是说

253
00:09:37,559 --> 00:09:39,079
我们写了一篇论文

254
00:09:39,399 --> 00:09:40,399
一篇论文是说

255
00:09:40,399 --> 00:09:44,360
我用一个自动机器学习来调参

256
00:09:45,360 --> 00:09:46,279
然后呢

257
00:09:46,879 --> 00:09:51,360
就是说你在一些流行的NLP的数据上去调参

258
00:09:52,480 --> 00:09:56,199
然后这个同事干了什么事情

259
00:09:56,360 --> 00:09:58,039
就是说他把训练机

260
00:09:58,039 --> 00:09:58,360
对吧

261
00:09:58,360 --> 00:09:59,919
训练机还是训练模型

262
00:10:00,039 --> 00:10:02,120
但是他在测试机上

263
00:10:03,039 --> 00:10:04,679
去调了参数

264
00:10:05,280 --> 00:10:08,680
就是我每一次去拿我的测试机去汇报

265
00:10:08,680 --> 00:10:10,560
去看我的超参数的好坏

266
00:10:10,600 --> 00:10:13,600
然后我用了100块GPU

267
00:10:13,600 --> 00:10:14,960
然后跑了一个星期

268
00:10:15,080 --> 00:10:17,320
试了上千种方案

269
00:10:17,480 --> 00:10:19,240
最后在测试数据上

270
00:10:19,240 --> 00:10:20,520
把最好的调出来

271
00:10:20,560 --> 00:10:21,760
然后报告这个精度

272
00:10:23,720 --> 00:10:24,680
所以当然有什么问题

273
00:10:24,760 --> 00:10:26,960
当然你一看我的精度比别人都高

274
00:10:26,960 --> 00:10:27,960
所以我写一篇论文说

275
00:10:28,080 --> 00:10:29,560
你看我做了一个新算法

276
00:10:29,600 --> 00:10:31,160
我比你的算法都要好

277
00:10:32,720 --> 00:10:33,640
那肯定是不对的

278
00:10:33,640 --> 00:10:34,120
对吧

279
00:10:34,440 --> 00:10:36,720
就是说你在测试数据上

280
00:10:37,560 --> 00:10:39,679
把它和验证数据集混合了

281
00:10:40,279 --> 00:10:42,639
所以这里会引出一个新的概念

282
00:10:42,639 --> 00:10:43,799
叫做测试数据集

283
00:10:43,840 --> 00:10:45,879
就是说test dataset

284
00:10:46,240 --> 00:10:48,360
就是说测试数据集

285
00:10:48,399 --> 00:10:49,480
理论上来说

286
00:10:49,480 --> 00:10:51,120
它只能被使用一次

287
00:10:51,440 --> 00:10:53,560
你不能用它来调你的超参数

288
00:10:54,360 --> 00:10:55,720
举个例子是说

289
00:10:55,759 --> 00:10:57,759
你未来的一次考试是

290
00:10:58,320 --> 00:11:00,240
就是说你就是考试那一次的分数

291
00:11:00,240 --> 00:11:02,639
就决定了你的分数

292
00:11:02,759 --> 00:11:03,879
你不能再去反过去

293
00:11:03,879 --> 00:11:04,919
再去重新考了

294
00:11:05,319 --> 00:11:08,279
或者是说我们做房价预测的时候

295
00:11:08,319 --> 00:11:11,000
我出价的房子的实际成交价

296
00:11:11,000 --> 00:11:12,639
那是我的测试数据集

297
00:11:13,080 --> 00:11:14,879
一旦发生了就无法改变了

298
00:11:15,639 --> 00:11:18,120
还有是说有时候在开国竞赛中

299
00:11:18,159 --> 00:11:21,039
有一些私有的排行榜的数据集

300
00:11:21,319 --> 00:11:24,159
就是说在最后的最后才会公布结果

301
00:11:24,159 --> 00:11:24,960
一旦公布了

302
00:11:24,960 --> 00:11:27,439
然后我们排行榜就固定住了

303
00:11:27,439 --> 00:11:28,480
就大家不会改了

304
00:11:28,480 --> 00:11:34,680
所以是说这里面测试数据集

305
00:11:34,680 --> 00:11:36,840
理论上来说只能被使用一次

306
00:11:36,879 --> 00:11:38,000
你用过之后

307
00:11:38,240 --> 00:11:40,920
应该是说我们就不会再看你

308
00:11:40,920 --> 00:11:41,920
下一次的结果了

309
00:11:43,879 --> 00:11:46,320
所以我们上一次提到这个问题是说

310
00:11:46,360 --> 00:11:50,440
你我这个同学用了我的测试数据集

311
00:11:50,480 --> 00:11:52,560
把它作为验证数据集使用

312
00:11:53,399 --> 00:11:56,320
这个是常犯的另外一个错误

313
00:11:57,320 --> 00:12:00,280
当然在我们在接下来的情况中

314
00:12:00,440 --> 00:12:04,960
我们其实并没有真正意义上的测试数据集

315
00:12:05,120 --> 00:12:06,840
所以很多时候我们在代码里面

316
00:12:06,840 --> 00:12:08,360
想这是一个test data

317
00:12:08,360 --> 00:12:10,600
很多时候它就是一个验证数据集

318
00:12:10,600 --> 00:12:12,160
就是一个validation data set

319
00:12:12,240 --> 00:12:13,560
它不是真正的测试

320
00:12:13,640 --> 00:12:16,080
就是说真正的测试是一个新的数据集

321
00:12:16,120 --> 00:12:18,040
甚至你都不知道标号的数据集

322
00:12:18,520 --> 00:12:21,240
但是我们在这里讲清这两个概念

323
00:12:21,280 --> 00:12:22,720
但是以后我们写代码的时候

324
00:12:22,720 --> 00:12:24,600
有时候为了偷懒就叫test data

325
00:12:24,640 --> 00:12:26,000
或者大家也经常偷懒

326
00:12:26,000 --> 00:12:26,919
就要test data

327
00:12:26,960 --> 00:12:28,200
其实你要意识到

328
00:12:28,240 --> 00:12:30,159
其实这个只是一个验证数据集

329
00:12:30,320 --> 00:12:33,200
验证数据集很有可能也是一个虚高的

330
00:12:33,360 --> 00:12:34,720
因为你的超参数

331
00:12:34,759 --> 00:12:37,480
很有可能是在验证数据集上调出来的

332
00:12:37,679 --> 00:12:40,440
所以导致说验证数据集的精度

333
00:12:40,480 --> 00:12:41,879
不是真正的代表

334
00:12:41,879 --> 00:12:43,879
你在新数据上的繁华能力

335
00:12:44,679 --> 00:12:45,120
OK

336
00:12:46,600 --> 00:12:48,440
然后我们这里提到是说

337
00:12:48,559 --> 00:12:50,320
我们在一个训练数据集上

338
00:12:50,320 --> 00:12:53,759
可以拿出50%的数据作为训练

339
00:12:53,759 --> 00:12:55,799
然后剩下的50%做验证

340
00:12:56,080 --> 00:12:58,120
但是这里会有一个问题是什么呢

341
00:12:58,320 --> 00:12:59,679
我们经常遇到的一个问题

342
00:12:59,679 --> 00:13:01,879
是说我们没有那么多的训练数据

343
00:13:02,440 --> 00:13:04,879
比如说回到最早的银行贷款的问题

344
00:13:04,919 --> 00:13:06,519
我就有100个

345
00:13:07,399 --> 00:13:09,360
100个申请人信息

346
00:13:09,720 --> 00:13:11,639
如果我就拿50个人做验证的话

347
00:13:11,639 --> 00:13:12,879
你会觉得很划不来

348
00:13:13,799 --> 00:13:14,320
对吧

349
00:13:14,360 --> 00:13:16,279
那一半的数据就去做验证集了

350
00:13:16,559 --> 00:13:18,000
所以在实际情况下

351
00:13:18,000 --> 00:13:20,840
确实我们经常是没有足够多的数据

352
00:13:20,840 --> 00:13:21,600
可以使用

353
00:13:22,080 --> 00:13:25,039
如果你直接拿一半的数据集做验证

354
00:13:25,039 --> 00:13:27,199
不参与训练模型的话

355
00:13:27,240 --> 00:13:28,599
其实你会觉得比较亏

356
00:13:29,199 --> 00:13:30,639
所以解决这个问题

357
00:13:30,639 --> 00:13:31,759
常见的一个做法

358
00:13:31,759 --> 00:13:35,439
是一个叫k折交叉验证的一个算法

359
00:13:37,079 --> 00:13:39,319
这个算法其实也是比较简单

360
00:13:40,480 --> 00:13:41,319
就是说

361
00:13:42,559 --> 00:13:44,879
我们拿到一个训练数据集后

362
00:13:44,879 --> 00:13:46,839
我们可以先把它随机打散一下

363
00:13:47,639 --> 00:13:49,759
然后我们把它分割成k块

364
00:13:50,120 --> 00:13:52,120
就所谓的k折就是这一个k

365
00:13:53,159 --> 00:13:55,000
我们把它分成k块之后

366
00:13:55,240 --> 00:13:57,639
然后我们做k次这样子的计算

367
00:13:57,959 --> 00:14:01,120
每一次我们将第k块数据集

368
00:14:01,599 --> 00:14:02,879
作为验证数据集

369
00:14:04,079 --> 00:14:05,679
其余的作为训练数据集

370
00:14:06,759 --> 00:14:08,079
我可以给大家画一下

371
00:14:08,839 --> 00:14:09,639
就是说

372
00:14:10,679 --> 00:14:12,120
比如说我有一个

373
00:14:12,159 --> 00:14:14,199
这是我的所谓的数据集的话

374
00:14:15,120 --> 00:14:16,439
然后我把它画成

375
00:14:16,439 --> 00:14:19,439
比如说我要做三则交叉验证

376
00:14:19,879 --> 00:14:21,039
就画成三项

377
00:14:21,719 --> 00:14:23,159
然后我第一次的话

378
00:14:23,879 --> 00:14:24,719
那么就是说

379
00:14:24,719 --> 00:14:27,879
我把第一块作为validation dataset

380
00:14:28,360 --> 00:14:30,159
然后这一块做成train

381
00:14:31,639 --> 00:14:32,000
对吧

382
00:14:32,000 --> 00:14:33,079
这两块做成train

383
00:14:33,719 --> 00:14:36,319
我在后面两块上训练我的模型

384
00:14:36,679 --> 00:14:38,199
在我的第一块数据集上

385
00:14:38,240 --> 00:14:39,719
进行验证一下我的进度

386
00:14:40,399 --> 00:14:41,959
然后在第二次的话

387
00:14:42,199 --> 00:14:44,120
那么我把这一块作为我的

388
00:14:44,519 --> 00:14:46,559
validation数据集

389
00:14:46,759 --> 00:14:49,000
然后这一块作为我的训练数据集

390
00:14:49,839 --> 00:14:51,879
这一块也可以作为我的训练数据集

391
00:14:52,879 --> 00:14:53,759
我还可以做一次

392
00:14:53,759 --> 00:14:54,559
第三次的话

393
00:14:54,559 --> 00:14:56,200
那就是说我写到下面一点点

394
00:14:57,159 --> 00:14:59,279
我在最后一块作为一个

395
00:15:00,000 --> 00:15:00,799
最后一块

396
00:15:01,720 --> 00:15:04,039
最后一块作为我的验证数据集

397
00:15:04,080 --> 00:15:05,799
前面两块作为训练

398
00:15:10,399 --> 00:15:10,919
这样的话

399
00:15:10,919 --> 00:15:12,720
我们会拿到三个测试

400
00:15:13,600 --> 00:15:15,759
验证的进度或验证的误差

401
00:15:16,200 --> 00:15:18,279
我们把这三个进度做平均

402
00:15:18,839 --> 00:15:22,120
就得到了我们的k则交叉验证的误差

403
00:15:24,159 --> 00:15:25,000
所以常用来说

404
00:15:25,000 --> 00:15:26,879
我们取k等于5或者10

405
00:15:28,679 --> 00:15:30,679
当然这个好处是说你会发现

406
00:15:30,879 --> 00:15:32,679
我们至少用了

407
00:15:32,679 --> 00:15:33,839
如果是三则的话

408
00:15:33,839 --> 00:15:36,079
我们用了66%的数据作为训练

409
00:15:39,199 --> 00:15:41,120
然后但是我因为我的

410
00:15:41,559 --> 00:15:43,319
validation会变小的话

411
00:15:43,319 --> 00:15:44,879
可能会存在一点误差

412
00:15:44,919 --> 00:15:45,720
那么这个误差

413
00:15:45,720 --> 00:15:49,000
我会是通过来做三次来弥补

414
00:15:51,160 --> 00:15:52,560
一个极端的情况下

415
00:15:52,560 --> 00:15:54,519
是说我做一个

416
00:15:54,519 --> 00:15:56,920
假设我的数据长度是n的话

417
00:15:57,200 --> 00:15:59,080
我做一个n则交叉验证

418
00:16:00,279 --> 00:16:01,879
每一次我留一个样本

419
00:16:01,879 --> 00:16:05,320
作为我的验证数据集

420
00:16:05,320 --> 00:16:07,000
剩下的所有作为训练

421
00:16:08,320 --> 00:16:09,639
最后我重复n次

422
00:16:09,639 --> 00:16:10,800
然后取平均

423
00:16:11,160 --> 00:16:12,519
那么这一个极端的算法

424
00:16:12,519 --> 00:16:14,840
是说我能够尽可能的

425
00:16:14,840 --> 00:16:16,920
尽大的使用我的数据集

426
00:16:16,920 --> 00:16:18,800
作为我的训练数据集

427
00:16:19,759 --> 00:16:20,960
但它的代价是说

428
00:16:20,960 --> 00:16:22,560
你算起来特别贵

429
00:16:23,320 --> 00:16:24,399
假设你是1万的话

430
00:16:24,399 --> 00:16:26,399
你得跑1万次

431
00:16:28,080 --> 00:16:29,160
所以常见来说

432
00:16:29,160 --> 00:16:30,879
我们一般取5或者10

433
00:16:31,000 --> 00:16:32,440
5的意思是说

434
00:16:32,440 --> 00:16:35,000
我其实是做了5次训练

435
00:16:35,080 --> 00:16:36,720
等于说我要跑5遍数据

436
00:16:37,600 --> 00:16:39,040
当然如果你的数据很大的话

437
00:16:39,040 --> 00:16:41,440
你可能取k等于2或者3

438
00:16:41,480 --> 00:16:42,160
小一点

439
00:16:42,160 --> 00:16:43,400
如果你的数据很小的话

440
00:16:43,399 --> 00:16:45,360
你可以去10或者更高都可以

441
00:16:46,039 --> 00:16:48,039
所以是说k是一个

442
00:16:48,879 --> 00:16:50,480
你要权衡一个

443
00:16:50,519 --> 00:16:53,600
你要用多少数据来作为训练

444
00:16:53,639 --> 00:16:56,199
以及你能承受多少次

445
00:16:56,199 --> 00:16:58,399
多少倍的训练的代价

446
00:16:59,279 --> 00:16:59,519
好

447
00:16:59,559 --> 00:17:01,759
这就是k轴交叉验证

448
00:17:01,799 --> 00:17:04,039
也是我们最常见的一个算法

449
00:17:04,039 --> 00:17:05,720
来使用超参数的

450
00:17:07,759 --> 00:17:08,680
我们总结一下

451
00:17:09,799 --> 00:17:12,639
所以我们这里有提出了三个概念

452
00:17:13,400 --> 00:17:15,600
第一个概念是一个训练数据机

453
00:17:16,080 --> 00:17:17,080
我们训练数据机

454
00:17:17,080 --> 00:17:19,160
是用来训练我们的模型参数了

455
00:17:19,800 --> 00:17:22,040
第二个数据机不参加训练

456
00:17:22,360 --> 00:17:23,600
它是一个额外的数据机

457
00:17:23,640 --> 00:17:26,360
我们是用来选择模型的超参数

458
00:17:27,920 --> 00:17:29,519
对于非的大数据机上

459
00:17:29,519 --> 00:17:31,040
我们通常会采用一个

460
00:17:31,040 --> 00:17:33,240
叫做k轴交叉验证的一个算法

461
00:17:33,759 --> 00:17:35,160
是每分成k份

462
00:17:35,480 --> 00:17:36,240
做k次

463
00:17:36,280 --> 00:17:37,600
每次留一份做验证

464
00:17:37,640 --> 00:17:39,519
剩下的作为我们的训练机

465
00:17:40,039 --> 00:17:43,559
来通过k轴的平均的误差

466
00:17:43,559 --> 00:17:45,480
来判断我一个超参数的好坏

467
00:17:46,200 --> 00:17:47,759
所以实际情况就是说

468
00:17:47,799 --> 00:17:49,119
我给你一个数据机

469
00:17:49,160 --> 00:17:51,519
我大概有10种不同的超参数

470
00:17:52,480 --> 00:17:53,839
比如说所谓的一种

471
00:17:53,839 --> 00:17:56,200
就是不同的隐藏大小

472
00:17:56,240 --> 00:17:57,160
不同的学习率

473
00:17:57,200 --> 00:17:58,879
不同的什么别的东西

474
00:17:59,160 --> 00:18:02,240
然后我采用5轴交叉验证

475
00:18:02,279 --> 00:18:03,480
对每一个超参数

476
00:18:03,559 --> 00:18:07,160
都会得到一个交叉验证的平均精度

477
00:18:07,360 --> 00:18:09,680
然后我们把最好的精度选出来

478
00:18:09,720 --> 00:18:12,759
作为我们的要采用的超参数

479
00:18:12,840 --> 00:18:14,600
这也是我们常见的一个做法

480
00:18:15,240 --> 00:18:15,680
OK

481
00:18:15,680 --> 00:18:17,920
这就是第一个概念

482
00:18:18,960 --> 00:18:20,519
我们接下来讲第二个概念

483
00:18:20,519 --> 00:18:22,400
然后我们来统一回答问题

484
00:18:25,400 --> 00:18:27,040
而且我自己觉得

485
00:18:27,080 --> 00:18:29,680
应该我这里应该显示一切正常

486
00:18:29,720 --> 00:18:31,000
应该大家如果卡的话

487
00:18:31,000 --> 00:18:33,880
你就换成流畅

488
00:18:33,880 --> 00:18:35,080
不要换原划

