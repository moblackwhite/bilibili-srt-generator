1
00:00:00,000 --> 00:00:01,880
好 我们来讨论一下问题

2
00:00:01,880 --> 00:00:08,560
很多问题是关于我们的前面的竞赛的

3
00:00:10,080 --> 00:00:11,880
如果要提高泛化性

4
00:00:11,880 --> 00:00:13,839
就有可能要增加数据

5
00:00:13,839 --> 00:00:16,080
调参是不是意思不是最大了

6
00:00:17,440 --> 00:00:18,920
我觉得你问了一个很好的问题

7
00:00:18,920 --> 00:00:23,960
就是说增加数据和调参和泛化性

8
00:00:23,960 --> 00:00:24,960
这三个事情

9
00:00:24,960 --> 00:00:26,560
就是说

10
00:00:27,280 --> 00:00:32,440
首先增加数据很有可能是在什么都不变的情况下

11
00:00:32,440 --> 00:00:36,520
增加数据确实是提高泛化性的

12
00:00:36,520 --> 00:00:38,840
最简单也是最有效的办法

13
00:00:40,480 --> 00:00:41,680
所谓的增加数据

14
00:00:41,680 --> 00:00:43,359
你不是说你差不多的数据

15
00:00:43,359 --> 00:00:44,760
就是说你假设你

16
00:00:45,800 --> 00:00:47,920
你要说做猫狗识别

17
00:00:47,920 --> 00:00:49,760
你就拿一只猫使劲拍使劲拍

18
00:00:49,760 --> 00:00:50,760
其实没有太多用的

19
00:00:51,200 --> 00:00:54,200
你得说这只猫在不同的背景

20
00:00:54,200 --> 00:00:55,000
不同的光照

21
00:00:55,000 --> 00:00:55,800
不同的地方

22
00:00:55,800 --> 00:00:57,720
不同的角度拍一拍有用

23
00:00:57,720 --> 00:00:59,640
还有是你得换一点别的猫来拍

24
00:00:59,640 --> 00:01:02,040
所以数据的质量是很关键的

25
00:01:02,040 --> 00:01:03,160
你不能只看数量

26
00:01:03,160 --> 00:01:04,800
数量就是说

27
00:01:05,000 --> 00:01:07,240
少量的高质量的数据

28
00:01:07,240 --> 00:01:11,719
比很多的低质量数据很有可能是更有用

29
00:01:12,520 --> 00:01:13,439
但反过来讲

30
00:01:13,439 --> 00:01:15,080
你有1000倍

31
00:01:15,080 --> 00:01:17,080
1万倍的低质量数据

32
00:01:17,080 --> 00:01:20,400
很有可能也是比你的就那么一点点的高质量数据有用

33
00:01:21,240 --> 00:01:21,920
OK

34
00:01:22,040 --> 00:01:23,000
所以你就

35
00:01:23,719 --> 00:01:26,159
就是说你低质量数据的高质量数据

36
00:01:26,159 --> 00:01:29,719
是说你可能有个10比1或者100比1的计算和换算

37
00:01:30,680 --> 00:01:33,159
所以就是说当你有很多数据的时候

38
00:01:33,159 --> 00:01:36,079
调参当然就不再是一个最重要的事情

39
00:01:37,280 --> 00:01:40,560
所以我就是说我也是一直让大家不要去过度调参

40
00:01:40,960 --> 00:01:44,599
因为过度调参很有可能只fit到你当前的数据

41
00:01:44,640 --> 00:01:47,400
在实际的业务场景中

42
00:01:47,400 --> 00:01:49,120
你可能会不断的去增加数据

43
00:01:49,519 --> 00:01:51,599
所以就是说你调的还行就行了

44
00:01:53,439 --> 00:01:55,519
但反过来讲你没有数据不能变的话

45
00:01:55,519 --> 00:01:56,480
你打比赛

46
00:01:56,599 --> 00:01:59,359
你去做研究的话

47
00:01:59,359 --> 00:02:00,599
你用公开数据集的话

48
00:02:00,599 --> 00:02:02,280
大家在同一个数据去拼的话

49
00:02:02,280 --> 00:02:03,640
那种调参还是有用的

50
00:02:05,359 --> 00:02:06,000
OK

51
00:02:08,520 --> 00:02:09,599
问题2

52
00:02:10,159 --> 00:02:12,199
我之前用AlexNet的行动实验发现

53
00:02:12,199 --> 00:02:15,560
RestNet18比AlexNet的模型要小很多

54
00:02:16,759 --> 00:02:18,520
好像是运算量要大

55
00:02:18,520 --> 00:02:19,360
这是什么问题

56
00:02:19,360 --> 00:02:21,400
就是说这个问题是说你的AlexNet

57
00:02:21,400 --> 00:02:24,159
存下来比RestNet18存下来这个模型大

58
00:02:24,159 --> 00:02:26,200
但是AlexNet算起来更快

59
00:02:27,080 --> 00:02:28,640
RestNet计算的更大

60
00:02:28,640 --> 00:02:29,680
这是怎么解释

61
00:02:30,719 --> 00:02:32,360
我们上节课有讲这个事情

62
00:02:32,800 --> 00:02:33,719
AlexNet之所以大

63
00:02:33,719 --> 00:02:35,240
Alex纯下来你大概是300兆

64
00:02:35,360 --> 00:02:38,120
我记得RestNet18可能存下来就18兆

65
00:02:38,319 --> 00:02:39,920
我记得RestNet的18

66
00:02:39,920 --> 00:02:42,879
就RestNet的xx就等于你这个18

67
00:02:42,879 --> 00:02:44,120
你就18就等于18兆

68
00:02:44,120 --> 00:02:46,120
你的152就等于152兆

69
00:02:46,120 --> 00:02:47,439
大概是这么换算

70
00:02:48,360 --> 00:02:50,640
就是说基本上你可以认为以它一个

71
00:02:51,280 --> 00:02:53,160
卷积层就是一兆的样子

72
00:02:53,160 --> 00:02:55,080
就是估算可以这么算

73
00:02:56,360 --> 00:02:59,720
所以AlexNet就等于是RestNet的300的样子

74
00:02:59,720 --> 00:03:00,280
对吧

75
00:03:00,840 --> 00:03:02,200
所以为什么AlexNet很大

76
00:03:02,200 --> 00:03:03,520
是因为它的全联阶层

77
00:03:04,680 --> 00:03:08,200
全联阶层后面有大全联阶层很大

78
00:03:08,240 --> 00:03:10,040
而且计算挺快的

79
00:03:10,160 --> 00:03:12,200
卷积层其实是说

80
00:03:13,200 --> 00:03:16,280
卷积层就是说参数更少

81
00:03:16,280 --> 00:03:18,840
但是计算比全联阶层其实要大一些

82
00:03:19,000 --> 00:03:20,200
所以这就是为什么说

83
00:03:20,240 --> 00:03:21,880
而且AlexNet更深

84
00:03:22,120 --> 00:03:22,560
更深

85
00:03:22,560 --> 00:03:25,360
而且它每次stride没有

86
00:03:25,360 --> 00:03:27,240
就是说不复没有变得那么小

87
00:03:27,240 --> 00:03:29,720
所以就是说前面的计算是比较大的

88
00:03:29,720 --> 00:03:33,920
所以为什么RestNet要慢

89
00:03:33,960 --> 00:03:36,160
就是说在深度学习里面

90
00:03:36,200 --> 00:03:39,400
模型大小和你的计算复杂度不是一个

91
00:03:39,400 --> 00:03:41,800
不是不能直接是换算的

92
00:03:42,440 --> 00:03:44,480
除非你就是你们的层都是一样的

93
00:03:44,480 --> 00:03:45,400
我们来换算一下

94
00:03:45,400 --> 00:03:46,880
不然的话就不能直接换算

95
00:03:51,200 --> 00:03:54,720
就是说你说RestNet其实跟GBTT很像

96
00:03:54,720 --> 00:03:56,640
也就是数模型换神经网络

97
00:03:56,840 --> 00:03:58,760
我倒不觉得

98
00:03:58,760 --> 00:04:02,080
就是说当然它也都有一个残差的概念

99
00:04:02,080 --> 00:04:05,520
就是说你每次说用一个简单模型fit了之后

100
00:04:05,520 --> 00:04:10,880
把剩下的去用哪一个再去剩下那些残差

101
00:04:10,880 --> 00:04:12,600
我再用一个更深的模型来fit

102
00:04:12,640 --> 00:04:15,840
但是我觉得他们算这点思想上来说

103
00:04:15,840 --> 00:04:16,879
就是跟

104
00:04:17,360 --> 00:04:18,960
Gradient boosting有点像

105
00:04:19,000 --> 00:04:22,919
但是他们数模型还是金网络

106
00:04:22,919 --> 00:04:24,879
它是两类完全不一样的模型

107
00:04:24,919 --> 00:04:26,839
换算起来不好那么换算

108
00:04:34,759 --> 00:04:36,240
这里有个很好的问题

109
00:04:36,240 --> 00:04:38,199
就是说你我其实没怎么看懂

110
00:04:38,199 --> 00:04:40,000
就是说你的W减等于

111
00:04:40,199 --> 00:04:42,439
Lenny rate乘以W的Grad

112
00:04:42,479 --> 00:04:47,120
但换算成W等于W减去LR乘以

113
00:04:47,439 --> 00:04:49,560
东西T度就会消失

114
00:04:49,600 --> 00:04:51,959
我觉得你是因为

115
00:04:55,000 --> 00:04:57,959
我觉得你是因为你要看一下这句话是干嘛

116
00:04:57,959 --> 00:04:59,920
这句话是说你的W

117
00:04:59,920 --> 00:05:02,439
这个W和这个W就不是一个W

118
00:05:02,439 --> 00:05:08,120
就这个W是一个在他就Python里面

119
00:05:08,120 --> 00:05:09,439
他当然都是一个东西

120
00:05:09,480 --> 00:05:11,120
他其实说预算在干嘛

121
00:05:11,240 --> 00:05:12,360
这个预算是说

122
00:05:12,399 --> 00:05:14,680
我把W减去这个东西

123
00:05:14,680 --> 00:05:18,199
然后把它存在一个新的一个Tensor里面

124
00:05:18,240 --> 00:05:20,439
再把新的Tensor给这个W

125
00:05:21,000 --> 00:05:22,560
让你下一次再算T度的时候

126
00:05:22,560 --> 00:05:24,199
你这个W没有Touch gradient

127
00:05:24,199 --> 00:05:25,000
他怎么算T度

128
00:05:25,000 --> 00:05:25,280
对吧

129
00:05:25,280 --> 00:05:26,759
你得这是一个新的Tensor了

130
00:05:26,759 --> 00:05:27,960
你得有Touch gradient

131
00:05:28,160 --> 00:05:29,240
如果你没Touch的话

132
00:05:29,240 --> 00:05:31,319
那就是你T度等于0了

133
00:05:31,319 --> 00:05:33,199
我觉得应该是这个原因

134
00:05:36,280 --> 00:05:37,240
问题5

135
00:05:37,439 --> 00:05:40,040
训练级的准确率不断增加

136
00:05:40,040 --> 00:05:42,560
但验证级的准确率大幅正当

137
00:05:42,600 --> 00:05:43,959
是过礼盒吗

138
00:05:43,959 --> 00:05:45,240
还是别的原因

139
00:05:45,959 --> 00:05:49,560
听上去是过礼盒

140
00:05:49,839 --> 00:05:50,680
就是说

141
00:05:51,839 --> 00:05:53,040
我们那个数据级

142
00:05:53,160 --> 00:05:54,840
我们特别如果你说我们那个一

143
00:05:54,840 --> 00:05:56,600
数页的数据级是一个很简单数据

144
00:05:56,600 --> 00:05:58,000
你可以去看他的

145
00:05:59,399 --> 00:06:01,800
就是他很容易训练到0的

146
00:06:01,800 --> 00:06:04,120
就是他的误差率或准确度

147
00:06:04,120 --> 00:06:05,959
就训练级的准确度很容易到8%

148
00:06:05,959 --> 00:06:07,519
因为它是一个很简单数据级

149
00:06:07,639 --> 00:06:08,560
它就是一个

150
00:06:08,680 --> 00:06:09,920
它的背景都是灰的

151
00:06:09,920 --> 00:06:11,560
它的背景要么是白要么是灰

152
00:06:11,759 --> 00:06:14,560
墨西叶子叶子就这么一个颜色

153
00:06:15,439 --> 00:06:16,920
所以就是说一个很简单

154
00:06:16,920 --> 00:06:18,360
就是说你可以认为他

155
00:06:18,360 --> 00:06:19,560
他也没有太多纹理

156
00:06:19,560 --> 00:06:21,240
就是说他的形状很简单

157
00:06:21,280 --> 00:06:25,160
所以很容易就被你训练到

158
00:06:25,800 --> 00:06:26,560
100%了

159
00:06:26,560 --> 00:06:27,879
就是训练进度

160
00:06:28,160 --> 00:06:30,680
所以就是说我猜应该是你的

161
00:06:31,560 --> 00:06:32,480
over fitting了

162
00:06:35,519 --> 00:06:36,360
问题6

163
00:06:36,399 --> 00:06:39,079
请问加的层数也是超三数吗

164
00:06:39,079 --> 00:06:39,879
如何去加层

165
00:06:40,120 --> 00:06:42,159
哪些层可以加到哪一些

166
00:06:42,159 --> 00:06:43,199
哪些层数不动

167
00:06:43,199 --> 00:06:44,439
我也不知道怎么改

168
00:06:44,800 --> 00:06:47,159
如加到resnet24

169
00:06:48,079 --> 00:06:50,000
层当然是超三数了

170
00:06:50,000 --> 00:06:51,480
就是说整个模型的架构

171
00:06:51,480 --> 00:06:53,040
就是一个巨大的超三数

172
00:06:55,159 --> 00:06:56,959
我们之前有讲过

173
00:06:57,120 --> 00:07:01,000
大家可以去回去看一下我们的录像

174
00:07:01,000 --> 00:07:02,279
就看一下我们在

175
00:07:03,279 --> 00:07:04,439
我们碰到很多情况

176
00:07:04,439 --> 00:07:05,480
会给大家讲一下

177
00:07:05,480 --> 00:07:07,319
就是说怎么加怎么搞

178
00:07:07,319 --> 00:07:08,279
但是整体来讲

179
00:07:08,280 --> 00:07:10,880
我其实觉得我们在这里无法

180
00:07:12,760 --> 00:07:14,560
就无法一次性给大家讲说

181
00:07:14,560 --> 00:07:15,080
到底怎么样

182
00:07:15,320 --> 00:07:19,520
整个深度学习不就是一个

183
00:07:19,560 --> 00:07:20,360
炼丹

184
00:07:22,240 --> 00:07:24,360
我都不是不算老中医了

185
00:07:24,360 --> 00:07:25,680
就是老中医是

186
00:07:25,680 --> 00:07:27,240
我觉得机器学习是老中医

187
00:07:27,520 --> 00:07:29,920
就深度学习已经到于炼丹的程度了

188
00:07:29,920 --> 00:07:32,160
因为它的复杂度比机器学习要高

189
00:07:32,280 --> 00:07:33,800
就空间要更大

190
00:07:33,800 --> 00:07:37,920
所以我的建议是你尽量不要去改

191
00:07:38,320 --> 00:07:39,520
比如说我们讲rest net的时候

192
00:07:39,520 --> 00:07:40,240
你尽量不要去改

193
00:07:40,240 --> 00:07:41,640
你就是你要么加宽一点

194
00:07:41,640 --> 00:07:44,480
要么就是按照他给的1834

195
00:07:44,480 --> 00:07:45,760
你不要搞到24出来

196
00:07:45,920 --> 00:07:46,800
除非你是专家

197
00:07:46,800 --> 00:07:48,360
不然你搞出来的可能不好

198
00:07:49,120 --> 00:07:50,760
你就加宽一点是又可以的

199
00:07:52,160 --> 00:07:53,680
就加宽加深是可以的

200
00:07:53,760 --> 00:07:56,000
就是说加深你来按照他的来

201
00:07:56,000 --> 00:07:56,840
加宽你还好

202
00:07:56,840 --> 00:07:57,480
加宽你

203
00:07:57,520 --> 00:07:58,920
你可以去看一下我们VGG里面

204
00:07:58,920 --> 00:08:01,080
是怎么样把整个channel数

205
00:08:01,080 --> 00:08:02,640
全部减小一点

206
00:08:03,640 --> 00:08:05,080
问题其实是Euro V4

207
00:08:05,080 --> 00:08:06,480
Euro V4的话

208
00:08:08,760 --> 00:08:09,400
Euro V4

209
00:08:09,400 --> 00:08:11,320
我们会我们不会讲Euro V4

210
00:08:11,480 --> 00:08:12,080
我们会讲一下

211
00:08:12,080 --> 00:08:13,640
Euro在在几周之后

212
00:08:13,640 --> 00:08:14,760
我们现在先不讲了

213
00:08:17,800 --> 00:08:20,600
LLC是显存还是缓存

214
00:08:20,600 --> 00:08:22,000
LLC是缓存

215
00:08:22,000 --> 00:08:23,920
叫做last level cache

216
00:08:24,120 --> 00:08:26,000
它是L1 L2还是L3

217
00:08:26,040 --> 00:08:27,720
假设你有三个cache

218
00:08:27,720 --> 00:08:29,800
的last level cache是L3

219
00:08:30,160 --> 00:08:31,200
假设你有4层的话

220
00:08:31,200 --> 00:08:32,279
他就要L4

221
00:08:32,320 --> 00:08:33,440
就取决你有几层

222
00:08:34,080 --> 00:08:35,680
就是最后一个缓存

223
00:08:35,720 --> 00:08:38,120
就是说你的内存的东西

224
00:08:38,120 --> 00:08:39,720
先堵到你的last level

225
00:08:39,720 --> 00:08:41,120
last level一般来说

226
00:08:41,120 --> 00:08:42,280
是一个全局的

227
00:08:42,640 --> 00:08:44,080
所谓的核都是共享

228
00:08:44,320 --> 00:08:45,360
而且是最大的

229
00:08:48,520 --> 00:08:49,800
而且一般来说

230
00:08:49,840 --> 00:08:52,600
如果你能把东西挪到LLC里面

231
00:08:52,600 --> 00:08:54,040
就基本上是一大块了

232
00:08:54,040 --> 00:08:55,360
就是你的瓶颈

233
00:08:55,360 --> 00:08:57,760
通常是在LLC到内存之间

234
00:08:57,800 --> 00:08:59,480
所以很多时候你都不要去管

235
00:08:59,480 --> 00:09:00,080
太多关系

236
00:09:00,080 --> 00:09:01,720
在L1还是L2还是什么

237
00:09:01,720 --> 00:09:04,040
只要你能把东西保存在你的

238
00:09:04,080 --> 00:09:05,200
LLC里面

239
00:09:05,200 --> 00:09:07,400
其实性能可能就差不多了

240
00:09:10,080 --> 00:09:10,280
对

241
00:09:10,280 --> 00:09:12,480
这也是一个就是说调参

242
00:09:12,720 --> 00:09:15,120
调参就是整个架构怎么搞

243
00:09:15,240 --> 00:09:18,240
我们整个课其实就再跟你讲

244
00:09:18,240 --> 00:09:19,840
整个模型是怎么设计的

245
00:09:19,840 --> 00:09:21,480
整个课就是这么做

246
00:09:23,240 --> 00:09:25,280
既然CPU那么不行

247
00:09:25,280 --> 00:09:26,920
为什么现在的不把GPU

248
00:09:26,920 --> 00:09:28,120
作为出厂设置的核心

249
00:09:30,800 --> 00:09:32,680
就是说你用电脑在干嘛

250
00:09:32,680 --> 00:09:34,440
你又平常你用电脑干嘛

251
00:09:34,480 --> 00:09:35,680
上上网

252
00:09:36,080 --> 00:09:37,480
发发邮件

253
00:09:37,520 --> 00:09:39,040
聊聊天

254
00:09:39,960 --> 00:09:42,560
你有多少时间是在用做深度学习

255
00:09:43,680 --> 00:09:44,600
就是说

256
00:09:45,440 --> 00:09:48,440
绝大部分人用CPU

257
00:09:48,440 --> 00:09:50,120
就是因为做做

258
00:09:51,400 --> 00:09:53,480
干干非计算性的东西

259
00:09:53,640 --> 00:09:54,640
你在多少时间

260
00:09:54,640 --> 00:09:55,520
就是说你

261
00:09:55,760 --> 00:10:01,400
而且就算是GPU的很长一段时间

262
00:10:01,400 --> 00:10:02,840
只是用来做显示用的

263
00:10:02,840 --> 00:10:04,240
就是说跟你做屏幕用的

264
00:10:04,240 --> 00:10:05,759
就是给你显示那些像素

265
00:10:06,000 --> 00:10:07,360
渲染那些东西

266
00:10:07,399 --> 00:10:09,759
然后现在说我们要达到游戏

267
00:10:09,879 --> 00:10:15,320
所以但是我觉得GPU只是在很长一段时间

268
00:10:15,320 --> 00:10:18,279
GPU也就是在整个硬件里面

269
00:10:18,279 --> 00:10:19,240
各种架构

270
00:10:19,240 --> 00:10:21,240
就是说各种专有硬件中的一种

271
00:10:21,360 --> 00:10:22,639
只是说深度学习

272
00:10:22,639 --> 00:10:24,080
把整个对计算的要求

273
00:10:24,080 --> 00:10:25,039
把整个东西拎出来

274
00:10:25,039 --> 00:10:26,159
让大家去关注了

275
00:10:26,480 --> 00:10:29,720
所以你不能用GPU作为默认的设置

276
00:10:29,720 --> 00:10:31,519
因为GPU不能让你上网

277
00:10:31,519 --> 00:10:32,480
你不能上网

278
00:10:32,480 --> 00:10:33,600
你能干嘛

279
00:10:35,240 --> 00:10:39,240
按行程主要怎么改代

280
00:10:39,240 --> 00:10:41,799
就是说你说你按行转按列

281
00:10:42,039 --> 00:10:44,759
就是说你的矩阵

282
00:10:44,759 --> 00:10:46,879
你得就是说这就是一个layout

283
00:10:46,879 --> 00:10:49,399
就是说你的矩阵是怎么存的

284
00:10:49,519 --> 00:10:52,480
这个东西在按行程还是按列存

285
00:10:52,600 --> 00:10:53,919
你是4D的话

286
00:10:53,919 --> 00:10:56,720
你的整个channel是放在前面

287
00:10:56,720 --> 00:10:57,360
就放在后面

288
00:10:57,360 --> 00:10:58,919
就是说整个怎么弄

289
00:11:00,120 --> 00:11:02,320
就是说这个都非常的讲究

290
00:11:02,440 --> 00:11:03,919
像TensorFlow和PyTorch

291
00:11:03,919 --> 00:11:06,199
它就PyTorch和MSNet都一样

292
00:11:06,199 --> 00:11:08,000
就channel放在通道

293
00:11:08,000 --> 00:11:09,879
放在第二个维度

294
00:11:09,879 --> 00:11:11,159
就是第一个维度

295
00:11:11,159 --> 00:11:12,639
你认为是P2大小的话

296
00:11:12,639 --> 00:11:14,599
TensorFlow那个通道是放在最后的

297
00:11:15,079 --> 00:11:17,120
这是因为你不同的做法

298
00:11:17,120 --> 00:11:18,240
它在计算上

299
00:11:18,240 --> 00:11:19,639
它因为内存本体性

300
00:11:19,679 --> 00:11:21,719
所以导致它的计算和不一样

301
00:11:21,839 --> 00:11:24,559
而且特别是在于深度学习框架里面

302
00:11:24,719 --> 00:11:25,599
来了一个

303
00:11:25,599 --> 00:11:27,559
就算你是按照某一个东西存的

304
00:11:27,599 --> 00:11:28,559
我为了计算的话

305
00:11:28,559 --> 00:11:30,000
我会将这个矩阵

306
00:11:30,000 --> 00:11:32,159
再转换成我更好的形式

307
00:11:33,079 --> 00:11:35,240
就我会把它切块

308
00:11:35,240 --> 00:11:36,480
切成我要的形式

309
00:11:36,959 --> 00:11:39,480
我甚至就是说先转一遍格式

310
00:11:39,480 --> 00:11:40,879
再参加做计算

311
00:11:41,799 --> 00:11:42,399
OK

312
00:11:45,719 --> 00:11:47,159
问题12

313
00:11:47,360 --> 00:11:49,120
有文章预测未来的设备

314
00:11:49,120 --> 00:11:49,799
都会专业化

315
00:11:49,799 --> 00:11:51,120
也不是在同样的计算机上

316
00:11:51,159 --> 00:11:52,879
比如说医疗专用计算设备

317
00:11:52,879 --> 00:11:54,000
物理专业计算设备

318
00:11:54,279 --> 00:11:55,279
这件事怎么看

319
00:11:55,519 --> 00:11:56,639
这个就是三国了

320
00:11:56,639 --> 00:11:58,639
就是分久必合 合久必分

321
00:11:58,799 --> 00:12:01,559
我们也有讲过

322
00:12:01,559 --> 00:12:02,480
NerdNet也有讲过

323
00:12:02,480 --> 00:12:03,240
NerdNet当年

324
00:12:03,799 --> 00:12:06,199
我们现在看起来特别快的一个东西

325
00:12:06,240 --> 00:12:08,439
当年也是要用硬件做的

326
00:12:08,439 --> 00:12:09,919
就杨冷坤在很多时候

327
00:12:09,919 --> 00:12:12,120
杨冷坤曾经去搞过硬件

328
00:12:12,360 --> 00:12:14,039
就搞过他的Seek

329
00:12:14,159 --> 00:12:17,319
所以他说杨冷坤的一般的观点

330
00:12:17,319 --> 00:12:18,439
是说你们现在搞的东西

331
00:12:18,439 --> 00:12:19,960
都是我们20年前搞的

332
00:12:19,960 --> 00:12:21,199
早就搞过了

333
00:12:21,279 --> 00:12:22,480
什么TPU什么东西

334
00:12:22,480 --> 00:12:23,639
我们早就搞过了

335
00:12:23,840 --> 00:12:25,360
那是因为当年

336
00:12:26,240 --> 00:12:30,240
就当年你的计算发展

337
00:12:30,240 --> 00:12:31,480
比硬件发展要快

338
00:12:31,480 --> 00:12:33,000
所以就导致说

339
00:12:33,680 --> 00:12:34,759
你得去做AC

340
00:12:34,879 --> 00:12:35,720
就是说你这个认为

341
00:12:35,720 --> 00:12:37,039
可以认为是一个

342
00:12:37,600 --> 00:12:38,919
就计算硬件

343
00:12:39,039 --> 00:12:39,960
就是摩艾定律

344
00:12:39,960 --> 00:12:42,279
就是说你有没有你的深度学习也好

345
00:12:42,279 --> 00:12:43,919
它都算个摩艾定律来的

346
00:12:44,360 --> 00:12:45,759
我觉得immediate GPU

347
00:12:45,759 --> 00:12:48,560
你不是因为深度学习

348
00:12:48,560 --> 00:12:49,480
我就怎么样了

349
00:12:49,560 --> 00:12:50,840
它就是你没有深度学习

350
00:12:50,840 --> 00:12:52,519
它也要这么更新换代的

351
00:12:52,720 --> 00:12:54,720
你想M&D它也不做深度学习

352
00:12:54,720 --> 00:12:56,160
他们一样的要更新换代

353
00:12:56,160 --> 00:12:58,320
因为它游戏也得更新换代

354
00:12:58,480 --> 00:12:59,000
对吧

355
00:12:59,600 --> 00:13:00,600
所以就是说

356
00:13:00,639 --> 00:13:03,360
硬件的规律是一个比较固定的

357
00:13:03,800 --> 00:13:05,320
就每年按照摩艾定律来

358
00:13:05,320 --> 00:13:06,120
每年怎么样

359
00:13:06,120 --> 00:13:08,160
多少个多少个月能翻多少番

360
00:13:08,200 --> 00:13:09,160
都是因为你的硬件

361
00:13:09,160 --> 00:13:10,800
就是你的纳米在往下走

362
00:13:10,840 --> 00:13:12,639
而且硬件每留一次片

363
00:13:12,759 --> 00:13:13,720
就大概要一年

364
00:13:13,720 --> 00:13:15,519
就设计一下设计个新的

365
00:13:15,519 --> 00:13:16,360
到下一个留片

366
00:13:16,360 --> 00:13:17,840
大概就几年的周期

367
00:13:17,840 --> 00:13:20,040
所以每年能留一次片就不错了

368
00:13:20,160 --> 00:13:22,519
当然国内有挖矿机做的比较快

369
00:13:22,519 --> 00:13:24,120
一年可以留三次片

370
00:13:24,279 --> 00:13:25,360
它能叠代三下

371
00:13:25,399 --> 00:13:26,159
那这样来讲

372
00:13:26,159 --> 00:13:27,600
一个硬件一年叠代一次

373
00:13:27,600 --> 00:13:28,799
或者两三年叠代一次

374
00:13:28,799 --> 00:13:29,399
这样正常

375
00:13:29,960 --> 00:13:32,480
所以硬件的发展周期是固定的

376
00:13:33,639 --> 00:13:34,759
就你不会因为说

377
00:13:34,759 --> 00:13:39,320
我今年得说

378
00:13:39,320 --> 00:13:40,679
我要翻10倍或怎么样

379
00:13:40,679 --> 00:13:41,320
不行的

380
00:13:41,399 --> 00:13:43,360
而且说现在大家都在缺芯片

381
00:13:43,480 --> 00:13:44,840
大家都在报道缺芯片

382
00:13:44,840 --> 00:13:46,840
那是因为去年

383
00:13:47,600 --> 00:13:48,879
当疫情缘故了

384
00:13:48,919 --> 00:13:49,799
但更多是说

385
00:13:49,799 --> 00:13:51,159
你去年没有做好plan

386
00:13:51,320 --> 00:13:53,000
就大家觉得疫情来了

387
00:13:53,000 --> 00:13:53,799
大家都要玩了

388
00:13:53,800 --> 00:13:55,400
我就不买不订芯片了

389
00:13:55,480 --> 00:13:57,000
你不订我就不订

390
00:13:57,240 --> 00:13:58,080
我也不订你的材料

391
00:13:58,080 --> 00:14:01,840
我也不给你reserve一些产量

392
00:14:01,880 --> 00:14:03,160
他们你再要订的话

393
00:14:03,160 --> 00:14:06,240
那得要几个月才能够回来

394
00:14:07,600 --> 00:14:09,960
所以为什么搞硬件的人

395
00:14:09,960 --> 00:14:12,520
和搞软件的人的思路是不一样的

396
00:14:12,520 --> 00:14:13,440
还我

397
00:14:13,600 --> 00:14:14,760
就是说搞硬件的人

398
00:14:14,760 --> 00:14:16,080
就是说我有个大天赋

399
00:14:16,080 --> 00:14:17,840
就是说反正生产流税线一样的

400
00:14:18,280 --> 00:14:19,240
就每一个东西

401
00:14:19,240 --> 00:14:20,360
多少星期

402
00:14:20,360 --> 00:14:20,840
多少星期

403
00:14:20,840 --> 00:14:21,680
多少星期排下来

404
00:14:21,680 --> 00:14:23,240
就是一个很成熟的一个东西

405
00:14:24,520 --> 00:14:26,760
这软件也不一样

406
00:14:26,760 --> 00:14:28,480
你说我今天一拍脑袋

407
00:14:28,480 --> 00:14:29,640
我要做一个

408
00:14:29,760 --> 00:14:32,760
不是前阵子有个悟道2.0

409
00:14:32,920 --> 00:14:35,800
就是说我说比GPT-3还贵个10倍

410
00:14:35,800 --> 00:14:37,480
还复杂个10倍

411
00:14:37,600 --> 00:14:38,800
就是我今天一拍脑袋

412
00:14:38,800 --> 00:14:40,520
我把resnet加到1000层

413
00:14:40,880 --> 00:14:41,600
我的数据

414
00:14:41,600 --> 00:14:43,680
我的计算量一下就涨了1000倍了

415
00:14:44,000 --> 00:14:45,480
所以就是计算量

416
00:14:45,480 --> 00:14:46,520
就是说它的发展

417
00:14:46,520 --> 00:14:48,000
它不是一个线性了

418
00:14:48,400 --> 00:14:50,080
它是一个指数级的

419
00:14:50,680 --> 00:14:52,160
物理的计算

420
00:14:52,160 --> 00:14:53,840
计算硬件也是指数级

421
00:14:53,840 --> 00:14:56,960
但是workload的事情

422
00:14:57,440 --> 00:14:59,120
它是取决于你的数据有多大

423
00:14:59,120 --> 00:15:00,000
数据怎么涨

424
00:15:00,000 --> 00:15:01,200
和你的计算量

425
00:15:01,200 --> 00:15:02,639
你的计算模型怎么涨

426
00:15:02,800 --> 00:15:03,520
通常来说

427
00:15:03,520 --> 00:15:04,600
它的一个发展逻辑

428
00:15:04,600 --> 00:15:05,320
是一个东西

429
00:15:05,320 --> 00:15:06,800
如果发现有效

430
00:15:06,840 --> 00:15:08,280
大家会死命的对

431
00:15:08,520 --> 00:15:10,040
就空空空空堆上去

432
00:15:10,400 --> 00:15:12,480
就给大家

433
00:15:13,240 --> 00:15:14,240
给大家演示一下

434
00:15:15,879 --> 00:15:17,200
就假设你的

435
00:15:18,000 --> 00:15:19,360
假设这是你的时间

436
00:15:20,639 --> 00:15:22,759
假设这是你的复杂度的话

437
00:15:23,040 --> 00:15:24,360
那么你反正你的

438
00:15:24,920 --> 00:15:26,200
假设我是去log了

439
00:15:26,200 --> 00:15:27,400
这是去log的话

440
00:15:28,680 --> 00:15:29,520
时间是线性

441
00:15:29,639 --> 00:15:30,920
就是计算量是log的话

442
00:15:30,920 --> 00:15:32,480
你的硬件反正是一个

443
00:15:32,840 --> 00:15:34,200
一个按照more来

444
00:15:34,440 --> 00:15:35,400
more

445
00:15:36,320 --> 00:15:37,040
more

446
00:15:39,520 --> 00:15:40,720
就你快不了

447
00:15:40,720 --> 00:15:41,800
你也不会慢

448
00:15:41,800 --> 00:15:43,879
反正只要我逆线厂商还活着

449
00:15:43,879 --> 00:15:44,879
我就是按照这个来

450
00:15:45,720 --> 00:15:49,000
但是你的

451
00:15:50,000 --> 00:15:51,320
但是你的计算任务

452
00:15:51,440 --> 00:15:52,840
它其实是一个这样子的过程

453
00:15:52,840 --> 00:15:53,559
就挺好玩

454
00:15:53,559 --> 00:15:54,440
它就是一个

455
00:15:54,480 --> 00:15:55,159
它是个

456
00:15:55,240 --> 00:15:57,679
我换一个颜色

457
00:15:59,759 --> 00:16:01,240
它可能是个这样子的过程

458
00:16:03,919 --> 00:16:06,960
就你会在一个短短的周期里面

459
00:16:06,960 --> 00:16:07,679
会框一下

460
00:16:07,679 --> 00:16:10,039
就到一个很大的一个程度

461
00:16:11,360 --> 00:16:12,559
就是说你在这个地方

462
00:16:12,559 --> 00:16:13,559
会出现什么问题

463
00:16:14,200 --> 00:16:14,679
你这个地方

464
00:16:14,679 --> 00:16:15,840
你会发现说

465
00:16:15,879 --> 00:16:16,960
我的一下就任务

466
00:16:16,960 --> 00:16:18,360
会涨到一个很高的地方

467
00:16:18,360 --> 00:16:19,800
你发现你这个硬件不行了

468
00:16:19,800 --> 00:16:20,759
你cp不行了

469
00:16:20,759 --> 00:16:21,240
cp不行

470
00:16:21,240 --> 00:16:22,120
我上GPU

471
00:16:22,360 --> 00:16:23,639
就上专有硬件

472
00:16:24,080 --> 00:16:25,399
GPU还是不行

473
00:16:25,639 --> 00:16:26,840
我上更专有的硬件

474
00:16:26,840 --> 00:16:27,560
我做AC

475
00:16:27,560 --> 00:16:29,159
我做别的东西

476
00:16:29,240 --> 00:16:31,039
就是说我们等会会讲

477
00:16:31,200 --> 00:16:32,759
我们回答完这QA之后

478
00:16:32,759 --> 00:16:34,080
会回来给大家讲说

479
00:16:34,080 --> 00:16:36,360
还有GPU不是不是终点

480
00:16:36,360 --> 00:16:37,759
GPU只是一个一步

481
00:16:38,279 --> 00:16:39,560
CPU到GPU只是一步

482
00:16:39,560 --> 00:16:40,159
后面还有

483
00:16:40,680 --> 00:16:41,639
所以就是说

484
00:16:41,840 --> 00:16:44,000
当你任务一直在涨

485
00:16:44,000 --> 00:16:45,039
涨的可能

486
00:16:45,440 --> 00:16:47,240
比硬件发展快的时候

487
00:16:47,360 --> 00:16:48,720
你只能通过

488
00:16:49,240 --> 00:16:49,960
并行计算

489
00:16:49,960 --> 00:16:51,440
就分布式计算

490
00:16:52,600 --> 00:16:54,360
就是我们也会明天会讲

491
00:16:55,000 --> 00:16:56,240
和更专有的芯片

492
00:16:56,240 --> 00:16:58,440
来提升我们单个卡的效率

493
00:16:59,680 --> 00:17:00,039
对吧

494
00:17:00,039 --> 00:17:01,240
就是说GPU怎么提升

495
00:17:01,240 --> 00:17:03,360
GPU就是说把我的空间

496
00:17:03,360 --> 00:17:04,640
把跟我运算

497
00:17:04,680 --> 00:17:05,319
高性能运算

498
00:17:05,319 --> 00:17:06,440
五官的全部删掉

499
00:17:06,480 --> 00:17:07,559
止观性高性能运算

500
00:17:07,559 --> 00:17:08,359
把所有的芯片

501
00:17:08,359 --> 00:17:09,359
都放在这个上面

502
00:17:09,640 --> 00:17:10,599
但我还有别的芯片

503
00:17:11,039 --> 00:17:11,759
我的别的芯片

504
00:17:11,759 --> 00:17:12,799
也一样都能做

505
00:17:12,920 --> 00:17:14,240
我会说别的芯片

506
00:17:14,240 --> 00:17:15,279
说我的成本

507
00:17:15,279 --> 00:17:16,880
我算量算力跟你一样

508
00:17:16,920 --> 00:17:17,840
但我的成本更低

509
00:17:17,840 --> 00:17:19,120
就TPU是干这个事情的

510
00:17:19,960 --> 00:17:20,840
所以就是说

511
00:17:20,880 --> 00:17:22,440
当你在这个阶段的时候

512
00:17:22,440 --> 00:17:23,800
你会发现你的计算

513
00:17:23,800 --> 00:17:25,080
发展太快了

514
00:17:25,080 --> 00:17:27,560
那就说大家都去做专有芯片

515
00:17:27,600 --> 00:17:30,440
那就是和久必分的阶段

516
00:17:30,920 --> 00:17:32,160
那么接下来这个东西

517
00:17:32,160 --> 00:17:35,280
就任务是不会无穷无尽的发展的

518
00:17:35,440 --> 00:17:36,960
因为你会发现是说

519
00:17:37,000 --> 00:17:38,560
你的数据到一个瓶颈之后

520
00:17:38,560 --> 00:17:39,160
你的

521
00:17:39,280 --> 00:17:40,000
就是说

522
00:17:40,080 --> 00:17:41,720
算法这个东西

523
00:17:41,800 --> 00:17:42,800
它是阶段性的

524
00:17:42,840 --> 00:17:45,120
你发现数据堆到一个层面

525
00:17:45,400 --> 00:17:46,280
就图片

526
00:17:46,440 --> 00:17:47,160
图片

527
00:17:47,200 --> 00:17:48,800
image net 100万

528
00:17:48,800 --> 00:17:49,720
现在1000万

529
00:17:49,720 --> 00:17:51,120
一个亿的图片

530
00:17:51,160 --> 00:17:52,560
大家没有再往下堆

531
00:17:52,560 --> 00:17:54,480
现在就很长一段时间

532
00:17:54,480 --> 00:17:55,360
大家都没有往下堆

533
00:17:55,360 --> 00:17:56,920
因为再多的数据

534
00:17:56,920 --> 00:17:57,720
再复杂的网络

535
00:17:57,720 --> 00:17:59,080
其实大家觉得划不来

536
00:17:59,960 --> 00:18:01,400
所以导致说这一块

537
00:18:01,400 --> 00:18:02,840
其实是涨的没那么快

538
00:18:02,880 --> 00:18:04,480
但是当时是NOP相关的

539
00:18:04,480 --> 00:18:05,400
资源处理相关

540
00:18:05,400 --> 00:18:06,640
还在大量的涨

541
00:18:06,680 --> 00:18:07,120
所以说

542
00:18:07,120 --> 00:18:07,880
但是反过来讲

543
00:18:07,880 --> 00:18:09,520
总是有一个瓶颈期

544
00:18:09,600 --> 00:18:11,680
你看几十年前的Net

545
00:18:12,360 --> 00:18:13,440
后来后面还有涨

546
00:18:13,440 --> 00:18:15,799
但是Net就停掉了

547
00:18:15,840 --> 00:18:17,200
就是说你后面就是

548
00:18:17,200 --> 00:18:18,759
到这个阶段的时候

549
00:18:18,759 --> 00:18:20,120
就比较停了

550
00:18:21,039 --> 00:18:22,320
就发现做不动了

551
00:18:22,759 --> 00:18:23,519
很正常

552
00:18:23,519 --> 00:18:25,039
一个领域做到一个时间

553
00:18:25,080 --> 00:18:25,680
就做不动了

554
00:18:25,680 --> 00:18:26,320
就没人做了

555
00:18:26,320 --> 00:18:27,880
就卷迹深究网络

556
00:18:27,880 --> 00:18:29,279
现在也做的比较少了

557
00:18:29,279 --> 00:18:29,920
所以这话

558
00:18:29,960 --> 00:18:31,840
大家都去做transformer去了

559
00:18:32,559 --> 00:18:33,279
所以

560
00:18:33,799 --> 00:18:35,640
一旦进入这个时候

561
00:18:35,720 --> 00:18:37,400
你GPU也好

562
00:18:37,400 --> 00:18:38,000
CPU的话

563
00:18:38,000 --> 00:18:39,519
它其实慢慢的赶上了

564
00:18:40,640 --> 00:18:42,039
等到过了这个点

565
00:18:42,440 --> 00:18:43,759
一个任何一个东西

566
00:18:43,759 --> 00:18:45,480
如果通用芯片能做的话

567
00:18:45,480 --> 00:18:46,799
大家就不会去做

568
00:18:46,839 --> 00:18:47,920
转由芯片了

569
00:18:48,359 --> 00:18:49,279
如果过了这个点

570
00:18:49,279 --> 00:18:50,839
如果这个是CPU的话

571
00:18:50,879 --> 00:18:52,319
CPU如果再过个

572
00:18:52,319 --> 00:18:53,680
你们如果深度学习说

573
00:18:53,680 --> 00:18:54,639
我们今年就

574
00:18:54,839 --> 00:18:55,879
就基本上就要到

575
00:18:55,879 --> 00:18:56,319
得一点了

576
00:18:56,319 --> 00:18:57,639
后面就慢慢的

577
00:18:57,680 --> 00:18:59,399
涨到涨线性上的话

578
00:18:59,440 --> 00:19:01,639
那么你的硬件在过10年之后

579
00:19:01,839 --> 00:19:03,720
我通用硬件也不错了

580
00:19:04,079 --> 00:19:05,519
我CPU也能跑了

581
00:19:06,399 --> 00:19:07,240
就是说

582
00:19:07,279 --> 00:19:08,759
一旦通用东西能做的话

583
00:19:08,759 --> 00:19:09,720
大家都去做通用

584
00:19:09,720 --> 00:19:11,399
所以当年Nolet做的

585
00:19:11,480 --> 00:19:12,440
一堆东西都没得用

586
00:19:12,440 --> 00:19:14,080
这次还是用英特尔架构

587
00:19:14,080 --> 00:19:14,480
对吧

588
00:19:14,480 --> 00:19:15,480
在过去很多年里面

589
00:19:15,480 --> 00:19:15,920
你再讲过

590
00:19:15,920 --> 00:19:17,800
直到最近五六年前

591
00:19:18,040 --> 00:19:19,560
七八年前说

592
00:19:19,560 --> 00:19:20,800
英特尔做深度学不行

593
00:19:20,800 --> 00:19:21,519
才用GPU

594
00:19:21,759 --> 00:19:23,320
不然以前超算

595
00:19:23,360 --> 00:19:24,519
不都是CPU吗

596
00:19:25,320 --> 00:19:26,720
就超算中心里面都是CPU

597
00:19:26,720 --> 00:19:27,840
云上面都是CPU

598
00:19:27,880 --> 00:19:29,080
GPU也没什么东西

599
00:19:29,240 --> 00:19:30,519
所以就是说

600
00:19:31,040 --> 00:19:32,120
一旦你的

601
00:19:32,759 --> 00:19:34,280
这一块深度学

602
00:19:34,280 --> 00:19:35,280
假设我们以后面

603
00:19:35,280 --> 00:19:36,519
就不会那么大的话

604
00:19:36,519 --> 00:19:37,240
那就是

605
00:19:37,400 --> 00:19:38,240
过了很多年之后

606
00:19:38,240 --> 00:19:40,040
会被硬件超上去

607
00:19:41,039 --> 00:19:43,119
所以分久必合

608
00:19:43,119 --> 00:19:44,359
这是我的观点

609
00:19:45,039 --> 00:19:48,279
就你看到从30年代到现在

610
00:19:48,279 --> 00:19:49,319
或60年代到现在

611
00:19:49,319 --> 00:19:50,759
其实这个

612
00:19:51,119 --> 00:19:53,680
就是workload driving和硬件

613
00:19:53,680 --> 00:19:55,519
它就是一个螺旋状的一个关系

614
00:19:56,159 --> 00:19:56,680
OK

615
00:20:02,480 --> 00:20:04,639
C++有OMP Python

616
00:20:04,639 --> 00:20:05,680
也有Multiprocessing

617
00:20:05,680 --> 00:20:06,759
Python Multiprocessing

618
00:20:06,759 --> 00:20:07,480
请做听

619
00:20:07,519 --> 00:20:09,440
找到它其实是一个多进程

620
00:20:09,480 --> 00:20:11,799
就是说它不能做很小单元东西

621
00:20:12,080 --> 00:20:13,960
但是说Python你可以用Number

622
00:20:13,960 --> 00:20:15,840
就是相对来说可以

623
00:20:16,400 --> 00:20:17,240
就是

624
00:20:18,559 --> 00:20:19,680
NUM

625
00:20:20,320 --> 00:20:21,000
也就是说

626
00:20:21,000 --> 00:20:22,440
你如果真的要在Python里面

627
00:20:22,440 --> 00:20:23,080
做进行的话

628
00:20:23,080 --> 00:20:24,480
你有比如TBM也能干

629
00:20:24,480 --> 00:20:24,840
对吧

630
00:20:24,840 --> 00:20:25,600
Number也能干

631
00:20:25,600 --> 00:20:28,200
或者我就不给大家细讲了

632
00:20:30,559 --> 00:20:33,200
Multiprocess会把计算分到各个核上

633
00:20:33,559 --> 00:20:34,920
Multiprocess

634
00:20:36,759 --> 00:20:38,519
就是说分到哪个核

635
00:20:38,519 --> 00:20:40,720
是操作系统和硬件给你调度了

636
00:20:40,720 --> 00:20:41,920
就是说你

637
00:20:42,839 --> 00:20:43,799
其实

638
00:20:44,319 --> 00:20:46,039
就取决于你是怎么调度的

639
00:20:46,200 --> 00:20:47,000
就是说你

640
00:20:48,000 --> 00:20:51,240
就我有4个线程或4个进程

641
00:20:51,839 --> 00:20:53,440
要怎么样分配到核上

642
00:20:53,440 --> 00:20:54,559
是不是我决定了

643
00:20:54,559 --> 00:20:55,920
是操作系统决定了

644
00:20:55,920 --> 00:20:59,599
但你几乎认为它会把你均匀的分到每个核上

645
00:21:02,799 --> 00:21:05,480
问题是做计算是把Followup的运算

646
00:21:05,480 --> 00:21:06,519
尽量的通过项链化

647
00:21:06,519 --> 00:21:08,039
就是说你尽量不要写Followup

648
00:21:08,559 --> 00:21:10,680
就尽量能够用矩阵化

649
00:21:10,680 --> 00:21:11,799
用向量做的

650
00:21:11,799 --> 00:21:14,039
就是说尽量用你的Tensor能够做的

651
00:21:14,039 --> 00:21:14,920
就尽量Tensor做

652
00:21:14,920 --> 00:21:15,799
不要写Followup

653
00:21:15,799 --> 00:21:16,960
实在写Followup的话

654
00:21:16,960 --> 00:21:18,879
你得不能用Python写

655
00:21:18,879 --> 00:21:20,519
你得用C++写行

656
00:21:20,519 --> 00:21:23,279
或者用Python比较low level一点的Python写

657
00:21:26,920 --> 00:21:30,480
可视化是需要把CPU之间做切换

658
00:21:30,480 --> 00:21:32,519
如何不要频繁做传输去

659
00:21:32,519 --> 00:21:33,599
这样错误在哪里

660
00:21:36,359 --> 00:21:37,319
就是说

661
00:21:39,079 --> 00:21:42,279
这是一个挺好的问题

662
00:21:42,279 --> 00:21:46,200
就是说你Eventually是要最后的最后

663
00:21:46,200 --> 00:21:48,039
你总是把数据得挪到CPU来

664
00:21:48,039 --> 00:21:49,519
就是说我要打印我的结果

665
00:21:49,519 --> 00:21:50,720
所谓打印print

666
00:21:51,720 --> 00:21:52,920
打一下我的预测结果

667
00:21:52,920 --> 00:21:55,119
我肯定得打到CPU来

668
00:21:55,119 --> 00:21:55,519
对吧

669
00:21:56,559 --> 00:21:59,279
所以如果你就是最后的最后打印下

670
00:21:59,279 --> 00:22:00,400
其实问题不大的

671
00:22:00,480 --> 00:22:02,200
就也带宽也有几十个GB了

672
00:22:02,200 --> 00:22:04,440
这比你网上下数据快多了

673
00:22:04,440 --> 00:22:05,000
对吧

674
00:22:05,319 --> 00:22:06,519
所以就是说你不要频繁

675
00:22:06,519 --> 00:22:08,799
就是说你不要算一个就转一下

676
00:22:08,799 --> 00:22:09,480
算一个转一下

677
00:22:09,480 --> 00:22:10,200
这是不行的

678
00:22:10,440 --> 00:22:12,079
但是你算完一个forward backward

679
00:22:12,079 --> 00:22:12,359
pass

680
00:22:12,359 --> 00:22:14,000
然后转到CPU没关系

681
00:22:14,039 --> 00:22:17,519
而且你像其实很多时候你是会

682
00:22:17,519 --> 00:22:18,519
你打印loss

683
00:22:18,519 --> 00:22:20,599
就是说你在每一个batch打一个

684
00:22:20,639 --> 00:22:22,879
把损失值打出来

685
00:22:22,879 --> 00:22:24,480
其实你是把它传到CPU

686
00:22:24,519 --> 00:22:25,639
但你就是传了一个值

687
00:22:26,039 --> 00:22:27,720
也就一秒钟传个几下

688
00:22:27,759 --> 00:22:28,480
那没关系

689
00:22:28,480 --> 00:22:29,839
你不是说一秒钟

690
00:22:29,839 --> 00:22:31,720
你不要传个一个GB就没事

691
00:22:31,879 --> 00:22:33,920
一秒钟不要传个几百次也没事

692
00:22:34,840 --> 00:22:36,400
就是说这个是说一般

693
00:22:36,400 --> 00:22:38,120
可是画什么东西是没关系的

694
00:22:38,320 --> 00:22:39,840
他贷款必须也不会很慢

695
00:22:40,279 --> 00:22:41,720
另外一个说你怎么debug

696
00:22:42,160 --> 00:22:43,960
你记得我们之前有讲过

697
00:22:44,080 --> 00:22:45,240
之前讲过说

698
00:22:45,279 --> 00:22:46,279
如果

699
00:22:48,880 --> 00:22:51,920
如果一个tensor在一个GPU上

700
00:22:51,920 --> 00:22:53,640
另外一个tensor在一个CPU上

701
00:22:53,640 --> 00:22:55,120
直接做印算会报错

702
00:22:55,320 --> 00:22:57,920
就深度学习框架就这么设计了

703
00:22:58,600 --> 00:23:01,800
让你说真的在两个不同的device

704
00:23:01,800 --> 00:23:03,840
做东西的时候会报错

705
00:23:04,720 --> 00:23:05,840
所以就是说

706
00:23:06,039 --> 00:23:07,080
你得去

707
00:23:07,120 --> 00:23:08,440
你通常来说

708
00:23:08,440 --> 00:23:10,200
你不会看到一些很隐性的

709
00:23:10,200 --> 00:23:11,560
说我要挪过来挪过去

710
00:23:12,200 --> 00:23:13,279
就他不会

711
00:23:13,440 --> 00:23:15,600
框架一般不会去隐视的

712
00:23:15,600 --> 00:23:17,080
说偷偷摸摸把你挪来挪去

713
00:23:17,080 --> 00:23:18,640
这个是一般不会做

714
00:23:18,640 --> 00:23:20,240
所以你知道你的代码没有说

715
00:23:20,240 --> 00:23:20,880
copy过来

716
00:23:20,880 --> 00:23:22,720
copy过去就问题不大

717
00:23:23,360 --> 00:23:24,480
当然是说

718
00:23:24,720 --> 00:23:26,240
这个我不决定不绝对

719
00:23:26,360 --> 00:23:27,840
当年Pytorch也好

720
00:23:27,840 --> 00:23:28,840
我M7也好

721
00:23:28,840 --> 00:23:29,640
Tensorflow也好

722
00:23:29,680 --> 00:23:31,640
在早期的时候

723
00:23:31,640 --> 00:23:32,560
有很多operator

724
00:23:32,559 --> 00:23:34,319
是没有实现GPU版本

725
00:23:34,319 --> 00:23:35,440
只有个CPU版本

726
00:23:35,480 --> 00:23:37,559
所以他就默默的偷偷的

727
00:23:37,599 --> 00:23:40,240
把你这个东西copy到CPU做印算

728
00:23:41,079 --> 00:23:42,639
另外像这些AC

729
00:23:42,679 --> 00:23:43,960
我们等会讲AC

730
00:23:44,000 --> 00:23:47,039
AC可其实很多时候你这种TPU也好

731
00:23:47,480 --> 00:23:49,200
他很多OP的不支持

732
00:23:49,559 --> 00:23:51,359
不支持他有两种做法

733
00:23:51,399 --> 00:23:52,440
一种是告诉你说

734
00:23:52,919 --> 00:23:54,399
error不支持

735
00:23:54,440 --> 00:23:55,559
你自己来

736
00:23:55,960 --> 00:23:57,279
自己把它挪过去

737
00:23:57,480 --> 00:23:59,559
而另外有一些做法

738
00:23:59,559 --> 00:24:01,079
是说他就偷偷摸摸的

739
00:24:01,079 --> 00:24:02,720
把你放到CPU做印算

740
00:24:02,720 --> 00:24:03,679
然后再偷回来

741
00:24:04,439 --> 00:24:05,119
就是说

742
00:24:06,319 --> 00:24:08,399
就是说你通常但是你

743
00:24:08,399 --> 00:24:09,559
既然他改这么做

744
00:24:09,679 --> 00:24:12,159
就是说你就觉得他肯定做的比较好了

745
00:24:12,159 --> 00:24:14,359
就是说假设他已经做的比较好了

746
00:24:14,519 --> 00:24:16,679
但所以你大部分情况下

747
00:24:16,679 --> 00:24:18,000
你只要去看说

748
00:24:18,039 --> 00:24:19,559
一只要没报错

749
00:24:19,599 --> 00:24:20,720
第二你去看一下你的代码

750
00:24:20,720 --> 00:24:22,599
没有说写了一个逻辑

751
00:24:22,599 --> 00:24:24,319
说copy到某个地方去

752
00:24:24,319 --> 00:24:26,399
一般来说是不会有太多这个问题

753
00:24:31,599 --> 00:24:32,679
问题是7

754
00:24:32,720 --> 00:24:34,159
go怎么样

755
00:24:34,199 --> 00:24:36,639
未来有可能用于高性能CPU

756
00:24:36,759 --> 00:24:39,399
go大家其实不用于做高性能的东西

757
00:24:39,839 --> 00:24:41,559
高性能现在比如说

758
00:24:42,599 --> 00:24:44,480
Julia也好

759
00:24:44,480 --> 00:24:45,439
Swift也好

760
00:24:45,439 --> 00:24:47,119
就go其实是用来做

761
00:24:47,199 --> 00:24:48,439
go是一个

762
00:24:48,759 --> 00:24:50,319
异步做的很好的一个框架

763
00:24:50,319 --> 00:24:53,279
就是说他的那些分布式系统做的很好

764
00:24:53,319 --> 00:24:55,119
就是说整个写网易很方便

765
00:24:55,119 --> 00:24:56,839
就整个异步那一块

766
00:24:56,839 --> 00:24:58,919
就并行那一块做的比较好

767
00:24:59,039 --> 00:24:59,759
就是说

768
00:24:59,960 --> 00:25:01,960
他的并行的分布式系统

769
00:25:01,960 --> 00:25:04,080
和我们这里的是不一样的

770
00:25:04,840 --> 00:25:06,160
就是说从学术上来讲

771
00:25:06,160 --> 00:25:07,840
那个叫distributed system

772
00:25:09,120 --> 00:25:10,640
就分布式系统

773
00:25:10,640 --> 00:25:11,960
其实很多时候是讲说

774
00:25:11,960 --> 00:25:13,000
我要做一个

775
00:25:13,560 --> 00:25:14,120
怎么说呢

776
00:25:14,120 --> 00:25:15,080
分布系统

777
00:25:17,279 --> 00:25:18,880
我要做一个网页加个服务器

778
00:25:18,960 --> 00:25:20,240
或者做一个数据库

779
00:25:20,240 --> 00:25:22,080
都不太数据库也算

780
00:25:22,200 --> 00:25:23,240
就是说或者我要说

781
00:25:23,240 --> 00:25:24,200
我要host一个网页

782
00:25:24,200 --> 00:25:25,480
我要host比如说

783
00:25:26,120 --> 00:25:27,240
我们的视频流

784
00:25:27,240 --> 00:25:28,880
我怎么样用一百台机器来host

785
00:25:28,920 --> 00:25:31,039
整个东西传过来传过去

786
00:25:31,039 --> 00:25:32,440
或做一个网页服务器

787
00:25:32,440 --> 00:25:34,240
就分布式那一块做多一点

788
00:25:34,240 --> 00:25:35,359
或分布式文件系统

789
00:25:36,640 --> 00:25:38,200
我们这里说的分布式

790
00:25:38,599 --> 00:25:39,799
是一个很局限性的

791
00:25:39,799 --> 00:25:41,799
其实更多的是HPC

792
00:25:41,920 --> 00:25:43,319
high performance computing

793
00:25:43,559 --> 00:25:45,240
就特别做这种

794
00:25:45,920 --> 00:25:46,960
稠密的计算

795
00:25:46,960 --> 00:25:48,759
就计算密集性的分布式

796
00:25:49,039 --> 00:25:50,960
所以go的分布式系统

797
00:25:50,960 --> 00:25:52,400
其实更多是那些

798
00:25:52,400 --> 00:25:54,720
真的就是整个你说

799
00:25:55,120 --> 00:25:56,799
这种网页服务器

800
00:25:56,960 --> 00:25:58,919
或者服务器那种做法

801
00:25:59,240 --> 00:26:01,079
我们这里是高性能计算

802
00:26:01,079 --> 00:26:02,119
还是不那么一样

803
00:26:02,119 --> 00:26:03,639
所以go我觉得

804
00:26:03,919 --> 00:26:05,240
不那么适合做高性能

805
00:26:08,240 --> 00:26:09,240
RUST

806
00:26:12,240 --> 00:26:13,599
RUST这个事情

807
00:26:13,839 --> 00:26:14,559
就像RUST

808
00:26:14,559 --> 00:26:16,759
他的他厉害的是说

809
00:26:16,759 --> 00:26:18,319
他的安全性做的比较好

810
00:26:18,440 --> 00:26:19,839
就是说各种吸垢什么

811
00:26:19,839 --> 00:26:22,960
但是对高性能这种东西

812
00:26:23,159 --> 00:26:24,159
不关心这种东西

813
00:26:24,159 --> 00:26:25,480
我们对指针吸垢

814
00:26:25,480 --> 00:26:26,759
这事情不那么关心

815
00:26:27,480 --> 00:26:28,960
因为你开不了这个tensor

816
00:26:28,960 --> 00:26:30,720
你每次开一个非常小心

817
00:26:30,720 --> 00:26:32,119
你不会开一堆东西出来

818
00:26:32,599 --> 00:26:33,759
所以我觉得他的特性

819
00:26:33,759 --> 00:26:35,159
不见得特别有用

820
00:26:36,960 --> 00:26:38,680
FORTUNE

821
00:26:38,680 --> 00:26:40,559
但现在不会有人用FORTUNE

822
00:26:40,559 --> 00:26:42,519
就当年高性能计算

823
00:26:42,519 --> 00:26:43,519
很多是用FORTUNE做的

824
00:26:43,519 --> 00:26:45,000
因为FORTUNE编译器比较好

825
00:26:45,879 --> 00:26:47,519
FORTUNE语法简单

826
00:26:47,519 --> 00:26:48,759
编译器比较好做

827
00:26:48,759 --> 00:26:50,519
所以FORTUNE编译器出来的东西

828
00:26:50,519 --> 00:26:51,519
当年是比较好的

829
00:26:51,519 --> 00:26:54,319
所以很多是用FORTUNE写的

830
00:26:54,359 --> 00:26:56,039
但是现在CHR也不弱了

831
00:26:56,039 --> 00:26:57,319
经过很多年开发之后

832
00:26:57,319 --> 00:26:58,839
CHR编译器也很好了

833
00:26:59,440 --> 00:27:02,279
所以现在FORTUNE几乎用的很少了

834
00:27:06,440 --> 00:27:10,240
问题二是看论文怎么复现论文

835
00:27:10,440 --> 00:27:12,559
其实我们跟我给大家讲

836
00:27:12,559 --> 00:27:14,000
我可能会录一个视频

837
00:27:14,000 --> 00:27:16,119
讲怎么样复现论文

838
00:27:17,639 --> 00:27:18,879
再简单给大家讲一下

839
00:27:18,879 --> 00:27:19,559
就是说

840
00:27:19,799 --> 00:27:22,399
其实说一句真话

841
00:27:22,920 --> 00:27:24,680
一篇论文复现不复现

842
00:27:24,680 --> 00:27:28,440
首先你要复现一篇论文

843
00:27:28,440 --> 00:27:32,920
很多时候你得去理解它的每一句话

844
00:27:33,920 --> 00:27:39,200
就假设作者是比较有水平的作者

845
00:27:39,200 --> 00:27:40,519
他已经把自己的东西

846
00:27:40,519 --> 00:27:43,519
首先80%的论文是不能复现的

847
00:27:43,519 --> 00:27:45,400
首先你要不要要做

848
00:27:45,400 --> 00:27:47,039
就20%论文是可以复现的

849
00:27:47,360 --> 00:27:49,720
所以经典的论文肯定是可以复现的

850
00:27:49,720 --> 00:27:51,080
但是你想有多少经典论文

851
00:27:51,119 --> 00:27:55,119
所以我觉得20%论文是可以复现的

852
00:27:56,240 --> 00:27:58,519
第二你还得假设说

853
00:27:58,519 --> 00:28:00,439
这个作者有把里面的

854
00:28:00,439 --> 00:28:02,319
所有的关键细节有写出来

855
00:28:02,679 --> 00:28:04,319
就你没写出来你怎么知道对吧

856
00:28:05,199 --> 00:28:07,480
所以在两个的前提下

857
00:28:07,679 --> 00:28:08,599
你得去说

858
00:28:08,599 --> 00:28:13,079
我就得看懂里面的每一句话

859
00:28:13,519 --> 00:28:15,519
这理解就是说真的是每一句话

860
00:28:15,519 --> 00:28:16,759
你要知道他在说什么

861
00:28:17,079 --> 00:28:18,319
所以这个是读PAPER

862
00:28:19,319 --> 00:28:21,359
看懂了每一句话之后

863
00:28:21,359 --> 00:28:24,480
你可能去尝试去实现它的细节

864
00:28:24,839 --> 00:28:29,559
但很多时候你不需要搞那么复杂

865
00:28:29,559 --> 00:28:31,480
就是说很多时候你可以

866
00:28:31,960 --> 00:28:33,679
作者可能会放代码

867
00:28:34,000 --> 00:28:35,279
别人可能也会放代码

868
00:28:35,279 --> 00:28:36,399
就是别人会复现的论文

869
00:28:36,399 --> 00:28:38,200
就是很多时候你去研究别人的代码

870
00:28:38,599 --> 00:28:40,599
读多少少代码

871
00:28:40,599 --> 00:28:42,720
其实跟论文读多少有点不一样

872
00:28:42,720 --> 00:28:45,279
就是说你会发现很多复现代码

873
00:28:45,279 --> 00:28:46,279
跟论文是不一样的

874
00:28:46,279 --> 00:28:47,559
就是说一些技术细节不一样

875
00:28:47,559 --> 00:28:49,799
所以你得去看论文

876
00:28:50,319 --> 00:28:51,559
看作者代码

877
00:28:51,559 --> 00:28:53,159
如果有的话看别人的代码

878
00:28:53,599 --> 00:28:54,759
如果别人很多代码的话

879
00:28:54,759 --> 00:28:55,639
你反复去看

880
00:28:55,639 --> 00:28:56,200
看里面的

881
00:28:56,200 --> 00:28:57,000
就是别人代码

882
00:28:57,000 --> 00:28:58,480
你还得看懂每一句话

883
00:28:58,759 --> 00:29:00,399
他们有很多细节是不一样的

884
00:29:00,399 --> 00:29:02,799
然后你去琢磨细节到底是干嘛

885
00:29:03,079 --> 00:29:05,599
你得去体会这个事情

886
00:29:05,799 --> 00:29:09,279
所以复现论文是一个很锻炼的事情

887
00:29:09,319 --> 00:29:12,720
然后我去建议大家可以去做一做

888
00:29:13,079 --> 00:29:14,759
你唯一做的就是一个

889
00:29:14,759 --> 00:29:18,160
你就是去搞懂每一个细节

890
00:29:18,720 --> 00:29:20,960
所以我们这个课

891
00:29:20,960 --> 00:29:22,519
其实没有讲太多细节

892
00:29:22,519 --> 00:29:25,559
我们就是讲主干的东西怎么实现

893
00:29:26,120 --> 00:29:26,640
OK

894
00:29:29,120 --> 00:29:29,759
问题21

895
00:29:29,759 --> 00:29:31,559
我做一个东西想跟别人的算法来比

896
00:29:31,559 --> 00:29:33,279
但是它的原始code是TF写的

897
00:29:33,279 --> 00:29:34,360
我要把它转成PyTorch

898
00:29:34,360 --> 00:29:35,160
是不是

899
00:29:35,440 --> 00:29:37,400
再比较会不会有争议

900
00:29:39,200 --> 00:29:39,960
还好吧

901
00:29:39,960 --> 00:29:42,000
就是说你大家其实觉得

902
00:29:42,519 --> 00:29:44,240
框架没本质区别

903
00:29:44,240 --> 00:29:46,400
我觉得当年还是有的

904
00:29:46,400 --> 00:29:48,119
现在的框架越来越成熟了

905
00:29:48,119 --> 00:29:50,440
就是说TFPyTorch M3或者什么

906
00:29:50,440 --> 00:29:53,240
或者新的JAX或者别的

907
00:29:53,279 --> 00:29:55,640
我觉得做起来都没那么

908
00:29:55,960 --> 00:29:57,200
都我觉得问题不大

909
00:29:57,240 --> 00:29:59,920
就是说你说我把TF的code

910
00:29:59,920 --> 00:30:01,880
port到PyTorch版

911
00:30:02,839 --> 00:30:03,640
其实也没关系

912
00:30:03,640 --> 00:30:05,359
就是说你可以论文说

913
00:30:05,839 --> 00:30:07,599
你说我你可以说一句

914
00:30:07,759 --> 00:30:10,319
所以就是说我是我的比较段

915
00:30:10,319 --> 00:30:11,480
你就给个footnote

916
00:30:11,480 --> 00:30:13,960
说我这个是我自己复现的

917
00:30:14,160 --> 00:30:15,519
我是用的PyTorch复现了

918
00:30:15,519 --> 00:30:16,720
它的原代码在什么地方

919
00:30:16,720 --> 00:30:18,120
就我把它放出来就行了

920
00:30:18,279 --> 00:30:19,680
大家如果觉得你放出来

921
00:30:19,680 --> 00:30:22,480
其实大家其实不那么真的关心

922
00:30:22,480 --> 00:30:24,400
你说一定要用怎么样

923
00:30:24,400 --> 00:30:27,759
就是说如果你的代码只能TF实现

924
00:30:27,759 --> 00:30:28,200
才能跑

925
00:30:28,200 --> 00:30:29,000
别的地方不能跑

926
00:30:29,000 --> 00:30:30,200
那你的代码就有问题

927
00:30:30,200 --> 00:30:31,039
就是你的算法

928
00:30:31,039 --> 00:30:32,759
就是说你的paper就有问题

929
00:30:33,039 --> 00:30:34,480
就一个paper讲一个idea

930
00:30:34,480 --> 00:30:37,240
这个idea不可能是只能在某个框架

931
00:30:37,240 --> 00:30:38,839
实现或者在某一个东西实现

932
00:30:38,920 --> 00:30:40,480
paper讲的东西是一个

933
00:30:41,360 --> 00:30:42,720
是一个更general的idea

934
00:30:42,720 --> 00:30:45,360
就是能脱离掉框架

935
00:30:45,360 --> 00:30:47,599
脱离掉实现能够也是成立的东西

936
00:30:49,720 --> 00:30:50,440
问题22

937
00:30:50,440 --> 00:30:51,680
我们会等会讲TPU

938
00:30:51,680 --> 00:30:53,160
不用急

939
00:30:53,160 --> 00:30:54,839
我们还有时间讲TPU

940
00:30:54,839 --> 00:30:57,480
我们一下时间过那么快

941
00:30:58,079 --> 00:30:59,279
大家问题那么多

942
00:31:01,319 --> 00:31:04,000
PyTorch比PyTorch有优劣是吗

943
00:31:04,160 --> 00:31:08,680
其实我参加过PyTorch的一些很小很小的开发

944
00:31:08,680 --> 00:31:09,799
当年我在百度的时候

945
00:31:10,319 --> 00:31:11,720
但PyTorch其实我不知道

946
00:31:11,720 --> 00:31:14,079
PyTorch是PyTorch的下一个版本

947
00:31:14,399 --> 00:31:16,000
所以我就不懂

948
00:31:16,000 --> 00:31:17,200
我就不给大家说了

949
00:31:17,200 --> 00:31:20,000
问题22

950
00:31:20,000 --> 00:31:23,279
24做笔记本或者云服务

951
00:31:23,279 --> 00:31:24,960
我在B站上有两个视频

952
00:31:25,119 --> 00:31:25,720
大家可以看一下

953
00:31:25,720 --> 00:31:29,079
就是说有一个Windows笔记本和一个G4

954
00:31:29,079 --> 00:31:29,440
的instance

955
00:31:29,440 --> 00:31:30,359
我觉得挺好的

956
00:31:30,799 --> 00:31:32,559
框GAC

957
00:31:32,559 --> 00:31:34,119
框GAC不能转到深度学习

958
00:31:34,119 --> 00:31:34,720
不行了

959
00:31:36,480 --> 00:31:37,440
你有框GAC

960
00:31:37,440 --> 00:31:38,119
那你去玩框

961
00:31:38,200 --> 00:31:39,240
现在来得及

962
00:31:40,799 --> 00:31:43,000
GPD3和GPD3

963
00:31:43,000 --> 00:31:43,960
我们会

964
00:31:44,720 --> 00:31:48,559
GPD3我们会讲

965
00:31:49,599 --> 00:31:50,839
我们不会讲GPD3

966
00:31:50,839 --> 00:31:52,240
但我们会讲Transformer

967
00:31:55,359 --> 00:31:58,639
国内外有比较好讨论硬件架构的技术网站吗

968
00:31:58,639 --> 00:31:59,200
还有吧

969
00:31:59,200 --> 00:32:02,240
就国内国外有挺多网站讨论这一块的

970
00:32:02,240 --> 00:32:04,079
就是说你可以去搜一下

971
00:32:04,079 --> 00:32:07,599
就是说国内有硬件网站还挺多了

972
00:32:07,720 --> 00:32:09,240
我一下就忘了名字

973
00:32:09,240 --> 00:32:10,640
反正我也我去看一下

974
00:32:10,640 --> 00:32:12,120
就是说你可以看一下

975
00:32:12,120 --> 00:32:14,120
TPU都是在哪些网站上被报道

976
00:32:14,120 --> 00:32:14,799
可以去看一下

977
00:32:16,079 --> 00:32:17,960
派多许data loader有哪些常用架构

978
00:32:17,960 --> 00:32:19,000
派多许data loader

979
00:32:19,000 --> 00:32:20,319
就是说你要开多进程

980
00:32:21,839 --> 00:32:23,400
分布式高性能的区别是什么

981
00:32:23,400 --> 00:32:24,359
为什么分布式做的好

982
00:32:24,359 --> 00:32:25,279
高性能不行

983
00:32:26,920 --> 00:32:27,960
没有本质区别

984
00:32:28,079 --> 00:32:29,920
分布式就是说我们所谓的分布式

985
00:32:29,920 --> 00:32:31,279
会考虑很多的容栽

986
00:32:32,200 --> 00:32:33,359
各种就是说一台机器挂了

987
00:32:33,359 --> 00:32:34,120
你要怎么办

988
00:32:34,160 --> 00:32:38,279
各种分布式大块是要考虑容栽容错

989
00:32:38,359 --> 00:32:41,200
就是说一台机器下线了

990
00:32:41,519 --> 00:32:42,240
要怎么办

991
00:32:42,279 --> 00:32:44,720
高性能其实不太考虑容错这个事情

992
00:32:45,160 --> 00:32:47,119
我觉得我理解是本质上这样子

993
00:32:47,119 --> 00:32:49,119
但别的东西倒不太觉得差不多

994
00:32:49,119 --> 00:32:50,200
反正都是优化通讯

995
00:32:50,319 --> 00:32:51,359
就通讯才是瓶颈

996
00:32:54,359 --> 00:32:55,680
分布式优化的是高性能

997
00:32:55,680 --> 00:32:56,519
应该是高并发

998
00:32:56,519 --> 00:32:58,000
分数学系的其实是大数

999
00:32:58,000 --> 00:32:59,799
这样其实也没有

1000
00:32:59,920 --> 00:33:02,960
就是说你大数据并行计算

1001
00:33:02,960 --> 00:33:05,720
其实也卡的是你的通讯

1002
00:33:05,759 --> 00:33:06,759
就是说高并发

1003
00:33:06,759 --> 00:33:07,440
就是说

1004
00:33:10,400 --> 00:33:11,680
我觉得其实

1005
00:33:11,680 --> 00:33:13,519
就我觉得主要是分布式

1006
00:33:13,519 --> 00:33:15,559
在容栽那一块做多一点

1007
00:33:15,559 --> 00:33:17,079
而且整个架构计算

1008
00:33:17,119 --> 00:33:18,279
就是说高性能

1009
00:33:18,279 --> 00:33:20,240
就是说是分布式的一个应用

1010
00:33:20,240 --> 00:33:21,759
分布式还可以考虑到网页

1011
00:33:21,920 --> 00:33:23,720
这种load balance这种东西

1012
00:33:23,759 --> 00:33:25,799
和考虑这种易购架构

1013
00:33:25,920 --> 00:33:26,920
你有不同的CPU

1014
00:33:27,039 --> 00:33:29,359
CPU会下线会变慢这种东西

1015
00:33:29,879 --> 00:33:32,519
HPC他就讲很多时候假设说

1016
00:33:32,519 --> 00:33:34,680
你机器都差不多快

1017
00:33:34,680 --> 00:33:38,200
然后也不会坏掉太多

1018
00:33:38,200 --> 00:33:39,680
所以也不太考虑容错

1019
00:33:39,680 --> 00:33:41,120
我觉得主要是这一块

1020
00:33:41,200 --> 00:33:43,120
而且GPC里面会讨论

1021
00:33:44,120 --> 00:33:45,480
很多时候你可以认为

1022
00:33:45,480 --> 00:33:47,400
他们是差不多一个东西

1023
00:33:50,240 --> 00:33:50,920
问题31

1024
00:33:50,920 --> 00:33:52,759
请问对抗样本是怎么样子

1025
00:33:52,920 --> 00:33:54,799
对抗样本我们先不讲了

1026
00:33:54,880 --> 00:33:56,480
我们今天时间不多了

1027
00:33:58,519 --> 00:33:59,600
好 我们来赶紧

1028
00:34:01,279 --> 00:34:02,279
讲嗨

1029
00:34:02,399 --> 00:34:05,079
讲的一下就讲了只剩10分钟了

1030
00:34:05,839 --> 00:34:06,799
赶紧给大家

1031
00:34:10,159 --> 00:34:11,039
10分钟讲不完

1032
00:34:19,800 --> 00:34:20,599
10分钟讲不完

1033
00:34:20,599 --> 00:34:21,199
我们明天

1034
00:34:21,400 --> 00:34:23,840
就是说我们也要讲个

1035
00:34:23,840 --> 00:34:25,279
我们15页slide

1036
00:34:25,279 --> 00:34:26,840
起码要讲个20分钟

1037
00:34:26,960 --> 00:34:28,119
我觉得10分钟讲不完

1038
00:34:28,119 --> 00:34:29,400
我们今天先到这里

1039
00:34:30,079 --> 00:34:34,280
要不我们今天就先把

1040
00:34:39,280 --> 00:34:40,920
我们今天还剩10分钟

1041
00:34:41,039 --> 00:34:41,840
我们今天

1042
00:34:44,320 --> 00:34:45,160
我们

1043
00:34:47,400 --> 00:34:48,760
把B型讲一下

1044
00:34:50,880 --> 00:34:52,599
大家什么意见

1045
00:34:52,800 --> 00:34:56,280
就是说我们要干脆大家再提点问题

1046
00:34:56,440 --> 00:34:58,480
就是说大家再提几个问题

1047
00:34:58,519 --> 00:35:00,719
然后我们就

1048
00:35:02,480 --> 00:35:03,400
今天就结束了

1049
00:35:03,400 --> 00:35:04,559
因为我讲完

1050
00:35:04,559 --> 00:35:05,280
我当然分不

1051
00:35:05,280 --> 00:35:06,679
我多几批我能讲完

1052
00:35:06,679 --> 00:35:07,199
讲完的话

1053
00:35:07,199 --> 00:35:08,679
但是我的时限又在明天

1054
00:35:08,679 --> 00:35:10,039
大家我怕你忘了

1055
00:35:10,159 --> 00:35:11,199
所以干脆就10分钟

1056
00:35:11,199 --> 00:35:12,559
我们就不拖糖

1057
00:35:12,719 --> 00:35:13,719
我们不拖糖

1058
00:35:16,519 --> 00:35:17,039
32

1059
00:35:17,039 --> 00:35:17,880
这个QA是什么

1060
00:35:17,880 --> 00:35:18,440
脚本写的

1061
00:35:18,440 --> 00:35:19,360
这个不是个脚本

1062
00:35:19,480 --> 00:35:21,400
这个是我们的机智性的同事

1063
00:35:21,400 --> 00:35:23,119
在后台把你的问题

1064
00:35:23,119 --> 00:35:24,360
一步步copy过来的

1065
00:35:24,559 --> 00:35:25,199
这是

1066
00:35:25,320 --> 00:35:26,360
这个是我们的同事

1067
00:35:26,679 --> 00:35:28,360
所以你们这个不是个脚本

1068
00:35:29,480 --> 00:35:30,519
这是我们的同事

1069
00:35:30,519 --> 00:35:31,519
辛苦我们的同事

1070
00:35:34,840 --> 00:35:37,480
也辛苦机器之心的两位同事

1071
00:35:38,480 --> 00:35:41,480
把我们的问题从我们的讨论框挪过来

1072
00:35:42,039 --> 00:35:42,519
这样走

1073
00:35:42,519 --> 00:35:43,800
因为大家以前说

1074
00:35:43,800 --> 00:35:45,639
我们说我如果是对的读的话

1075
00:35:45,639 --> 00:35:48,519
大家觉得说没看到

1076
00:35:48,599 --> 00:35:50,480
就是说放在copy的柜来

1077
00:35:50,480 --> 00:35:51,719
大家就能看到问题

1078
00:35:52,719 --> 00:35:53,920
所以就是说

1079
00:35:54,200 --> 00:35:59,079
就我们干脆就带回来这个问题

1080
00:35:59,079 --> 00:36:01,639
深度学就可以用做测量

1081
00:36:01,639 --> 00:36:02,440
测量吗

1082
00:36:02,440 --> 00:36:03,559
还是传统算法

1083
00:36:03,559 --> 00:36:05,599
多测量一个物体宽度

1084
00:36:06,400 --> 00:36:07,480
测量一个物体宽度

1085
00:36:07,480 --> 00:36:08,639
你需要用深度学习吗

1086
00:36:08,639 --> 00:36:09,320
也许你要

1087
00:36:09,639 --> 00:36:11,639
就是说你可以做深度学

1088
00:36:11,639 --> 00:36:12,400
你可以做3D

1089
00:36:12,639 --> 00:36:14,200
3D是用深度学习

1090
00:36:14,200 --> 00:36:15,800
但是如果你就测量的话

1091
00:36:16,000 --> 00:36:16,880
不太需要

1092
00:36:16,880 --> 00:36:18,760
我觉得测量这个事情

1093
00:36:18,960 --> 00:36:19,760
你换个硬件

1094
00:36:19,840 --> 00:36:21,360
换个景深摄像头就好了

1095
00:36:22,079 --> 00:36:24,760
iPhone不是有一个景深摄像头吗

1096
00:36:24,760 --> 00:36:25,800
据说是这个东西

1097
00:36:25,960 --> 00:36:29,440
然后能用硬件解决就硬件解决

1098
00:36:29,440 --> 00:36:32,360
所以我觉得不太需要深度学习

1099
00:36:33,680 --> 00:36:34,519
34

1100
00:36:34,519 --> 00:36:36,280
Go语言可以做分布式很好

1101
00:36:36,280 --> 00:36:37,480
但为什么高性能不行

1102
00:36:37,480 --> 00:36:39,440
我没有说Go做分布式不行

1103
00:36:39,920 --> 00:36:41,200
Go是可以写的

1104
00:36:41,200 --> 00:36:43,840
但是很少有人用Go来写分布式

1105
00:36:43,840 --> 00:36:44,519
那一块

1106
00:36:44,519 --> 00:36:45,840
我觉得是因为

1107
00:36:45,840 --> 00:36:49,960
一Go这个语言相对来说是比较小众的

1108
00:36:50,159 --> 00:36:52,360
就是说一个语言它其实有一个特性

1109
00:36:52,960 --> 00:36:53,800
它是说

1110
00:36:53,800 --> 00:36:55,079
所以它这个语言的

1111
00:36:55,360 --> 00:36:56,000
Community

1112
00:36:56,000 --> 00:36:56,840
就开发者

1113
00:36:56,920 --> 00:36:57,960
它是有一块的

1114
00:36:57,960 --> 00:36:59,159
就是写Go的都是

1115
00:36:59,159 --> 00:37:00,039
我理解

1116
00:37:00,079 --> 00:37:01,280
写Go的都是做

1117
00:37:02,360 --> 00:37:06,119
比如说网页的服务器

1118
00:37:06,360 --> 00:37:09,039
或者比如说很多时候

1119
00:37:09,079 --> 00:37:10,079
分布式文件系统

1120
00:37:10,199 --> 00:37:11,159
你可以用Go写

1121
00:37:13,280 --> 00:37:17,599
但是Go没有太多人做高性能这一块计算

1122
00:37:17,599 --> 00:37:18,240
高性能计算

1123
00:37:18,280 --> 00:37:21,360
大家其实用C或者C++用的比较多

1124
00:37:21,400 --> 00:37:22,280
传统的来说

1125
00:37:22,720 --> 00:37:23,800
所以就为什么

1126
00:37:23,800 --> 00:37:25,000
我不是说它不行

1127
00:37:25,000 --> 00:37:25,960
存在是这个语言

1128
00:37:25,960 --> 00:37:28,440
它的社区

1129
00:37:28,440 --> 00:37:29,800
它没有关注这一块

1130
00:37:29,800 --> 00:37:32,240
一旦你这社区不关注这一块的话

1131
00:37:32,280 --> 00:37:33,560
就很难做起来

1132
00:37:34,520 --> 00:37:35,280
就是说

1133
00:37:35,320 --> 00:37:36,160
Media

1134
00:37:36,160 --> 00:37:37,440
它也支持OpenCL

1135
00:37:37,440 --> 00:37:38,200
也支持CUDA

1136
00:37:38,200 --> 00:37:39,800
为什么大家都是用CUDA写

1137
00:37:39,800 --> 00:37:40,960
而不是OpenCL写

1138
00:37:41,000 --> 00:37:43,360
这两个语言在本质上没有太多区别

1139
00:37:43,400 --> 00:37:44,680
当然一方面是说

1140
00:37:44,680 --> 00:37:46,280
Media当年是推CUDA

1141
00:37:46,280 --> 00:37:48,120
然后它的编辑做好一点

1142
00:37:48,159 --> 00:37:49,679
所以就慢慢起来了

1143
00:37:49,719 --> 00:37:51,199
但是OpenCL就是说

1144
00:37:51,199 --> 00:37:52,039
现在基本上

1145
00:37:52,039 --> 00:37:53,880
我觉得OpenCL和CUDA的

1146
00:37:53,960 --> 00:37:55,880
你用两个写在Media的编辑器上

1147
00:37:55,880 --> 00:37:56,799
是区别不大的

1148
00:37:56,799 --> 00:37:57,839
但是大家还是用CUDA

1149
00:37:57,839 --> 00:37:59,039
是因为它是有个惯性

1150
00:37:59,400 --> 00:38:00,759
整个社区是有惯性的

1151
00:38:03,319 --> 00:38:06,359
框架调用CPP的API和PyAPI差距多大

1152
00:38:07,799 --> 00:38:12,679
框架在C那一块调C的API

1153
00:38:12,679 --> 00:38:14,519
基本上是没有太多overhead的

1154
00:38:14,559 --> 00:38:16,000
就有点系统级的overhead

1155
00:38:16,159 --> 00:38:18,239
但是你的python那边

1156
00:38:18,239 --> 00:38:19,760
取决于你是怎么写的

1157
00:38:19,800 --> 00:38:21,840
目前我知道写的比较好的

1158
00:38:21,840 --> 00:38:23,239
是numpy写的是比较好的

1159
00:38:23,239 --> 00:38:26,320
它用的是Cython做的

1160
00:38:26,320 --> 00:38:29,760
用的是Cpython的API做的是最好的

1161
00:38:29,760 --> 00:38:31,000
但是也是最难写的

1162
00:38:31,360 --> 00:38:34,480
所以numpy的开销就做的比较好

1163
00:38:34,519 --> 00:38:35,920
而PyTorch做的也还可以

1164
00:38:35,920 --> 00:38:38,000
就是说它用的是

1165
00:38:39,599 --> 00:38:42,760
它用的py还是用的Cython

1166
00:38:42,800 --> 00:38:43,480
我都忘了

1167
00:38:43,840 --> 00:38:44,599
它还行

1168
00:38:44,599 --> 00:38:45,920
我们当时测过还行

1169
00:38:46,639 --> 00:38:48,320
但是还是有挺大的开销的

1170
00:38:48,360 --> 00:38:51,000
所以就是说你发现

1171
00:38:51,039 --> 00:38:52,639
你为什么要用多进程

1172
00:38:52,639 --> 00:38:54,119
很多时候用多进程

1173
00:38:54,159 --> 00:38:57,720
就是说是用来避免python有个全局锁

1174
00:38:58,639 --> 00:39:00,200
就你在运行一个东西的时候

1175
00:39:00,200 --> 00:39:01,119
别的就不能运行了

1176
00:39:01,119 --> 00:39:02,119
就是说它要锁住

1177
00:39:02,119 --> 00:39:03,639
它有一个存在

1178
00:39:03,639 --> 00:39:04,800
就整个python一个进程

1179
00:39:04,800 --> 00:39:05,760
它有一个全局的锁

1180
00:39:05,760 --> 00:39:08,200
锁住说每一次得去拿锁

1181
00:39:08,200 --> 00:39:10,000
所以是一个顺序的东西

1182
00:39:10,039 --> 00:39:11,960
这个东西会给你带来很大的影响

1183
00:39:12,039 --> 00:39:13,720
所以很多事你要做多进程

1184
00:39:14,039 --> 00:39:15,280
你就是把一个任务

1185
00:39:15,280 --> 00:39:17,440
就是说你就可以多进程的时候

1186
00:39:17,440 --> 00:39:20,080
那就是每个你又变成4个线

1187
00:39:20,080 --> 00:39:21,240
在黑同时跑对吧

1188
00:39:21,280 --> 00:39:23,840
可以把你那些调用的开销

1189
00:39:23,840 --> 00:39:25,040
给你弥补掉一些

1190
00:39:28,440 --> 00:39:30,040
Ulo你用DockerNet

1191
00:39:30,040 --> 00:39:31,480
DockerNet不好别人你用

1192
00:39:31,519 --> 00:39:33,360
DockerNet现在多了去了

1193
00:39:33,360 --> 00:39:35,080
你用GurongCV都可以

1194
00:39:35,080 --> 00:39:36,600
GurongCV也有Ulo

1195
00:39:36,760 --> 00:39:38,560
DockerNet那个东西

1196
00:39:38,680 --> 00:39:41,000
大家很少用DockerNet的框架

1197
00:39:41,560 --> 00:39:42,800
那是个C++写的

1198
00:39:42,800 --> 00:39:44,519
也没怎么维护的一个框架

1199
00:39:44,519 --> 00:39:45,360
很少人用

1200
00:39:45,400 --> 00:39:46,880
我觉得Pytorch有DockerNet

1201
00:39:46,880 --> 00:39:48,159
GurongCV也有

1202
00:39:48,159 --> 00:39:48,880
TensorFlow也有

1203
00:39:48,880 --> 00:39:49,880
就是说你不要用

1204
00:39:50,000 --> 00:39:51,239
不一定要用DockerNet

1205
00:39:53,639 --> 00:39:55,559
对国内出的AI芯片

1206
00:39:55,559 --> 00:39:56,920
韩5G平头哥

1207
00:39:56,920 --> 00:39:59,119
还有DP线怎么看

1208
00:40:01,039 --> 00:40:02,759
其实我不是特别清楚

1209
00:40:03,239 --> 00:40:06,119
就是说没有特别多的技术细节

1210
00:40:06,119 --> 00:40:07,360
其实我就很难

1211
00:40:07,400 --> 00:40:08,880
因为目前来说技术细节

1212
00:40:08,880 --> 00:40:10,320
公布的比较多是TPU

1213
00:40:10,320 --> 00:40:11,400
就是说一般来说

1214
00:40:11,400 --> 00:40:12,400
大家不会去

1215
00:40:12,720 --> 00:40:14,840
公布一个芯片的技术细节

1216
00:40:14,840 --> 00:40:15,840
因为这个里面

1217
00:40:16,760 --> 00:40:17,840
跟我们软件不一样

1218
00:40:17,840 --> 00:40:19,119
软件我们都可以开源

1219
00:40:19,880 --> 00:40:20,639
什么都可以讲

1220
00:40:20,639 --> 00:40:23,400
但硬件还是不怎么讲

1221
00:40:23,400 --> 00:40:25,240
所以比如说我知道

1222
00:40:25,240 --> 00:40:28,280
我AWS那些AI芯片的技术细节

1223
00:40:28,280 --> 00:40:29,680
因为我也做这一块

1224
00:40:29,680 --> 00:40:31,400
但我肯定不会出来说

1225
00:40:31,760 --> 00:40:33,599
我出来说我只能说TPU

1226
00:40:33,599 --> 00:40:35,400
因为TPU是因为它已经公开了

1227
00:40:35,400 --> 00:40:36,639
它有论文讲

1228
00:40:36,720 --> 00:40:38,360
韩5G也当然有论文

1229
00:40:38,360 --> 00:40:39,880
平头哥我其实不知道

1230
00:40:39,920 --> 00:40:41,039
也可能有

1231
00:40:41,440 --> 00:40:42,400
但是我觉得

1232
00:40:43,079 --> 00:40:43,800
他很有可能

1233
00:40:43,800 --> 00:40:45,519
他没有公布很多的技术细节

1234
00:40:45,519 --> 00:40:46,880
所以我也没仔细研究过

1235
00:40:47,519 --> 00:40:48,000
所以

1236
00:40:53,119 --> 00:40:54,119
问题38

1237
00:40:54,119 --> 00:40:56,920
做统计加审计网络的算法

1238
00:40:56,920 --> 00:40:58,679
提升模型的五方性可解释性

1239
00:40:58,679 --> 00:40:59,960
这个方向有人做吗

1240
00:41:03,599 --> 00:41:05,159
统计当然有人做了

1241
00:41:05,159 --> 00:41:06,360
统计我们

1242
00:41:06,960 --> 00:41:08,519
我们大半是统计

1243
00:41:11,840 --> 00:41:12,679
大家都觉得

1244
00:41:13,000 --> 00:41:14,480
我们之前有讲过这个观点

1245
00:41:14,480 --> 00:41:17,599
就是说所谓的机器学习

1246
00:41:17,599 --> 00:41:19,199
就是统计的计算机版本

1247
00:41:19,199 --> 00:41:21,400
就统计是数学人把这个东西叫统计

1248
00:41:21,400 --> 00:41:23,320
计算机人把统计叫做机器学习

1249
00:41:24,599 --> 00:41:26,279
所以你的五方性可解释性

1250
00:41:26,880 --> 00:41:28,159
可解释性这个东西

1251
00:41:28,159 --> 00:41:29,719
我觉得这个东西

1252
00:41:29,719 --> 00:41:31,440
我觉得还挺有用的

1253
00:41:31,440 --> 00:41:34,599
就是说我们可能会在之后

1254
00:41:34,599 --> 00:41:37,960
我们这个课没有plan做可解释性

1255
00:41:38,599 --> 00:41:41,119
五方性我们倒也没有

1256
00:41:41,119 --> 00:41:42,679
其实我们也没有plan做五方性

1257
00:41:42,679 --> 00:41:45,519
但我觉得这两个是挺重要的两个概念

1258
00:41:46,920 --> 00:41:50,000
我可能我们再考虑在之后

1259
00:41:50,000 --> 00:41:51,720
会再给大家讲一讲这一块

1260
00:41:55,840 --> 00:41:57,800
矿机厂上做深度学习芯片

1261
00:41:57,800 --> 00:41:58,599
为什么不行

1262
00:41:59,000 --> 00:41:59,840
我没有说不行

1263
00:41:59,920 --> 00:42:02,679
我说矿机的AC可不能做深度学习

1264
00:42:02,679 --> 00:42:05,679
但厂家可以做深度学习

1265
00:42:05,679 --> 00:42:06,199
就是说

1266
00:42:07,200 --> 00:42:10,280
这么说芯片不难

1267
00:42:12,520 --> 00:42:13,680
做芯片真不难

1268
00:42:14,360 --> 00:42:17,680
因为芯片就是说

1269
00:42:19,120 --> 00:42:22,560
你有你一个应届厂商想去做深度学习芯片

1270
00:42:22,560 --> 00:42:24,120
深度学习是一个很简单芯片

1271
00:42:24,120 --> 00:42:25,440
它就是一点时数

1272
00:42:25,440 --> 00:42:26,880
就是一点矩阵运算

1273
00:42:26,880 --> 00:42:27,680
它有什么复杂的

1274
00:42:27,680 --> 00:42:29,720
它比CPU做起来容易多了

1275
00:42:30,200 --> 00:42:32,360
为什么就我们明天会讲TPU

1276
00:42:32,360 --> 00:42:33,280
为什么大家做TPU

1277
00:42:33,280 --> 00:42:34,160
因为TPU简单

1278
00:42:34,880 --> 00:42:35,920
它比GPU还简单

1279
00:42:35,920 --> 00:42:36,920
GPU为什么

1280
00:42:37,320 --> 00:42:38,639
GPU比CPU简单

1281
00:42:38,639 --> 00:42:39,760
TPU比GPU简单

1282
00:42:39,760 --> 00:42:40,680
就架构上来讲

1283
00:42:40,680 --> 00:42:43,720
所以做这个东西

1284
00:42:44,760 --> 00:42:47,000
其实做硬件不是最难的

1285
00:42:47,000 --> 00:42:51,000
最难的是要做别人器做软件和别人用力的

1286
00:42:51,280 --> 00:42:52,639
而Media为什么厉害

1287
00:42:52,639 --> 00:42:54,360
Media是它的CUDA厉害

1288
00:42:54,599 --> 00:42:56,559
它的整个生态厉害

1289
00:42:56,599 --> 00:42:57,800
大家都用CUDA那些

1290
00:42:57,800 --> 00:43:00,079
整个所有的深度学习框架都是基于CUDA

1291
00:43:00,320 --> 00:43:01,639
你绕不过去

1292
00:43:01,880 --> 00:43:05,800
所以就是说等于说你操作系统都绑定住了

1293
00:43:05,920 --> 00:43:08,079
然后你自己做芯片的话

1294
00:43:08,079 --> 00:43:09,680
你最难的是你的生态

1295
00:43:09,680 --> 00:43:11,320
你怎么让别人用你的芯片

1296
00:43:11,320 --> 00:43:12,320
你的开发

1297
00:43:12,680 --> 00:43:14,200
开发门槛很重要

1298
00:43:14,760 --> 00:43:16,480
如果就能自己给自己开发的话

1299
00:43:16,480 --> 00:43:18,240
那就打不赢别人

1300
00:43:18,680 --> 00:43:19,559
所以就是说

1301
00:43:20,000 --> 00:43:21,360
做芯片可以做

1302
00:43:21,400 --> 00:43:22,240
最难是生态

1303
00:43:22,240 --> 00:43:23,920
所以你会发现很多人会去讲生态

1304
00:43:24,079 --> 00:43:27,000
就是说华为不是release一个Android的

1305
00:43:29,000 --> 00:43:29,920
HOMO2.0

1306
00:43:30,440 --> 00:43:32,720
就是说核心都是一个生态的竞争

1307
00:43:32,760 --> 00:43:34,599
就是说开发者你没有生态

1308
00:43:34,599 --> 00:43:36,759
你就没有开发者

1309
00:43:36,759 --> 00:43:38,199
没有开发者就没有用户

1310
00:43:39,319 --> 00:43:41,360
所以除非你自产自销

1311
00:43:41,360 --> 00:43:42,400
比如云计算可以做

1312
00:43:42,480 --> 00:43:43,159
云计算可以做

1313
00:43:43,159 --> 00:43:44,799
是因为我可以自产自销

1314
00:43:45,239 --> 00:43:45,920
Google能做

1315
00:43:45,920 --> 00:43:46,759
因为我有Tensorflow

1316
00:43:46,880 --> 00:43:48,319
我Tensorflow给自己开发

1317
00:43:48,719 --> 00:43:49,960
云的话我也能

1318
00:43:50,000 --> 00:43:51,400
我自己造芯片卖给自己

1319
00:43:51,839 --> 00:43:52,839
但你别人造的话

1320
00:43:52,839 --> 00:43:53,400
你卖给谁

1321
00:43:53,400 --> 00:43:54,239
你来想一下这个问题

1322
00:43:54,239 --> 00:43:55,239
这是个产品问题

1323
00:43:57,119 --> 00:43:58,719
RESNET只能用图像领域吗

1324
00:43:58,719 --> 00:43:59,559
文本可以吗

1325
00:43:59,559 --> 00:44:00,839
文本不行

1326
00:44:00,880 --> 00:44:02,239
RESNET文本不行

1327
00:44:02,239 --> 00:44:04,519
但我们会讲怎么样卷进去做文本

1328
00:44:04,519 --> 00:44:05,360
我们之后会讲

1329
00:44:07,440 --> 00:44:09,079
Julia用于机械解深度学习

1330
00:44:09,440 --> 00:44:11,639
Julia我其实没用过

1331
00:44:11,719 --> 00:44:13,599
Julia我看别人用

1332
00:44:14,239 --> 00:44:17,599
我就他们Julia开发区

1333
00:44:17,599 --> 00:44:18,880
有做很多Julia的包

1334
00:44:20,679 --> 00:44:22,759
我们课程会讲分布式推卸系统

1335
00:44:24,039 --> 00:44:25,159
分布式推卸系统

1336
00:44:25,159 --> 00:44:27,119
我觉得好像国内还是挺火的

1337
00:44:27,119 --> 00:44:29,759
因为国内我觉得是卖货卖的比较多

1338
00:44:29,759 --> 00:44:31,000
就是头条系

1339
00:44:31,320 --> 00:44:32,440
就淘宝系

1340
00:44:32,480 --> 00:44:33,079
频道多

1341
00:44:33,119 --> 00:44:35,800
就是大家带货就推荐比较多

1342
00:44:37,200 --> 00:44:38,800
国内我知道是很多做推荐

1343
00:44:39,159 --> 00:44:40,880
我觉得是美国其实做的不多

1344
00:44:41,320 --> 00:44:42,039
这一块

1345
00:44:42,880 --> 00:44:44,320
所以但我们很可惜

1346
00:44:44,320 --> 00:44:46,200
我们没打算讲

1347
00:44:46,200 --> 00:44:48,480
是因为我们虽然我们这本书有分布系统

1348
00:44:48,559 --> 00:44:49,200
英文版有

1349
00:44:49,639 --> 00:44:51,880
但不是分布系统有推荐系统

1350
00:44:52,159 --> 00:44:57,559
但我觉得质量没有到一本教材的水平

1351
00:44:57,559 --> 00:44:58,960
所以我还在有一种

1352
00:44:58,960 --> 00:45:00,639
就是我们如果要讲的话

1353
00:45:00,639 --> 00:45:03,000
我可能还会把整个再完善

1354
00:45:03,400 --> 00:45:04,199
就写的

1355
00:45:06,199 --> 00:45:08,960
就写的更好一点

1356
00:45:08,960 --> 00:45:09,519
其实我在想

1357
00:45:13,679 --> 00:45:14,799
就底层都C++

1358
00:45:14,799 --> 00:45:17,039
为什么模型在inference还是C++

1359
00:45:17,039 --> 00:45:17,400
那么快

1360
00:45:17,839 --> 00:45:20,000
就是说你前段是python

1361
00:45:20,000 --> 00:45:21,039
下面是C++

1362
00:45:21,039 --> 00:45:23,319
就是说你python掉C++是有overhead的

1363
00:45:23,480 --> 00:45:24,799
但通常来说还好

1364
00:45:24,799 --> 00:45:25,679
没那么快

1365
00:45:25,759 --> 00:45:27,639
就是说一般现在其实你用

1366
00:45:28,559 --> 00:45:30,759
你用C++做inference的时候

1367
00:45:30,879 --> 00:45:32,799
为什么是因为你可以不用python

1368
00:45:32,879 --> 00:45:33,960
你得不用装python

1369
00:45:34,039 --> 00:45:35,440
就主要是这个好处

1370
00:45:35,440 --> 00:45:37,920
但我觉得说一定快还快到没有

1371
00:45:38,759 --> 00:45:39,719
太多区别

1372
00:45:41,239 --> 00:45:41,879
问题44

1373
00:45:41,879 --> 00:45:43,000
为什么是用pytorch

1374
00:45:43,000 --> 00:45:44,079
非msnet

1375
00:45:44,119 --> 00:45:45,839
是因为pytorch更流行吗

1376
00:45:46,279 --> 00:45:46,759
是的

1377
00:45:47,000 --> 00:45:47,719
我觉得是的

1378
00:45:49,599 --> 00:45:52,679
就是说我觉得pytorch更流行

1379
00:45:52,679 --> 00:45:53,599
但实际上来说

1380
00:45:54,879 --> 00:45:55,480
就举个例子

1381
00:45:55,679 --> 00:45:58,159
我们这本书本来是基于msnet写的

1382
00:45:58,480 --> 00:46:00,800
然后我说加个pytorch

1383
00:46:00,800 --> 00:46:04,519
是不是pytorch说你比我们比msnet用户大

1384
00:46:04,519 --> 00:46:05,639
是不是加个pytorch

1385
00:46:05,639 --> 00:46:07,199
说我们的流量会涨个10倍

1386
00:46:08,079 --> 00:46:09,240
而我们就做了

1387
00:46:09,280 --> 00:46:11,159
做完之后还在我们这本书

1388
00:46:11,159 --> 00:46:12,719
还在pytorch的官网上列了

1389
00:46:12,719 --> 00:46:12,960
对吧

1390
00:46:12,960 --> 00:46:15,079
pytorch的org上面有我们这本书link

1391
00:46:15,280 --> 00:46:16,679
但实际上没有涨5倍

1392
00:46:17,199 --> 00:46:19,000
就涨了个不到一倍

1393
00:46:19,000 --> 00:46:20,639
所以这我就很confusing

1394
00:46:20,639 --> 00:46:22,719
我觉得pytorch的用户比msnet大

1395
00:46:23,280 --> 00:46:24,400
我是这么觉得的

1396
00:46:25,079 --> 00:46:26,360
也不是我自黑

1397
00:46:26,559 --> 00:46:28,079
我观察是怎么

1398
00:46:28,079 --> 00:46:29,599
但实际上来说好像

1399
00:46:31,000 --> 00:46:33,039
好像也没有那么多

1400
00:46:33,039 --> 00:46:34,519
我也不知道为什么

1401
00:46:34,519 --> 00:46:34,840
anyway

1402
00:46:34,840 --> 00:46:37,240
我就可能是大家如果是初学者的话

1403
00:46:37,240 --> 00:46:38,280
其实你都无所谓

1404
00:46:38,280 --> 00:46:39,440
用谁都没关系的

1405
00:46:39,440 --> 00:46:40,559
代码我觉得还是说

1406
00:46:40,800 --> 00:46:43,599
框架其实我反正都不懂的情况下

1407
00:46:43,599 --> 00:46:44,480
我用谁都没关系

1408
00:46:44,480 --> 00:46:46,079
但是你学会了一个之后

1409
00:46:46,079 --> 00:46:47,400
可能会一直用那一个

1410
00:46:48,079 --> 00:46:49,360
但我觉得还是

1411
00:46:51,039 --> 00:46:52,119
但我觉得整体来讲

1412
00:46:52,119 --> 00:46:53,639
我觉得pytorch做的比msnet好

1413
00:46:54,239 --> 00:46:55,239
不是

1414
00:46:57,119 --> 00:46:58,039
我也不是怎么样

1415
00:46:58,039 --> 00:46:59,319
我觉得平心而论

1416
00:46:59,679 --> 00:47:00,359
客观上讲

1417
00:47:00,359 --> 00:47:02,559
所以我觉得讲pytorch

1418
00:47:02,559 --> 00:47:04,400
很有可能大家学了之后

1419
00:47:04,400 --> 00:47:07,359
去公司可能要用的pytorch用的多一点

1420
00:47:07,359 --> 00:47:08,759
所以我跟你讲pytorch

1421
00:47:09,639 --> 00:47:10,960
可能对你以后会有用一点

1422
00:47:10,960 --> 00:47:11,839
我觉得是这样子

1423
00:47:14,119 --> 00:47:15,879
Arm Bay Media收购会有影响吗

1424
00:47:15,920 --> 00:47:17,319
我目前看不到

1425
00:47:18,319 --> 00:47:20,480
Rust高性能前景如何

1426
00:47:21,000 --> 00:47:22,839
其实我Rust我觉得

1427
00:47:23,000 --> 00:47:24,039
大家是觉得

1428
00:47:24,039 --> 00:47:25,480
因为是一个更安全的语言

1429
00:47:25,640 --> 00:47:27,000
在高性能我还真不知道

1430
00:47:28,880 --> 00:47:31,240
XVR和BM可以一起用吗

1431
00:47:31,240 --> 00:47:32,120
效果会更好吗

1432
00:47:32,120 --> 00:47:32,640
可以一起用

1433
00:47:33,160 --> 00:47:34,960
XVR和BM是可以一起用的

1434
00:47:37,200 --> 00:47:38,360
好带货了

1435
00:47:39,240 --> 00:47:40,039
带货了

1436
00:47:40,960 --> 00:47:43,320
3080ti和3060ti怎么选

1437
00:47:43,880 --> 00:47:45,960
1万块钱你买不到3080ti

1438
00:47:48,960 --> 00:47:50,039
正常价你都买不到

1439
00:47:50,039 --> 00:47:52,320
现在是现在你都拿不到正常价了

1440
00:47:52,519 --> 00:47:53,680
大家都挖矿去了

1441
00:47:53,680 --> 00:47:57,559
所以我其实也没关心到底多少钱

1442
00:47:57,559 --> 00:47:59,680
我觉得3080ti应该按在美国买

1443
00:47:59,680 --> 00:48:00,600
大概1000刀

1444
00:48:00,600 --> 00:48:02,080
1000刀7000人民币

1445
00:48:02,360 --> 00:48:04,360
所以现在你1000刀肯定买不到

1446
00:48:04,559 --> 00:48:06,440
你估计2000刀就是16000人民币

1447
00:48:06,440 --> 00:48:08,440
至少两三万人民币买一块

1448
00:48:08,920 --> 00:48:10,200
你1万块钱你买不到

1449
00:48:10,200 --> 00:48:11,519
1万块钱其实你都买不到

1450
00:48:11,559 --> 00:48:12,120
我觉得

1451
00:48:13,200 --> 00:48:13,880
不用想了

1452
00:48:14,039 --> 00:48:15,080
可能再过几个月

1453
00:48:17,120 --> 00:48:17,920
问题49

1454
00:48:17,920 --> 00:48:19,120
我看了很多paper

1455
00:48:19,120 --> 00:48:20,680
但是打比赛用简单几层

1456
00:48:20,759 --> 00:48:22,399
没有感觉人生性怎么麻的

1457
00:48:23,759 --> 00:48:24,960
打比赛

1458
00:48:25,119 --> 00:48:28,159
打比赛不是让你去拼模型的

1459
00:48:28,279 --> 00:48:29,440
打比赛是拼很多东西

1460
00:48:29,440 --> 00:48:29,960
就是说

1461
00:48:30,119 --> 00:48:32,519
我觉得打比赛大家打一打就行了

1462
00:48:32,519 --> 00:48:33,679
就要练习练习

1463
00:48:33,679 --> 00:48:35,879
不要觉得打比赛打多了以后能学到什么

1464
00:48:35,879 --> 00:48:36,440
学不到什么

1465
00:48:38,759 --> 00:48:41,039
就参加比赛是一个学习目的

1466
00:48:41,039 --> 00:48:42,039
你要去赢的话

1467
00:48:42,039 --> 00:48:43,480
其实这种东西

1468
00:48:43,879 --> 00:48:45,799
我觉得你有兴趣可以去做

1469
00:48:45,799 --> 00:48:48,159
但是你不要指望打比赛能学到太多

1470
00:48:51,279 --> 00:48:54,039
Google net中inception使用resnet跳转

1471
00:48:54,039 --> 00:48:54,559
是否有意义

1472
00:48:54,559 --> 00:48:54,919
有的

1473
00:48:54,919 --> 00:48:57,639
Google net v3就是用的resnet

1474
00:48:58,319 --> 00:48:59,759
Hugging face做的好

1475
00:48:59,919 --> 00:49:01,679
如果要做平台

1476
00:49:03,319 --> 00:49:04,239
Hugging face

1477
00:49:05,480 --> 00:49:05,759
对

1478
00:49:05,759 --> 00:49:07,639
你就是说你不要觉得hugging face有

1479
00:49:07,639 --> 00:49:09,239
4万个star

1480
00:49:09,239 --> 00:49:11,159
然后卖了就拿了很多融资

1481
00:49:11,159 --> 00:49:12,039
你就觉得可以做

1482
00:49:12,039 --> 00:49:13,440
这东西不是人

1483
00:49:13,440 --> 00:49:14,599
不是每个人都可以做的

1484
00:49:14,599 --> 00:49:15,559
就做生态

1485
00:49:15,559 --> 00:49:17,759
Hugging face是因为它有很多人在用

1486
00:49:17,839 --> 00:49:19,239
就是说你要创业

1487
00:49:21,679 --> 00:49:22,839
怎么说

1488
00:49:22,839 --> 00:49:25,399
Hugging face它的商业化是有

1489
00:49:25,399 --> 00:49:26,599
目前是有问题的

1490
00:49:26,599 --> 00:49:28,960
就是说它没有找到很好的商业化的途径

1491
00:49:29,239 --> 00:49:30,239
但是它流行

1492
00:49:30,440 --> 00:49:31,079
就是说

1493
00:49:31,079 --> 00:49:31,679
但反过来讲

1494
00:49:31,679 --> 00:49:33,519
我觉得你创业不一定说我要做一个

1495
00:49:33,519 --> 00:49:36,719
很流行的一个什么东西

1496
00:49:36,719 --> 00:49:39,039
你像D2L我们不是有我们中文版

1497
00:49:39,039 --> 00:49:40,000
有2万5千个star

1498
00:49:40,000 --> 00:49:41,000
英文版有1万个star

1499
00:49:41,000 --> 00:49:42,799
加起来3万5也不比hugging face低

1500
00:49:42,799 --> 00:49:45,159
但也没看见别人给我们投对吧

1501
00:49:45,239 --> 00:49:47,399
我们b站打赏也就500块钱

1502
00:49:47,440 --> 00:49:48,199
还没有500块钱

1503
00:49:48,480 --> 00:49:49,759
b站打赏200块钱

1504
00:49:50,040 --> 00:49:52,600
所以你不能这么换算

1505
00:49:53,120 --> 00:49:55,160
所以我觉得创业就是创业

1506
00:49:55,160 --> 00:49:56,560
不要hugging face

1507
00:49:56,560 --> 00:49:59,000
就不要觉得去copy

1508
00:50:00,760 --> 00:50:02,920
Spark比map reduce用的多

1509
00:50:02,960 --> 00:50:03,280
对

1510
00:50:03,280 --> 00:50:05,080
Spark比map reduce用的多

1511
00:50:05,080 --> 00:50:07,040
是因为Hadoop

1512
00:50:07,040 --> 00:50:07,600
就Hadoop

1513
00:50:07,600 --> 00:50:10,480
Hadoop就是说Spark在设计上比Hadoop

1514
00:50:10,480 --> 00:50:12,640
觉得memory那一块会好一点点

1515
00:50:12,680 --> 00:50:14,600
确实公司推的比较好

1516
00:50:15,680 --> 00:50:18,240
所以现在用Spark比Hadoop比较多

1517
00:50:19,240 --> 00:50:20,680
自动驾驶是烧钱

1518
00:50:20,680 --> 00:50:21,400
很难看多的

1519
00:50:24,800 --> 00:50:26,400
我不看好NAS

1520
00:50:26,400 --> 00:50:29,800
就我不看好NAS和

1521
00:50:29,800 --> 00:50:31,720
我没有说不看好自动驾驶

1522
00:50:31,720 --> 00:50:32,880
自动驾驶烧钱

1523
00:50:32,880 --> 00:50:35,240
但是自动驾驶有非常大的商业目的

1524
00:50:35,240 --> 00:50:37,200
但NAS这个事情

1525
00:50:37,200 --> 00:50:39,280
NAS就是说我说我写个paper说

1526
00:50:39,280 --> 00:50:40,200
我比人调的好了

1527
00:50:40,200 --> 00:50:41,640
但是你的商业前景是什么

1528
00:50:41,840 --> 00:50:43,440
就是说烧钱

1529
00:50:43,440 --> 00:50:44,200
你烧多少钱

1530
00:50:44,200 --> 00:50:46,360
是看你有多大的商业前景

1531
00:50:46,640 --> 00:50:48,240
自动驾驶我觉得特别有意义

1532
00:50:48,240 --> 00:50:49,599
就不用开车了

1533
00:50:49,599 --> 00:50:50,200
多好

1534
00:50:50,200 --> 00:50:51,760
NAS你调的比我调的好

1535
00:50:51,760 --> 00:50:52,280
有什么用

1536
00:50:53,680 --> 00:50:55,120
对你写个NAS说

1537
00:50:55,120 --> 00:50:56,680
比我的上面paper打赢我了

1538
00:50:56,680 --> 00:50:57,160
有什么用

1539
00:50:57,160 --> 00:50:57,800
就是说

1540
00:50:57,800 --> 00:50:59,400
所以你要看你的商业价值

1541
00:51:01,559 --> 00:51:04,120
用ResNet在大图像做物体检测

1542
00:51:04,120 --> 00:51:05,760
是要把切块还是怎么样

1543
00:51:05,760 --> 00:51:07,000
我们会在

1544
00:51:07,160 --> 00:51:08,640
我们会讲物体检测

1545
00:51:08,640 --> 00:51:10,680
而你在大图片做

1546
00:51:10,680 --> 00:51:11,680
你可以切块

1547
00:51:11,680 --> 00:51:13,160
可以切块是没关系

1548
00:51:13,160 --> 00:51:14,360
切块你一般是什么

1549
00:51:14,360 --> 00:51:15,400
切1.24 1.24

1550
00:51:15,599 --> 00:51:16,240
就是说

1551
00:51:17,160 --> 00:51:18,920
但是你可以去看一下

1552
00:51:18,920 --> 00:51:20,280
这专门有一块叫做

1553
00:51:20,280 --> 00:51:21,680
high resolution image

1554
00:51:21,680 --> 00:51:23,720
就是说比如说卫星图片做物体检测

1555
00:51:23,720 --> 00:51:26,559
它是不会用简简单单用个ResNet做的

1556
00:51:26,559 --> 00:51:27,960
那个东西效率太低了

1557
00:51:27,960 --> 00:51:28,519
所以

1558
00:51:30,480 --> 00:51:34,440
所以你要去关注一下

1559
00:51:34,440 --> 00:51:35,680
这一块有专门的东西

1560
00:51:35,880 --> 00:51:38,160
我这里就不暂时展开了

1561
00:51:38,160 --> 00:51:39,599
我们时间来不差不多

1562
00:51:39,599 --> 00:51:40,000
好

1563
00:51:40,000 --> 00:51:40,880
我们今天

1564
00:51:41,720 --> 00:51:43,240
感谢大家的问题

1565
00:51:44,280 --> 00:51:45,280
问了54个问题

1566
00:51:45,280 --> 00:51:45,960
大家挺厉害的

1567
00:51:46,480 --> 00:51:47,760
我们就讲讲硬件

1568
00:51:47,960 --> 00:51:48,560
我们

1569
00:51:48,960 --> 00:51:49,760
反正我还讲

1570
00:51:49,760 --> 00:51:52,080
我本来觉得今天能讲完

1571
00:51:52,080 --> 00:51:52,600
没关系

1572
00:51:52,600 --> 00:51:53,480
就大家

1573
00:51:53,640 --> 00:51:56,240
我们直播直播就是要个氛围

1574
00:51:56,240 --> 00:51:58,000
不然的话我录了传一下就行了

1575
00:51:58,000 --> 00:51:58,240
对吧

1576
00:51:58,240 --> 00:52:00,080
我们直播就是有交互性

1577
00:52:00,080 --> 00:52:02,519
我觉得交互性是我比较喜欢的一个东西

1578
00:52:02,720 --> 00:52:04,000
不然的话我就对着讲

1579
00:52:04,000 --> 00:52:04,440
讲完之后

1580
00:52:04,440 --> 00:52:05,560
大家看比较看一看

1581
00:52:05,560 --> 00:52:06,400
就是没意思

1582
00:52:06,560 --> 00:52:08,120
所以挺好的

1583
00:52:08,280 --> 00:52:09,160
大家问我问题

1584
00:52:09,360 --> 00:52:10,320
所以也跟

1585
00:52:10,440 --> 00:52:12,800
别的同学说声抱歉

1586
00:52:12,960 --> 00:52:13,880
可能你是想说

1587
00:52:13,880 --> 00:52:15,000
我要尽快的学点东西

1588
00:52:15,000 --> 00:52:16,679
结果我们都在先聊去了

1589
00:52:16,840 --> 00:52:17,480
所以

1590
00:52:18,760 --> 00:52:20,440
所以感谢大家耐心

1591
00:52:20,599 --> 00:52:22,639
不要说可能有很多同学

1592
00:52:22,639 --> 00:52:24,199
就我们聊一聊的多

1593
00:52:24,199 --> 00:52:25,800
就说不来直播了

1594
00:52:25,800 --> 00:52:27,639
我就看回放去了

1595
00:52:27,880 --> 00:52:30,440
所以我们确实也会有

1596
00:52:30,440 --> 00:52:31,199
我觉得都行

1597
00:52:31,199 --> 00:52:32,440
就是说如果你觉得我们慢

1598
00:52:32,440 --> 00:52:34,599
就是说可以等到等会我们看回放

1599
00:52:34,639 --> 00:52:35,280
没关系

1600
00:52:35,320 --> 00:52:37,000
如果大家愿意来听我们先聊

1601
00:52:37,000 --> 00:52:38,559
或者愿意聊我们就聊

1602
00:52:39,000 --> 00:52:40,280
这我们都可以行

1603
00:52:40,360 --> 00:52:40,639
行

1604
00:52:40,639 --> 00:52:41,840
我们今天先到这里

1605
00:52:42,639 --> 00:52:43,920
谢谢大家的问题

1606
00:52:43,920 --> 00:52:45,680
我们明天见

1607
00:52:45,680 --> 00:52:46,200
拜拜

