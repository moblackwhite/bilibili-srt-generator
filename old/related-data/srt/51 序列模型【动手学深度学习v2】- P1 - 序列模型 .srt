1
00:00:00,000 --> 00:00:00,880
好

2
00:00:00,880 --> 00:00:03,200
我们这个是第四部分的一开始

3
00:00:03,200 --> 00:00:06,120
就是一个叫做序列模型的东西

4
00:00:06,560 --> 00:00:08,120
就是叫做sequence mode

5
00:00:08,359 --> 00:00:09,400
就整个RNN

6
00:00:09,640 --> 00:00:10,439
整个NLP

7
00:00:10,560 --> 00:00:12,640
就基本上是在处理一个序列

8
00:00:12,720 --> 00:00:15,839
我们之前看到图片是一个空间信息

9
00:00:16,039 --> 00:00:18,480
我们现在考虑一个时间信息的模型

10
00:00:18,600 --> 00:00:20,559
这个跟之前是很不一样的地方

11
00:00:20,839 --> 00:00:21,039
好

12
00:00:21,039 --> 00:00:23,600
我们来先看看这个模型长什么样子

13
00:00:25,000 --> 00:00:27,120
首先说序列数据

14
00:00:27,519 --> 00:00:29,320
就是说现实生活中

15
00:00:29,519 --> 00:00:33,079
其实很多数据是有时序结构的

16
00:00:33,799 --> 00:00:34,359
举个例子

17
00:00:34,359 --> 00:00:35,439
就是说电影的评分

18
00:00:35,560 --> 00:00:36,799
你去看豆瓣的评分

19
00:00:37,159 --> 00:00:38,480
一个电影出来

20
00:00:38,480 --> 00:00:40,880
它的评分它不是一个随机的

21
00:00:40,880 --> 00:00:42,480
就是说它也不是一个固定的

22
00:00:42,600 --> 00:00:43,679
它也不是一个随机的

23
00:00:43,679 --> 00:00:45,280
它是有一个pattern在里面的

24
00:00:46,079 --> 00:00:48,280
你就是说一个东西出来

25
00:00:48,439 --> 00:00:50,359
你看说我说是几点几分

26
00:00:50,359 --> 00:00:52,640
但是你可能随着时间变化会变化

27
00:00:53,000 --> 00:00:53,760
再举这个例子

28
00:00:53,760 --> 00:00:56,679
就是说假设你有个电影拿奖了

29
00:00:57,200 --> 00:00:58,280
然后你的评分

30
00:00:58,679 --> 00:00:59,560
大家就拿奖

31
00:00:59,560 --> 00:01:00,480
那个电影肯定很厉害

32
00:01:00,480 --> 00:01:01,960
就是说大家有鲜艳知识

33
00:01:02,240 --> 00:01:03,280
就不要鲜艳知识

34
00:01:03,399 --> 00:01:05,000
大家会被受影响

35
00:01:05,239 --> 00:01:07,719
觉得你们专业评审出来的东西就是厉害

36
00:01:07,879 --> 00:01:09,680
所以它的评分就是会上升

37
00:01:10,079 --> 00:01:10,960
直到你慢慢的

38
00:01:11,120 --> 00:01:12,159
这个奖项我都不记得

39
00:01:12,159 --> 00:01:13,320
比如说一个电影

40
00:01:13,719 --> 00:01:14,840
你告诉我一个电影

41
00:01:14,840 --> 00:01:16,599
10年前拿过什么奖

42
00:01:16,599 --> 00:01:17,480
我谁记得

43
00:01:17,599 --> 00:01:20,000
就讲是一个新闻效应

44
00:01:20,159 --> 00:01:21,560
可能过几天就不记得了

45
00:01:22,879 --> 00:01:23,799
另外一个是说

46
00:01:23,799 --> 00:01:25,319
假设你同样一个题材

47
00:01:25,520 --> 00:01:27,359
有很多经典电影

48
00:01:28,079 --> 00:01:31,439
下一次同大家再看到同样的题材的话

49
00:01:32,879 --> 00:01:34,319
就是说期望会变高

50
00:01:34,319 --> 00:01:37,359
或者是说你在一个电影出来之后

51
00:01:37,560 --> 00:01:39,400
后续有出了很多好电影

52
00:01:39,400 --> 00:01:40,840
大家看了好电影之后

53
00:01:40,840 --> 00:01:43,120
再来看新原来电影的话

54
00:01:43,120 --> 00:01:44,719
他觉得那些经典电影

55
00:01:44,960 --> 00:01:46,319
就是说你去看30年代

56
00:01:46,319 --> 00:01:47,400
40年代经典电影

57
00:01:47,400 --> 00:01:48,640
你觉得就这么样

58
00:01:48,879 --> 00:01:50,480
60年的70年代是一样的

59
00:01:50,719 --> 00:01:53,439
就是说电影在不断的改进

60
00:01:54,920 --> 00:01:56,439
还有一个是说你有季节性

61
00:01:56,959 --> 00:01:59,560
就是说你如果你是个贺岁片的话

62
00:01:59,679 --> 00:02:01,599
那么你在过年的时候看

63
00:02:01,599 --> 00:02:04,280
可能在平常时候看的感觉是不一样的

64
00:02:04,399 --> 00:02:05,239
就是他的题材

65
00:02:05,400 --> 00:02:06,039
暑期党

66
00:02:06,239 --> 00:02:09,960
就是说暑期党针对的人群也是不一样的

67
00:02:10,639 --> 00:02:11,919
最后一个就是说大家知道

68
00:02:11,919 --> 00:02:15,199
如果你的导演演员干了不好的事情

69
00:02:15,360 --> 00:02:18,079
就经常大家看看新闻说

70
00:02:18,360 --> 00:02:19,400
谁被封了

71
00:02:19,400 --> 00:02:22,360
谁出什么事了

72
00:02:22,360 --> 00:02:23,560
大家吃了西瓜之后

73
00:02:23,560 --> 00:02:24,800
然后被怎么样了

74
00:02:24,800 --> 00:02:25,919
就下线了

75
00:02:25,920 --> 00:02:26,680
人都没了

76
00:02:26,680 --> 00:02:27,360
电影里面

77
00:02:27,360 --> 00:02:29,960
所以会导致评分变得很低

78
00:02:30,160 --> 00:02:35,000
所以电影也是跟着会评分会下降

79
00:02:35,600 --> 00:02:37,920
所以就是说核心思想是说

80
00:02:39,480 --> 00:02:40,880
一个电影出来之后

81
00:02:41,000 --> 00:02:42,840
大家对电影的评价打分

82
00:02:43,040 --> 00:02:44,400
这个事情不是一个

83
00:02:44,400 --> 00:02:46,880
不仅仅是跟电影的质量的好坏

84
00:02:46,920 --> 00:02:48,920
它是跟很多因素相关的

85
00:02:49,280 --> 00:02:50,680
随着时间的变化

86
00:02:50,680 --> 00:02:51,280
这个评分

87
00:02:51,280 --> 00:02:53,120
大家对他的评分也会发生变化

88
00:02:54,120 --> 00:02:56,599
另外一些是说数据序列

89
00:02:56,599 --> 00:03:00,240
是一个非常在现实生活中

90
00:03:01,000 --> 00:03:02,879
特别常见的一种序列

91
00:03:03,120 --> 00:03:04,039
你的音乐

92
00:03:04,680 --> 00:03:05,280
语言

93
00:03:05,719 --> 00:03:06,360
文本

94
00:03:06,680 --> 00:03:07,599
就语言就说话

95
00:03:07,680 --> 00:03:08,120
文本

96
00:03:08,240 --> 00:03:09,879
视频都是一个连续的

97
00:03:10,680 --> 00:03:13,759
就是说你说我写个标题叫狗咬人

98
00:03:13,759 --> 00:03:17,360
也没有说我说一个标题叫人咬狗

99
00:03:17,800 --> 00:03:20,800
三个词我就交换一下人和狗

100
00:03:20,920 --> 00:03:22,400
那么一下就不一样了

101
00:03:22,400 --> 00:03:22,640
对吧

102
00:03:22,760 --> 00:03:23,400
人咬狗

103
00:03:23,400 --> 00:03:24,480
你可以上头条

104
00:03:24,480 --> 00:03:25,240
然后狗咬人

105
00:03:25,240 --> 00:03:26,800
经常咬

106
00:03:28,200 --> 00:03:29,160
另外一个是说

107
00:03:29,160 --> 00:03:31,480
假设一个地方出现了大地震之后

108
00:03:32,040 --> 00:03:33,880
可能会有几次小的地震

109
00:03:35,000 --> 00:03:36,720
所以大地震之后

110
00:03:36,720 --> 00:03:38,040
出现小地震的概率

111
00:03:38,040 --> 00:03:40,320
远远的高于平常会出现小地震

112
00:03:40,880 --> 00:03:42,440
人的交互是连续的

113
00:03:42,640 --> 00:03:44,560
在微博上大家吵一吵架

114
00:03:44,560 --> 00:03:47,400
然后你在评论上面

115
00:03:47,400 --> 00:03:49,640
大家互动一下

116
00:03:49,640 --> 00:03:51,120
也是一个连续的序列

117
00:03:52,120 --> 00:03:53,280
另外一个是说

118
00:03:53,319 --> 00:03:55,560
预测明天的股价

119
00:03:55,879 --> 00:03:57,080
是一件很难的事情

120
00:03:57,920 --> 00:04:00,200
然后因为它是一个

121
00:04:00,200 --> 00:04:02,680
虽然明天股价跟今天有点相关了

122
00:04:02,800 --> 00:04:04,400
但是它有大量的随机性

123
00:04:04,480 --> 00:04:07,759
也是跟明天新发生什么事情相关

124
00:04:08,000 --> 00:04:08,879
反过来讲

125
00:04:08,879 --> 00:04:12,680
假设我知道今天的股价

126
00:04:12,719 --> 00:04:14,719
去预测昨天的股价

127
00:04:14,719 --> 00:04:16,240
就会容易很多

128
00:04:16,399 --> 00:04:20,160
就是说你是去预测中间缺失的部分

129
00:04:20,560 --> 00:04:22,920
远远比预测未来是简单一些

130
00:04:23,840 --> 00:04:24,200
OK

131
00:04:24,200 --> 00:04:26,880
这是序列数据

132
00:04:26,880 --> 00:04:28,400
然后我们看一下

133
00:04:28,400 --> 00:04:30,480
我们对这样子数据怎么建模

134
00:04:32,440 --> 00:04:34,520
就是说假设我们在时间t

135
00:04:34,520 --> 00:04:37,200
观察到了一个数据叫xt

136
00:04:38,520 --> 00:04:41,240
那么假设我们有大t个时间的话

137
00:04:42,000 --> 00:04:44,040
那么我们会得到t个

138
00:04:44,040 --> 00:04:45,879
不独立的随机变量

139
00:04:47,320 --> 00:04:49,000
就我们当然没有讲过随机变量

140
00:04:49,000 --> 00:04:50,519
我假设大家是知道的是

141
00:04:50,519 --> 00:04:51,600
大概是什么意思

142
00:04:52,519 --> 00:04:54,959
就是说我们在之前都是假设

143
00:04:54,959 --> 00:04:56,360
我有t个样本的话

144
00:04:56,360 --> 00:04:59,519
我们这样本都是一个独立的随机变量

145
00:05:00,360 --> 00:05:01,240
就一张图片

146
00:05:01,240 --> 00:05:04,000
上一张图片和下一张图片是没有关系的

147
00:05:04,560 --> 00:05:06,560
都是反正都是我在哪里爬来的

148
00:05:06,560 --> 00:05:07,959
或随机采样过来的

149
00:05:08,839 --> 00:05:09,839
但是这个地方

150
00:05:10,040 --> 00:05:11,759
就是说我们t个数据

151
00:05:11,759 --> 00:05:13,639
是不独立的随机变量

152
00:05:14,800 --> 00:05:17,279
所以这个就是时序序列

153
00:05:17,320 --> 00:05:19,400
跟之前的序列的主要的一个区别

154
00:05:20,080 --> 00:05:22,600
然后假设我们t个数据

155
00:05:22,760 --> 00:05:24,560
我们打算联合分布

156
00:05:24,560 --> 00:05:26,640
继承p大写的

157
00:05:29,040 --> 00:05:30,640
粗体的x的话

158
00:05:32,040 --> 00:05:34,640
我们知道我们其实基本上

159
00:05:34,640 --> 00:05:37,000
我们所有的机械模型

160
00:05:37,000 --> 00:05:39,360
就是去对px建模

161
00:05:40,520 --> 00:05:41,520
对整个数据

162
00:05:41,520 --> 00:05:44,240
我们去看它概率分布什么样子

163
00:05:44,560 --> 00:05:45,720
概率分布对应的是

164
00:05:45,720 --> 00:05:48,200
它背后产生数据的基础

165
00:05:48,400 --> 00:05:50,000
就假设我能知道 px

166
00:05:50,120 --> 00:05:52,320
我就可以无限的产生数据

167
00:05:52,360 --> 00:05:53,680
我能够产生数据的话

168
00:05:53,720 --> 00:05:54,360
当然我知道

169
00:05:54,400 --> 00:05:56,320
你想让数据的任何信息

170
00:05:56,360 --> 00:05:56,800
你是什么

171
00:05:56,840 --> 00:05:57,800
要谁在里面

172
00:05:57,840 --> 00:05:58,760
什么东西我都知道

173
00:05:59,760 --> 00:06:01,960
所以就是说px是我们追求的事情

174
00:06:02,560 --> 00:06:03,280
现在我们要看

175
00:06:03,280 --> 00:06:05,480
我们对于不独立的随机变量

176
00:06:05,520 --> 00:06:07,080
我们怎么做px

177
00:06:08,640 --> 00:06:09,200
大家知道

178
00:06:09,400 --> 00:06:10,320
如果有

179
00:06:10,520 --> 00:06:12,480
我们可以就是说联合概率

180
00:06:12,480 --> 00:06:15,160
可以通过用条件概率展开

181
00:06:15,760 --> 00:06:16,720
pab

182
00:06:16,720 --> 00:06:19,120
就ab是两个变量的话

183
00:06:19,280 --> 00:06:23,200
那么它会等于pa乘以pb

184
00:06:23,200 --> 00:06:24,480
给定a出现

185
00:06:25,880 --> 00:06:27,080
它也反过来也可以

186
00:06:27,320 --> 00:06:28,440
它等于pb

187
00:06:28,440 --> 00:06:29,600
就是b的概率

188
00:06:29,640 --> 00:06:31,680
乘以pa

189
00:06:31,680 --> 00:06:32,560
就是a的概率

190
00:06:32,560 --> 00:06:34,280
给定b是出现的情况

191
00:06:34,400 --> 00:06:34,720
OK

192
00:06:34,720 --> 00:06:36,400
这就是条件概率

193
00:06:37,600 --> 00:06:38,760
那么有了它之后

194
00:06:38,960 --> 00:06:41,840
我们当然就可以把我们的px写出来

195
00:06:42,440 --> 00:06:43,320
就大家可以看一下

196
00:06:43,320 --> 00:06:44,080
就是说

197
00:06:44,120 --> 00:06:45,359
然后给大家

198
00:06:46,639 --> 00:06:48,039
首先 px

199
00:06:48,079 --> 00:06:50,000
我先按一个方向写

200
00:06:50,000 --> 00:06:51,399
就是先把pe

201
00:06:51,959 --> 00:06:53,199
x1写在这个地方

202
00:06:53,399 --> 00:06:56,199
就是说这个地方其实是x1了

203
00:06:56,839 --> 00:07:00,039
然后换一个白色

204
00:07:00,719 --> 00:07:02,240
然后这个地方是x2

205
00:07:02,879 --> 00:07:04,439
就基本上你可以认为是说

206
00:07:04,599 --> 00:07:07,719
我先算px1

207
00:07:08,279 --> 00:07:11,079
然后再写到

208
00:07:11,479 --> 00:07:13,639
算px2的概率

209
00:07:13,639 --> 00:07:14,919
给定x1

210
00:07:14,919 --> 00:07:16,719
就给定就是你有一个箭头

211
00:07:16,879 --> 00:07:17,959
就意味着是说

212
00:07:18,000 --> 00:07:20,719
你这个x2是依赖于x1的

213
00:07:21,279 --> 00:07:23,039
就x2的出现的概率

214
00:07:23,120 --> 00:07:25,120
我是当我知道x1怎么样子

215
00:07:25,120 --> 00:07:25,919
我才知道

216
00:07:27,079 --> 00:07:29,399
当然我可以写说px3

217
00:07:29,599 --> 00:07:30,560
就是x3

218
00:07:31,439 --> 00:07:33,599
它是要算它的概率

219
00:07:33,719 --> 00:07:37,159
要给要依赖于前面x1和x2的值

220
00:07:38,319 --> 00:07:39,399
这基本上很好理解

221
00:07:39,399 --> 00:07:39,680
对吧

222
00:07:39,680 --> 00:07:42,279
就是说我如果我这个x是有

223
00:07:42,280 --> 00:07:43,960
持续序列的信息的话

224
00:07:44,000 --> 00:07:46,040
那么我算时间t的话

225
00:07:46,480 --> 00:07:48,360
它去对它建模的话

226
00:07:48,600 --> 00:07:50,760
我得知道它过去发生了什么事情

227
00:07:52,040 --> 00:07:52,680
就是说

228
00:07:52,920 --> 00:07:53,960
所以你基本上可以认为

229
00:07:53,960 --> 00:07:55,160
就是这么一直写下来

230
00:07:55,440 --> 00:07:57,320
最后xT的话

231
00:07:57,360 --> 00:07:58,280
那么算它的话

232
00:07:58,280 --> 00:08:01,480
我要知道之前所有的t一个事情

233
00:08:01,480 --> 00:08:03,240
是发生什么事情了

234
00:08:05,040 --> 00:08:05,600
OK

235
00:08:05,800 --> 00:08:07,240
这是一个方向

236
00:08:07,680 --> 00:08:08,920
我也可以反过来写

237
00:08:10,000 --> 00:08:10,720
反过来写

238
00:08:10,720 --> 00:08:14,040
也就是说我先去算x大体

239
00:08:14,320 --> 00:08:15,760
就算最后一个

240
00:08:18,560 --> 00:08:19,560
算x大体

241
00:08:19,600 --> 00:08:22,280
然后一直算到最后的x1

242
00:08:22,680 --> 00:08:24,280
就基本上你看到是说

243
00:08:24,280 --> 00:08:28,680
我们这个地方最后一项

244
00:08:29,600 --> 00:08:30,920
算x1的时候

245
00:08:30,920 --> 00:08:33,600
我要知道x2到xT

246
00:08:34,160 --> 00:08:35,600
就是一个反序的

247
00:08:36,840 --> 00:08:39,840
反序在某些时候是有意义的

248
00:08:40,759 --> 00:08:42,759
就是说我说我知道

249
00:08:42,759 --> 00:08:45,879
我已经知道过去的未来的事情了

250
00:08:45,920 --> 00:08:49,080
然后我去推前面的事情会是什么样子

251
00:08:49,480 --> 00:08:51,480
这个是在某些时候是成立的

252
00:08:51,720 --> 00:08:54,480
但某些时候你物理上不一定可行

253
00:08:55,600 --> 00:08:55,879
对吧

254
00:08:55,879 --> 00:08:58,200
就是说你是一个

255
00:08:58,200 --> 00:08:59,120
你按照

256
00:08:59,120 --> 00:09:01,360
如果你是一个真实的时间的话

257
00:09:01,399 --> 00:09:02,279
你是

258
00:09:03,279 --> 00:09:04,399
你无法说

259
00:09:04,399 --> 00:09:06,360
根据未来的一个事件

260
00:09:06,360 --> 00:09:08,080
去推前面发生了什么

261
00:09:08,080 --> 00:09:09,759
因为很有可能未来事件

262
00:09:09,759 --> 00:09:11,960
是基于你前面发生事件产生的

263
00:09:11,960 --> 00:09:13,039
而不是反过来

264
00:09:13,279 --> 00:09:13,840
Ok

265
00:09:15,439 --> 00:09:16,480
但是这两个

266
00:09:16,480 --> 00:09:18,240
我们在之后都会看到

267
00:09:18,240 --> 00:09:19,600
就是对Rn来讲

268
00:09:19,600 --> 00:09:20,480
我可以正着来

269
00:09:20,480 --> 00:09:21,759
我也可以反着过去

270
00:09:23,840 --> 00:09:24,120
好

271
00:09:24,120 --> 00:09:24,879
另外一个是说

272
00:09:24,879 --> 00:09:27,000
假设我们再仔细看一下

273
00:09:27,000 --> 00:09:29,240
我们假设我们是前项算的

274
00:09:29,439 --> 00:09:32,600
就是每一次就是根据前面的事件

275
00:09:32,600 --> 00:09:33,960
来算后面事件的话

276
00:09:34,080 --> 00:09:35,519
我们再来仔细看一下

277
00:09:36,399 --> 00:09:39,360
就是我们这里核心要去算的是这个东西

278
00:09:40,679 --> 00:09:43,080
我要去算Pxt的概率

279
00:09:43,559 --> 00:09:47,720
给定它之前t减1个数据

280
00:09:49,279 --> 00:09:50,039
我们怎么算

281
00:09:50,559 --> 00:09:52,679
我们一个算法是说

282
00:09:52,919 --> 00:09:55,319
我们可以对前面的t个

283
00:09:55,360 --> 00:09:56,319
对它建模

284
00:09:56,319 --> 00:10:00,279
就是说算把它表示成一个f一个函数

285
00:10:01,360 --> 00:10:02,679
这个f就是去

286
00:10:02,679 --> 00:10:04,480
你可以认为它去表示说

287
00:10:04,519 --> 00:10:05,159
前面

288
00:10:05,159 --> 00:10:08,559
这个x1到xt减1

289
00:10:08,559 --> 00:10:10,000
这个东西表示什么东西

290
00:10:10,000 --> 00:10:12,279
你可以认为就是一个机器学习的模型

291
00:10:13,639 --> 00:10:14,639
所以这样子的话

292
00:10:14,639 --> 00:10:16,439
假设我能对它建模的话

293
00:10:16,439 --> 00:10:18,120
那么我算xt的话

294
00:10:18,240 --> 00:10:20,279
就是给定模型

295
00:10:20,279 --> 00:10:20,679
ok

296
00:10:20,679 --> 00:10:22,319
算出来xt的概率

297
00:10:23,959 --> 00:10:25,319
然后基本上你可以认为

298
00:10:25,319 --> 00:10:27,279
就是说我其实就f的话

299
00:10:27,279 --> 00:10:28,279
我就训练一个模型

300
00:10:28,480 --> 00:10:29,279
训练一个模型

301
00:10:29,279 --> 00:10:32,759
然后在过去的t减1个数据上

302
00:10:32,759 --> 00:10:33,559
训练一个模型

303
00:10:34,560 --> 00:10:37,040
然后来预测下一个模型

304
00:10:38,600 --> 00:10:40,960
就是说这个跟我们之前会不一样

305
00:10:41,440 --> 00:10:43,040
之前我们讲到是说

306
00:10:43,040 --> 00:10:44,280
我给一些图片

307
00:10:44,280 --> 00:10:45,480
然后去训练一个

308
00:10:45,480 --> 00:10:47,040
去预测一个标号

309
00:10:47,600 --> 00:10:49,440
标号和图片不是一个东西

310
00:10:49,960 --> 00:10:50,920
图片是图片

311
00:10:50,920 --> 00:10:51,920
标号是标号

312
00:10:52,960 --> 00:10:53,840
但现在这个地方

313
00:10:53,960 --> 00:10:57,160
我们是给定你们前面的t个数据

314
00:10:57,160 --> 00:10:59,440
去预测第t个数据

315
00:10:59,880 --> 00:11:01,800
就是我的标号和我的

316
00:11:02,760 --> 00:11:03,680
真实的样本

317
00:11:03,840 --> 00:11:04,920
其实是一个东西

318
00:11:05,360 --> 00:11:07,400
所以这样子的模型叫做

319
00:11:08,720 --> 00:11:09,720
自回归模型

320
00:11:09,720 --> 00:11:11,640
假设我是个回归的话

321
00:11:12,240 --> 00:11:13,200
那叫自回归

322
00:11:13,200 --> 00:11:13,960
假如分类的话

323
00:11:14,000 --> 00:11:14,880
当然叫自分类了

324
00:11:14,880 --> 00:11:17,400
分类就会没那么常见一点

325
00:11:19,040 --> 00:11:21,520
所以就是说所谓的自回归

326
00:11:21,520 --> 00:11:25,200
就是我给你一些数据

327
00:11:25,280 --> 00:11:28,120
然后我去预测这个数据的时候

328
00:11:28,159 --> 00:11:29,919
不是用了另外一组数据

329
00:11:30,240 --> 00:11:32,519
而是用这个数据前面的那些样本

330
00:11:32,519 --> 00:11:33,759
所以叫自己回归

331
00:11:33,759 --> 00:11:34,200
对

332
00:11:34,200 --> 00:11:34,960
见过的数据

333
00:11:34,960 --> 00:11:36,560
见过叫做自己回归

334
00:11:36,919 --> 00:11:38,000
叫Auto regression

335
00:11:38,560 --> 00:11:39,080
Ok

336
00:11:39,440 --> 00:11:39,879
好

337
00:11:40,039 --> 00:11:42,360
接下来基本上就是说核心思想是说

338
00:11:42,360 --> 00:11:43,879
你怎么样去算

339
00:11:44,360 --> 00:11:46,240
Fxc到xt

340
00:11:46,240 --> 00:11:48,000
这个就是你核心的事情

341
00:11:48,000 --> 00:11:48,919
第二个是说

342
00:11:48,919 --> 00:11:49,799
你给定他之后

343
00:11:49,799 --> 00:11:50,799
你怎么算这个p

344
00:11:52,680 --> 00:11:52,919
好

345
00:11:52,919 --> 00:11:54,840
我们首先来看一个方案

346
00:11:55,840 --> 00:11:59,680
第一个方案叫做马尔科夫假设

347
00:11:59,680 --> 00:12:02,240
大家可能都多多少少听说过马尔科夫

348
00:12:02,240 --> 00:12:05,120
就是一个俄罗斯的科学家

349
00:12:05,560 --> 00:12:07,720
就是说他的假设是说

350
00:12:07,759 --> 00:12:09,759
我的当前数据

351
00:12:10,600 --> 00:12:14,040
只跟淘个过去数据点相关

352
00:12:16,320 --> 00:12:18,680
具体讲看一下这个例子

353
00:12:20,040 --> 00:12:21,800
就是说你看一下这个东西

354
00:12:22,000 --> 00:12:23,840
就这个数据点

355
00:12:23,879 --> 00:12:26,040
在过去在原始的模型里面

356
00:12:26,040 --> 00:12:30,440
它是跟相关

357
00:12:30,440 --> 00:12:31,879
就所有的箭头都过去了

358
00:12:32,480 --> 00:12:34,280
这个东西会导致很多问题

359
00:12:34,280 --> 00:12:36,920
当你时间变得特别长的时候

360
00:12:36,920 --> 00:12:38,720
你得往回看很多东西

361
00:12:39,040 --> 00:12:41,600
再导致你的计算其实不容易

362
00:12:42,040 --> 00:12:44,120
那么现在马尔科夫假设是说

363
00:12:44,480 --> 00:12:46,000
我其实我只

364
00:12:46,360 --> 00:12:48,920
如果我只跟过去淘个数据点相关

365
00:12:49,040 --> 00:12:50,400
如果我们的淘等于二的时候

366
00:12:50,400 --> 00:12:51,000
是这个情况

367
00:12:51,280 --> 00:12:52,080
就这个数据

368
00:12:52,280 --> 00:12:54,000
就跟这个相关

369
00:12:54,639 --> 00:12:57,320
就跟它是前面那个是不相关的

370
00:12:58,520 --> 00:13:02,560
所以就每一次我只预测一个新的数据

371
00:13:02,600 --> 00:13:04,080
只需要看过去淘个

372
00:13:04,680 --> 00:13:06,759
淘我可以选择可以小一点大一点

373
00:13:06,920 --> 00:13:07,680
小一点的话

374
00:13:07,800 --> 00:13:09,160
就是模型简单一点

375
00:13:09,480 --> 00:13:10,160
大一点的话

376
00:13:10,320 --> 00:13:13,440
就是更加复杂一点

377
00:13:14,280 --> 00:13:15,160
但好就是说

378
00:13:15,160 --> 00:13:16,480
我这淘就固定住了

379
00:13:16,480 --> 00:13:19,600
就是不会随着你的时间增加

380
00:13:19,600 --> 00:13:21,160
然后就变得特别大

381
00:13:21,519 --> 00:13:24,360
这个也多多少少是符合我们一定的

382
00:13:24,959 --> 00:13:26,039
现实生活的逻辑

383
00:13:26,480 --> 00:13:28,000
比如说你股票预测的话

384
00:13:28,039 --> 00:13:30,360
你可能真的你的股价

385
00:13:30,399 --> 00:13:32,079
跟一个月前相关

386
00:13:32,079 --> 00:13:33,480
跟一年前也许相关

387
00:13:33,480 --> 00:13:36,839
可能跟5年前10年前关系可能就不大了

388
00:13:37,559 --> 00:13:38,439
另外一个是说

389
00:13:38,439 --> 00:13:41,079
假设我要去测一个文本里面的文字的话

390
00:13:41,480 --> 00:13:45,000
我可以说跟过去多少个句子相关

391
00:13:45,000 --> 00:13:48,000
可能再往前可能就关系就不那么大了

392
00:13:48,839 --> 00:13:49,399
OK

393
00:13:49,799 --> 00:13:53,000
所以假设我们有马尔科夫假设的话

394
00:13:53,120 --> 00:13:56,360
那么我们对条件概率的计算的话

395
00:13:56,360 --> 00:13:58,000
那就变成了 X1

396
00:13:58,000 --> 00:14:00,959
就会改写成了XT-TAU

397
00:14:01,120 --> 00:14:03,879
然后的XT-TAU-E

398
00:14:03,919 --> 00:14:07,000
一直到XT一直到T-E

399
00:14:07,360 --> 00:14:11,879
就是说这里就只有淘个数据了

400
00:14:13,840 --> 00:14:15,559
所以如果是淘个数据的话

401
00:14:15,559 --> 00:14:16,519
你可以看一下

402
00:14:17,000 --> 00:14:19,319
我们说我们在后面对它建模的话

403
00:14:20,199 --> 00:14:22,600
对它做F的话

404
00:14:23,559 --> 00:14:24,519
那么就是说

405
00:14:25,519 --> 00:14:27,159
这个就比较容易做了

406
00:14:27,159 --> 00:14:27,759
看上去对吧

407
00:14:27,759 --> 00:14:30,759
我们就在上面券一个Multi-Layer Perception

408
00:14:30,759 --> 00:14:32,720
就是一个多层感測机就行了

409
00:14:33,039 --> 00:14:33,879
就是说

410
00:14:34,199 --> 00:14:37,559
等于是说假设X是一个标量的话

411
00:14:38,600 --> 00:14:41,199
那么就是说我们这个F干嘛

412
00:14:41,439 --> 00:14:43,759
就是每次给你淘个

413
00:14:43,960 --> 00:14:46,399
淘长的一个特征

414
00:14:46,679 --> 00:14:48,079
一个向量的数据

415
00:14:48,279 --> 00:14:50,279
然后你去预测一个标量

416
00:14:50,639 --> 00:14:53,159
那不就是一个最简单的一个回归问题

417
00:14:53,199 --> 00:14:55,000
我们可以用信息回归也行

418
00:14:55,159 --> 00:14:56,679
就是MLP也行都行

419
00:14:57,120 --> 00:14:58,240
所以就是说

420
00:14:58,399 --> 00:15:02,319
给淘使得我们不要去处理变长的数据

421
00:15:02,360 --> 00:15:03,439
然后是定长的话

422
00:15:03,439 --> 00:15:03,639
好

423
00:15:03,639 --> 00:15:05,120
我们之前的所有的技术

424
00:15:05,120 --> 00:15:05,919
我们都可以用

425
00:15:06,199 --> 00:15:06,799
OK

426
00:15:06,840 --> 00:15:08,079
所以就是说我们最简单

427
00:15:08,079 --> 00:15:09,399
就是用个MLP

428
00:15:09,840 --> 00:15:12,439
就可以来对F建模

429
00:15:13,720 --> 00:15:13,919
好

430
00:15:13,919 --> 00:15:15,279
这是第一个方案

431
00:15:15,720 --> 00:15:16,839
第二个方案

432
00:15:17,039 --> 00:15:18,679
就是说一个叫做

433
00:15:19,039 --> 00:15:20,839
Latent Variable

434
00:15:21,600 --> 00:15:22,959
也叫前变量

435
00:15:23,679 --> 00:15:27,519
跟我们的引变量有一点点的区别

436
00:15:27,519 --> 00:15:29,360
在统计上来说有一点点区别

437
00:15:30,240 --> 00:15:32,360
前变量相对来说

438
00:15:35,439 --> 00:15:37,240
从概念上来说更加广一点

439
00:15:37,639 --> 00:15:38,879
就认为是

440
00:15:39,240 --> 00:15:42,240
引变量的一个稍微特别广一点的类型

441
00:15:42,959 --> 00:15:43,279
好

442
00:15:43,319 --> 00:15:45,079
我们前变量是什么意思呢

443
00:15:45,600 --> 00:15:47,519
就前面的想法是说

444
00:15:47,559 --> 00:15:50,199
我们引入一个前变量

445
00:15:50,879 --> 00:15:52,120
Ht

446
00:15:52,759 --> 00:15:55,199
来表示过去的信息

447
00:15:56,360 --> 00:15:57,919
就是说我说我有一个

448
00:15:58,039 --> 00:16:01,079
我就把它不再是写成一个函数的形式

449
00:16:01,240 --> 00:16:03,079
我就写成一个变量的形式

450
00:16:03,079 --> 00:16:03,559
就变量

451
00:16:03,559 --> 00:16:05,399
你可以认为就是一个数

452
00:16:05,519 --> 00:16:06,360
或者一个向量

453
00:16:06,519 --> 00:16:07,480
或者什么东西

454
00:16:08,480 --> 00:16:11,439
然后Ht它就表示成了一个F

455
00:16:11,559 --> 00:16:15,120
可以表示成Fx1-Fxt-1

456
00:16:15,799 --> 00:16:18,000
这样的话我们算

457
00:16:18,279 --> 00:16:19,079
这里不一样的是

458
00:16:19,559 --> 00:16:20,879
这个地方是一个函数

459
00:16:20,879 --> 00:16:21,360
对吧

460
00:16:21,839 --> 00:16:22,919
这个地方是一个模型

461
00:16:23,079 --> 00:16:24,319
这个地方是一个数据

462
00:16:24,319 --> 00:16:26,199
它是主要的区别

463
00:16:26,600 --> 00:16:27,679
所以这样子的话

464
00:16:27,720 --> 00:16:29,319
我们计算xt的话

465
00:16:29,319 --> 00:16:33,720
那就是Pxt给定Ht

466
00:16:34,679 --> 00:16:36,480
Ht是一个你认为是一个向量

467
00:16:36,639 --> 00:16:38,639
或者是一个甚至是一个数都行

468
00:16:39,639 --> 00:16:39,839
好

469
00:16:39,839 --> 00:16:41,279
所以就变成了一个比较简单

470
00:16:41,279 --> 00:16:42,279
不管你要多长

471
00:16:42,480 --> 00:16:44,240
我现在都变成一个比较简单

472
00:16:44,240 --> 00:16:46,159
只是给定Ht就行了

473
00:16:47,080 --> 00:16:52,840
从下面这个图来看

474
00:16:52,840 --> 00:16:53,759
是这么看的

475
00:16:55,080 --> 00:16:55,799
就是说

476
00:16:55,919 --> 00:16:57,680
首先我的蓝色是x

477
00:16:57,720 --> 00:16:59,399
我的绿色是h

478
00:17:00,200 --> 00:17:01,840
我算x的话

479
00:17:02,600 --> 00:17:05,559
就是说或者这样

480
00:17:07,680 --> 00:17:10,599
我算x'的话

481
00:17:10,880 --> 00:17:12,759
当然是说我跟前面的x相关

482
00:17:13,079 --> 00:17:16,000
我也跟我的引变量

483
00:17:17,119 --> 00:17:19,000
这前面的h一撇相关

484
00:17:20,319 --> 00:17:21,759
但这里核心的是说

485
00:17:22,200 --> 00:17:25,319
我们一旦引入了前变量概念的话

486
00:17:25,319 --> 00:17:27,960
那么我们可以不断去更新我的h

487
00:17:29,000 --> 00:17:29,960
就是说你可以认为

488
00:17:29,960 --> 00:17:31,240
H是什么算出来的

489
00:17:31,559 --> 00:17:34,000
H一撇是根据你前一个时间的

490
00:17:34,000 --> 00:17:34,720
前变量

491
00:17:35,039 --> 00:17:37,759
和前一个时间的x相关

492
00:17:38,879 --> 00:17:41,640
就是说等于说我这里就建两个模型

493
00:17:42,040 --> 00:17:43,280
一个模型是说

494
00:17:43,680 --> 00:17:47,400
怎么样根据前面一个时间的h

495
00:17:47,759 --> 00:17:48,960
和前面时间的x

496
00:17:48,960 --> 00:17:51,200
来算我的新的前变量

497
00:17:51,560 --> 00:17:52,560
这个是模型一

498
00:17:54,120 --> 00:17:54,920
我来标记一下

499
00:17:55,680 --> 00:17:57,040
这个是模型一

500
00:17:57,880 --> 00:17:59,720
第二个是说我给定

501
00:18:00,680 --> 00:18:02,080
前变量

502
00:18:02,120 --> 00:18:03,600
就新的前变量的状态

503
00:18:03,600 --> 00:18:05,960
和我的前一个时间的x

504
00:18:05,960 --> 00:18:08,960
怎么样算我新的x

505
00:18:09,800 --> 00:18:10,800
这是模型二

506
00:18:11,680 --> 00:18:12,240
这样子的话

507
00:18:12,240 --> 00:18:14,000
我们就把它拆成了两个模型

508
00:18:14,000 --> 00:18:15,040
然后相对来说

509
00:18:15,040 --> 00:18:17,240
每个模型都是只跟一个

510
00:18:17,240 --> 00:18:18,600
或者两个变量相关

511
00:18:18,600 --> 00:18:19,960
相对来说是比较简单

512
00:18:19,960 --> 00:18:22,000
容易去计算

513
00:18:22,680 --> 00:18:26,560
当然核心是说你去选择什么样的

514
00:18:26,560 --> 00:18:28,080
模型来对它建模了

515
00:18:29,240 --> 00:18:29,759
OK

516
00:18:30,720 --> 00:18:32,120
所以总结一下

517
00:18:33,280 --> 00:18:35,720
在时序模型中

518
00:18:36,560 --> 00:18:38,000
当前的数据

519
00:18:38,400 --> 00:18:40,759
跟之前观察的数据是相关的

520
00:18:41,359 --> 00:18:43,920
我们在这一节课之前

521
00:18:44,279 --> 00:18:45,160
所有的假设

522
00:18:45,160 --> 00:18:46,160
就是说我的样本

523
00:18:46,279 --> 00:18:47,039
那些图片

524
00:18:48,039 --> 00:18:49,440
图片之间是没关系的

525
00:18:49,720 --> 00:18:52,000
现在我们说我们的每一个数据

526
00:18:52,000 --> 00:18:54,440
跟是在时间上是相关的

527
00:18:55,920 --> 00:18:57,640
然后其中一个模型

528
00:18:57,640 --> 00:18:58,680
是自回归模型

529
00:18:58,799 --> 00:19:02,519
就是说用过去的那些数据

530
00:19:02,519 --> 00:19:04,160
来预测现在的数据

531
00:19:04,640 --> 00:19:05,759
就自回归

532
00:19:06,039 --> 00:19:08,319
其中有两个比较正常的

533
00:19:08,319 --> 00:19:09,920
一个长期的解决方案

534
00:19:10,320 --> 00:19:12,200
一个是用马尔科夫假设

535
00:19:12,320 --> 00:19:14,200
使得说我当前的数据

536
00:19:14,200 --> 00:19:18,039
只跟前面某特定长时刻的数据相关

537
00:19:19,480 --> 00:19:21,160
这样子我的模型就比较简化了

538
00:19:21,160 --> 00:19:23,240
然后是每一次我都能固定长度

539
00:19:23,240 --> 00:19:25,360
用过去固定长度的历史信息

540
00:19:25,360 --> 00:19:26,200
来预测现在

541
00:19:27,039 --> 00:19:29,120
第二个是说我用一个前变量模型

542
00:19:29,360 --> 00:19:30,720
用一个前变量

543
00:19:30,759 --> 00:19:32,519
来概括历史信息

544
00:19:32,560 --> 00:19:33,200
这样子的话

545
00:19:33,200 --> 00:19:34,320
我的模型变成两块

546
00:19:34,560 --> 00:19:36,200
一块是说怎么样

547
00:19:36,200 --> 00:19:39,200
根据现在的观察到的数据

548
00:19:39,200 --> 00:19:40,759
来更新我的前变量

549
00:19:40,799 --> 00:19:43,440
以及说根据现在更新后的前变量

550
00:19:43,440 --> 00:19:44,880
和我们过去的数据

551
00:19:44,920 --> 00:19:48,840
来更新我们现在将来要观察的数据

552
00:19:49,840 --> 00:19:51,120
基本上我们的RN

553
00:19:51,319 --> 00:19:52,640
之后要介绍的RN

554
00:19:52,640 --> 00:19:54,440
是属于一个前变量模型

555
00:19:54,920 --> 00:19:57,240
在我们在介绍RN之前

556
00:19:57,240 --> 00:19:58,240
我们来看一下

557
00:19:58,600 --> 00:20:00,200
用马尔科夫假设

558
00:20:00,200 --> 00:20:03,440
然后用MLP来训练是什么样子

