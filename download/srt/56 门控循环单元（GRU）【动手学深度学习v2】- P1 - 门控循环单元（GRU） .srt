1
00:00:00,000 --> 00:00:01,360
问题一

2
00:00:02,200 --> 00:00:05,040
GiU网络中RT和ZT的网络结构一样

3
00:00:05,040 --> 00:00:07,839
为什么就可以把这种RT设成ZT设成

4
00:00:07,839 --> 00:00:08,839
选成这个东西

5
00:00:08,839 --> 00:00:09,240
对

6
00:00:09,240 --> 00:00:11,880
就是说它网络结构是一样的

7
00:00:11,880 --> 00:00:15,519
但是你那些W是可以学的

8
00:00:15,960 --> 00:00:17,199
因为我们那个作用

9
00:00:17,320 --> 00:00:19,280
就是说我们说白了

10
00:00:19,280 --> 00:00:19,960
就是说

11
00:00:20,719 --> 00:00:23,719
我们觉得通过我们这么写的东西

12
00:00:23,719 --> 00:00:27,320
我们觉得RT和ZT是应该去干这个事情

13
00:00:27,400 --> 00:00:29,960
这是我们对模型的要求

14
00:00:30,199 --> 00:00:33,119
但模型到底是不是这么算的

15
00:00:34,000 --> 00:00:34,920
你不知道

16
00:00:34,920 --> 00:00:35,560
对吧

17
00:00:35,799 --> 00:00:37,840
就是看模型怎么去学你那个W

18
00:00:37,840 --> 00:00:39,120
说它对应的W

19
00:00:39,159 --> 00:00:42,359
也许它把W学成我想要的样子

20
00:00:42,640 --> 00:00:44,960
也许是这么学出来的

21
00:00:45,200 --> 00:00:46,760
有可能它没学出这个样子

22
00:00:46,760 --> 00:00:47,159
对吧

23
00:00:47,159 --> 00:00:48,280
所以一般你怎么去干

24
00:00:48,400 --> 00:00:50,480
一般你可以干的事情是说

25
00:00:50,480 --> 00:00:51,280
你训练好之后

26
00:00:51,280 --> 00:00:53,000
你去可视化

27
00:00:54,039 --> 00:00:55,240
你真的拿一个

28
00:00:56,039 --> 00:00:58,480
就是说你拿一个句子放进去

29
00:00:58,480 --> 00:01:00,280
然后看那些东西的输出

30
00:01:00,280 --> 00:01:03,200
看看它是不是可视化

31
00:01:03,200 --> 00:01:06,000
就是看一下它那些值

32
00:01:06,159 --> 00:01:07,719
是不是按照你的要求来

33
00:01:07,760 --> 00:01:10,480
我们在RNN不会做这个事情

34
00:01:10,520 --> 00:01:12,200
但是我们在之后的

35
00:01:12,960 --> 00:01:13,920
注意力机制

36
00:01:13,920 --> 00:01:14,920
Attention里面

37
00:01:14,920 --> 00:01:16,439
会给大家去看那些权重

38
00:01:16,439 --> 00:01:17,200
它的变化

39
00:01:17,200 --> 00:01:18,560
看看它那些说

40
00:01:18,600 --> 00:01:21,560
怎么样给序列中间每一个东西加权

41
00:01:21,560 --> 00:01:22,800
它到底是什么样子的

42
00:01:22,799 --> 00:01:27,560
GiU的激活

43
00:01:27,560 --> 00:01:28,239
缓缓速

44
00:01:28,239 --> 00:01:30,719
为什么要TimeH用ReLu

45
00:01:30,719 --> 00:01:32,719
或其他激活还是可以吗

46
00:01:34,560 --> 00:01:35,640
可以的

47
00:01:36,640 --> 00:01:38,319
我觉得

48
00:01:41,959 --> 00:01:43,640
我觉得你用

49
00:01:43,679 --> 00:01:44,560
我感觉不说

50
00:01:44,560 --> 00:01:46,000
你要用ReLu有什么问题

51
00:01:46,120 --> 00:01:47,239
你可以试一下

52
00:01:48,120 --> 00:01:49,879
大家用TimeH是为什么

53
00:01:49,879 --> 00:01:53,560
是因为当年LSTM出来的时候

54
00:01:53,560 --> 00:01:54,879
还没有TimeH这个东西

55
00:01:54,879 --> 00:01:57,159
所以RNN

56
00:01:57,159 --> 00:01:58,640
LSTM都是用的

57
00:01:58,640 --> 00:01:59,239
不

58
00:01:59,239 --> 00:02:00,719
就当年LSTM

59
00:02:00,879 --> 00:02:02,479
RNN出来之后

60
00:02:02,479 --> 00:02:03,840
还没有ReLu这个东西

61
00:02:03,879 --> 00:02:05,879
所以他们都用的是TimeH

62
00:02:06,640 --> 00:02:07,840
之所以拥有TimeH

63
00:02:07,840 --> 00:02:08,479
是因为这样子

64
00:02:08,479 --> 00:02:10,400
你能够在0上下都能生成

65
00:02:11,439 --> 00:02:14,120
然后所以

66
00:02:15,240 --> 00:02:17,560
所以大家用TimeH多一点

67
00:02:17,560 --> 00:02:19,199
可能我觉得你换成ReLu

68
00:02:19,200 --> 00:02:20,520
也估计问题不大

69
00:02:23,080 --> 00:02:23,960
G等于1的时候

70
00:02:23,960 --> 00:02:25,840
相当于HT等于HT-1

71
00:02:25,840 --> 00:02:27,080
那么等于G等于0的时候

72
00:02:27,080 --> 00:02:28,080
是什么意思呢

73
00:02:28,440 --> 00:02:29,520
G等于0的时候

74
00:02:29,520 --> 00:02:30,640
就是没什么意思

75
00:02:30,640 --> 00:02:31,400
G等于0的时候

76
00:02:31,400 --> 00:02:34,960
就是按照正常的逻辑更新

77
00:02:35,240 --> 00:02:36,000
G等于0的时候

78
00:02:36,000 --> 00:02:39,560
就是HT就等于HT了

79
00:02:40,200 --> 00:02:40,840
OK

80
00:02:41,040 --> 00:02:42,680
所以就是说

81
00:02:43,680 --> 00:02:45,280
他就是说他G等于0的时候

82
00:02:45,280 --> 00:02:47,000
不是说完全不看HT-1

83
00:02:47,000 --> 00:02:48,280
是通过你的

84
00:02:49,039 --> 00:02:51,080
那个HT要打里面去

85
00:02:51,080 --> 00:02:52,360
通过更新

86
00:02:52,360 --> 00:02:54,800
我从HT-1

87
00:02:55,000 --> 00:02:57,159
叫通过权重到HT

88
00:02:57,400 --> 00:02:58,560
正常途径更新

89
00:02:59,439 --> 00:03:00,240
就是说

90
00:03:01,000 --> 00:03:02,400
他主要的意义是说

91
00:03:02,400 --> 00:03:03,520
G等于0的时候

92
00:03:03,520 --> 00:03:04,639
是跟之前是一样的

93
00:03:04,639 --> 00:03:05,479
一样的更新

94
00:03:05,479 --> 00:03:06,199
唯一的是说

95
00:03:06,199 --> 00:03:06,800
加油的G

96
00:03:06,800 --> 00:03:08,840
主要是给你一个选项说

97
00:03:08,840 --> 00:03:10,800
我可以让你当前的HT

98
00:03:11,199 --> 00:03:13,120
可以绕过XT

99
00:03:13,120 --> 00:03:14,400
就绕过当前看的东西

100
00:03:14,400 --> 00:03:16,000
直接用上一个时候的状态

101
00:03:16,280 --> 00:03:17,240
就是这个意思

102
00:03:20,240 --> 00:03:22,639
GRU相比RN多了那么多参数

103
00:03:22,639 --> 00:03:23,719
需不需要提高

104
00:03:23,719 --> 00:03:25,439
Gradient clipping的预值

105
00:03:26,560 --> 00:03:28,800
就GRU比RN多了参数

106
00:03:28,919 --> 00:03:31,080
但是你不见得梯度就会爆炸

107
00:03:32,000 --> 00:03:32,920
事实上来说

108
00:03:32,920 --> 00:03:34,800
GRU还有LSTN

109
00:03:34,960 --> 00:03:39,759
它的数值稳定性比RN要高

110
00:03:40,039 --> 00:03:40,479
为什么

111
00:03:40,479 --> 00:03:41,800
是因为你那些sigmoid

112
00:03:41,879 --> 00:03:43,639
都是一些0到1之间的值

113
00:03:43,639 --> 00:03:45,439
而且他通常

114
00:03:45,520 --> 00:03:47,639
通常他不会很靠近

115
00:03:48,079 --> 00:03:49,919
就sigmoid是不能变成1的

116
00:03:49,919 --> 00:03:50,359
对吧

117
00:03:50,479 --> 00:03:51,439
通常是个

118
00:03:51,439 --> 00:03:53,079
因为它是它无限阶级1

119
00:03:53,439 --> 00:03:55,759
而且通常sigmoid这个东西

120
00:03:55,919 --> 00:03:57,159
你不会在

121
00:03:57,199 --> 00:03:58,759
你不会在0和1之间

122
00:03:58,759 --> 00:03:59,319
那个极端

123
00:03:59,319 --> 00:04:01,079
通常是在0.5上下附近

124
00:04:01,079 --> 00:04:01,759
那个地方

125
00:04:01,879 --> 00:04:04,919
所以其实GRU的那些

126
00:04:05,919 --> 00:04:06,400
参数

127
00:04:06,800 --> 00:04:07,400
那些值

128
00:04:07,800 --> 00:04:10,759
比RN那些东西要少

129
00:04:11,639 --> 00:04:12,240
OK

130
00:04:12,400 --> 00:04:14,000
所以就是说参数多

131
00:04:14,000 --> 00:04:15,800
不见得你梯度会爆炸

132
00:04:15,879 --> 00:04:17,319
取决于你是怎么做的

133
00:04:17,360 --> 00:04:19,319
比如说你把乘法变加法

134
00:04:19,360 --> 00:04:19,920
那么就是说

135
00:04:19,920 --> 00:04:22,079
你之前是尽量用了10个

136
00:04:22,079 --> 00:04:22,839
举人乘法

137
00:04:22,839 --> 00:04:24,920
现在我变成100个举人加法的话

138
00:04:24,920 --> 00:04:27,319
虽然我这些参数

139
00:04:27,319 --> 00:04:28,600
从10个变100个

140
00:04:28,639 --> 00:04:30,199
但是因为你的运算

141
00:04:30,439 --> 00:04:31,959
它里面做了那些

142
00:04:33,240 --> 00:04:33,879
它的数字

143
00:04:33,920 --> 00:04:35,560
这些运算的数字稳定性比较高

144
00:04:35,560 --> 00:04:36,800
所以相当于说问题不大

145
00:04:38,759 --> 00:04:39,680
但是反过来讲

146
00:04:39,759 --> 00:04:40,920
GRU和RN

147
00:04:41,079 --> 00:04:42,319
它的gradient clipping

148
00:04:42,480 --> 00:04:43,480
就是基本上等于

149
00:04:43,519 --> 00:04:44,399
1 2 5 10

150
00:04:44,560 --> 00:04:45,800
就这三个值比较常见

151
00:04:48,680 --> 00:04:49,719
GRU有了RT

152
00:04:49,719 --> 00:04:50,920
是不是不需要像RN

153
00:04:50,920 --> 00:04:51,480
再换数

154
00:04:51,519 --> 00:04:53,120
就是reset H了

155
00:04:55,680 --> 00:04:57,719
GRU可以学到这个东西

156
00:04:57,759 --> 00:04:59,120
其实是不一样的

157
00:04:59,159 --> 00:05:00,920
就是说这两个东西

158
00:05:02,560 --> 00:05:04,039
就会后来给大家解释一下

159
00:05:04,039 --> 00:05:04,839
就是说

160
00:05:05,039 --> 00:05:07,000
R和Z的作用不一样

161
00:05:07,639 --> 00:05:09,039
R的作用是说

162
00:05:09,040 --> 00:05:11,319
在跟我的

163
00:05:11,319 --> 00:05:12,760
在更新我的

164
00:05:13,080 --> 00:05:13,439
就是说

165
00:05:13,439 --> 00:05:15,319
在用我的XT

166
00:05:15,319 --> 00:05:17,200
用到我的XT的时候

167
00:05:17,600 --> 00:05:19,800
和用到XT和HT-1

168
00:05:19,800 --> 00:05:21,400
去更新HT的时候

169
00:05:21,920 --> 00:05:24,120
看多少HT-1的信息

170
00:05:24,600 --> 00:05:25,200
OK

171
00:05:25,240 --> 00:05:28,160
就是说是这两个东西算过来的时候

172
00:05:28,320 --> 00:05:31,320
用就是说你看有一个XT在这里

173
00:05:31,320 --> 00:05:32,680
然后用多少这个地方

174
00:05:33,200 --> 00:05:35,080
Z的意思是说

175
00:05:35,080 --> 00:05:37,439
我就有多少概率

176
00:05:37,719 --> 00:05:38,439
或者是多

177
00:05:38,719 --> 00:05:40,959
我就直接绕过XT了

178
00:05:41,000 --> 00:05:42,000
直接用它

179
00:05:42,040 --> 00:05:43,759
就直接从它那里过去了

180
00:05:43,959 --> 00:05:45,120
就绕过这一块

181
00:05:45,920 --> 00:05:47,199
所以一个是说

182
00:05:47,199 --> 00:05:48,000
在

183
00:05:48,480 --> 00:05:49,759
给就是说

184
00:05:50,279 --> 00:05:52,639
它这个地方主要的用处是让你

185
00:05:53,680 --> 00:05:56,279
在尽量的多去看XT

186
00:05:56,279 --> 00:06:00,000
就不要被前面的状态所太多的带动了

187
00:06:00,040 --> 00:06:01,439
就是说尽量说

188
00:06:01,439 --> 00:06:02,600
我去关注

189
00:06:02,600 --> 00:06:04,720
我当前XT里面给我的信息

190
00:06:05,879 --> 00:06:06,839
那么这个Z

191
00:06:07,040 --> 00:06:08,520
的意思就是说

192
00:06:08,520 --> 00:06:10,400
我尽量不去看XT

193
00:06:10,840 --> 00:06:13,520
所以这两个是有一点点不一样的

194
00:06:13,560 --> 00:06:14,960
所以为什么叫做

195
00:06:15,000 --> 00:06:17,320
一个叫做reset

196
00:06:18,880 --> 00:06:20,640
一个叫做update

197
00:06:21,400 --> 00:06:24,760
update是说我要不要对我的

198
00:06:25,480 --> 00:06:28,600
要不要根据我的XT来update我的H

199
00:06:29,400 --> 00:06:31,160
reset的意思是说

200
00:06:31,160 --> 00:06:33,400
我是不是把过去的信息

201
00:06:33,800 --> 00:06:34,480
都不要

202
00:06:34,480 --> 00:06:35,360
都reset掉

203
00:06:35,360 --> 00:06:36,080
就忘掉

204
00:06:36,160 --> 00:06:36,560
OK

205
00:06:36,560 --> 00:06:38,480
所以叫做遗忘和更新

206
00:06:39,040 --> 00:06:41,519
这是两个是作用是不一样的

207
00:06:46,959 --> 00:06:49,920
GiU的初始隐藏状态层的大小

208
00:06:49,920 --> 00:06:50,879
可以随便写吗

209
00:06:50,879 --> 00:06:53,199
跟MLP一样

210
00:06:53,240 --> 00:06:53,560
可以

211
00:06:53,720 --> 00:06:54,639
你可以随便写

212
00:06:54,639 --> 00:06:58,160
其实跟你的MLP没有本质太多区别

213
00:06:59,120 --> 00:07:00,040
你那个隐藏大小

214
00:07:00,040 --> 00:07:00,920
不是说随便写

215
00:07:00,920 --> 00:07:02,000
就是说你写的方式

216
00:07:02,079 --> 00:07:04,279
跟MLP没有太多区别

217
00:07:04,279 --> 00:07:04,920
就是说

218
00:07:05,040 --> 00:07:06,520
一般是128 256

219
00:07:06,520 --> 00:07:07,840
512 1024多

220
00:07:08,199 --> 00:07:09,080
很大很大的时候

221
00:07:09,080 --> 00:07:09,920
你用到1024

222
00:07:09,920 --> 00:07:12,680
一般就是128 256

223
00:07:12,800 --> 00:07:14,520
256是挺正常的一个大小

224
00:07:18,600 --> 00:07:19,120
问题七

225
00:07:19,120 --> 00:07:20,400
你为什么要撑个0.01

226
00:07:20,400 --> 00:07:21,439
0.01为什么

227
00:07:21,439 --> 00:07:24,319
是因为我们这本书就是这么写的

228
00:07:24,319 --> 00:07:25,639
我们这本书就基本上

229
00:07:25,639 --> 00:07:28,520
我们之前最早给大家介绍

230
00:07:29,160 --> 00:07:30,120
现行回归的时候

231
00:07:30,120 --> 00:07:32,360
我们就是用了0.01这个方差

232
00:07:32,680 --> 00:07:33,639
0.01这个方差

233
00:07:33,639 --> 00:07:34,680
就是说还不错

234
00:07:34,759 --> 00:07:36,400
就是说挺通用的

235
00:07:36,400 --> 00:07:38,600
就是说没有说这个东西很好

236
00:07:38,720 --> 00:07:39,720
没有说这个值很好

237
00:07:39,720 --> 00:07:41,160
我们有解释过很多次

238
00:07:41,160 --> 00:07:43,920
就在XVR那个初始化的时候

239
00:07:44,199 --> 00:07:44,840
解释过

240
00:07:44,840 --> 00:07:45,639
就是说这个值

241
00:07:45,639 --> 00:07:46,600
我们之所以用它

242
00:07:46,600 --> 00:07:47,879
是尽量我们整本书

243
00:07:47,879 --> 00:07:49,360
尽量用一个差不多的值

244
00:07:49,360 --> 00:07:50,960
就0.01的方差

245
00:07:51,280 --> 00:07:54,560
这个值在比较不那么深的网络时候

246
00:07:54,560 --> 00:07:55,759
效果还不错

247
00:07:56,280 --> 00:07:57,319
但是如果很深的时候

248
00:07:57,319 --> 00:07:59,399
当然你用更好一点的算法

249
00:07:59,399 --> 00:08:01,560
但是我们这个是一个很简单的

250
00:08:01,560 --> 00:08:02,800
单次隐藏层的网络

251
00:08:02,920 --> 00:08:03,879
所以用这个东西

252
00:08:03,879 --> 00:08:05,519
为了简洁性

253
00:08:08,800 --> 00:08:09,800
问题8

254
00:08:10,000 --> 00:08:10,959
看到一篇文章

255
00:08:10,959 --> 00:08:14,159
对视频用CN用LSTN做回归分析

256
00:08:14,439 --> 00:08:15,920
采用率是200赫兹

257
00:08:15,920 --> 00:08:18,199
但最后可以回归出500赫兹的频率信号

258
00:08:18,199 --> 00:08:20,639
这种东西是怎么样得出采样频率的

259
00:08:21,199 --> 00:08:24,079
采样频率规定之外的信息值

260
00:08:27,159 --> 00:08:28,079
我其实没看懂

261
00:08:28,199 --> 00:08:30,399
就是说你视频的采样频率是200赫兹

262
00:08:30,399 --> 00:08:32,240
为什么出来回归出500赫兹

263
00:08:32,279 --> 00:08:33,279
所有的信号

264
00:08:33,279 --> 00:08:33,879
频率信息

265
00:08:36,440 --> 00:08:38,320
我觉得你可能要仔细看一下

266
00:08:41,720 --> 00:08:42,759
你应该仔细看一下

267
00:08:42,960 --> 00:08:44,120
其实你这样子说

268
00:08:44,120 --> 00:08:45,200
我也不是特别清楚

269
00:08:45,200 --> 00:08:45,879
为什么是这样

270
00:08:45,879 --> 00:08:47,840
说不定是你看漏了一个地方

271
00:08:48,039 --> 00:08:48,840
OK

272
00:08:50,720 --> 00:08:52,960
RNN在长文本的时候效果不好

273
00:08:52,960 --> 00:08:54,840
但长文本多长

274
00:08:54,840 --> 00:08:57,320
还是RNN的隐藏向内有关系

275
00:08:59,960 --> 00:09:01,120
我很难告诉你说

276
00:09:01,120 --> 00:09:02,360
到底多长不行

277
00:09:02,560 --> 00:09:06,159
这个东西没有一个具体的数值

278
00:09:06,200 --> 00:09:09,000
所以我的建议是这样子的

279
00:09:09,000 --> 00:09:10,720
我的建议是不要用RNN

280
00:09:12,159 --> 00:09:14,480
用GRU或者LSTN都行

281
00:09:14,519 --> 00:09:15,879
就是说你在实际情况下

282
00:09:15,879 --> 00:09:17,039
不要去用RNN

283
00:09:18,360 --> 00:09:21,320
就是说GRU和LSTN

284
00:09:21,919 --> 00:09:23,000
没有太多坏处

285
00:09:23,000 --> 00:09:25,720
除了计算量多那么一点点之外

286
00:09:25,720 --> 00:09:26,720
没有太多坏处

287
00:09:26,720 --> 00:09:27,200
真的

288
00:09:27,560 --> 00:09:31,000
所以能尽量用GRU和LSTN就好

289
00:09:31,000 --> 00:09:32,279
所以你要去关心的

290
00:09:32,279 --> 00:09:34,240
不再是在实际中

291
00:09:34,600 --> 00:09:37,480
不要去关心RNN能处理多长

292
00:09:37,480 --> 00:09:39,840
你要关心你的GRU和LSTN

293
00:09:39,840 --> 00:09:40,759
能处理多长

294
00:09:41,000 --> 00:09:44,559
它我觉得我拍拍脑袋觉得

295
00:09:44,840 --> 00:09:47,519
你觉得差不多在100左右

296
00:09:48,519 --> 00:09:51,559
就你GRU和LSTN不要太

297
00:09:51,600 --> 00:09:54,240
长度最好不要超过100

298
00:09:55,080 --> 00:09:57,679
这是我的拍拍脑袋的直觉

299
00:09:57,720 --> 00:09:58,840
如果你超过100

300
00:09:59,080 --> 00:10:00,519
如果你要做到几百

301
00:10:00,519 --> 00:10:01,720
或者1000这种

302
00:10:02,399 --> 00:10:03,080
长度的话

303
00:10:03,440 --> 00:10:05,440
我建议考虑我们之后

304
00:10:05,440 --> 00:10:07,399
会介绍的注意力值

305
00:10:07,399 --> 00:10:08,600
就是BERT或者

306
00:10:08,600 --> 00:10:10,560
Transformer Attention这一块

307
00:10:10,759 --> 00:10:14,040
它能够更有效的去对长序列

308
00:10:14,040 --> 00:10:16,360
做一些建模

309
00:10:17,120 --> 00:10:17,720
OK

310
00:10:18,040 --> 00:10:20,360
所以但是如果你的反过来讲

311
00:10:20,360 --> 00:10:22,920
如果你的数据量不是那么大

312
00:10:22,920 --> 00:10:24,519
你不要处理那么长的时候

313
00:10:24,639 --> 00:10:27,840
GRU和LSTN都是很不错的选项

