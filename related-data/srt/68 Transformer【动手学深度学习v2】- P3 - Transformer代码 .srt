1
00:00:00,000 --> 00:00:03,200
现在我们有所有我们要的东西了

2
00:00:03,200 --> 00:00:04,280
Transformer的东西

3
00:00:04,280 --> 00:00:08,240
包括了Position Coding, Multi-Head

4
00:00:08,240 --> 00:00:10,400
然后之前我们讲过Tension

5
00:00:10,400 --> 00:00:12,839
现在我们就可以实现我们的Transformer

6
00:00:12,839 --> 00:00:13,960
我们Data也是一样的

7
00:00:13,960 --> 00:00:16,080
我们Data用的seq,to seq那个Data

8
00:00:16,080 --> 00:00:17,480
所以也不需要重新讲

9
00:00:17,480 --> 00:00:18,199
OK

10
00:00:18,199 --> 00:00:20,839
所以我们就直接要讲剩下Transformer

11
00:00:20,839 --> 00:00:21,879
最后那一点点

12
00:00:21,879 --> 00:00:24,000
就怎么样把东西给你合起来

13
00:00:26,400 --> 00:00:28,480
首先这个东西就是Point

14
00:00:28,640 --> 00:00:30,600
Position wise FFm

15
00:00:31,519 --> 00:00:32,840
说白了就是一个

16
00:00:32,840 --> 00:00:35,280
你看到就是一个全连线程

17
00:00:35,280 --> 00:00:36,359
两个全连线程

18
00:00:36,359 --> 00:00:37,240
一个reloop

19
00:00:37,520 --> 00:00:39,560
当然你告诉我Hidden size

20
00:00:40,359 --> 00:00:41,159
然后它怎么做

21
00:00:41,280 --> 00:00:43,039
就是PyTorch的

22
00:00:43,039 --> 00:00:44,240
它的默认的实现

23
00:00:44,399 --> 00:00:45,719
Dense的默认实现

24
00:00:45,719 --> 00:00:46,439
就是说

25
00:00:46,439 --> 00:00:49,159
当你的输入不是一个二维的时候

26
00:00:49,600 --> 00:00:50,960
它把前面那些维度

27
00:00:50,960 --> 00:00:52,799
都当做是你的样本维

28
00:00:53,439 --> 00:00:54,560
所以后面那个维度

29
00:00:54,760 --> 00:00:56,600
就是当做是featured

30
00:00:56,600 --> 00:00:57,560
所以它就这么做

31
00:00:57,560 --> 00:00:58,840
所以说白了

32
00:00:59,400 --> 00:01:01,000
虽然它的名字叫这个

33
00:01:01,000 --> 00:01:02,760
它说白了就是一个MLP

34
00:01:02,920 --> 00:01:04,200
就是一个单影

35
00:01:04,200 --> 00:01:04,840
单影间

36
00:01:05,000 --> 00:01:06,879
它实际上你看就是一个MLP

37
00:01:07,120 --> 00:01:10,280
只是说它就是一个单影参数的MLP

38
00:01:10,280 --> 00:01:11,920
但是你的输入不再是一个二维

39
00:01:11,920 --> 00:01:13,680
你的输入是一个三维的东西

40
00:01:13,680 --> 00:01:15,240
所以它的名字叫做这个东西

41
00:01:15,840 --> 00:01:16,359
OK

42
00:01:16,359 --> 00:01:17,320
就是名字取得好

43
00:01:17,920 --> 00:01:19,480
就是Fancy

44
00:01:19,480 --> 00:01:21,719
但是实际上就是一个MLP

45
00:01:23,520 --> 00:01:24,240
这个我们就不管了

46
00:01:24,359 --> 00:01:25,680
这个东西反正就是

47
00:01:25,760 --> 00:01:27,320
你说我告诉你一个

48
00:01:27,320 --> 00:01:29,240
448的东西出去

49
00:01:29,800 --> 00:01:31,120
我说448就是说

50
00:01:31,120 --> 00:01:34,920
反正你就是一个234的东西出去

51
00:01:34,920 --> 00:01:36,640
那么就是把这个4会变成一个8

52
00:01:36,880 --> 00:01:40,000
就会对你后面维度发现一点变化

53
00:01:40,520 --> 00:01:41,000
OK

54
00:01:43,800 --> 00:01:44,840
另外一个是说

55
00:01:45,240 --> 00:01:46,640
LayerLong和BatchLong

56
00:01:46,960 --> 00:01:47,960
BatchLong你就可以看到

57
00:01:47,960 --> 00:01:49,040
是说反正是

58
00:01:49,800 --> 00:01:51,880
你一个同样一个东西出来

59
00:01:52,040 --> 00:01:53,280
就是说有东西进去

60
00:01:53,280 --> 00:01:54,200
就是说LayerLong

61
00:01:54,359 --> 00:01:55,840
就是把每个样本

62
00:01:56,040 --> 00:01:58,320
就变成了均值为0方程为1

63
00:01:58,320 --> 00:02:00,519
但是BatchLong就是每一个特征

64
00:02:00,640 --> 00:02:02,599
就是一列变成了这个东西

65
00:02:02,599 --> 00:02:04,599
所以它就是切的不一样

66
00:02:04,960 --> 00:02:07,680
用起来就是一个BatchLong和LayerLong

67
00:02:08,120 --> 00:02:09,400
反正参数都一样

68
00:02:09,719 --> 00:02:11,199
所以就是调用的时候不一样

69
00:02:13,199 --> 00:02:16,280
另外一个是用参商连接怎么做

70
00:02:16,759 --> 00:02:18,080
就给你一个

71
00:02:19,599 --> 00:02:20,680
你先不管这个东西

72
00:02:20,719 --> 00:02:21,840
你看一下是说

73
00:02:21,840 --> 00:02:23,920
我给一个X给一个Y的时候

74
00:02:23,920 --> 00:02:26,080
它就把Y

75
00:02:26,200 --> 00:02:30,200
就是你Transformer的中间一块的输出

76
00:02:30,319 --> 00:02:32,560
那个Y dropout一下

77
00:02:33,280 --> 00:02:34,520
加上你的输入

78
00:02:34,520 --> 00:02:36,159
就加上你的Y就是

79
00:02:36,480 --> 00:02:38,560
X进入某一个东西的输出

80
00:02:39,000 --> 00:02:40,680
所以resizure就是说

81
00:02:40,680 --> 00:02:42,760
本来就是把你的输入和输出加起来

82
00:02:42,760 --> 00:02:43,879
然后用了一个dropout

83
00:02:44,000 --> 00:02:45,960
然后再加一个LayerLong

84
00:02:46,560 --> 00:02:47,040
OK

85
00:02:47,080 --> 00:02:48,159
就是LayerLong

86
00:02:48,439 --> 00:02:48,680
OK

87
00:02:48,680 --> 00:02:50,000
这就是你那个AddLong

88
00:02:50,000 --> 00:02:51,560
就刚刚那个图里面的AddLong

89
00:02:51,560 --> 00:02:52,159
那个东西

90
00:02:54,479 --> 00:02:55,439
这个也不用管

91
00:02:55,439 --> 00:02:59,479
反正这个东西不会改变输出的形状

92
00:03:01,639 --> 00:03:02,199
好

93
00:03:02,199 --> 00:03:05,000
接下来看就是一个EncoderBlock

94
00:03:05,560 --> 00:03:08,520
就刚刚就是一个TransformerBlock

95
00:03:09,039 --> 00:03:09,759
里面什么东西

96
00:03:10,599 --> 00:03:11,479
有一个

97
00:03:11,599 --> 00:03:14,520
首先有一个Attention的一个

98
00:03:14,520 --> 00:03:15,840
Multi-head Attention

99
00:03:17,560 --> 00:03:17,920
然后

100
00:03:18,920 --> 00:03:20,280
有一个AddLong

101
00:03:20,440 --> 00:03:21,840
然后有个FFN

102
00:03:22,120 --> 00:03:23,080
又一个AddLong

103
00:03:23,840 --> 00:03:25,360
就这个东西就QuerySize

104
00:03:25,360 --> 00:03:26,000
就是说

105
00:03:26,160 --> 00:03:26,720
KeySize

106
00:03:26,720 --> 00:03:27,280
QuerySize

107
00:03:27,280 --> 00:03:28,200
ValueSize这东西

108
00:03:28,200 --> 00:03:29,560
反正就是挺啰里吧嗦的

109
00:03:29,560 --> 00:03:30,280
说白了

110
00:03:30,600 --> 00:03:31,200
最后的最后

111
00:03:31,320 --> 00:03:32,360
其实这些东西都长一样

112
00:03:32,360 --> 00:03:33,240
都是一个

113
00:03:33,280 --> 00:03:34,120
都等于一个数

114
00:03:34,280 --> 00:03:35,360
所以不要被他吓到

115
00:03:35,360 --> 00:03:36,040
其实说白了

116
00:03:36,040 --> 00:03:36,640
最后的

117
00:03:36,640 --> 00:03:38,320
虽然这么写是写了很多东西

118
00:03:38,760 --> 00:03:39,680
就各种参数

119
00:03:39,720 --> 00:03:40,960
其实最后就等于一个

120
00:03:40,960 --> 00:03:42,280
等于比如说1024

121
00:03:42,280 --> 00:03:43,960
还是等于768

122
00:03:43,960 --> 00:03:44,840
反正就是一个数

123
00:03:44,840 --> 00:03:45,680
所以你就

124
00:03:46,160 --> 00:03:47,440
虽然写起来很啰嗦

125
00:03:47,479 --> 00:03:48,680
实际上用的时候

126
00:03:48,680 --> 00:03:49,199
就

127
00:03:49,319 --> 00:03:50,599
你会看到这个东西很简单

128
00:03:50,599 --> 00:03:51,039
对吧

129
00:03:51,800 --> 00:03:52,719
就是说

130
00:03:53,840 --> 00:03:54,359
他怎么做

131
00:03:54,479 --> 00:03:55,199
Fold怎么做

132
00:03:58,159 --> 00:03:59,439
我换个行这里

133
00:04:04,719 --> 00:04:06,120
所谓的Self-Attention

134
00:04:06,120 --> 00:04:07,000
就是把Key

135
00:04:07,039 --> 00:04:07,520
Value

136
00:04:07,560 --> 00:04:07,960
Query

137
00:04:08,159 --> 00:04:10,280
就是把X放三下丢进去

138
00:04:10,319 --> 00:04:11,280
就是Self-Attention了

139
00:04:11,319 --> 00:04:11,759
对吧

140
00:04:12,520 --> 00:04:14,319
然后这个东西是Multi-head的

141
00:04:14,560 --> 00:04:15,159
反正Multi-head

142
00:04:15,199 --> 00:04:16,000
已经藏在里面了

143
00:04:16,000 --> 00:04:16,720
就是它

144
00:04:16,720 --> 00:04:17,360
内容

145
00:04:17,400 --> 00:04:18,360
自己把你做掉了

146
00:04:18,360 --> 00:04:18,880
就用起来

147
00:04:18,880 --> 00:04:20,320
跟用Attention是一样的

148
00:04:20,360 --> 00:04:21,520
然后把你Value的Length

149
00:04:21,520 --> 00:04:22,840
就是说你的X的Value的Length

150
00:04:22,840 --> 00:04:23,560
也传进去

151
00:04:23,560 --> 00:04:24,640
如果你有的话

152
00:04:25,360 --> 00:04:25,840
然后

153
00:04:26,600 --> 00:04:27,560
这是它的输出

154
00:04:27,840 --> 00:04:28,760
就是它这个Y

155
00:04:29,360 --> 00:04:31,320
它XY放到Add-a-Long里面

156
00:04:31,760 --> 00:04:32,040
好

157
00:04:32,040 --> 00:04:32,800
做成Y

158
00:04:33,120 --> 00:04:34,680
接下来你就把这个Y放到

159
00:04:35,160 --> 00:04:36,720
全连接层FFN里面

160
00:04:37,600 --> 00:04:39,080
然后和它的输入

161
00:04:39,080 --> 00:04:39,920
和它的输入

162
00:04:40,000 --> 00:04:41,320
又放到一个Add-a-Long里面

163
00:04:41,760 --> 00:04:42,400
OK

164
00:04:42,600 --> 00:04:43,440
这就实现完了

165
00:04:43,440 --> 00:04:44,160
就是说说白了

166
00:04:44,160 --> 00:04:44,640
就是刚刚

167
00:04:45,160 --> 00:04:46,400
就是一个Transformer block

168
00:04:46,400 --> 00:04:47,760
里面有一个不是有一个

169
00:04:47,760 --> 00:04:48,840
就是Encode的block

170
00:04:49,160 --> 00:04:50,240
Decode还没说

171
00:04:50,240 --> 00:04:51,360
Encode的就是一个

172
00:04:51,960 --> 00:04:52,840
Separation

173
00:04:53,240 --> 00:04:54,120
一个Add-a-Long

174
00:04:54,640 --> 00:04:55,880
然后再加一个FFN

175
00:04:55,880 --> 00:04:56,720
再加一个Add-a-Long

176
00:04:56,720 --> 00:04:57,280
就三下

177
00:04:57,280 --> 00:04:57,680
对吧

178
00:04:59,080 --> 00:04:59,640
OK

179
00:05:00,720 --> 00:05:02,000
然后你可以看一下

180
00:05:02,000 --> 00:05:02,800
就是反正

181
00:05:02,840 --> 00:05:03,520
就是说

182
00:05:05,560 --> 00:05:06,480
这个东西反正

183
00:05:06,480 --> 00:05:07,760
你可以不用太管这个东西

184
00:05:07,760 --> 00:05:08,560
反正就是

185
00:05:09,280 --> 00:05:11,360
一个长为Batch Size为2

186
00:05:11,640 --> 00:05:12,760
长度为100

187
00:05:12,760 --> 00:05:14,600
Dimension是24的东西进去

188
00:05:14,880 --> 00:05:15,920
出来之后

189
00:05:15,920 --> 00:05:16,879
还是一个Shape

190
00:05:16,879 --> 00:05:18,800
还是Batch Size为2

191
00:05:19,000 --> 00:05:20,160
Sequence Length100

192
00:05:20,400 --> 00:05:21,480
Dimension为24

193
00:05:21,720 --> 00:05:22,000
就是说

194
00:05:22,000 --> 00:05:23,439
虽然你这个东西看着也很复杂

195
00:05:23,439 --> 00:05:24,840
就2424什么

196
00:05:25,480 --> 00:05:26,240
但实际上来说

197
00:05:26,240 --> 00:05:26,680
一般来说

198
00:05:26,680 --> 00:05:27,439
反正就是

199
00:05:27,439 --> 00:05:28,720
你的Dimension为24的话

200
00:05:28,720 --> 00:05:29,920
出去反正都是

201
00:05:30,640 --> 00:05:32,720
都是24

202
00:05:33,040 --> 00:05:34,360
中间当然你可以说

203
00:05:34,639 --> 00:05:36,439
可以把一个隐藏层

204
00:05:36,439 --> 00:05:37,720
弄大一点是可以的

205
00:05:38,080 --> 00:05:39,240
或者Multi-head是8

206
00:05:39,240 --> 00:05:39,840
这个地方

207
00:05:40,639 --> 00:05:41,639
但是一般来说

208
00:05:41,639 --> 00:05:43,160
就是也挺简单的

209
00:05:43,160 --> 00:05:43,600
对吧

210
00:05:43,639 --> 00:05:45,120
就是输入输出不变

211
00:05:45,319 --> 00:05:47,120
主要是你要知道是说

212
00:05:47,720 --> 00:05:48,800
丢进一个Layer之后

213
00:05:48,800 --> 00:05:50,399
你不会对你的输入输出

214
00:05:50,399 --> 00:05:51,199
发生变化

215
00:05:51,480 --> 00:05:52,680
所以就导致你很容易

216
00:05:52,680 --> 00:05:53,800
把你N个东西

217
00:05:53,800 --> 00:05:54,519
给你弄起来

218
00:05:54,519 --> 00:05:55,160
就可以

219
00:05:56,240 --> 00:05:57,560
所以这样子

220
00:05:57,560 --> 00:05:58,120
我们就可以做

221
00:05:58,120 --> 00:06:00,040
我们的Transformer Encoder了

222
00:06:01,360 --> 00:06:02,720
Encoder里面

223
00:06:02,879 --> 00:06:03,720
基本上就是说

224
00:06:03,720 --> 00:06:04,560
你能看到

225
00:06:06,120 --> 00:06:07,000
一个重要的参数

226
00:06:07,000 --> 00:06:08,120
是Number of Hiddens

227
00:06:08,319 --> 00:06:09,840
就是你能隐藏的大小

228
00:06:10,280 --> 00:06:12,280
它输入

229
00:06:12,480 --> 00:06:14,240
输入首先基于Embedded

230
00:06:14,439 --> 00:06:15,519
我们之前都是一样的

231
00:06:15,519 --> 00:06:16,920
基于Embedded出来之后

232
00:06:16,920 --> 00:06:18,000
会得到一个

233
00:06:18,040 --> 00:06:19,040
Number of Hiddens

234
00:06:19,040 --> 00:06:20,040
长的一些向量

235
00:06:20,600 --> 00:06:23,120
然后会有个Position Encoding

236
00:06:23,759 --> 00:06:25,199
然后如果Number of Layers

237
00:06:25,199 --> 00:06:25,519
就是说

238
00:06:25,519 --> 00:06:27,560
你有多少个Transformer block

239
00:06:28,000 --> 00:06:29,280
然后把它全部存起来

240
00:06:29,280 --> 00:06:31,160
就是这种东西都存起来

241
00:06:32,120 --> 00:06:34,600
你Forward其实也挺简单的

242
00:06:34,600 --> 00:06:34,879
对吧

243
00:06:34,879 --> 00:06:35,439
你给看一下

244
00:06:38,360 --> 00:06:40,639
首先你的X进来

245
00:06:40,639 --> 00:06:41,879
就是那些Token进来

246
00:06:42,199 --> 00:06:43,879
先丢到Embedded层

247
00:06:44,720 --> 00:06:45,319
Embedded层

248
00:06:45,439 --> 00:06:46,680
这里有个比较有意思的东西

249
00:06:46,680 --> 00:06:46,960
是说

250
00:06:46,960 --> 00:06:48,319
它会乘以一个

251
00:06:48,319 --> 00:06:49,480
你的Hidden Size的

252
00:06:49,480 --> 00:06:50,400
Square Root

253
00:06:51,120 --> 00:06:52,079
是因为

254
00:06:53,439 --> 00:06:54,360
Embedded层

255
00:06:54,600 --> 00:06:55,120
它出来一个

256
00:06:55,120 --> 00:06:55,960
成为D的东西

257
00:06:56,319 --> 00:06:57,040
你可以经常

258
00:06:57,040 --> 00:06:58,120
我们会把那个东西的

259
00:06:58,120 --> 00:06:58,439
None

260
00:06:58,600 --> 00:06:59,400
就是L2 None

261
00:06:59,400 --> 00:07:00,040
缩成1

262
00:07:00,040 --> 00:07:00,800
所以它都是

263
00:07:00,800 --> 00:07:01,639
如果D越大

264
00:07:01,759 --> 00:07:03,160
它的数值越小

265
00:07:03,800 --> 00:07:05,120
但是Position Encoding

266
00:07:05,120 --> 00:07:05,720
都是一些

267
00:07:05,720 --> 00:07:06,920
正义到负义之间的东西

268
00:07:06,920 --> 00:07:07,759
就是说正义到负义之间

269
00:07:07,759 --> 00:07:09,280
都是正义到负义

270
00:07:09,439 --> 00:07:10,199
Scale的东西

271
00:07:10,360 --> 00:07:12,480
所以这种东西通常比较小

272
00:07:12,480 --> 00:07:13,480
特别D越大

273
00:07:13,480 --> 00:07:15,000
它的每个元素值越小

274
00:07:15,040 --> 00:07:16,400
所以你就把它乘一个

275
00:07:16,400 --> 00:07:16,800
这东西

276
00:07:16,920 --> 00:07:18,600
使得它这个东西

277
00:07:19,040 --> 00:07:20,759
跟你的Position Encoding

278
00:07:20,759 --> 00:07:21,319
那个P

279
00:07:21,480 --> 00:07:23,800
它的数值差不多大小

280
00:07:24,120 --> 00:07:24,840
所以就为什么

281
00:07:24,840 --> 00:07:25,360
乘了一个

282
00:07:25,360 --> 00:07:26,319
Square Root of

283
00:07:26,319 --> 00:07:27,360
那个D的东西

284
00:07:28,480 --> 00:07:28,920
这个东西

285
00:07:28,920 --> 00:07:30,200
是为了Visualization用的

286
00:07:30,360 --> 00:07:31,720
就是我们最后为了看用的

287
00:07:32,520 --> 00:07:33,960
然后你做

288
00:07:34,400 --> 00:07:35,480
你做Transformer

289
00:07:35,480 --> 00:07:36,280
就是

290
00:07:36,560 --> 00:07:38,439
你反正有N个Transformer Layer

291
00:07:39,319 --> 00:07:40,960
然后每一次就是

292
00:07:41,319 --> 00:07:42,720
把X丢进去

293
00:07:42,960 --> 00:07:43,760
出来一个X

294
00:07:43,760 --> 00:07:44,320
就是

295
00:07:44,760 --> 00:07:45,600
做完一下

296
00:07:46,760 --> 00:07:48,040
之所以我们这个地方

297
00:07:48,040 --> 00:07:49,320
没有用那个

298
00:07:49,720 --> 00:07:51,680
用N-Sequential把它串起来

299
00:07:51,680 --> 00:07:52,720
就纯粹是因为这样子

300
00:07:52,720 --> 00:07:53,440
我能够

301
00:07:54,720 --> 00:07:55,920
把你这个

302
00:07:56,760 --> 00:07:58,760
把这个东西给存起来

303
00:07:59,160 --> 00:07:59,720
就说白了

304
00:07:59,920 --> 00:08:00,720
反正就是

305
00:08:01,400 --> 00:08:02,640
就是一个Sequential的东西

306
00:08:02,720 --> 00:08:03,960
就是一层一层丢进去

307
00:08:03,960 --> 00:08:05,880
然后大小还不会

308
00:08:05,920 --> 00:08:07,520
就是说你的输入输出

309
00:08:07,520 --> 00:08:08,560
还不会发生变化

310
00:08:08,880 --> 00:08:10,040
这就是你的

311
00:08:11,040 --> 00:08:13,240
Transformer Encoder

312
00:08:13,400 --> 00:08:13,920
对吧

313
00:08:13,960 --> 00:08:15,640
就是Embedding

314
00:08:15,640 --> 00:08:16,680
加一个Position

315
00:08:17,080 --> 00:08:17,840
Encoding

316
00:08:17,879 --> 00:08:20,200
然后再输入到你的N层

317
00:08:20,400 --> 00:08:22,720
Transformer Layer里面

318
00:08:22,720 --> 00:08:24,000
就完事了

319
00:08:27,240 --> 00:08:29,120
然后你可以反正创建

320
00:08:29,120 --> 00:08:29,840
一堆东西出来

321
00:08:30,360 --> 00:08:31,240
创建一堆东西出来

322
00:08:31,240 --> 00:08:31,840
就是

323
00:08:32,440 --> 00:08:33,879
核心思想是说

324
00:08:33,920 --> 00:08:36,800
假设你的Hidden Size是24的话

325
00:08:38,440 --> 00:08:39,360
你的Multi-Head

326
00:08:39,360 --> 00:08:41,120
Multi-Head是不会改变

327
00:08:42,200 --> 00:08:42,720
输出的

328
00:08:42,879 --> 00:08:43,639
Multi-Head是说

329
00:08:43,639 --> 00:08:45,600
我要把它切成多少个

330
00:08:45,600 --> 00:08:46,120
在里面

331
00:08:46,480 --> 00:08:47,639
Multi-Head我们用的是8

332
00:08:47,759 --> 00:08:48,240
这个地方

333
00:08:48,600 --> 00:08:49,200
然后Layer

334
00:08:49,200 --> 00:08:50,320
Number of Layers用的是2

335
00:08:50,519 --> 00:08:51,480
0.5是dropout

336
00:08:52,399 --> 00:08:53,279
然后就是说

337
00:08:53,279 --> 00:08:54,560
你给一个2乘10

338
00:08:54,560 --> 00:08:55,840
就是说Batch Size是2

339
00:08:55,840 --> 00:08:57,000
然后长度是100

340
00:08:57,000 --> 00:08:57,960
东西进去的话

341
00:08:59,159 --> 00:09:01,080
那么你的出来就是Batch Size

342
00:09:01,360 --> 00:09:03,039
乘以长度100

343
00:09:03,080 --> 00:09:04,200
再乘以24

344
00:09:04,200 --> 00:09:05,920
24就是Hidden Size

345
00:09:06,120 --> 00:09:06,399
OK

346
00:09:06,399 --> 00:09:07,840
就是Encoder的输出

347
00:09:08,840 --> 00:09:09,600
Encoder输出

348
00:09:09,800 --> 00:09:11,120
就会放到Decoder里面

349
00:09:11,120 --> 00:09:11,519
对吧

350
00:09:12,040 --> 00:09:12,720
然后Decoder

351
00:09:13,000 --> 00:09:14,840
就是首先看一下Decoder Block

352
00:09:15,600 --> 00:09:16,720
它跟Encoder有点像

353
00:09:17,840 --> 00:09:19,480
但是稍微会麻烦一点点

354
00:09:19,480 --> 00:09:20,200
就是说

355
00:09:20,440 --> 00:09:22,800
首先它有一个Attention

356
00:09:23,720 --> 00:09:24,560
还有两个Attention

357
00:09:24,560 --> 00:09:26,240
就是中间那个Attention

358
00:09:27,000 --> 00:09:27,639
这个是一样的

359
00:09:27,639 --> 00:09:28,280
就是

360
00:09:29,200 --> 00:09:30,680
这样子会有三个Add-on

361
00:09:30,680 --> 00:09:31,639
和一个FFN

362
00:09:32,080 --> 00:09:32,440
OK

363
00:09:32,960 --> 00:09:35,200
然后它还得记一下I这个东西

364
00:09:35,200 --> 00:09:37,840
我给大家解释一下

365
00:09:37,840 --> 00:09:38,600
为什么GUI

366
00:09:40,879 --> 00:09:41,440
就首先

367
00:09:42,879 --> 00:09:44,640
首先它有个State传过来

368
00:09:44,640 --> 00:09:46,320
State是哪里来的呢

369
00:09:47,120 --> 00:09:48,480
State里面有

370
00:09:50,400 --> 00:09:52,320
State里面其实是有三个东西

371
00:09:52,480 --> 00:09:54,680
一个是你的Encoder的输出

372
00:09:54,720 --> 00:09:57,320
一个是你的Encoder的ValidName

373
00:09:57,560 --> 00:09:58,320
第三个东西

374
00:09:58,320 --> 00:09:58,960
我们再解释

375
00:09:58,960 --> 00:10:00,600
第三个东西是存了一个东西

376
00:10:00,600 --> 00:10:01,640
存了一个说

377
00:10:01,680 --> 00:10:03,200
过去的那一些东西

378
00:10:05,800 --> 00:10:07,480
就如果你没有的话

379
00:10:07,480 --> 00:10:08,400
就如果没有的话

380
00:10:08,400 --> 00:10:09,000
就是Training

381
00:10:09,000 --> 00:10:09,600
Training的话

382
00:10:09,600 --> 00:10:10,920
其实说白了就是

383
00:10:12,680 --> 00:10:13,360
就是X

384
00:10:13,520 --> 00:10:13,879
不然的话

385
00:10:13,879 --> 00:10:15,640
我就是一直在空开了起来

386
00:10:15,640 --> 00:10:17,040
等会我们再来讲这个东西

387
00:10:17,040 --> 00:10:19,240
这是一些Key-Value的东西

388
00:10:20,960 --> 00:10:21,560
OK

389
00:10:24,000 --> 00:10:26,280
所以我们就直接跳到

390
00:10:26,280 --> 00:10:27,640
叫ValidName也是说

391
00:10:27,640 --> 00:10:28,480
ValidName是说

392
00:10:28,480 --> 00:10:29,720
如果你做

393
00:10:30,000 --> 00:10:31,360
Training的时候

394
00:10:32,000 --> 00:10:34,879
我要把后面算第I个输出的时候

395
00:10:34,879 --> 00:10:36,639
我把后面那些东西遮掉

396
00:10:36,879 --> 00:10:38,720
所以就是一定要有个ValidName

397
00:10:40,240 --> 00:10:42,279
但是对Prediction的时候不需要

398
00:10:42,279 --> 00:10:43,000
Prediction的时候

399
00:10:43,000 --> 00:10:44,159
反正就是一个一个过来

400
00:10:44,159 --> 00:10:45,200
反正你也看不到之后

401
00:10:45,200 --> 00:10:46,159
所以就不需要了

402
00:10:47,439 --> 00:10:48,399
然后你可以看到

403
00:10:48,399 --> 00:10:49,240
就是它的东西

404
00:10:53,639 --> 00:10:55,559
首先要Tension进来

405
00:10:56,240 --> 00:10:57,639
看到它的X

406
00:10:57,759 --> 00:10:59,759
然后这是它的Query

407
00:10:59,799 --> 00:11:01,320
它的Key和Value

408
00:11:02,279 --> 00:11:04,039
假设你是Training的时候

409
00:11:04,599 --> 00:11:05,679
假设你是Training的时候

410
00:11:05,679 --> 00:11:06,719
它其实就是本身

411
00:11:07,079 --> 00:11:08,719
你的Key和Value就是X本身

412
00:11:08,719 --> 00:11:09,799
就是说你是

413
00:11:10,240 --> 00:11:12,000
但是你做Prediction的时候

414
00:11:12,000 --> 00:11:12,360
不一样

415
00:11:12,360 --> 00:11:12,599
对吧

416
00:11:12,599 --> 00:11:13,360
Prediction的时候

417
00:11:13,360 --> 00:11:14,319
你的Key和Value

418
00:11:14,319 --> 00:11:16,399
是之前的那一些输出的东西

419
00:11:16,399 --> 00:11:17,159
做在这里

420
00:11:17,279 --> 00:11:18,480
所以这个就是说

421
00:11:18,679 --> 00:11:20,000
如果是在Prediction的时候

422
00:11:20,279 --> 00:11:22,319
它要把之前你看到那些东西

423
00:11:22,599 --> 00:11:24,240
要不断的给你存在里面

424
00:11:24,240 --> 00:11:25,000
不断的就是说

425
00:11:25,279 --> 00:11:26,519
慢慢的把这些Key-Value

426
00:11:26,519 --> 00:11:27,240
Pair联系起来

427
00:11:27,240 --> 00:11:29,799
就是在做T时刻的输出的时候

428
00:11:30,079 --> 00:11:31,519
要把前面T

429
00:11:31,959 --> 00:11:33,079
所有时刻的输出

430
00:11:33,680 --> 00:11:34,520
那个东西输入

431
00:11:34,840 --> 00:11:36,240
全部把它空开了起来

432
00:11:37,240 --> 00:11:38,400
这个东西就干这个事情

433
00:11:39,480 --> 00:11:40,200
之所以这么做

434
00:11:40,320 --> 00:11:40,960
是因为这样子

435
00:11:40,960 --> 00:11:42,560
我就不需要在外面的东西

436
00:11:42,560 --> 00:11:43,240
写这个东西

437
00:11:43,480 --> 00:11:44,759
我在模型内部

438
00:11:44,759 --> 00:11:47,360
就把之前的那些输出

439
00:11:47,440 --> 00:11:48,240
全部给你

440
00:11:48,680 --> 00:11:49,480
存在这个地方

441
00:11:49,480 --> 00:11:51,360
所以到之前调用API的时候

442
00:11:51,480 --> 00:11:53,080
就不会发生什么

443
00:11:54,240 --> 00:11:55,280
跟之前不一样

444
00:11:56,000 --> 00:11:56,639
OK

445
00:11:56,920 --> 00:11:57,879
所以说白了

446
00:11:58,320 --> 00:11:59,640
Training就是Self-Attention

447
00:11:59,640 --> 00:12:00,720
在Prediction的时候

448
00:12:00,840 --> 00:12:03,000
就是用的是前面那些输出

449
00:12:03,720 --> 00:12:04,680
前面时刻的输出

450
00:12:04,800 --> 00:12:05,560
我没有讲过

451
00:12:05,960 --> 00:12:06,080
好

452
00:12:06,080 --> 00:12:06,800
那就Add-A-Long

453
00:12:07,639 --> 00:12:09,040
第二个是说第二个Tension

454
00:12:09,040 --> 00:12:09,800
第二个Tension看一下

455
00:12:09,800 --> 00:12:10,360
就是说

456
00:12:10,759 --> 00:12:12,280
Y就是第一个的输出

457
00:12:12,280 --> 00:12:12,560
对吧

458
00:12:12,560 --> 00:12:13,400
就这个东西的输出

459
00:12:13,400 --> 00:12:13,840
对吧

460
00:12:13,960 --> 00:12:16,040
然后它的Key和Value

461
00:12:16,680 --> 00:12:19,320
就是来自于你的Encoded Output

462
00:12:21,560 --> 00:12:22,160
OK

463
00:12:22,600 --> 00:12:24,160
就是说就跟我们之前

464
00:12:24,360 --> 00:12:25,120
Seq-to-Seq

465
00:12:25,120 --> 00:12:26,040
Tension是一样的

466
00:12:26,200 --> 00:12:26,920
它的Key-Value

467
00:12:26,920 --> 00:12:28,040
都来自于前一个

468
00:12:28,040 --> 00:12:30,560
就编码器的输出

469
00:12:31,320 --> 00:12:32,040
然后当然是说

470
00:12:32,039 --> 00:12:33,639
你用的是编码器的Valid Length

471
00:12:34,639 --> 00:12:35,159
这样子的话

472
00:12:35,159 --> 00:12:36,559
你能把那些Padding去掉

473
00:12:36,639 --> 00:12:38,519
这个地方就是加了Decode

474
00:12:38,519 --> 00:12:40,279
就是说Decode的Valid Length

475
00:12:40,279 --> 00:12:41,639
就是说在你Predict的时候

476
00:12:41,639 --> 00:12:42,279
不要看后面

477
00:12:42,439 --> 00:12:43,039
就Training的时候

478
00:12:43,039 --> 00:12:44,319
不要看后面那些东西

479
00:12:45,559 --> 00:12:47,480
然后最后又Add-A-Long

480
00:12:47,480 --> 00:12:48,199
拿到Z

481
00:12:48,199 --> 00:12:48,719
Z的话

482
00:12:48,719 --> 00:12:50,279
反正就是放到一个FFN里面

483
00:12:50,279 --> 00:12:51,679
然后Add-A-Long就行了

484
00:12:52,719 --> 00:12:55,360
所以Decoder和Encoder的区别

485
00:12:55,519 --> 00:12:56,360
就Decoder的时候

486
00:12:56,360 --> 00:12:58,000
在做Prediction的时候

487
00:12:58,079 --> 00:12:59,399
那些输入的Key和Value

488
00:12:59,399 --> 00:13:00,439
它会发生变化

489
00:13:00,639 --> 00:13:01,879
然后另外一个时候

490
00:13:01,879 --> 00:13:03,200
它有多了一层这个东西

491
00:13:03,360 --> 00:13:06,439
它是来去拿Encoder的输出

492
00:13:06,480 --> 00:13:07,039
OK

493
00:13:07,039 --> 00:13:08,080
但是实际上本质上

494
00:13:08,080 --> 00:13:09,159
也没什么区别

495
00:13:09,320 --> 00:13:10,559
本质上你看的话

496
00:13:10,679 --> 00:13:12,279
就是说我给一个

497
00:13:12,679 --> 00:13:14,439
2124的东西进来

498
00:13:14,639 --> 00:13:15,759
它输出也是自己

499
00:13:16,000 --> 00:13:17,399
就形状不会发生变化

500
00:13:17,679 --> 00:13:18,240
OK

501
00:13:18,480 --> 00:13:19,480
我就不仔细过了

502
00:13:20,919 --> 00:13:21,519
好

503
00:13:22,039 --> 00:13:23,480
就Transformer Decode

504
00:13:23,879 --> 00:13:24,919
Decode的那个东西

505
00:13:25,240 --> 00:13:26,360
就跟Encoder写起来

506
00:13:26,360 --> 00:13:28,679
就我觉得是没什么区别的

507
00:13:28,679 --> 00:13:29,440
就反正

508
00:13:29,680 --> 00:13:32,200
就你要多少个Embedding

509
00:13:32,400 --> 00:13:33,200
Position Embedding

510
00:13:33,560 --> 00:13:34,640
然后把这些Block

511
00:13:34,680 --> 00:13:36,000
全部放在这里面

512
00:13:36,520 --> 00:13:38,000
然后最后的最后

513
00:13:38,000 --> 00:13:39,960
当然你需要一个Dense Layer做输出

514
00:13:40,320 --> 00:13:42,440
Dense Layer我们是用的

515
00:13:42,480 --> 00:13:44,040
我们是用Multicap Size输出

516
00:13:44,160 --> 00:13:46,240
这样子我们能做英语和法语翻译

517
00:13:47,280 --> 00:13:48,520
然后Unit State

518
00:13:48,720 --> 00:13:51,600
就是说你的Encoder Output

519
00:13:51,800 --> 00:13:53,400
和它的Width Length

520
00:13:53,600 --> 00:13:54,320
而这些State

521
00:13:54,520 --> 00:13:55,400
反正我就是每一层

522
00:13:55,400 --> 00:13:57,160
我给它先去个Long

523
00:13:58,159 --> 00:14:00,360
所以这个东西是用来存

524
00:14:00,719 --> 00:14:02,240
预测的时候用来存东西用的

525
00:14:04,240 --> 00:14:07,199
然后反正你可以看到

526
00:14:09,199 --> 00:14:10,719
Forward其实没本子区别

527
00:14:10,839 --> 00:14:11,759
Forward就是

528
00:14:13,240 --> 00:14:14,120
Embedding进来

529
00:14:14,120 --> 00:14:14,679
乘一下

530
00:14:14,679 --> 00:14:16,199
然后放到Position Encoding

531
00:14:16,679 --> 00:14:17,519
我就

532
00:14:18,039 --> 00:14:19,000
这里写的啰嗦点

533
00:14:19,039 --> 00:14:19,959
主要是把这些Weight

534
00:14:19,959 --> 00:14:20,679
给你存下来

535
00:14:20,679 --> 00:14:22,360
给大家画用的

536
00:14:22,679 --> 00:14:24,519
然后反正每个Block

537
00:14:24,519 --> 00:14:26,159
就是把State X丢进去

538
00:14:26,159 --> 00:14:26,959
然后拿回一个

539
00:14:27,480 --> 00:14:28,719
更新的X的State

540
00:14:28,879 --> 00:14:31,039
就是做N下

541
00:14:31,199 --> 00:14:32,279
就是你有N个层

542
00:14:32,559 --> 00:14:33,319
后面这些东西

543
00:14:33,319 --> 00:14:34,199
就是把你这个东西

544
00:14:34,199 --> 00:14:34,839
Weight存起来

545
00:14:34,839 --> 00:14:36,079
给大家Visualize用的

546
00:14:36,639 --> 00:14:38,279
最后拿到X之后

547
00:14:38,279 --> 00:14:39,159
做一个Dense

548
00:14:40,279 --> 00:14:42,159
这样子就拿到输出了

549
00:14:42,600 --> 00:14:44,120
Ok这样子就是说

550
00:14:44,120 --> 00:14:45,159
Dense还是一样的

551
00:14:46,360 --> 00:14:47,559
对于每一个序列中的

552
00:14:47,559 --> 00:14:49,000
每一个样本做Dense

553
00:14:49,399 --> 00:14:50,679
如果强度是100的话

554
00:14:50,879 --> 00:14:52,039
就会拿到一个

555
00:14:52,600 --> 00:14:53,600
每100个元素

556
00:14:53,600 --> 00:14:54,000
都会有一个

557
00:14:54,000 --> 00:14:55,439
Volume和Cap Size的东西出来

558
00:14:56,279 --> 00:14:57,719
Ok这就是我的

559
00:15:00,079 --> 00:15:01,199
我的Encode Decode

560
00:15:01,240 --> 00:15:03,000
所以你有了这个东西之后

561
00:15:03,240 --> 00:15:04,600
你就可以直接训练了

562
00:15:04,639 --> 00:15:05,639
直接训练是说

563
00:15:05,639 --> 00:15:06,559
虽然看上去很麻烦

564
00:15:06,679 --> 00:15:07,279
就是说

565
00:15:08,679 --> 00:15:09,600
反正都是32

566
00:15:09,639 --> 00:15:10,639
这个地方你看一下

567
00:15:10,839 --> 00:15:11,559
反正我们基本上

568
00:15:11,559 --> 00:15:12,000
你可以认为

569
00:15:12,319 --> 00:15:14,039
Hinder Size就基本都是32

570
00:15:14,480 --> 00:15:15,439
Head用的是什么

571
00:15:15,600 --> 00:15:17,199
Number of layers用的是两层

572
00:15:17,879 --> 00:15:19,959
然后Number of Epoch

573
00:15:19,959 --> 00:15:21,159
这个东西是训练Epoch

574
00:15:21,360 --> 00:15:23,519
然后Head用的是4

575
00:15:24,639 --> 00:15:25,679
说白了就是说

576
00:15:25,720 --> 00:15:27,160
Hinder Size32

577
00:15:27,160 --> 00:15:28,360
用了两层

578
00:15:28,360 --> 00:15:30,040
然后4个Head

579
00:15:30,640 --> 00:15:31,520
反正就是

580
00:15:32,240 --> 00:15:34,520
这主要是超传数就这么些

581
00:15:34,640 --> 00:15:37,080
然后生成一个Encode Decode

582
00:15:37,120 --> 00:15:38,000
然后构建一个

583
00:15:38,000 --> 00:15:39,400
Encode Decode的类

584
00:15:39,400 --> 00:15:40,480
就我们之前讲过了

585
00:15:40,840 --> 00:15:41,960
因为它的API

586
00:15:41,960 --> 00:15:42,920
长的是一样的

587
00:15:43,480 --> 00:15:45,000
虽然我们用的是Attention

588
00:15:45,120 --> 00:15:46,320
但是跟你用RN

589
00:15:46,320 --> 00:15:47,360
实现的Encode Decode

590
00:15:47,360 --> 00:15:48,480
它用起来是一样的

591
00:15:48,600 --> 00:15:50,040
所以就直接可以训练了

592
00:15:50,280 --> 00:15:52,320
所以这一块就不用讲了

593
00:15:52,560 --> 00:15:53,840
就训练就是刚刚

594
00:15:53,840 --> 00:15:55,520
就我们之前英语翻法语

595
00:15:55,720 --> 00:15:56,360
就训练

596
00:15:57,680 --> 00:15:59,040
所以回过来讲一下

597
00:15:59,040 --> 00:15:59,760
就是说

598
00:16:00,480 --> 00:16:01,480
这个东西就是

599
00:16:01,640 --> 00:16:02,360
反正

600
00:16:02,880 --> 00:16:04,480
虽然超传数看起来很多

601
00:16:04,640 --> 00:16:05,720
但一般来说

602
00:16:05,720 --> 00:16:06,840
关键的就是说

603
00:16:06,880 --> 00:16:08,000
Hinder Size多大

604
00:16:08,000 --> 00:16:09,200
就32还是64

605
00:16:09,200 --> 00:16:10,200
还是当然大一点

606
00:16:10,200 --> 00:16:10,720
一般就是说

607
00:16:10,720 --> 00:16:12,240
But你可以取代1024

608
00:16:13,160 --> 00:16:14,040
多少个Head

609
00:16:14,360 --> 00:16:16,400
8个12个还是24个

610
00:16:16,560 --> 00:16:17,120
对吧

611
00:16:17,360 --> 00:16:19,080
然后主要是这两个

612
00:16:19,080 --> 00:16:19,840
重要的参数

613
00:16:19,880 --> 00:16:21,600
别的参数都不那么重要

614
00:16:21,600 --> 00:16:22,120
OK

615
00:16:22,600 --> 00:16:24,960
所以虽然看上去很啰嗦

616
00:16:25,400 --> 00:16:26,960
但实际上就两个参数

617
00:16:27,920 --> 00:16:29,759
然后这个训练也不慢

618
00:16:29,759 --> 00:16:31,920
就是说5000个Token Per Second

619
00:16:32,920 --> 00:16:34,519
比RN不会慢到哪一区

620
00:16:34,519 --> 00:16:36,080
因为它确实算起来

621
00:16:36,080 --> 00:16:37,200
还挺好算的

622
00:16:37,200 --> 00:16:38,680
就是并行度很高

623
00:16:39,480 --> 00:16:40,519
然后做一些预测

624
00:16:40,639 --> 00:16:41,519
做预测

625
00:16:41,879 --> 00:16:42,960
就不给大家仔细讲了

626
00:16:42,960 --> 00:16:44,360
就是说还是那几个一样

627
00:16:44,360 --> 00:16:44,960
做预测

628
00:16:44,960 --> 00:16:46,120
就基本上看到

629
00:16:46,160 --> 00:16:48,160
我们之前的最原始的

630
00:16:48,160 --> 00:16:49,160
那个Seq to Seq

631
00:16:49,160 --> 00:16:51,040
还是Blue Square比较低

632
00:16:51,160 --> 00:16:52,160
我们现在基本上

633
00:16:52,440 --> 00:16:53,600
这两个都到1了

634
00:16:54,120 --> 00:16:54,879
这个就很奇怪

635
00:16:55,039 --> 00:16:56,240
这个就是Fail了

636
00:16:56,240 --> 00:16:57,360
直接就是零

637
00:16:57,679 --> 00:16:59,240
所以还是一样

638
00:16:59,399 --> 00:16:59,879
就这个

639
00:16:59,879 --> 00:17:01,279
虽然我们讲的是

640
00:17:01,439 --> 00:17:02,240
Transformer

641
00:17:02,240 --> 00:17:03,759
但是我们的数据很小

642
00:17:03,919 --> 00:17:05,279
所以当然这个地方

643
00:17:05,279 --> 00:17:06,400
看不出太多效果

644
00:17:06,440 --> 00:17:08,680
但是因为它用的是

645
00:17:08,680 --> 00:17:10,119
纯注意力架构

646
00:17:10,319 --> 00:17:11,319
就是Transformer

647
00:17:11,319 --> 00:17:13,079
是可以做到比较大的数据的

648
00:17:13,119 --> 00:17:15,759
真的可以做到比较长的句子

649
00:17:15,759 --> 00:17:16,960
然后比较大的句子

650
00:17:18,599 --> 00:17:20,720
最后就是说一些Visualization

651
00:17:20,799 --> 00:17:22,160
就给你换一换了个Tension

652
00:17:22,160 --> 00:17:23,440
我就不自己讲了

653
00:17:23,640 --> 00:17:24,759
就是说基本上就是说

654
00:17:24,960 --> 00:17:25,759
每个Head

655
00:17:25,759 --> 00:17:26,799
就你基本上可以看到

656
00:17:27,000 --> 00:17:28,319
每个Head的那些

657
00:17:28,319 --> 00:17:29,480
那些weight

658
00:17:29,879 --> 00:17:31,079
就是Tension那些weight

659
00:17:31,319 --> 00:17:32,319
基本上还是有点不一样

660
00:17:32,319 --> 00:17:32,640
对吧

661
00:17:32,640 --> 00:17:33,799
就是你看到每个Head

662
00:17:33,799 --> 00:17:34,720
它就是说

663
00:17:35,440 --> 00:17:36,920
就是说你这个东西是什么

664
00:17:36,920 --> 00:17:38,400
这个东西是你的

665
00:17:39,559 --> 00:17:40,920
每一行是一个Query

666
00:17:41,720 --> 00:17:43,000
就每一行是一个Query

667
00:17:43,240 --> 00:17:45,279
每一列就表示一个Key Value Pair

668
00:17:45,279 --> 00:17:46,720
就是每个Query

669
00:17:46,720 --> 00:17:48,879
去看了哪个Key Value Pair

670
00:17:49,359 --> 00:17:49,879
OK

671
00:17:49,879 --> 00:17:50,759
所以基本上可以看到

672
00:17:50,759 --> 00:17:51,759
还是有一点的不一样

673
00:17:52,160 --> 00:17:54,359
就每一个去看的东西会不一样

674
00:17:55,320 --> 00:17:55,720
一样的

675
00:17:55,720 --> 00:17:56,040
就是说

676
00:17:56,040 --> 00:17:58,000
因为现在你有三个

677
00:17:58,000 --> 00:17:59,240
你只有三个Tension

678
00:17:59,560 --> 00:18:01,120
所以你可以画三个出来

679
00:18:01,120 --> 00:18:01,320
对吧

680
00:18:01,320 --> 00:18:02,160
我就不自己讲了

681
00:18:02,160 --> 00:18:02,760
就是说

682
00:18:02,840 --> 00:18:04,760
这个是你

683
00:18:05,800 --> 00:18:06,960
这个应该是

684
00:18:09,240 --> 00:18:10,800
就是说这个应该是到

685
00:18:11,240 --> 00:18:12,760
Incode和Decode之间

686
00:18:12,760 --> 00:18:13,320
那个Tension

687
00:18:13,320 --> 00:18:14,640
就是画的会比较开一点

688
00:18:14,840 --> 00:18:16,320
就是说基本上是比较线性关系

689
00:18:16,320 --> 00:18:18,440
就是说你偏后的那些词

690
00:18:18,880 --> 00:18:21,360
会在解码偏后的词的时候

691
00:18:21,560 --> 00:18:23,760
会去看编码偏后的那些词

692
00:18:24,520 --> 00:18:26,920
因为句子都是从左到右的

693
00:18:27,600 --> 00:18:29,440
然后最后也是不同的Head

694
00:18:29,600 --> 00:18:31,840
就是Decode的不同Head

695
00:18:31,840 --> 00:18:32,840
Separation之间

696
00:18:32,840 --> 00:18:33,720
那些权重变化

697
00:18:34,160 --> 00:18:35,920
不同Head也是会有一点不一样

698
00:18:36,840 --> 00:18:37,480
OK

699
00:18:37,480 --> 00:18:38,680
所以基本上这个就是

700
00:18:38,880 --> 00:18:40,520
我们的整个代码

701
00:18:41,040 --> 00:18:41,800
虽然

702
00:18:42,080 --> 00:18:43,360
虽然就是说超参数

703
00:18:43,360 --> 00:18:44,520
写起来还挺多的

704
00:18:44,520 --> 00:18:46,880
实际上就是两个

705
00:18:47,080 --> 00:18:47,560
对吧

706
00:18:47,560 --> 00:18:49,040
就隐藏着大小

707
00:18:49,400 --> 00:18:50,280
多少个Head

708
00:18:50,400 --> 00:18:53,120
然后因为我们把那些Layer

709
00:18:53,120 --> 00:18:54,160
都包装起来了

710
00:18:54,200 --> 00:18:55,560
就是说你那些Tension

711
00:18:55,640 --> 00:18:57,080
都包装成一个正常Layer

712
00:18:57,080 --> 00:18:58,040
所以用起来

713
00:18:58,240 --> 00:18:59,560
从感觉上来说

714
00:18:59,600 --> 00:19:00,840
你通过包装之后

715
00:19:01,800 --> 00:19:02,680
也用起来

716
00:19:02,720 --> 00:19:04,480
就是说跟你做卷迹

717
00:19:04,519 --> 00:19:05,880
做R没太多区别

718
00:19:05,880 --> 00:19:06,200
对吧

719
00:19:06,200 --> 00:19:08,320
虽然里面会稍微会复杂一点

720
00:19:08,480 --> 00:19:10,279
然后你特别是Transformer block

721
00:19:10,759 --> 00:19:11,200
就很好

722
00:19:11,200 --> 00:19:12,440
就是什么Ship的东西进来

723
00:19:12,480 --> 00:19:13,279
什么Ship出去

724
00:19:13,279 --> 00:19:13,759
对吧

725
00:19:15,000 --> 00:19:16,720
所以就是说

726
00:19:16,720 --> 00:19:18,640
虽然它内部看起来很麻烦

727
00:19:18,680 --> 00:19:22,519
但是它确实是作为一个Layer本身来讲

728
00:19:22,519 --> 00:19:23,400
它的API定义

729
00:19:23,600 --> 00:19:25,640
就输入输出都是挺规则的

730
00:19:25,680 --> 00:19:27,080
所以意味着说

731
00:19:27,600 --> 00:19:28,560
Transformer block

732
00:19:28,920 --> 00:19:29,800
会在今后

733
00:19:30,200 --> 00:19:33,360
也是在最近那些工作里面

734
00:19:33,360 --> 00:19:34,680
被大量的使用

735
00:19:35,120 --> 00:19:36,519
虽然里面多么复杂

736
00:19:36,519 --> 00:19:36,960
不管

737
00:19:36,960 --> 00:19:38,840
就是反正什么输入进去

738
00:19:38,840 --> 00:19:39,840
什么输出出来

739
00:19:40,120 --> 00:19:41,880
然后可以做比较长的序列

740
00:19:42,480 --> 00:19:43,920
大家觉得这个东西很好用

741
00:19:44,360 --> 00:19:45,680
之后可以看到BERT

742
00:19:45,880 --> 00:19:46,400
GBT

743
00:19:46,519 --> 00:19:47,880
基本上都是用了这一套

