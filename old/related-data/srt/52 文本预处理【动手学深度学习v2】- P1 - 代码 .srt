1
00:00:00,000 --> 00:00:02,600
好 我们接下来看就是说

2
00:00:02,600 --> 00:00:05,000
怎么样对文本作与处理

3
00:00:05,000 --> 00:00:06,320
所谓的文本与处理

4
00:00:06,320 --> 00:00:09,519
就是说我们把文本当做一个时序序列

5
00:00:09,519 --> 00:00:12,320
这也是整个载元处理干的事情

6
00:00:12,320 --> 00:00:14,280
整个NLP说白了

7
00:00:14,280 --> 00:00:16,080
就是把一个文本拿过来

8
00:00:16,080 --> 00:00:19,359
把里面每一个字符或者字词

9
00:00:19,359 --> 00:00:22,080
当做一个变量

10
00:00:22,080 --> 00:00:23,000
当成一个样本

11
00:00:23,000 --> 00:00:25,879
然后它样本之间是有时序信息的

12
00:00:25,879 --> 00:00:26,600
它是一个

13
00:00:26,600 --> 00:00:27,400
你看到一个文本

14
00:00:27,400 --> 00:00:29,879
就是一个一条很长的这样子的序列

15
00:00:30,279 --> 00:00:32,320
好 我们先看一下文本的与处理

16
00:00:32,320 --> 00:00:34,359
文本的与处理核心思想是说

17
00:00:34,359 --> 00:00:36,159
你怎么样把你那些词

18
00:00:36,159 --> 00:00:38,280
变成能够训练的东西

19
00:00:41,079 --> 00:00:42,519
好 我们第一个干什么事情

20
00:00:42,600 --> 00:00:44,399
我们第一个漏的一本书

21
00:00:44,519 --> 00:00:47,280
叫做Time Machine这本书

22
00:00:47,480 --> 00:00:49,840
说白了它就是一个.txt文件

23
00:00:50,239 --> 00:00:52,640
我们把它漏了进来

24
00:00:53,000 --> 00:00:54,120
所以这个东西就是说

25
00:00:54,120 --> 00:00:55,480
我们为什么要漏的这个书

26
00:00:57,039 --> 00:00:58,439
其实没有别的太多原因

27
00:00:58,439 --> 00:01:00,359
第一个主要一个原因是说

28
00:01:00,359 --> 00:01:01,960
这本书没有版权信息

29
00:01:02,439 --> 00:01:04,719
就是这本书已经很老了

30
00:01:04,799 --> 00:01:06,560
然后首先它是一本科幻小说

31
00:01:06,879 --> 00:01:08,759
所以大家觉得科幻小说不错

32
00:01:09,039 --> 00:01:10,920
就是你漏的一本延期小说

33
00:01:10,920 --> 00:01:11,959
就有点问题了

34
00:01:12,159 --> 00:01:14,400
然后第二个是说它没有版权信息

35
00:01:14,439 --> 00:01:16,039
所以它是一个一九七几年

36
00:01:16,039 --> 00:01:16,959
三几年写的书

37
00:01:16,959 --> 00:01:18,239
所以现在已经版权过期了

38
00:01:18,239 --> 00:01:19,439
所以我们用它没问题

39
00:01:19,759 --> 00:01:23,759
之前我们用的是一个周杰伦的歌词的信息

40
00:01:23,759 --> 00:01:25,680
就是说大家有阵子流行什么

41
00:01:26,280 --> 00:01:28,560
汪峰的歌词

42
00:01:28,760 --> 00:01:29,360
写作记

43
00:01:29,360 --> 00:01:31,400
就是说反正那几个词就来回弄

44
00:01:31,400 --> 00:01:32,160
所以就是说

45
00:01:32,160 --> 00:01:34,080
你基本上可以训练一个RN来

46
00:01:34,080 --> 00:01:35,800
预测很好的歌词

47
00:01:36,000 --> 00:01:38,320
周杰伦的歌词也还有难一点点

48
00:01:38,320 --> 00:01:40,160
但是也能弄

49
00:01:40,200 --> 00:01:43,120
但是这个东西有版权信息

50
00:01:43,160 --> 00:01:47,000
最后我们被律师说了一下

51
00:01:47,160 --> 00:01:49,360
所以我们还是换回到

52
00:01:49,360 --> 00:01:52,760
我们最保险的时间机器

53
00:01:53,520 --> 00:01:54,640
所以这个东西就是说

54
00:01:54,640 --> 00:01:55,480
它是一个TXT

55
00:01:55,480 --> 00:01:55,960
TXT文件

56
00:01:55,960 --> 00:01:57,960
我们反正打开之后

57
00:01:58,120 --> 00:02:00,520
我们一行一行读进来

58
00:02:00,520 --> 00:02:01,680
get rid of noise

59
00:02:01,840 --> 00:02:02,960
接下来做一个操作

60
00:02:02,960 --> 00:02:05,159
就是说把非

61
00:02:05,159 --> 00:02:06,040
因为它是英文

62
00:02:06,400 --> 00:02:08,080
就把非的

63
00:02:08,200 --> 00:02:10,000
不是

64
00:02:10,039 --> 00:02:11,640
就是说A

65
00:02:11,640 --> 00:02:14,159
不是大写字母和小写字母的东西

66
00:02:15,039 --> 00:02:17,159
全部变成空格

67
00:02:18,319 --> 00:02:20,480
就是说把标点符号

68
00:02:21,159 --> 00:02:22,080
各种

69
00:02:22,120 --> 00:02:23,640
然后branch的东西

70
00:02:23,840 --> 00:02:25,440
全部变成空格

71
00:02:26,680 --> 00:02:27,960
就这是一个

72
00:02:28,000 --> 00:02:29,120
有损的操作

73
00:02:29,280 --> 00:02:31,040
但是它操作好处是说

74
00:02:31,040 --> 00:02:33,280
让我们的变得简单

75
00:02:33,280 --> 00:02:35,520
就是我们26个字母

76
00:02:35,520 --> 00:02:36,480
再加26个字母

77
00:02:36,480 --> 00:02:37,280
再加一个空格

78
00:02:37,280 --> 00:02:38,720
整个文本就完事了

79
00:02:38,720 --> 00:02:39,240
对吧

80
00:02:40,240 --> 00:02:42,600
接下来我们把

81
00:02:43,400 --> 00:02:47,680
把每一行的那些东西回车弄掉

82
00:02:47,680 --> 00:02:48,840
然后再把它变成小写

83
00:02:49,040 --> 00:02:50,000
大写我们也不管了

84
00:02:50,000 --> 00:02:52,040
就是说最后是26个字符

85
00:02:52,040 --> 00:02:52,800
加一个空格

86
00:02:52,800 --> 00:02:55,040
就整个文本就超级简单

87
00:02:56,240 --> 00:02:57,400
这个是我们最简单的

88
00:02:57,400 --> 00:02:59,600
一个很暴力的一个预处理

89
00:02:59,880 --> 00:03:01,080
我们到之后会看到

90
00:03:01,080 --> 00:03:02,520
稍微复杂一点的预处理

91
00:03:02,800 --> 00:03:03,800
但是这个东西

92
00:03:03,840 --> 00:03:05,600
很多时候对一个模型来讲

93
00:03:05,600 --> 00:03:07,480
这也挺好的

94
00:03:07,480 --> 00:03:08,480
就简单

95
00:03:08,960 --> 00:03:10,439
当然是说实际生活中

96
00:03:10,520 --> 00:03:11,520
我们不会这么做

97
00:03:11,520 --> 00:03:12,680
那么暴力的预处理

98
00:03:12,720 --> 00:03:13,800
就是说标点符号

99
00:03:13,840 --> 00:03:14,880
大小写这种东西

100
00:03:14,880 --> 00:03:16,080
我们还是会保留的

101
00:03:17,600 --> 00:03:19,160
但是我们这里是为了简单

102
00:03:19,280 --> 00:03:20,680
让看一下就长什么样子

103
00:03:20,680 --> 00:03:21,360
就是说

104
00:03:22,960 --> 00:03:23,600
这个

105
00:03:24,200 --> 00:03:25,439
这个地方少了一点点

106
00:03:28,280 --> 00:03:29,920
你基本上可以看到这本书

107
00:03:30,080 --> 00:03:33,200
有3221行

108
00:03:33,240 --> 00:03:35,640
然后第一行就是长这样子

109
00:03:35,960 --> 00:03:37,400
第10行就是这样子

110
00:03:37,560 --> 00:03:40,040
就是说你也不用太拐说

111
00:03:40,760 --> 00:03:41,800
这个里面是什么东西

112
00:03:41,920 --> 00:03:43,320
就是直到有3000多行

113
00:03:43,320 --> 00:03:44,800
然后每一行里面可能是空

114
00:03:44,800 --> 00:03:46,120
也可能是有一些字

115
00:03:49,600 --> 00:03:50,240
好

116
00:03:50,280 --> 00:03:52,040
接下来我们要干嘛

117
00:03:52,199 --> 00:03:53,079
就是说你还是

118
00:03:53,079 --> 00:03:54,319
现在我们是一行一行

119
00:03:54,679 --> 00:03:56,239
一行你不能训练

120
00:03:57,120 --> 00:03:59,039
就是说一行线是一串之不串

121
00:03:59,079 --> 00:04:00,719
我们还得表示一下它

122
00:04:00,959 --> 00:04:03,919
就是说把一行东西变成

123
00:04:04,719 --> 00:04:06,399
词源叫做token

124
00:04:07,399 --> 00:04:09,759
就是我们这里翻译成标记

125
00:04:09,759 --> 00:04:11,199
但是要token文

126
00:04:11,239 --> 00:04:15,399
跟前几天跟周老师

127
00:04:15,399 --> 00:04:16,519
他们讨论

128
00:04:16,519 --> 00:04:17,000
李航老师

129
00:04:17,000 --> 00:04:17,839
他们讨论了半天

130
00:04:17,839 --> 00:04:20,240
就是说大家就是要词源

131
00:04:20,240 --> 00:04:20,719
叫做

132
00:04:21,000 --> 00:04:21,880
就token这个东西

133
00:04:23,040 --> 00:04:24,000
在英语里面

134
00:04:24,080 --> 00:04:25,200
一般你可以有两种

135
00:04:25,200 --> 00:04:27,080
很常见的token的表示单元

136
00:04:28,080 --> 00:04:30,160
一种是一个词

137
00:04:30,640 --> 00:04:32,120
就是说一个词

138
00:04:32,120 --> 00:04:35,360
作为一个基本的单元

139
00:04:36,320 --> 00:04:37,240
就是说基本单元

140
00:04:37,240 --> 00:04:38,040
就是一个元素

141
00:04:38,920 --> 00:04:40,600
或者一个字不串的

142
00:04:41,160 --> 00:04:42,120
一个chart

143
00:04:42,480 --> 00:04:43,720
就词当然是说

144
00:04:43,720 --> 00:04:44,680
相对来说

145
00:04:44,680 --> 00:04:46,240
让你的基础性模型

146
00:04:46,240 --> 00:04:47,840
可能会简单一点

147
00:04:47,960 --> 00:04:49,960
就像是我告诉一个词的

148
00:04:50,159 --> 00:04:51,680
当然问题是说

149
00:04:51,680 --> 00:04:53,519
那个词其实挺多东西的

150
00:04:53,719 --> 00:04:54,759
就有很多

151
00:04:55,120 --> 00:04:56,159
英语有几万个词

152
00:04:57,239 --> 00:04:58,919
然后char的话

153
00:04:59,079 --> 00:05:00,560
如果你去把一个字符串

154
00:05:00,560 --> 00:05:01,599
作为一个标准的

155
00:05:01,599 --> 00:05:02,359
一个token的话

156
00:05:03,719 --> 00:05:04,919
好处是说

157
00:05:04,919 --> 00:05:06,759
你的

158
00:05:07,719 --> 00:05:09,079
一共就我们这个地方

159
00:05:09,079 --> 00:05:11,279
一共就27个

160
00:05:11,359 --> 00:05:12,319
就比较少

161
00:05:12,839 --> 00:05:14,039
但坏处是说

162
00:05:14,039 --> 00:05:15,079
你还得去学

163
00:05:15,079 --> 00:05:16,359
那个词是怎么构成的

164
00:05:16,359 --> 00:05:18,839
怎么用字符构成一个词

165
00:05:20,279 --> 00:05:21,319
但是我们就支持

166
00:05:21,319 --> 00:05:22,359
这两个最简单的

167
00:05:22,359 --> 00:05:24,000
一个token的表示方法

168
00:05:24,680 --> 00:05:25,879
然后我们就tokenize

169
00:05:25,879 --> 00:05:27,439
tokenize就是NLP里面

170
00:05:27,439 --> 00:05:28,879
最常见的一个操作

171
00:05:28,879 --> 00:05:31,120
就是把一个句子

172
00:05:31,120 --> 00:05:32,479
或者一段文字

173
00:05:32,479 --> 00:05:34,799
把它转化成一个个的token

174
00:05:34,839 --> 00:05:35,399
这个token

175
00:05:35,719 --> 00:05:36,279
我们在用

176
00:05:36,279 --> 00:05:37,719
要么是一个字符串

177
00:05:37,879 --> 00:05:39,719
要么是一个词

178
00:05:40,039 --> 00:05:41,679
要么是一个字符

179
00:05:42,039 --> 00:05:43,519
中文的话会不一样一点

180
00:05:43,639 --> 00:05:44,279
中文的话

181
00:05:44,279 --> 00:05:46,000
但你可以用chart

182
00:05:46,000 --> 00:05:47,519
中文的就是一个中文字

183
00:05:47,639 --> 00:05:49,240
但中文的词就比较麻烦

184
00:05:49,720 --> 00:05:50,600
就分词

185
00:05:50,600 --> 00:05:51,280
也就是说

186
00:05:51,280 --> 00:05:52,759
你说我们中文写一段话

187
00:05:52,759 --> 00:05:55,199
词与词之间是不空格的

188
00:05:55,960 --> 00:05:57,160
所以中文的话

189
00:05:57,160 --> 00:05:59,079
你想用词来表示一个token的话

190
00:05:59,439 --> 00:06:01,280
你还得对它进行分词

191
00:06:01,519 --> 00:06:03,840
分词是一个不容易的事情

192
00:06:05,160 --> 00:06:07,280
我记得现在会好一些了

193
00:06:07,280 --> 00:06:09,400
当年分词就是一个巨大的

194
00:06:09,400 --> 00:06:11,879
一个基于规则的系统

195
00:06:14,079 --> 00:06:16,480
而且整个中文NLP里面

196
00:06:16,600 --> 00:06:17,079
分词

197
00:06:17,079 --> 00:06:18,360
中文分词是一大块

198
00:06:18,560 --> 00:06:22,000
就是曾经08年的时候

199
00:06:22,000 --> 00:06:24,199
百度宣传

200
00:06:24,360 --> 00:06:26,240
说百度比Google更懂中文

201
00:06:26,240 --> 00:06:27,360
其实说白了

202
00:06:27,360 --> 00:06:29,280
就是分词做得更好一点

203
00:06:29,280 --> 00:06:32,680
然后就是说我们说

204
00:06:32,800 --> 00:06:33,800
我们要token的话

205
00:06:33,840 --> 00:06:35,040
假设用了word的话

206
00:06:35,040 --> 00:06:36,199
那就token就是说

207
00:06:36,720 --> 00:06:38,800
这一行第一行就是title

208
00:06:39,160 --> 00:06:39,840
就是

209
00:06:40,040 --> 00:06:41,000
字是一个token

210
00:06:41,000 --> 00:06:42,160
time是一个machine

211
00:06:42,160 --> 00:06:43,080
是这个东西是一个

212
00:06:43,199 --> 00:06:46,000
后面都是一些空的一些行

213
00:06:46,000 --> 00:06:47,439
然后你看到每一个token

214
00:06:47,480 --> 00:06:48,360
就是一个词

215
00:06:49,199 --> 00:06:49,839
这样子的话

216
00:06:49,839 --> 00:06:51,959
我们一句话就表示成了

217
00:06:52,000 --> 00:06:53,600
list of token

218
00:06:54,079 --> 00:06:54,680
要么是空

219
00:06:54,680 --> 00:06:56,279
要么就是有一堆token在里面

220
00:06:59,240 --> 00:06:59,879
好

221
00:07:00,319 --> 00:07:02,319
接下来是另外一个重要的概念

222
00:07:02,439 --> 00:07:04,560
NLP里面叫做vocabulary

223
00:07:04,759 --> 00:07:06,759
就字典叫词汇表

224
00:07:07,159 --> 00:07:08,399
这东西干嘛呢

225
00:07:08,519 --> 00:07:09,519
这东西就是说

226
00:07:09,519 --> 00:07:10,959
将你的token

227
00:07:11,439 --> 00:07:12,600
这要么是一个word

228
00:07:12,600 --> 00:07:13,839
要么是一个chart

229
00:07:14,120 --> 00:07:15,879
从一个字符串

230
00:07:16,759 --> 00:07:17,719
映射到一个

231
00:07:17,719 --> 00:07:19,759
从0开始表示的数字

232
00:07:19,759 --> 00:07:22,199
所以就做叫index

233
00:07:23,279 --> 00:07:23,839
Ok

234
00:07:23,839 --> 00:07:25,240
所以这是一个很

235
00:07:25,879 --> 00:07:28,240
因为你最后要

236
00:07:28,240 --> 00:07:30,120
你要放进模型训练的话

237
00:07:30,120 --> 00:07:31,319
模型训练都是tensor

238
00:07:31,360 --> 00:07:33,000
tensor都是基于下标的

239
00:07:33,000 --> 00:07:35,360
就是说你不好用字符串

240
00:07:35,360 --> 00:07:36,079
字符串的话

241
00:07:36,079 --> 00:07:39,199
这个东西在做起来很难很慢

242
00:07:39,240 --> 00:07:40,920
就是在CPU上很慢

243
00:07:40,920 --> 00:07:43,040
然后GPU上几乎上做不了

244
00:07:43,720 --> 00:07:46,319
所以你需要把每一个token

245
00:07:46,400 --> 00:07:48,080
映射到一个

246
00:07:48,120 --> 00:07:49,480
不同token

247
00:07:49,480 --> 00:07:51,240
都映射到一个不同的字符串

248
00:07:51,280 --> 00:07:54,120
一个从0开始的数字

249
00:07:54,120 --> 00:07:54,960
缩影下面

250
00:07:55,760 --> 00:07:56,400
Ok

251
00:07:58,480 --> 00:08:01,040
然后我可以看一下

252
00:08:01,040 --> 00:08:02,080
这个类是怎么实现的

253
00:08:02,759 --> 00:08:03,360
这类的话

254
00:08:03,360 --> 00:08:04,600
我们稍微给大家过一遍

255
00:08:04,600 --> 00:08:05,160
这个类

256
00:08:05,720 --> 00:08:08,680
就是vocab是一个class

257
00:08:09,200 --> 00:08:09,840
告诉我们

258
00:08:09,960 --> 00:08:12,160
就是说你现在所有的token是谁

259
00:08:13,040 --> 00:08:14,319
然后这个东西干嘛

260
00:08:14,319 --> 00:08:15,280
这个东西是说

261
00:08:15,480 --> 00:08:16,600
我们这NLP

262
00:08:17,080 --> 00:08:18,400
就是说那些词

263
00:08:18,800 --> 00:08:20,640
有很多词是不出现的

264
00:08:20,640 --> 00:08:21,600
就是一些常委的

265
00:08:21,600 --> 00:08:22,920
就你用字符串

266
00:08:22,920 --> 00:08:24,600
用字符是没问题

267
00:08:24,600 --> 00:08:25,320
用词的话

268
00:08:25,320 --> 00:08:27,520
很多词可能就在文本里面

269
00:08:27,520 --> 00:08:29,200
就出现过几次

270
00:08:29,680 --> 00:08:31,160
就如果几次你去训练的话

271
00:08:31,160 --> 00:08:32,080
就很难训练

272
00:08:32,080 --> 00:08:32,519
对吧

273
00:08:33,519 --> 00:08:37,360
所以我们min frequency是什么

274
00:08:37,680 --> 00:08:39,720
就是说如果一个token

275
00:08:40,360 --> 00:08:41,879
在我整个里面

276
00:08:41,879 --> 00:08:43,879
出现少于你这个次数

277
00:08:43,879 --> 00:08:44,800
假设我取个5

278
00:08:45,920 --> 00:08:46,879
就如果一个token

279
00:08:46,879 --> 00:08:48,320
被少于5个的话

280
00:08:48,800 --> 00:08:50,040
那么我就把它丢掉

281
00:08:50,040 --> 00:08:51,279
就不管它了

282
00:08:51,320 --> 00:08:53,320
就全部做成一个branch

283
00:08:53,320 --> 00:08:54,879
就unknown这个token里面

284
00:08:56,360 --> 00:08:57,360
然后reserved token

285
00:08:57,360 --> 00:08:58,080
我们现在没有

286
00:08:58,080 --> 00:08:59,279
就是说我们之后会看

287
00:08:59,279 --> 00:09:01,360
就是说我们说reserved token

288
00:09:01,360 --> 00:09:02,200
就是说我们告诉你说

289
00:09:02,320 --> 00:09:04,000
这是一个句子的开始token

290
00:09:04,000 --> 00:09:05,279
这是一个句子结束token

291
00:09:05,279 --> 00:09:05,960
这个东西

292
00:09:06,160 --> 00:09:07,000
我们现在不需要

293
00:09:07,000 --> 00:09:08,360
但是我们先放那个地方

294
00:09:09,720 --> 00:09:10,720
好我们看一下这个函数

295
00:09:11,519 --> 00:09:14,000
就是说第一句话不用管

296
00:09:14,000 --> 00:09:15,440
就是如果token没有token的话

297
00:09:15,440 --> 00:09:16,360
你就给个空

298
00:09:16,560 --> 00:09:19,920
就保证你不要这个函数

299
00:09:19,960 --> 00:09:21,480
运行会报错

300
00:09:22,519 --> 00:09:23,720
如果reserved token你没有

301
00:09:23,720 --> 00:09:24,560
我也给你一个空

302
00:09:25,240 --> 00:09:26,480
接下来就这个东西

303
00:09:27,000 --> 00:09:28,680
接下来这个其实就很简单

304
00:09:28,680 --> 00:09:29,680
函数就是count

305
00:09:29,680 --> 00:09:30,879
就是说count干嘛呢

306
00:09:31,000 --> 00:09:32,320
就给一个token

307
00:09:32,320 --> 00:09:33,360
我用一个

308
00:09:33,800 --> 00:09:35,759
这些东西都不用太管

309
00:09:35,759 --> 00:09:36,879
就是说说白了

310
00:09:36,879 --> 00:09:38,040
就是一个python里面

311
00:09:38,040 --> 00:09:39,560
大家知道有个叫connection的

312
00:09:39,560 --> 00:09:40,600
一个library

313
00:09:40,600 --> 00:09:41,720
没有个counter

314
00:09:41,920 --> 00:09:43,000
counter是干嘛呢

315
00:09:43,000 --> 00:09:46,160
就是把你每给我一堆token

316
00:09:46,200 --> 00:09:47,000
我去看一下

317
00:09:47,000 --> 00:09:49,120
每一个独一无二的token

318
00:09:49,120 --> 00:09:50,200
它出现的次数

319
00:09:51,880 --> 00:09:52,840
就做一个字典

320
00:09:53,280 --> 00:09:54,920
就每一次在对token里面

321
00:09:54,920 --> 00:09:55,480
每一个字典

322
00:09:55,480 --> 00:09:56,400
就插到字典里面

323
00:09:56,400 --> 00:09:57,720
然后把它的技术加一

324
00:09:57,760 --> 00:09:59,880
就能算出每一个

325
00:10:00,400 --> 00:10:01,360
不一样的token

326
00:10:01,360 --> 00:10:03,320
在这里面出现的次数

327
00:10:03,640 --> 00:10:04,240
OK

328
00:10:04,680 --> 00:10:05,480
就是count

329
00:10:05,960 --> 00:10:07,760
所以我们把它放在一个小函数

330
00:10:07,760 --> 00:10:08,000
里面

331
00:10:08,399 --> 00:10:10,279
就在里面处理一点

332
00:10:10,279 --> 00:10:11,759
各种是list

333
00:10:11,919 --> 00:10:13,399
还是什么东西的东西

334
00:10:13,600 --> 00:10:15,360
所以就包了一下

335
00:10:15,879 --> 00:10:17,480
然后它这个东西干嘛

336
00:10:17,480 --> 00:10:19,840
这个东西我如果有

337
00:10:21,159 --> 00:10:24,240
每个token出现的频率的话

338
00:10:24,279 --> 00:10:25,919
那么我把它sort一下

339
00:10:26,279 --> 00:10:27,679
然后从大排到小

340
00:10:27,679 --> 00:10:29,360
就是出现最频

341
00:10:29,360 --> 00:10:30,840
最频繁的放到最前面

342
00:10:30,840 --> 00:10:32,759
最不频繁的放到最后面

343
00:10:34,000 --> 00:10:35,720
就是token frequency

344
00:10:36,720 --> 00:10:38,360
另外一个是我们这里有一个

345
00:10:38,360 --> 00:10:39,279
unknown token

346
00:10:40,279 --> 00:10:41,160
unknown

347
00:10:41,639 --> 00:10:44,200
unk这是NLP常见的一个表示

348
00:10:44,200 --> 00:10:45,000
就是unknown

349
00:10:45,000 --> 00:10:45,680
unknown就是说

350
00:10:45,680 --> 00:10:47,360
我这个token是一个未知的token

351
00:10:48,519 --> 00:10:49,440
就是它的

352
00:10:49,440 --> 00:10:51,080
我们的unknown token的下标

353
00:10:51,080 --> 00:10:51,879
记成0

354
00:10:52,800 --> 00:10:53,200
然后

355
00:10:53,879 --> 00:10:55,160
然后unique token里面

356
00:10:55,160 --> 00:10:56,480
就放在unknown里面

357
00:10:56,639 --> 00:10:57,279
unknown里面

358
00:10:57,279 --> 00:11:02,560
就是我们这些reserved的东西

359
00:11:02,920 --> 00:11:03,480
然后用

360
00:11:04,480 --> 00:11:06,320
放监控号

361
00:11:06,440 --> 00:11:07,720
监控也是NLP常见的

362
00:11:07,720 --> 00:11:10,200
表示一个特殊的token的东西

363
00:11:10,360 --> 00:11:12,200
然后你之后你可以传一些

364
00:11:12,200 --> 00:11:13,279
你还想什么

365
00:11:13,560 --> 00:11:14,200
句子开始

366
00:11:14,320 --> 00:11:14,840
句子结尾

367
00:11:14,840 --> 00:11:16,560
你可以用这样子的东西表示进来

368
00:11:17,720 --> 00:11:18,320
好

369
00:11:18,360 --> 00:11:19,639
接下来就是说

370
00:11:19,920 --> 00:11:20,920
这些unique token

371
00:11:20,920 --> 00:11:22,879
就是说我字典里面要存的东西

372
00:11:22,879 --> 00:11:23,480
就是

373
00:11:24,159 --> 00:11:24,920
我们

374
00:11:25,120 --> 00:11:26,879
这reserve加上unknown

375
00:11:26,879 --> 00:11:29,080
再加上我们之前

376
00:11:29,080 --> 00:11:31,960
这些里面出现次数

377
00:11:31,960 --> 00:11:34,360
大于等于minimum frequency的东西

378
00:11:35,879 --> 00:11:36,480
OK

379
00:11:36,480 --> 00:11:36,960
说白了

380
00:11:36,960 --> 00:11:37,480
就是说

381
00:11:37,480 --> 00:11:39,879
我们把我们传进来的token

382
00:11:39,879 --> 00:11:40,480
list里面

383
00:11:40,480 --> 00:11:42,160
全部count一遍

384
00:11:42,160 --> 00:11:44,560
然后那些出现次数

385
00:11:44,560 --> 00:11:46,840
少于我们要求的

386
00:11:47,200 --> 00:11:48,040
就丢掉

387
00:11:48,400 --> 00:11:49,400
然后剩下的东西

388
00:11:49,400 --> 00:11:50,080
我们就留进来

389
00:11:50,080 --> 00:11:51,840
全部放在unique token里面

390
00:11:52,040 --> 00:11:52,840
所以token

391
00:11:53,519 --> 00:11:55,160
在这个时候就表示了

392
00:11:55,400 --> 00:11:57,320
我们字典里面那些词

393
00:11:57,320 --> 00:11:59,360
要字典里面的token是谁了

394
00:12:00,280 --> 00:12:01,080
那么接下来就是说

395
00:12:01,080 --> 00:12:03,120
我们对每一个unique token

396
00:12:03,360 --> 00:12:05,840
就是给一个从0开始的

397
00:12:05,840 --> 00:12:07,800
下边从01234一直下去了

398
00:12:08,440 --> 00:12:09,759
这样子我们就维护一些东西

399
00:12:09,920 --> 00:12:11,400
就是说index to token

400
00:12:11,400 --> 00:12:12,680
就是给你一个

401
00:12:13,440 --> 00:12:15,160
给你一个index

402
00:12:15,360 --> 00:12:17,800
怎么把对应的token返回出来

403
00:12:18,440 --> 00:12:19,360
token to index

404
00:12:19,360 --> 00:12:20,320
就是一个dictionary

405
00:12:20,759 --> 00:12:21,639
一个词典

406
00:12:21,639 --> 00:12:23,160
就给我一个token

407
00:12:23,160 --> 00:12:24,720
我返回给你一个index

408
00:12:25,320 --> 00:12:25,680
OK

409
00:12:25,680 --> 00:12:27,280
所以下面就是构造它们

410
00:12:27,520 --> 00:12:30,360
就比较简单了

411
00:12:31,879 --> 00:12:33,560
那么另外一个就是说

412
00:12:34,120 --> 00:12:35,879
它的一个是说它的长度

413
00:12:36,000 --> 00:12:37,520
长度就是你的那些

414
00:12:37,520 --> 00:12:38,759
unique token的个数

415
00:12:38,759 --> 00:12:39,440
就是说

416
00:12:41,080 --> 00:12:43,000
get item就是给你一个token

417
00:12:43,320 --> 00:12:44,280
我给你一个token

418
00:12:44,280 --> 00:12:45,560
或给你一个list token

419
00:12:45,600 --> 00:12:48,600
我把它的index返回给你

420
00:12:48,600 --> 00:12:50,240
就是get item

421
00:12:50,240 --> 00:12:52,560
就是返回index

422
00:12:53,160 --> 00:12:54,960
那to tokens就是说

423
00:12:54,960 --> 00:12:57,600
给我一些index

424
00:12:57,600 --> 00:13:00,000
就是说给一些从0开始的下标

425
00:13:00,000 --> 00:13:01,679
我把你字符上的token

426
00:13:01,679 --> 00:13:02,519
你返回出来

427
00:13:03,000 --> 00:13:04,960
所以就是说这两个是一个反函数

428
00:13:05,799 --> 00:13:06,320
OK

429
00:13:06,320 --> 00:13:09,080
所以基本上看到就是字典的

430
00:13:09,960 --> 00:13:11,679
叫vocabulary的实现

431
00:13:12,120 --> 00:13:13,960
最简单就是说你给我一些token

432
00:13:14,000 --> 00:13:15,879
然后我来构造一个

433
00:13:15,879 --> 00:13:17,240
每一个unique token

434
00:13:17,240 --> 00:13:19,240
到一个从0开始的

435
00:13:19,240 --> 00:13:20,679
数字索引的一个映射

436
00:13:21,000 --> 00:13:22,320
然后当然我们做一点点

437
00:13:22,320 --> 00:13:24,600
就是说可以做一个过滤

438
00:13:24,840 --> 00:13:26,639
把长尾的那些东西去掉

439
00:13:26,759 --> 00:13:28,480
然后里面主要两个函数

440
00:13:28,480 --> 00:13:30,399
一个是说给我一个

441
00:13:30,440 --> 00:13:31,840
构造完之后

442
00:13:31,840 --> 00:13:34,920
再给我一个其他token

443
00:13:34,920 --> 00:13:35,639
任何一个token

444
00:13:35,639 --> 00:13:37,240
我可以返回给你一个下标

445
00:13:37,399 --> 00:13:38,600
要么就是一个unknown

446
00:13:38,639 --> 00:13:39,759
要么就是一个对应的

447
00:13:39,759 --> 00:13:41,680
一个你自己的token

448
00:13:41,680 --> 00:13:42,480
对应的下标

449
00:13:42,759 --> 00:13:44,039
反过来讲给一个index

450
00:13:44,039 --> 00:13:45,240
我一样的给你还原出

451
00:13:45,240 --> 00:13:46,960
你原始token长什么样子

452
00:13:47,879 --> 00:13:48,279
OK

453
00:13:48,279 --> 00:13:51,519
这就是我们的vocab的实现

454
00:13:54,159 --> 00:13:54,320
好

455
00:13:54,320 --> 00:13:55,200
我们看一下怎么用它

456
00:13:56,200 --> 00:13:57,159
就这个token

457
00:13:57,439 --> 00:13:58,079
这个token

458
00:13:58,360 --> 00:14:00,279
这个token就是我们之前

459
00:14:01,000 --> 00:14:01,839
它里面的表示

460
00:14:01,839 --> 00:14:02,799
其实是说

461
00:14:03,600 --> 00:14:04,799
我们回一下

462
00:14:04,799 --> 00:14:07,159
我们token就是我们time machine

463
00:14:07,240 --> 00:14:07,799
time machine

464
00:14:08,039 --> 00:14:10,120
就是说它里面是一个list of list

465
00:14:10,799 --> 00:14:12,679
它里面每个元素是一行

466
00:14:13,399 --> 00:14:15,679
一行里面就是一个list of token

467
00:14:15,679 --> 00:14:17,439
它是一个list of list的东西

468
00:14:17,519 --> 00:14:18,919
所以我们支持你

469
00:14:18,919 --> 00:14:19,959
给我一个list也行

470
00:14:19,959 --> 00:14:21,639
给我一个list of list也行

471
00:14:21,839 --> 00:14:23,639
反正我可以构造一个vocab出来

472
00:14:24,559 --> 00:14:25,639
然后vocab出来之后

473
00:14:25,799 --> 00:14:27,159
我就可以把那个

474
00:14:27,799 --> 00:14:29,039
叫token to index

475
00:14:29,199 --> 00:14:30,120
就可以看到说

476
00:14:30,159 --> 00:14:30,919
每一个token

477
00:14:30,919 --> 00:14:34,279
它表示出的数字下标是谁

478
00:14:34,360 --> 00:14:35,159
叫null是0

479
00:14:35,360 --> 00:14:37,600
the就出现了最频繁的the

480
00:14:37,639 --> 00:14:38,360
就是1

481
00:14:38,519 --> 00:14:39,639
i就是2

482
00:14:39,759 --> 00:14:40,480
and就是3

483
00:14:40,480 --> 00:14:41,559
就是基本上就是说

484
00:14:41,559 --> 00:14:44,000
前面都是一些高频词

485
00:14:44,159 --> 00:14:44,600
高频词

486
00:14:44,600 --> 00:14:45,679
我们给了一个小下标

487
00:14:45,679 --> 00:14:47,919
然后低频词给了大下标

488
00:14:47,919 --> 00:14:48,679
因为我们排序

489
00:14:50,879 --> 00:14:52,919
然后我们这个函数

490
00:14:52,919 --> 00:14:54,519
就是说把每一个文本

491
00:14:54,679 --> 00:14:56,399
转换成一个数字索引

492
00:14:56,639 --> 00:14:57,039
你看

493
00:14:59,240 --> 00:14:59,960
给一个token

494
00:15:01,279 --> 00:15:01,960
i的话

495
00:15:03,639 --> 00:15:04,360
就是看一下

496
00:15:04,679 --> 00:15:05,639
words

497
00:15:05,639 --> 00:15:07,240
就是the time machine

498
00:15:07,399 --> 00:15:08,240
就是第一行

499
00:15:09,199 --> 00:15:10,480
然后我们把所有东西

500
00:15:10,480 --> 00:15:11,919
都转成我们的index

501
00:15:12,960 --> 00:15:13,639
给一句话

502
00:15:13,639 --> 00:15:15,079
然后丢到vocab里面

503
00:15:15,319 --> 00:15:16,279
用方括号

504
00:15:16,279 --> 00:15:17,759
就会得到你这句话

505
00:15:17,759 --> 00:15:19,240
对应的下标

506
00:15:19,480 --> 00:15:20,279
数字下标

507
00:15:20,480 --> 00:15:20,960
同样道理

508
00:15:21,120 --> 00:15:22,439
给另外一句话

509
00:15:22,480 --> 00:15:23,039
就一行

510
00:15:23,159 --> 00:15:23,799
不是一句话

511
00:15:23,799 --> 00:15:24,480
是一行

512
00:15:24,799 --> 00:15:26,000
给了每一个token

513
00:15:26,000 --> 00:15:26,960
它对应的下标

514
00:15:26,960 --> 00:15:27,279
给了

515
00:15:27,279 --> 00:15:28,919
就会返回出一个

516
00:15:29,600 --> 00:15:31,519
a list of integers

517
00:15:32,199 --> 00:15:34,159
这些整数的序列

518
00:15:34,159 --> 00:15:36,079
我们之后就可以构造tensor了

519
00:15:36,600 --> 00:15:37,079
OK

520
00:15:38,919 --> 00:15:41,240
最后我们就把所有的东西打包

521
00:15:41,960 --> 00:15:44,840
我们把所有的东西打包

522
00:15:44,840 --> 00:15:45,679
到一个函数里面

523
00:15:45,679 --> 00:15:48,360
叫load corpus time machine

524
00:15:48,919 --> 00:15:50,799
然后告诉你max token

525
00:15:51,000 --> 00:15:52,679
就是说最大的token的

526
00:15:53,640 --> 00:15:54,120
次数

527
00:15:54,320 --> 00:15:54,800
个数

528
00:15:54,800 --> 00:15:56,280
就是说你可以先不用管

529
00:15:57,080 --> 00:15:58,600
就是说最后我们就返回了

530
00:15:58,600 --> 00:15:59,920
我们就是读进来

531
00:15:59,920 --> 00:16:00,800
构造vocab

532
00:16:00,800 --> 00:16:02,520
然后把它全部转成index

533
00:16:04,280 --> 00:16:05,520
然后叫corpus

534
00:16:05,520 --> 00:16:06,280
就是说

535
00:16:06,320 --> 00:16:08,680
corpus就是对我们每一句话

536
00:16:09,120 --> 00:16:10,200
就token的一句话

537
00:16:10,200 --> 00:16:12,040
我都丢进vocab里面

538
00:16:12,080 --> 00:16:14,040
转成了一个数字下标

539
00:16:14,280 --> 00:16:15,440
所以我的corpus

540
00:16:16,240 --> 00:16:17,080
你可以认为

541
00:16:17,120 --> 00:16:20,680
它就是一个一长串的整数

542
00:16:21,560 --> 00:16:23,280
就每个整数堆的是一个token

543
00:16:24,160 --> 00:16:24,720
OK

544
00:16:25,120 --> 00:16:28,560
然后我再把vocab给你回出来

545
00:16:28,720 --> 00:16:29,720
所以这个函数干嘛

546
00:16:29,720 --> 00:16:30,560
这个函数就是说

547
00:16:30,560 --> 00:16:31,760
我们把一个

548
00:16:31,920 --> 00:16:33,880
我们就把所有东西打包起来

549
00:16:33,920 --> 00:16:37,480
我给你读一个字符串的文本

550
00:16:37,840 --> 00:16:38,600
读进来之后

551
00:16:38,600 --> 00:16:40,120
我们现在是默认按词份

552
00:16:40,360 --> 00:16:41,320
就按词

553
00:16:44,160 --> 00:16:45,400
我们这个是默认按char

554
00:16:45,480 --> 00:16:46,680
我们用的是char这个东西

555
00:16:46,840 --> 00:16:47,520
你可以看到

556
00:16:47,600 --> 00:16:50,679
所以我们按char分开之后

557
00:16:50,720 --> 00:16:54,759
然后把整个文本

558
00:16:55,159 --> 00:16:56,279
所有的char

559
00:16:56,279 --> 00:16:58,559
map成一个数字的下标

560
00:16:58,960 --> 00:17:01,000
这样子我们出来corpus

561
00:17:01,159 --> 00:17:03,759
它其实就是一个很长的

562
00:17:03,759 --> 00:17:04,960
一个现在是多少个

563
00:17:04,960 --> 00:17:07,759
一十七万个长度的

564
00:17:07,759 --> 00:17:10,559
一个整形的一个list

565
00:17:10,639 --> 00:17:13,920
我们可以把它变成一个vector之后

566
00:17:14,079 --> 00:17:15,319
然后vocab包括了

567
00:17:15,319 --> 00:17:16,119
所有这些下标

568
00:17:16,119 --> 00:17:18,240
怎么map成一个char

569
00:17:18,240 --> 00:17:19,240
char怎么map回来

570
00:17:20,000 --> 00:17:21,639
vocab的长度是28

571
00:17:21,639 --> 00:17:23,119
就是你字典大小

572
00:17:23,279 --> 00:17:25,000
28是因为我们有26个字母

573
00:17:25,000 --> 00:17:25,519
对吧

574
00:17:25,599 --> 00:17:26,799
加一个空格

575
00:17:26,879 --> 00:17:28,639
再加一个unknown的token

576
00:17:28,639 --> 00:17:29,359
就是说别的

577
00:17:29,359 --> 00:17:30,319
我都不认识的东西

578
00:17:30,319 --> 00:17:31,960
全部可以就是说

579
00:17:32,639 --> 00:17:34,399
变成这个样子

580
00:17:35,679 --> 00:17:36,319
OK

581
00:17:36,519 --> 00:17:37,960
所以这个就是我们

582
00:17:38,000 --> 00:17:40,359
怎么样做文本的预处理

583
00:17:40,679 --> 00:17:42,319
说白了就是文本读进来

584
00:17:42,319 --> 00:17:44,519
最后返回一个整形的

585
00:17:44,519 --> 00:17:46,839
变成一个整形的一个项量

586
00:17:47,160 --> 00:17:48,759
做成一个持续的序列

587
00:17:48,759 --> 00:17:49,920
这个就跟我们之前

588
00:17:49,920 --> 00:17:51,879
刚刚我们生成了个sign函数

589
00:17:52,160 --> 00:17:54,119
这序列就长一样了

590
00:17:54,160 --> 00:17:54,440
好

591
00:17:54,440 --> 00:17:56,480
这就是我们的文本预处理

592
00:17:56,920 --> 00:17:59,119
我们在之后所有的东西

593
00:17:59,119 --> 00:17:59,839
都是基于这个

594
00:18:00,079 --> 00:18:01,119
就是说这样子

595
00:18:01,119 --> 00:18:02,960
我们知道我们拿到的是一条

596
00:18:02,960 --> 00:18:03,960
整形的项量

