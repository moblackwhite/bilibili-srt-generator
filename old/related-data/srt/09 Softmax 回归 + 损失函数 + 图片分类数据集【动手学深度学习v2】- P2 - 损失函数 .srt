1
00:00:00,000 --> 00:00:06,080
损失函数用来衡量预测值和真实值之间的区别

2
00:00:06,120 --> 00:00:09,120
是机器学系里面一个非常重要的概念

3
00:00:09,679 --> 00:00:15,000
这里我们来给大家简单介绍三个常用的损失函数

4
00:00:16,280 --> 00:00:19,600
第一个损失函数是我们已经介绍过的军方损失

5
00:00:19,600 --> 00:00:21,320
又叫L2 loss

6
00:00:22,039 --> 00:00:23,359
它的定义非常简单

7
00:00:23,359 --> 00:00:27,280
就是真实值y减去预测值

8
00:00:27,359 --> 00:00:30,359
这里预测值我们是用y一撇来表示

9
00:00:30,640 --> 00:00:33,079
那么再做平方再除以2

10
00:00:33,320 --> 00:00:37,079
除以2的意思是说当你求导数的时候

11
00:00:37,079 --> 00:00:40,600
它就是2和1 2分之一抵消就变成1

12
00:00:41,640 --> 00:00:43,520
下面我们画了三条曲线

13
00:00:43,840 --> 00:00:47,600
来给大家可视化一下损失函数的特性

14
00:00:48,320 --> 00:00:52,079
蓝色的曲线表示的是当我y等于0的时候

15
00:00:52,079 --> 00:00:55,560
我变换我的预测值y一撇它的函数

16
00:00:56,120 --> 00:00:58,400
可以看到这是一个二次函数

17
00:00:59,039 --> 00:01:02,320
它的绿色它是它的四函函数

18
00:01:02,320 --> 00:01:05,000
也就是1的-L次方

19
00:01:05,320 --> 00:01:07,079
我们并没有讲四函函数

20
00:01:07,079 --> 00:01:11,840
但是它确实是统计里面一个比较重要的概念

21
00:01:12,400 --> 00:01:15,640
可以看到它的四函函数就是一个高斯分布了

22
00:01:17,400 --> 00:01:22,480
橙色线表示的是我损失函数的t度

23
00:01:23,359 --> 00:01:26,200
我们知道它的t度就是一个一次函数

24
00:01:26,200 --> 00:01:28,200
所以而且是穿过原点的

25
00:01:29,439 --> 00:01:33,280
我们知道在t度下降的时候

26
00:01:33,280 --> 00:01:35,560
我们是对负t度导

27
00:01:36,000 --> 00:01:38,439
负t度方向来更新我们的参数

28
00:01:38,840 --> 00:01:43,600
所以它的导数就决定我们是如何更新我们的参数的

29
00:01:44,320 --> 00:01:47,600
可以看到是说当我的预测值y一撇

30
00:01:47,600 --> 00:01:50,560
跟我的真实值y隔得比较远的时候

31
00:01:50,760 --> 00:01:52,439
那么我的t度比较大

32
00:01:52,480 --> 00:01:54,840
所以我对我的参数更新是比较多的

33
00:01:55,120 --> 00:01:56,600
当你随着我的预测值

34
00:01:56,600 --> 00:01:59,159
慢慢的靠近我的真实值的时候

35
00:01:59,159 --> 00:02:00,719
那么靠近原点的时候

36
00:02:00,719 --> 00:02:03,680
我的t度会绝对值会变得越来越小

37
00:02:03,880 --> 00:02:07,120
这样子意味着我们对我们的参数的更新的幅度

38
00:02:07,120 --> 00:02:08,400
也变得越来越小

39
00:02:09,520 --> 00:02:13,439
当然它也不是一个特别好的事情

40
00:02:13,439 --> 00:02:19,159
因为特别是当我对于离原点比较远的时候

41
00:02:19,159 --> 00:02:23,639
我其实不一定想要那么大的t度来更新我的参数

42
00:02:23,879 --> 00:02:26,319
所以另外一个选择是说

43
00:02:26,319 --> 00:02:29,479
我们可以考虑绝对值损失函数

44
00:02:29,560 --> 00:02:30,919
也就是L1 loss

45
00:02:31,280 --> 00:02:32,680
它的定义非常简单

46
00:02:32,719 --> 00:02:37,759
就是预测值减去我的真实值的绝对值

47
00:02:37,759 --> 00:02:39,240
当然你反过来也是一样的

48
00:02:40,120 --> 00:02:42,199
可以看到是说蓝色的线

49
00:02:42,199 --> 00:02:45,039
仍然是它的损失的函数的曲线

50
00:02:45,039 --> 00:02:47,240
就是当你y等于0的时候的样子

51
00:02:47,920 --> 00:02:50,240
它的绿色的线是它的四二函数

52
00:02:50,240 --> 00:02:53,320
可以看到是有一个很尖的点在原点处

53
00:02:53,879 --> 00:02:56,480
比较有意思的是它的导数

54
00:02:56,840 --> 00:03:00,040
可以看到是说当你y'大于0的时候

55
00:03:00,040 --> 00:03:01,600
它的导数是1

56
00:03:02,159 --> 00:03:03,360
常数为1

57
00:03:03,520 --> 00:03:05,480
当你y'小于0的时候

58
00:03:05,480 --> 00:03:06,680
你的导数是-1

59
00:03:06,680 --> 00:03:07,800
也是一个常数

60
00:03:08,280 --> 00:03:09,760
我们之前有提过

61
00:03:10,040 --> 00:03:12,480
因为绝对值函数在零点处不可导

62
00:03:12,480 --> 00:03:16,480
所以你的subgradient可以在-1和-1之间

63
00:03:17,840 --> 00:03:21,760
所以损失函数主要的核心是说

64
00:03:21,760 --> 00:03:24,280
当我的预测值跟我的真实值

65
00:03:24,280 --> 00:03:25,719
隔得比较远的时候

66
00:03:25,719 --> 00:03:26,800
不管你有多远

67
00:03:26,840 --> 00:03:28,520
我的t度永远是常数

68
00:03:28,560 --> 00:03:30,680
所以的话就算你隔得很远

69
00:03:30,680 --> 00:03:34,520
我也给你的权重的更新也不会特别大

70
00:03:35,080 --> 00:03:38,640
这个会带来很多稳定性上的好处

71
00:03:39,320 --> 00:03:40,680
但是它的不好的地方

72
00:03:40,680 --> 00:03:41,520
我们也提过

73
00:03:41,520 --> 00:03:43,560
就是零点处不可导

74
00:03:43,560 --> 00:03:45,240
另外是说在零点处

75
00:03:45,240 --> 00:03:48,080
有一个正义和负义之间的剧烈的变化

76
00:03:48,600 --> 00:03:50,159
不平化性导致说

77
00:03:50,159 --> 00:03:52,800
我们在当你的预测值和真实值

78
00:03:52,800 --> 00:03:54,000
靠得比较近的时候

79
00:03:54,000 --> 00:03:55,000
也就是说

80
00:03:55,040 --> 00:03:58,040
当你优化到了末期的时候

81
00:03:58,360 --> 00:04:00,560
这个地方可能会变得不那么稳定了

82
00:04:02,240 --> 00:04:03,760
这里显示的是说

83
00:04:05,160 --> 00:04:06,040
不管你有多远

84
00:04:06,040 --> 00:04:08,480
我们的t度基本上是帮你

85
00:04:08,800 --> 00:04:11,360
向同样的力度往原点处扯

86
00:04:11,720 --> 00:04:16,439
当然我们可以提出一个新的损失函数

87
00:04:16,439 --> 00:04:20,480
来结合这两个的好处和避免劣处

88
00:04:20,840 --> 00:04:21,759
我们举个例子

89
00:04:21,759 --> 00:04:25,199
这是一个叫做Hobber鲁邦损失

90
00:04:25,840 --> 00:04:27,080
它的定义是这样子

91
00:04:27,639 --> 00:04:31,240
当我的预测值和真实值差的比较大的时候

92
00:04:31,240 --> 00:04:32,800
绝对值大于1的时候

93
00:04:32,840 --> 00:04:35,120
我是一个绝对值误差

94
00:04:35,280 --> 00:04:37,560
就是y减去y一撇的绝对值

95
00:04:37,759 --> 00:04:39,199
但我这里减去了1分之2

96
00:04:39,199 --> 00:04:40,960
使得我的曲线能连起来

97
00:04:41,560 --> 00:04:45,439
当你的预测值和真实值靠的比较近的时候

98
00:04:45,439 --> 00:04:47,080
就是小于等于的时候

99
00:04:47,199 --> 00:04:48,680
它就是一个平方误差

100
00:04:49,400 --> 00:04:52,360
可以看到是说我的蓝色是我的曲线

101
00:04:52,680 --> 00:04:54,560
就是说在正义负义之间

102
00:04:54,560 --> 00:04:55,639
它是一个二次函数

103
00:04:55,639 --> 00:04:57,400
是一个比较平滑的二次函数

104
00:04:57,560 --> 00:05:00,120
但是在之外那就是一条曲线

105
00:05:00,840 --> 00:05:03,120
它的绿色线是我的四二函数

106
00:05:03,400 --> 00:05:07,040
可以看到是说它还是挺像高斯分布的

107
00:05:07,120 --> 00:05:10,040
但是它不像绝对值误差那样

108
00:05:10,040 --> 00:05:11,800
在原点处有个很尖的地方

109
00:05:12,840 --> 00:05:15,439
它的导数当然是最值得注意的地方

110
00:05:15,760 --> 00:05:19,280
可以看到是说当你的y一撇在

111
00:05:19,560 --> 00:05:21,480
大于1或者小于负义的时候

112
00:05:21,480 --> 00:05:22,840
它的导数是常数

113
00:05:23,200 --> 00:05:24,439
当你在之间的时候

114
00:05:24,439 --> 00:05:26,040
它是一个渐变的一个过程

115
00:05:26,759 --> 00:05:28,200
所以它的好处是说

116
00:05:28,240 --> 00:05:32,360
当我的预测值和真实值差的比较远的时候

117
00:05:32,680 --> 00:05:34,759
那么我的不管怎么样

118
00:05:34,759 --> 00:05:37,160
我的梯度还是用比较均匀的力度

119
00:05:37,160 --> 00:05:38,759
帮你往回拉

120
00:05:39,039 --> 00:05:40,560
但是在你靠近的时候

121
00:05:40,560 --> 00:05:42,959
就是在优化比较默契的时候

122
00:05:42,959 --> 00:05:45,519
我的梯度的绝对值会变得越来越小

123
00:05:45,519 --> 00:05:49,959
这样子我的保证我的优化是比较平滑的

124
00:05:49,959 --> 00:05:52,079
不会出现太多数值上的问题

125
00:05:52,519 --> 00:05:54,000
这样我们就介绍了三个

126
00:05:54,000 --> 00:05:55,800
比较简单的损失函数

127
00:05:56,240 --> 00:05:58,519
在机器学习和深度学习中

128
00:05:58,519 --> 00:06:00,839
还有很多其他的损失函数

129
00:06:01,159 --> 00:06:02,680
不管它是多么复杂

130
00:06:02,680 --> 00:06:04,719
我们同样可以通过类似的方法

131
00:06:04,839 --> 00:06:06,159
来研究它的特性

132
00:06:06,480 --> 00:06:09,439
特别是在离预测值比较远的时候

133
00:06:09,439 --> 00:06:12,680
它的作用和离预测值比较近的时候

134
00:06:12,680 --> 00:06:13,320
它的作用

135
00:06:13,439 --> 00:06:14,320
最简单的时候

136
00:06:14,320 --> 00:06:16,360
我们可以通过它的函数的形状

137
00:06:16,360 --> 00:06:17,760
它的梯度的形状

138
00:06:17,760 --> 00:06:19,040
来分析这些特性

139
00:06:19,760 --> 00:06:20,280
好

140
00:06:21,160 --> 00:06:23,920
我们损失函数就介绍到这里

