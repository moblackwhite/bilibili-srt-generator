1
00:00:00,000 --> 00:00:02,000
注意力机制

2
00:00:02,000 --> 00:00:04,000
又叫 Attention Mechanism

3
00:00:04,000 --> 00:00:06,500
首先呢

4
00:00:06,500 --> 00:00:08,900
它从心理学上来讲

5
00:00:08,900 --> 00:00:16,000
就是说做一个动物需要在复杂的环境下有效地关注你值得关注的地方

6
00:00:16,000 --> 00:00:16,600
为什么呢

7
00:00:16,600 --> 00:00:18,500
就是说你每天要看很多东西

8
00:00:18,500 --> 00:00:22,000
但是绝大部分东西潜意识帮你做掉了

9
00:00:22,000 --> 00:00:25,600
所以你只要去关注你比较需要关注的东西

10
00:00:25,600 --> 00:00:28,000
在心理学上有个框架

11
00:00:28,000 --> 00:00:36,399
叫做人类会跟着随意线索和不随意线索来选择注意点

12
00:00:36,399 --> 00:00:38,399
随意不是随便的随意

13
00:00:38,399 --> 00:00:41,399
随意中文翻译的有点怪

14
00:00:41,399 --> 00:00:46,799
就是有点像主动或者有意识地去观察的样子

15
00:00:46,799 --> 00:00:48,799
举个例子

16
00:00:48,799 --> 00:00:52,000
就是说假设你在这里看

17
00:00:52,000 --> 00:00:54,200
眼睛前面有四个东西

18
00:00:54,200 --> 00:00:54,799
报纸

19
00:00:54,799 --> 00:00:57,700
然后下面是一堆纸

20
00:00:57,700 --> 00:00:59,700
然后一个红色的咖啡杯

21
00:00:59,700 --> 00:01:02,100
然后下面是另外一个

22
00:01:02,100 --> 00:01:04,500
那个巧克子和最下是一本书

23
00:01:05,900 --> 00:01:07,700
那么你第一眼啊

24
00:01:07,700 --> 00:01:10,600
第一眼你可能会看到红色的杯子

25
00:01:11,600 --> 00:01:15,400
为什么是因为红色的杯子它比较显著

26
00:01:15,400 --> 00:01:20,100
然后你看我一看就是眼睛会下意识地去看一些比较亮的东西

27
00:01:20,100 --> 00:01:23,900
所以所以说他其实这个叫做不随意线索

28
00:01:23,900 --> 00:01:27,200
就是说你不需要真的有自己有什么想法

29
00:01:27,200 --> 00:01:28,200
你看一眼过去哦

30
00:01:28,200 --> 00:01:29,000
看到那个杯子了

31
00:01:29,000 --> 00:01:30,100
因为就他是红色

32
00:01:31,100 --> 00:01:33,799
假设你把那个杯子拿起来喝了咖啡之后

33
00:01:34,799 --> 00:01:36,799
那么你就会可能会想啊

34
00:01:36,799 --> 00:01:37,799
我接下来干嘛

35
00:01:38,799 --> 00:01:40,000
如果你接下来就说啊

36
00:01:40,000 --> 00:01:41,299
我想去看一本书

37
00:01:41,299 --> 00:01:41,500
哎呦

38
00:01:41,500 --> 00:01:43,500
我读完喝完咖啡比较兴奋

39
00:01:43,500 --> 00:01:46,300
我可以去搞点学习了对吧

40
00:01:46,300 --> 00:01:48,100
然后你就是你想去读书的话

41
00:01:48,100 --> 00:01:49,800
你会去看到那本书啊

42
00:01:49,800 --> 00:01:52,600
那本书叫做随意线索啊

43
00:01:52,600 --> 00:01:55,100
就是说你会去有意识地去观察

44
00:01:55,100 --> 00:01:56,500
你要想要的东西

45
00:01:58,200 --> 00:01:58,799
然后呢

46
00:01:58,799 --> 00:01:59,799
注意力机制啊

47
00:01:59,799 --> 00:02:02,100
就是说多多少少啊

48
00:02:02,100 --> 00:02:03,799
虽然他没有心理学背景啊

49
00:02:03,799 --> 00:02:05,600
但是你从心理学角度来讲

50
00:02:05,600 --> 00:02:07,500
他也是能讲过去的啊

51
00:02:07,500 --> 00:02:08,000
首先呢

52
00:02:08,000 --> 00:02:08,800
卷迹呀

53
00:02:08,800 --> 00:02:10,300
全连接啊

54
00:02:10,300 --> 00:02:11,099
迟化呀

55
00:02:12,599 --> 00:02:15,099
基本上只考虑不随意的线索

56
00:02:15,099 --> 00:02:16,800
就是说卷迹大家知道啊

57
00:02:16,800 --> 00:02:21,199
迟化就是说把里面那一块里面最大的那个signal抽出来

58
00:02:21,199 --> 00:02:22,500
其实基本上啊

59
00:02:22,500 --> 00:02:24,500
你也不我也不知道我要干嘛

60
00:02:24,500 --> 00:02:26,400
就是说我就看看过去对吧

61
00:02:26,400 --> 00:02:28,000
然后把里面最大东西抽出来

62
00:02:28,000 --> 00:02:31,200
卷迹其实很多时候就是一个盒对吧

63
00:02:31,200 --> 00:02:33,200
把所有东西都给你弄出来

64
00:02:33,200 --> 00:02:34,099
通常来说啊

65
00:02:34,099 --> 00:02:37,200
那些比较卷迹比较容易抽的特征啊

66
00:02:37,200 --> 00:02:37,900
会就抽出来

67
00:02:37,900 --> 00:02:41,700
比如说那些大量的方块啊

68
00:02:41,700 --> 00:02:45,000
比如说大量的比较饱和的颜色啊

69
00:02:45,000 --> 00:02:46,200
就大的那些pixel

70
00:02:47,599 --> 00:02:48,200
所以呢

71
00:02:48,200 --> 00:02:49,500
但是呢

72
00:02:49,500 --> 00:02:50,700
注意力机制啊

73
00:02:50,700 --> 00:02:54,599
就是从就很明显啊

74
00:02:54,599 --> 00:02:57,299
就是说很显示的去建模

75
00:02:57,299 --> 00:02:58,900
你那个随意线索

76
00:03:00,699 --> 00:03:03,199
大家可以把那个心理学的里面那个东西啊

77
00:03:03,199 --> 00:03:06,299
就直接可以对应到注意力机制里面来

78
00:03:06,299 --> 00:03:07,799
首先呢

79
00:03:07,799 --> 00:03:09,299
随意线索啊

80
00:03:09,299 --> 00:03:12,000
就是那个东西会被称之为query

81
00:03:12,000 --> 00:03:13,599
就是你想要干嘛

82
00:03:13,599 --> 00:03:15,299
比如说我想要喝咖啡

83
00:03:15,299 --> 00:03:16,199
我想要干嘛

84
00:03:17,400 --> 00:03:18,599
然后你的环境啊

85
00:03:18,599 --> 00:03:19,500
你的环境呢

86
00:03:19,500 --> 00:03:21,400
他就认为是一些key value pair

87
00:03:21,400 --> 00:03:24,000
就是一些值和一些啊

88
00:03:24,000 --> 00:03:25,199
那些啊

89
00:03:25,199 --> 00:03:27,199
你的不随意线索

90
00:03:27,199 --> 00:03:28,400
不随意线索是个key

91
00:03:28,400 --> 00:03:30,400
就是你基本上就是啊

92
00:03:30,400 --> 00:03:31,500
报纸也好啊

93
00:03:31,500 --> 00:03:32,300
什么东西也好

94
00:03:32,300 --> 00:03:33,000
咖啡杯也好

95
00:03:33,000 --> 00:03:35,500
就是说那些都是一些环境的东西

96
00:03:35,500 --> 00:03:36,000
所以呢

97
00:03:36,000 --> 00:03:38,400
他的本身叫做一个key

98
00:03:38,400 --> 00:03:40,300
他会对应一个值

99
00:03:40,300 --> 00:03:41,199
key和值呢

100
00:03:41,199 --> 00:03:42,000
可以是一样

101
00:03:42,000 --> 00:03:43,599
可以是不一样啊

102
00:03:43,599 --> 00:03:48,900
比如说我说我可以把对应一个对我的价值吧

103
00:03:48,900 --> 00:03:52,900
就是说比如说咖啡杯这个东西摆在那里是他的属性

104
00:03:52,900 --> 00:03:54,200
然后就是他的key

105
00:03:54,200 --> 00:03:57,500
然后我的value可以变成是我觉得那个东西对我有什么用

106
00:03:57,500 --> 00:03:58,000
对吧

107
00:03:59,099 --> 00:04:00,000
然后呢

108
00:04:00,000 --> 00:04:02,099
注意力机制啊

109
00:04:02,099 --> 00:04:04,300
你也可以叫做注意力啊

110
00:04:04,300 --> 00:04:06,900
持话叫做tension pooling

111
00:04:06,900 --> 00:04:08,900
他呢会根据你的query啊

112
00:04:10,200 --> 00:04:14,200
去有偏向的选择某一些东西

113
00:04:14,200 --> 00:04:16,600
就是选择某些key value pair

114
00:04:17,899 --> 00:04:22,000
所以他跟你那个我们之前讲过的持话层不一样的是

115
00:04:22,000 --> 00:04:23,800
他多了一个query在这里

116
00:04:23,800 --> 00:04:27,100
就是说你要查询查询就是你的随意线索

117
00:04:27,100 --> 00:04:28,899
就是说你自己有个想法我要干嘛

118
00:04:29,899 --> 00:04:32,899
所以这个也是说他区别于啊

119
00:04:32,899 --> 00:04:36,600
别的我们之前所谓讲过的也成了一个特点

120
00:04:36,600 --> 00:04:41,199
在于这个地方就是说他显示的加入了query这个东西

121
00:04:41,199 --> 00:04:43,199
然后会根据我的查询啊

122
00:04:43,199 --> 00:04:46,399
去在我的里面去寻找我比较感兴趣的东西

123
00:04:49,199 --> 00:04:49,699
然后呢

124
00:04:49,699 --> 00:04:51,600
我们就是说接下来讲一下

125
00:04:51,600 --> 00:04:53,300
他到底是怎么做的啊

126
00:04:53,300 --> 00:04:54,200
接下来怎么讲了

127
00:04:54,200 --> 00:04:56,100
就是说虽然啊啊

128
00:04:56,100 --> 00:04:58,100
就是就是说深度学习嘛

129
00:04:58,100 --> 00:05:01,900
就是说你也知道这个我们这个community啊

130
00:05:01,900 --> 00:05:04,200
我们这个深度学习的圈子啊

131
00:05:04,200 --> 00:05:05,300
喜欢把一些

132
00:05:06,800 --> 00:05:07,300
啊

133
00:05:07,300 --> 00:05:12,500
之前是出过的东西叫做全新的啊

134
00:05:12,500 --> 00:05:13,200
breakthrough

135
00:05:13,200 --> 00:05:14,500
然后是什么什么啊

136
00:05:14,500 --> 00:05:15,400
就跟你苹果一样

137
00:05:15,400 --> 00:05:16,500
苹果说我做个手机

138
00:05:16,500 --> 00:05:17,600
我是啊

139
00:05:17,600 --> 00:05:20,000
这个整个是世界人类最伟大的创造

140
00:05:20,000 --> 00:05:24,300
虽然很有可能你这个idea是别人已经有了啊

141
00:05:24,300 --> 00:05:25,199
注意力其实呢

142
00:05:25,199 --> 00:05:27,399
其实虽然就是说作为啊

143
00:05:27,399 --> 00:05:31,399
深度学习在最近十年里面最大的突破之一啊

144
00:05:31,399 --> 00:05:34,300
就卷积和全年阶RNN啊都不算

145
00:05:34,300 --> 00:05:37,500
因为他在八十年代九十年代就已经有了

146
00:05:37,500 --> 00:05:38,800
所以呢

147
00:05:38,800 --> 00:05:41,000
attention确实在深度学是新的

148
00:05:41,000 --> 00:05:42,100
但实际上来讲啊

149
00:05:42,100 --> 00:05:44,100
他其实呢嗯

150
00:05:44,100 --> 00:05:45,600
你要真的往回看的话

151
00:05:45,600 --> 00:05:47,300
就从统计那边来看的话

152
00:05:47,300 --> 00:05:49,500
其实五六十年代就有了

153
00:05:49,500 --> 00:05:51,600
比如我们稍微讲一点点背景啊

154
00:05:51,600 --> 00:05:53,199
就是说怎么样啊

155
00:05:53,199 --> 00:05:58,000
从很古老的技术到我们现在技术长什么样子

156
00:05:59,199 --> 00:06:03,300
就第一个东西叫做非参的注意力使化层

157
00:06:03,300 --> 00:06:05,199
非参就是我不要学参数

158
00:06:06,500 --> 00:06:08,199
就是说我给定一些数据啊

159
00:06:08,199 --> 00:06:11,000
我要我一些x i和y

160
00:06:11,000 --> 00:06:12,300
就x是你的key啊

161
00:06:12,300 --> 00:06:14,300
你的y是你的value

162
00:06:14,300 --> 00:06:15,199
就是说是你的

163
00:06:17,000 --> 00:06:17,899
key和value pair

164
00:06:18,900 --> 00:06:22,000
我最简单的使化当然是平均使化了

165
00:06:22,000 --> 00:06:25,000
就是就对所有的我要值的后

166
00:06:25,000 --> 00:06:26,700
就所有的y做一个平均

167
00:06:26,700 --> 00:06:28,400
这是最简单最简单的版本

168
00:06:29,700 --> 00:06:31,700
当然是说你最好不要那么做

169
00:06:31,700 --> 00:06:35,700
是因为你因为你你看到这个x没有

170
00:06:35,700 --> 00:06:37,100
这个x就是你的query啊

171
00:06:38,100 --> 00:06:39,100
我拿个笔过来啊

172
00:06:40,100 --> 00:06:42,900
我先我再讲一下这个x是你的query

173
00:06:42,900 --> 00:06:44,200
就是你的查询的东西

174
00:06:44,200 --> 00:06:44,600
然后呢

175
00:06:44,600 --> 00:06:45,200
这个东西呢

176
00:06:45,200 --> 00:06:47,900
就是你的所有的那些key value pair

177
00:06:47,900 --> 00:06:49,600
候选的那些东西

178
00:06:49,600 --> 00:06:50,100
所以呢

179
00:06:50,100 --> 00:06:52,800
我给一个x我要去查询的东西的话

180
00:06:52,800 --> 00:06:54,800
我最简单就是我不管x

181
00:06:54,800 --> 00:06:56,300
我不管你的查询

182
00:06:56,300 --> 00:06:59,100
我就直接把你所有的你要的y做个均值给你

183
00:06:59,100 --> 00:06:59,900
当是最傻的

184
00:07:01,600 --> 00:07:03,400
好一点的办法是怎么做呢

185
00:07:03,400 --> 00:07:04,100
就是说啊

186
00:07:07,100 --> 00:07:09,600
我呢对你给定的query

187
00:07:10,600 --> 00:07:11,200
然后呢

188
00:07:11,200 --> 00:07:12,000
我去啊

189
00:07:13,000 --> 00:07:16,500
跟我所有的候选这些key啊

190
00:07:16,500 --> 00:07:17,199
减一下

191
00:07:18,300 --> 00:07:19,300
然后做一个k

192
00:07:19,300 --> 00:07:20,399
k是一个函数啊

193
00:07:20,399 --> 00:07:21,399
所以这个东西呢

194
00:07:21,399 --> 00:07:24,199
通常也叫做科诺叫做和

195
00:07:24,199 --> 00:07:25,800
所以为什么有个科诺在这个地方啊

196
00:07:25,800 --> 00:07:27,100
大家学过SVM的话

197
00:07:27,100 --> 00:07:28,800
大家知道科诺是什么东西

198
00:07:28,800 --> 00:07:29,399
就k呢

199
00:07:29,399 --> 00:07:35,500
就是你可以认为是衡量x和xi之间的距离的一个函数

200
00:07:36,800 --> 00:07:38,800
但我可以选择很多啊

201
00:07:38,800 --> 00:07:40,300
有很多不同的选择啊

202
00:07:40,400 --> 00:07:41,500
基本上你会认为啊

203
00:07:41,500 --> 00:07:42,600
这个东西呢

204
00:07:42,600 --> 00:07:44,300
越小就距离越近越大呢

205
00:07:44,300 --> 00:07:45,600
可能就嗯

206
00:07:45,600 --> 00:07:46,400
或者你反过来吧

207
00:07:46,400 --> 00:07:48,600
就是说越大可能距离就啊

208
00:07:48,600 --> 00:07:51,100
越近就是说越小的距离就越远啊

209
00:07:51,100 --> 00:07:51,600
在这个地方

210
00:07:53,000 --> 00:07:53,500
然后呢

211
00:07:53,500 --> 00:07:55,900
就是说当然我会把它去除除的话

212
00:07:55,900 --> 00:07:57,199
就就变成一个概率吧

213
00:07:57,199 --> 00:07:58,199
就是说啊

214
00:07:58,199 --> 00:08:01,500
你假设它是一个大于等于零的东西啊

215
00:08:01,500 --> 00:08:02,000
然后呢

216
00:08:02,000 --> 00:08:04,000
你除的话就是每一项呢

217
00:08:04,000 --> 00:08:07,800
就拿到了它的相对的重要性

218
00:08:07,800 --> 00:08:08,199
然后呢

219
00:08:08,199 --> 00:08:10,899
用这个东西加权对yi求和

220
00:08:12,199 --> 00:08:12,899
那什么意思呢

221
00:08:12,899 --> 00:08:15,599
就是说假设我我给个x

222
00:08:15,599 --> 00:08:17,800
我去看你要我的东西的话啊

223
00:08:17,800 --> 00:08:22,300
我会选择跟我的x比较近的那些啊

224
00:08:22,300 --> 00:08:23,800
xi

225
00:08:23,800 --> 00:08:24,300
然后呢

226
00:08:24,300 --> 00:08:26,099
把他们这个y拎出来

227
00:08:27,300 --> 00:08:29,699
就比较比较就比较很明显啊

228
00:08:29,699 --> 00:08:30,500
就是说

229
00:08:30,500 --> 00:08:32,100
我有一堆数据的地方

230
00:08:32,100 --> 00:08:33,799
我来了一个新数据怎么看呢

231
00:08:33,799 --> 00:08:36,899
那我去找跟我相近的数据对吧

232
00:08:36,899 --> 00:08:38,699
把那些数据拿出来看一看就行了

233
00:08:38,699 --> 00:08:40,000
别的就不管了

234
00:08:40,000 --> 00:08:41,100
所以这个就是啊

235
00:08:41,100 --> 00:08:42,699
这个是六十年代出来的啊

236
00:08:42,699 --> 00:08:44,699
叫做Nadarowa

237
00:08:44,699 --> 00:08:47,199
然后Watson的何回归叫Colonel Regress

238
00:08:48,500 --> 00:08:50,399
所以它是一个非参的东西

239
00:08:50,399 --> 00:08:53,000
是因为你不需要学任何东西

240
00:08:53,000 --> 00:08:55,600
所以你的数据就是你的

241
00:08:55,600 --> 00:08:57,299
只有只有数据就行了

242
00:08:57,299 --> 00:08:58,299
就你拿一个新值

243
00:08:58,299 --> 00:08:59,699
我就去查数据啊

244
00:08:59,699 --> 00:09:01,000
有点有点像啊

245
00:09:01,000 --> 00:09:01,799
KNN啊

246
00:09:01,799 --> 00:09:05,600
如果大家知道的话就是K精灵

247
00:09:05,600 --> 00:09:07,100
当然这里面做一些啊

248
00:09:07,100 --> 00:09:08,100
Smooth的东西在里面

249
00:09:08,100 --> 00:09:10,600
就有一个权柱在这个地方啊

250
00:09:10,600 --> 00:09:13,500
这是非参的注意力持话词

251
00:09:13,500 --> 00:09:14,600
就是说你可以认为啊

252
00:09:14,600 --> 00:09:16,000
其实啊

253
00:09:16,000 --> 00:09:20,700
他跟我们的现代的持话词的注意力持话词是很相近的

254
00:09:20,700 --> 00:09:22,700
让我们接下来看是怎么样相近的方法

255
00:09:24,700 --> 00:09:25,300
首先呢

256
00:09:25,300 --> 00:09:27,100
就是说那我们选啊

257
00:09:27,100 --> 00:09:29,300
我接下来选说我的K怎么选

258
00:09:30,300 --> 00:09:33,500
如果你的K选一个高斯科诺啊

259
00:09:33,500 --> 00:09:36,500
就说他是一个高斯的那个分布啊

260
00:09:37,799 --> 00:09:40,600
那么就是说对你的U就是你的距离啊

261
00:09:40,600 --> 00:09:41,700
取平方啊

262
00:09:41,700 --> 00:09:42,899
复然后取除二

263
00:09:42,899 --> 00:09:43,700
然后做指数

264
00:09:43,700 --> 00:09:44,899
然后除以一分之二π

265
00:09:44,899 --> 00:09:48,600
就是高斯的那个分布那个东西啊

266
00:09:48,600 --> 00:09:49,200
然后呢

267
00:09:49,200 --> 00:09:51,600
你把他这个东西带进去啊

268
00:09:51,600 --> 00:09:54,000
带到刚刚那个K

269
00:09:54,000 --> 00:09:56,299
X减去Xi的话

270
00:09:56,299 --> 00:09:57,899
那就是长这个样子

271
00:09:59,200 --> 00:10:01,000
因为这里有个EXP啊

272
00:10:01,000 --> 00:10:02,100
EXP有什么好处啊

273
00:10:02,100 --> 00:10:05,899
比如把你的东西map到总数大于等于0那个东西

274
00:10:05,899 --> 00:10:07,800
然后你下面再除了一下

275
00:10:07,800 --> 00:10:09,200
这东西等于干嘛呢

276
00:10:09,200 --> 00:10:11,300
等于对他做了一个softmax

277
00:10:13,000 --> 00:10:16,100
就是说我给定X的时候

278
00:10:16,100 --> 00:10:19,399
我对所有的候选的那些Xi那些K啊

279
00:10:19,399 --> 00:10:21,000
算一下那个距离

280
00:10:21,000 --> 00:10:22,300
把这个值算出来

281
00:10:22,300 --> 00:10:25,300
然后在这上面做一个softmax

282
00:10:25,300 --> 00:10:27,500
softmax就给你一些啊

283
00:10:27,500 --> 00:10:29,100
一些0到1之间的值

284
00:10:29,100 --> 00:10:30,700
然后加起来等于1啊

285
00:10:30,700 --> 00:10:32,400
然后把这个东西作为权重啊

286
00:10:32,400 --> 00:10:33,600
套到Y上面去

287
00:10:35,100 --> 00:10:35,900
OK

288
00:10:35,900 --> 00:10:37,100
所以这个其实说白了

289
00:10:37,100 --> 00:10:39,000
就是如果你选用高斯核的话

290
00:10:39,000 --> 00:10:40,500
他干的就是这个事情

291
00:10:40,500 --> 00:10:45,400
这个东西等会你会看到是说跟我们的注意力机制是已经非常非常像了啊

292
00:10:47,600 --> 00:10:49,400
那么另外一个是说啊

293
00:10:49,400 --> 00:10:52,700
我们说我们这东西没有什么东西可以学的对吧

294
00:10:52,700 --> 00:10:55,600
我们现在基学系都得学东西啊

295
00:10:55,600 --> 00:10:57,300
当年60年的统计啊

296
00:10:57,300 --> 00:10:58,600
统计当然是不愿意学东西

297
00:10:58,899 --> 00:11:02,300
统计学家那时候计算机用的不溜啊

298
00:11:02,300 --> 00:11:04,200
那时候没什么太多计算机可以用

299
00:11:04,200 --> 00:11:05,000
所以呢

300
00:11:05,000 --> 00:11:07,000
统计学家说不学最好

301
00:11:07,000 --> 00:11:09,700
所以我就直接这么算啊

302
00:11:09,700 --> 00:11:11,600
当然如果你可以让他可以学

303
00:11:11,600 --> 00:11:12,500
就是说啊

304
00:11:12,500 --> 00:11:13,200
可以学呢

305
00:11:13,200 --> 00:11:14,600
叫做啊

306
00:11:14,600 --> 00:11:19,300
参数化就是非参就是没有参数化的话

307
00:11:19,300 --> 00:11:23,600
那就是可以说我可以加入一个可以学习的W

308
00:11:25,500 --> 00:11:26,300
这个W呢

309
00:11:26,300 --> 00:11:26,899
是干嘛呢

310
00:11:26,899 --> 00:11:27,800
就是啊

311
00:11:28,899 --> 00:11:31,100
就是说我这个东西

312
00:11:31,100 --> 00:11:32,500
然后乘一个W

313
00:11:32,500 --> 00:11:37,200
然后我用这个W来学习说到底是什么样的东西啊

314
00:11:37,200 --> 00:11:40,399
要要取个多宽的和比较重要一点

315
00:11:40,399 --> 00:11:40,899
然后呢

316
00:11:40,899 --> 00:11:42,899
就是说我可以让他可以学

317
00:11:42,899 --> 00:11:44,300
然后你每次去迭代

318
00:11:44,300 --> 00:11:46,899
然后被他可以学习

319
00:11:46,899 --> 00:11:51,000
这个也是注意到这个是一个标量啊

320
00:11:51,000 --> 00:11:52,000
我们都不是向量

321
00:11:52,000 --> 00:11:52,399
所以呢

322
00:11:52,399 --> 00:11:54,500
W就是一个亿元的东西

323
00:11:54,500 --> 00:11:56,100
当你要拓展到多维的话

324
00:11:56,100 --> 00:11:58,300
你也可以变成一个累积啊

325
00:11:58,300 --> 00:11:59,700
就是说你就W变成一个项了

326
00:11:59,700 --> 00:12:02,000
就更像我们之后的要讲的东西了

327
00:12:03,100 --> 00:12:03,400
OK

328
00:12:05,700 --> 00:12:07,200
所以啊

329
00:12:07,200 --> 00:12:09,000
我们总结一下啊

330
00:12:09,000 --> 00:12:17,600
就是说心理学认为人是可以通过随意线索和不随意线索来选择注意点啊

331
00:12:17,600 --> 00:12:20,500
我们之前讲的所有的那些东西

332
00:12:20,500 --> 00:12:23,200
他基本上都是用不随意线索

333
00:12:23,200 --> 00:12:24,300
就是啊

334
00:12:24,300 --> 00:12:26,500
你不能要告诉我说你要什么东西

335
00:12:26,500 --> 00:12:27,700
只能是我给我一个数据

336
00:12:27,700 --> 00:12:29,000
我自己去看

337
00:12:29,000 --> 00:12:30,800
然后最后的最后你运气好

338
00:12:30,800 --> 00:12:32,400
然后要的东西跟我比较像

339
00:12:33,500 --> 00:12:35,300
但是在注意力机制里面啊

340
00:12:35,300 --> 00:12:38,300
他通过一个query引入这个query东西

341
00:12:38,300 --> 00:12:39,300
然后啊

342
00:12:39,300 --> 00:12:41,000
当做你的随意线索

343
00:12:41,000 --> 00:12:44,900
然后跟你所有的环境里面的那些key value啊

344
00:12:44,900 --> 00:12:47,800
然后就不随意的线索有偏向性的进行选择

345
00:12:48,900 --> 00:12:50,100
然后呢

346
00:12:50,100 --> 00:12:51,000
所以一般呢

347
00:12:51,000 --> 00:12:52,700
可以写作是说啊

348
00:12:52,700 --> 00:12:55,200
你的FX就是X是你的key

349
00:12:55,200 --> 00:12:56,100
然后呢

350
00:12:56,200 --> 00:12:58,200
你这个啊

351
00:12:58,200 --> 00:13:02,500
他和他的key做所有那些不随意线索的key啊

352
00:13:02,500 --> 00:13:05,800
做一个这样子的距离的计算

353
00:13:05,800 --> 00:13:07,700
就αXXI

354
00:13:07,700 --> 00:13:12,500
然后乘以的Y就是对每一个YI就是你要的value啊

355
00:13:12,500 --> 00:13:14,500
做一个权重的地方

356
00:13:14,500 --> 00:13:15,800
这地方的α呢

357
00:13:15,800 --> 00:13:18,000
我们通常叫做注意力权重

358
00:13:19,200 --> 00:13:20,500
然后呢

359
00:13:20,500 --> 00:13:22,100
在其实这个东西也不新鲜

360
00:13:22,100 --> 00:13:25,100
这个东西就是说早在六十年代就有说

361
00:13:25,100 --> 00:13:26,899
非参数的注意力机制

362
00:13:26,899 --> 00:13:29,700
然后就说你就用个X-XI

363
00:13:29,700 --> 00:13:33,700
然后做一个放一个高斯的科诺上去就行了

364
00:13:33,700 --> 00:13:36,000
当然你可以拓展到加一个W进去

365
00:13:36,000 --> 00:13:37,700
让他可以学习啊

366
00:13:37,700 --> 00:13:40,200
这个是说我们从六十年代开始

367
00:13:40,200 --> 00:13:41,100
但现在呢

368
00:13:41,100 --> 00:13:43,200
接下来我们会给大家介绍啊

369
00:13:43,200 --> 00:13:47,500
两个不一样的现在常用的权重的设计

370
00:13:47,500 --> 00:13:49,600
使得就是说怎么样计算α

371
00:13:50,700 --> 00:13:51,300
OK

372
00:13:51,300 --> 00:13:56,300
这就是我们做一个简单的对注意力机制的一个介绍

