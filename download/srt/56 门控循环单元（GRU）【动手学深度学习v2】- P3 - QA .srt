1
00:00:00,000 --> 00:00:04,679
它实现跟我们之前RN的实现有点像

2
00:00:04,679 --> 00:00:08,560
但是这里因为我们绝大部分函数已经讲过了

3
00:00:08,560 --> 00:00:10,560
所以这里相对来说是比较简单的

4
00:00:10,560 --> 00:00:11,960
然后跟之前一样

5
00:00:12,120 --> 00:00:13,359
我们先来

6
00:00:13,480 --> 00:00:16,399
我们先说我们的P量大小是32

7
00:00:16,399 --> 00:00:19,160
然后我们的每个G则长度是35

8
00:00:20,559 --> 00:00:24,879
然后我们构建我们的训练Iterator和我们的Vocab

9
00:00:25,160 --> 00:00:26,800
这个是跟之前是一样的

10
00:00:27,519 --> 00:00:30,000
这个地方就是主要了

11
00:00:30,000 --> 00:00:34,160
就是首先初实化你的模型参数

12
00:00:34,679 --> 00:00:37,719
这个函数跟我们之前的RN的初实化模型

13
00:00:37,719 --> 00:00:39,880
函数的它的前面几行是一样的

14
00:00:40,799 --> 00:00:41,760
这几行是一样的

15
00:00:41,840 --> 00:00:42,399
你可以看见

16
00:00:42,399 --> 00:00:45,600
就是说你要告诉我你的Vocabsize

17
00:00:45,600 --> 00:00:47,240
就是你的字典的大小

18
00:00:47,320 --> 00:00:48,840
它就是你的RN

19
00:00:49,040 --> 00:00:51,679
它的输入和输出都是长成这个大小

20
00:00:52,359 --> 00:00:55,799
你要告诉我你的隐藏单元的个数是什么样子

21
00:00:55,840 --> 00:00:57,600
和是不是在GPU上做训练

22
00:00:57,960 --> 00:01:00,240
然后我们构造一个辅助函数说

23
00:01:02,280 --> 00:01:03,000
Normal

24
00:01:03,880 --> 00:01:04,960
给我一个Shape的话

25
00:01:04,960 --> 00:01:07,359
我把它放成均值为0

26
00:01:07,359 --> 00:01:11,640
放成为0.01的一个随机初实化的群众

27
00:01:12,280 --> 00:01:12,520
好

28
00:01:12,520 --> 00:01:13,800
这里有一个不一样的东西

29
00:01:15,480 --> 00:01:16,680
这里我们有个3

30
00:01:17,000 --> 00:01:18,280
这个3这个

31
00:01:18,480 --> 00:01:19,719
3这个函数干嘛呢

32
00:01:19,880 --> 00:01:20,640
就是基本上

33
00:01:23,240 --> 00:01:23,880
其实说白了

34
00:01:24,079 --> 00:01:26,199
我们在做RN的时候

35
00:01:26,199 --> 00:01:27,439
你会发现你的

36
00:01:27,519 --> 00:01:31,959
我们是要初实化一个WHXH

37
00:01:32,119 --> 00:01:36,519
WHH和BH这三个东西

38
00:01:36,519 --> 00:01:37,039
对吧

39
00:01:37,239 --> 00:01:39,079
我们之前是写了三行

40
00:01:39,199 --> 00:01:42,599
现在我们要把三行再做三下

41
00:01:43,479 --> 00:01:45,439
所以当然我可以复制两次

42
00:01:45,439 --> 00:01:46,560
就变成9行代码

43
00:01:46,560 --> 00:01:47,039
对吧

44
00:01:47,199 --> 00:01:48,599
所以但是为了简单起见

45
00:01:48,640 --> 00:01:50,519
我们就直接定了一个辅助函数

46
00:01:50,519 --> 00:01:51,319
叫做3

47
00:01:51,360 --> 00:01:52,440
所以就是说

48
00:01:52,480 --> 00:01:54,520
把第一个群众

49
00:01:54,600 --> 00:01:55,320
就是

50
00:01:55,880 --> 00:01:58,720
输入大小到隐藏大小这个矩阵

51
00:01:58,720 --> 00:02:02,280
就是跟输入跟隐藏做的W

52
00:02:02,360 --> 00:02:04,360
然后隐藏到隐藏的

53
00:02:04,360 --> 00:02:07,480
就是W和偏移Bias

54
00:02:07,640 --> 00:02:09,040
就是Number of Hindrances

55
00:02:09,400 --> 00:02:11,240
就全零的东西放在一起

56
00:02:11,760 --> 00:02:13,760
就每调用它就返回三个东西

57
00:02:14,400 --> 00:02:15,080
这样子的话

58
00:02:15,200 --> 00:02:16,159
我们就可以初实化

59
00:02:16,159 --> 00:02:17,040
我们那一堆东西了

60
00:02:17,200 --> 00:02:17,840
就是

61
00:02:18,719 --> 00:02:21,120
Z gate的Wxz

62
00:02:21,360 --> 00:02:22,240
Whz

63
00:02:22,439 --> 00:02:22,840
Bz

64
00:02:23,360 --> 00:02:24,800
R gate那个东西

65
00:02:25,280 --> 00:02:26,640
还有我们算真正的

66
00:02:26,640 --> 00:02:28,680
算候选领域状态那个东西

67
00:02:28,840 --> 00:02:30,879
这样子我们就通过这几行

68
00:02:31,719 --> 00:02:33,360
创建了9个

69
00:02:33,360 --> 00:02:34,960
我们可以学习的参数

70
00:02:36,240 --> 00:02:38,800
最后这一个是我们的输出层

71
00:02:39,000 --> 00:02:42,800
就上面我们要输出多类分类的东西

72
00:02:44,319 --> 00:02:45,439
所以跟之前比

73
00:02:45,960 --> 00:02:47,879
这两个是多的

74
00:02:47,879 --> 00:02:48,879
就跟我们的Rn比

75
00:02:49,400 --> 00:02:50,960
Gre多了这两行

76
00:02:51,479 --> 00:02:52,280
别的都一样

77
00:02:52,280 --> 00:02:52,599
其实

78
00:02:53,520 --> 00:02:54,400
而且这两行

79
00:02:54,960 --> 00:02:57,439
其实就是下面这一行复制一下

80
00:02:57,439 --> 00:02:57,879
对吧

81
00:02:58,599 --> 00:02:59,199
Ok

82
00:02:59,599 --> 00:03:01,079
所以然后你的Parents

83
00:03:01,240 --> 00:03:05,120
那么就有9个加两个

84
00:03:05,120 --> 00:03:06,120
就有11个

85
00:03:06,120 --> 00:03:07,520
我们就一个隐含层

86
00:03:07,840 --> 00:03:10,599
我们就有11个可以学习的参数

87
00:03:10,800 --> 00:03:11,680
后面都是一样

88
00:03:11,759 --> 00:03:12,840
就是对所有的Parents

89
00:03:12,840 --> 00:03:14,400
我们要要求T度

90
00:03:14,400 --> 00:03:15,400
然后我们返回它

91
00:03:16,439 --> 00:03:16,680
Ok

92
00:03:16,680 --> 00:03:17,879
就这个函数干这个事情

93
00:03:21,319 --> 00:03:22,520
我看一下我后面

94
00:03:22,800 --> 00:03:23,560
应该是有训练

95
00:03:23,680 --> 00:03:25,439
所以我就不用提前再训练一遍了

96
00:03:26,039 --> 00:03:27,159
另外一个是说

97
00:03:27,520 --> 00:03:29,719
隐藏状态的初始函数

98
00:03:29,919 --> 00:03:31,919
这个东西跟我们之前没区别

99
00:03:32,159 --> 00:03:34,400
我们的隐藏状态就是H

100
00:03:34,759 --> 00:03:35,439
H的话

101
00:03:35,560 --> 00:03:39,280
就是跟我们之前的Rn是没有区别的

102
00:03:39,280 --> 00:03:41,479
所以这个地方我们还是返回一个Tuple

103
00:03:41,719 --> 00:03:44,599
一个Tuple它就是一个全零的东西

104
00:03:44,840 --> 00:03:46,079
然后因为我们做小批量

105
00:03:46,199 --> 00:03:48,000
所以有一个Batch Size在这个地方

106
00:03:48,039 --> 00:03:51,919
然后每一个样本对应的隐藏状态

107
00:03:52,079 --> 00:03:53,400
就是一个Number of Hinters

108
00:03:53,400 --> 00:03:54,319
一个长的项量

109
00:03:55,120 --> 00:03:56,240
Ok这个函数是

110
00:03:56,359 --> 00:03:59,000
Init GRU state和Init RN state

111
00:03:59,039 --> 00:04:01,240
其实是两个函数是长一样的

112
00:04:03,439 --> 00:04:03,719
好

113
00:04:03,719 --> 00:04:05,599
然后我们来看一下GRU是怎么算的

114
00:04:07,039 --> 00:04:07,599
就说白了

115
00:04:07,599 --> 00:04:10,159
就是把你刚刚公式Copy过来

116
00:04:11,000 --> 00:04:12,400
跟之前的Rn

117
00:04:12,680 --> 00:04:17,280
在函数在结构上来讲是差不多的

118
00:04:17,399 --> 00:04:19,040
主要是这一块有点不一样

119
00:04:19,480 --> 00:04:20,120
结构上说

120
00:04:20,120 --> 00:04:21,959
你说我先把我的state那个东西

121
00:04:24,199 --> 00:04:26,600
这Parents那个东西先展开

122
00:04:26,879 --> 00:04:29,759
就展现我们刚刚是一个东西

123
00:04:29,920 --> 00:04:31,800
然后state就是一个H

124
00:04:32,079 --> 00:04:34,360
Output就是每一个时刻的输出

125
00:04:35,319 --> 00:04:35,600
好

126
00:04:35,600 --> 00:04:36,560
然后我们

127
00:04:37,199 --> 00:04:38,040
然后一样的

128
00:04:38,160 --> 00:04:38,879
Input里面

129
00:04:38,920 --> 00:04:40,240
它其实是一个

130
00:04:41,120 --> 00:04:43,240
D位的长度是Number of Steps

131
00:04:43,240 --> 00:04:45,240
就是那个长度序列长度

132
00:04:45,240 --> 00:04:47,319
然后我们对每一个序列

133
00:04:47,639 --> 00:04:49,680
每一个时间拿出我的x

134
00:04:50,199 --> 00:04:50,439
好

135
00:04:50,439 --> 00:04:51,519
接下来我们做计算

136
00:04:52,120 --> 00:04:52,960
这里有一点不一样

137
00:04:52,960 --> 00:04:53,519
我们用

138
00:04:53,720 --> 00:04:55,000
at这个符号

139
00:04:55,639 --> 00:04:57,759
at这个符号就是矩阵乘法

140
00:04:57,759 --> 00:04:58,400
就是

141
00:04:59,519 --> 00:05:00,400
就touchmm

142
00:05:00,600 --> 00:05:01,759
touchmult

143
00:05:02,040 --> 00:05:02,519
mult

144
00:05:02,960 --> 00:05:04,600
就是都是一个东西

145
00:05:04,680 --> 00:05:06,000
就是说做矩阵乘法

146
00:05:06,199 --> 00:05:08,560
就是说这个就是x乘以whz

147
00:05:08,720 --> 00:05:10,120
这样子写起来相对来说

148
00:05:10,120 --> 00:05:10,600
方便点

149
00:05:10,759 --> 00:05:12,720
我们定稿的时候

150
00:05:12,720 --> 00:05:14,839
我会把它统一成一种格式

151
00:05:14,959 --> 00:05:16,560
我们各个是都出现过

152
00:05:16,839 --> 00:05:18,800
因为PyTorch在各个时候

153
00:05:19,079 --> 00:05:20,920
加入一些不一样的API

154
00:05:21,759 --> 00:05:23,040
而且我们在不同时期

155
00:05:23,040 --> 00:05:24,079
写的风格也都不一样

156
00:05:24,079 --> 00:05:26,040
我们到时候会统一化一下

157
00:05:26,920 --> 00:05:28,160
首先看一下我们的z

158
00:05:29,160 --> 00:05:31,680
z就是x

159
00:05:32,120 --> 00:05:34,079
跟我的w乘

160
00:05:34,079 --> 00:05:35,319
再加上h

161
00:05:35,319 --> 00:05:36,319
跟我的w乘

162
00:05:36,319 --> 00:05:37,160
再加上我的b

163
00:05:37,160 --> 00:05:37,680
对吧

164
00:05:38,280 --> 00:05:39,920
然后当不一样的时候

165
00:05:39,920 --> 00:05:41,400
我们用的sigmoid

166
00:05:41,400 --> 00:05:42,280
这个激活函数

167
00:05:43,360 --> 00:05:45,079
r也是一样的做

168
00:05:45,800 --> 00:05:48,040
那就是也是x跟w乘

169
00:05:48,040 --> 00:05:49,079
h跟w乘

170
00:05:49,079 --> 00:05:50,160
再加上一个b

171
00:05:51,360 --> 00:05:51,600
好

172
00:05:51,600 --> 00:05:52,439
h tilde

173
00:05:52,439 --> 00:05:54,040
就是后旋隐藏状态

174
00:05:54,040 --> 00:05:54,879
是什么样子

175
00:05:56,360 --> 00:05:57,600
这基本上是

176
00:05:57,720 --> 00:05:58,840
也是

177
00:05:59,600 --> 00:06:01,600
x乘跟w乘

178
00:06:02,040 --> 00:06:03,160
然后这里有点不一样

179
00:06:03,160 --> 00:06:05,120
这就是你这里需要有个r

180
00:06:05,480 --> 00:06:08,199
跟h做按元素的点乘

181
00:06:08,199 --> 00:06:09,160
就是乘法

182
00:06:09,160 --> 00:06:11,759
就是你的reset gate

183
00:06:11,879 --> 00:06:12,920
跟你的h

184
00:06:13,360 --> 00:06:14,720
按元素乘一下

185
00:06:14,920 --> 00:06:17,079
再跟你的w做矩阵乘法

186
00:06:17,079 --> 00:06:18,519
再加上你的偏移

187
00:06:18,560 --> 00:06:20,439
然后你用的是time h

188
00:06:20,439 --> 00:06:21,519
这个激活函数

189
00:06:22,879 --> 00:06:23,759
最后你的更新

190
00:06:23,879 --> 00:06:27,600
你的h就是z乘以你的前一个时刻的h

191
00:06:27,639 --> 00:06:28,600
所以这些地方

192
00:06:28,600 --> 00:06:29,720
都是前一个时刻的h

193
00:06:29,840 --> 00:06:31,560
到直到这个时候才是ht

194
00:06:31,560 --> 00:06:33,040
前面都是ht-1

195
00:06:33,840 --> 00:06:35,680
然后ht就等于z

196
00:06:35,720 --> 00:06:37,080
乘以上一个时刻的h

197
00:06:37,080 --> 00:06:38,800
加上1-z乘以ht

198
00:06:38,800 --> 00:06:40,439
对吧

199
00:06:40,920 --> 00:06:43,760
然后y就是等于你的h乘以你的w

200
00:06:44,000 --> 00:06:44,800
再加上你的b

201
00:06:44,800 --> 00:06:46,200
然后把这个东西放进去

202
00:06:46,400 --> 00:06:47,920
后面东西跟我们之前是一样的

203
00:06:48,720 --> 00:06:50,280
所以总结来看

204
00:06:50,280 --> 00:06:50,920
就是

205
00:06:51,480 --> 00:06:52,240
从代码上来讲

206
00:06:52,400 --> 00:06:53,520
就是多了这两行

207
00:06:53,520 --> 00:06:54,000
对吧

208
00:06:55,280 --> 00:06:56,120
然后这个地方

209
00:06:56,520 --> 00:06:58,000
我们之前算h的时候

210
00:06:58,160 --> 00:06:59,879
就是没有这个选项

211
00:07:00,480 --> 00:07:01,879
这个是新加进来的

212
00:07:02,120 --> 00:07:02,959
最后新加进来

213
00:07:02,959 --> 00:07:04,600
也是说这一行

214
00:07:05,240 --> 00:07:06,319
就基本上这个东西

215
00:07:06,319 --> 00:07:07,839
就是我们刚刚那一页

216
00:07:08,480 --> 00:07:09,439
总结的时候

217
00:07:10,240 --> 00:07:12,959
就是多的公式

218
00:07:13,040 --> 00:07:14,120
总结的公式

219
00:07:14,199 --> 00:07:15,120
就是照搬过来

220
00:07:15,120 --> 00:07:16,639
会长这个样子

221
00:07:18,560 --> 00:07:19,120
Ok

222
00:07:20,519 --> 00:07:21,759
我们来看一下训练

223
00:07:22,719 --> 00:07:23,560
训练的话

224
00:07:23,560 --> 00:07:25,680
跟我们之前其实也没什么

225
00:07:25,680 --> 00:07:27,600
就是把前面东西给调整一下

226
00:07:28,600 --> 00:07:29,839
你看我们的workapp

227
00:07:30,120 --> 00:07:30,959
Hindran

228
00:07:31,160 --> 00:07:32,720
然后用GPU

229
00:07:32,720 --> 00:07:33,640
然后我们这个东西

230
00:07:33,640 --> 00:07:35,080
应该是跟之前是一样的

231
00:07:35,280 --> 00:07:37,120
然后我们之前调用

232
00:07:37,360 --> 00:07:40,200
实现过model scratch模型

233
00:07:40,720 --> 00:07:42,000
所以我们这个地方

234
00:07:42,040 --> 00:07:44,320
我们模型实现的足够的通用化

235
00:07:44,400 --> 00:07:46,080
所以我们只要把我们的

236
00:07:46,720 --> 00:07:47,920
怎么样生成

237
00:07:47,920 --> 00:07:49,720
初始化我们的状态函数

238
00:07:50,000 --> 00:07:52,120
初始化我们的参数函数

239
00:07:52,400 --> 00:07:53,880
初始化我们的状态函数

240
00:07:54,200 --> 00:07:56,240
和我们的forward怎么算的

241
00:07:56,240 --> 00:07:57,640
这三个函数丢进去

242
00:07:57,680 --> 00:07:58,840
那么就会变成了

243
00:07:58,840 --> 00:07:59,800
这样子就会变成了

244
00:07:59,800 --> 00:08:01,000
我的GRU模型

245
00:08:01,480 --> 00:08:03,560
我的这就是我们的GRU模型了

246
00:08:03,760 --> 00:08:05,320
然后我们就丢进去训练

247
00:08:05,720 --> 00:08:07,560
就是我们也是在

248
00:08:08,520 --> 00:08:10,400
昨天讲过的函数里面

249
00:08:10,400 --> 00:08:11,320
丢进去训练

250
00:08:12,040 --> 00:08:13,200
就看一下效果

251
00:08:13,760 --> 00:08:14,520
就看一下效果

252
00:08:14,640 --> 00:08:17,280
其实你看不出太多效果是真的

253
00:08:17,400 --> 00:08:19,240
因为这个数据集比较小

254
00:08:19,240 --> 00:08:20,640
所以你能看到是说

255
00:08:20,680 --> 00:08:21,800
反正也还行

256
00:08:22,000 --> 00:08:25,080
就是我们publicity到了1.1

257
00:08:25,240 --> 00:08:27,320
所以之前我们训练到了1.0

258
00:08:27,319 --> 00:08:29,719
但是就这么一点点细微区别

259
00:08:29,920 --> 00:08:31,199
反映不了太多事情

260
00:08:32,480 --> 00:08:33,960
速度上来说

261
00:08:34,360 --> 00:08:34,960
速度上来说

262
00:08:34,960 --> 00:08:35,639
我们慢了吗

263
00:08:35,639 --> 00:08:36,159
还是快了

264
00:08:36,159 --> 00:08:37,000
我们看一眼

265
00:08:37,519 --> 00:08:38,240
干脆我

266
00:08:39,919 --> 00:08:40,960
我看一眼

267
00:08:40,960 --> 00:08:42,200
我们是慢了还是快了

268
00:08:48,120 --> 00:08:48,879
不是这个

269
00:08:57,879 --> 00:08:59,240
速度我们是慢了

270
00:08:59,879 --> 00:09:02,440
就我们之前是每秒都能训练

271
00:09:02,440 --> 00:09:03,200
65000

272
00:09:03,200 --> 00:09:04,160
66000个

273
00:09:04,840 --> 00:09:06,240
现在变成了

274
00:09:06,640 --> 00:09:07,640
26000个

275
00:09:07,720 --> 00:09:10,200
是慢了将近3倍

276
00:09:10,600 --> 00:09:11,760
2.5倍

277
00:09:12,000 --> 00:09:14,520
两倍多一点点

278
00:09:15,000 --> 00:09:16,280
所以这个也挺正常

279
00:09:16,280 --> 00:09:16,520
对吧

280
00:09:16,560 --> 00:09:18,000
因为你中间那个东西

281
00:09:18,560 --> 00:09:21,560
我们之前只要更新隐藏状态的时候

282
00:09:21,560 --> 00:09:22,440
我们做一次

283
00:09:22,480 --> 00:09:25,600
现在等于是我们要多了两次的计算量

284
00:09:26,200 --> 00:09:27,399
是多了两次计算量

285
00:09:27,560 --> 00:09:29,360
所以那个东西其实占的是

286
00:09:29,360 --> 00:09:33,200
我们比较主要的计算在那一块

287
00:09:33,600 --> 00:09:34,320
那一块计算

288
00:09:34,440 --> 00:09:35,480
因为你翻了两倍

289
00:09:35,480 --> 00:09:38,159
所以你现在我们慢了个两倍多

290
00:09:38,159 --> 00:09:40,000
所以也是亲友科员

291
00:09:40,000 --> 00:09:40,480
对吧

292
00:09:42,240 --> 00:09:43,960
另外一块就是说你看一下它效果

293
00:09:44,040 --> 00:09:45,720
效果就是说还是一样的

294
00:09:45,720 --> 00:09:49,200
就是说我们是用的chart做了训练

295
00:09:49,200 --> 00:09:51,279
所以那些字看上去还行

296
00:09:51,279 --> 00:09:52,560
就是说这一句话

297
00:09:52,680 --> 00:09:53,759
看上去像一句话

298
00:09:53,759 --> 00:09:55,560
但是实际上还是一样的

299
00:09:55,560 --> 00:09:58,000
就是说你仔细看看不是特别多的意义

300
00:09:58,400 --> 00:09:59,840
这也是反过来讲

301
00:09:59,840 --> 00:10:02,520
也就是这个数据集相对来说比较简单

302
00:10:02,880 --> 00:10:05,640
所以你做不了太多事情

303
00:10:05,920 --> 00:10:07,160
但大家有兴趣的话

304
00:10:07,600 --> 00:10:08,840
用GRU这个东西

305
00:10:09,240 --> 00:10:12,160
大家是真的可以去用一个比较大一点的

306
00:10:12,160 --> 00:10:12,800
数据解

307
00:10:13,120 --> 00:10:15,240
就是说你去比如说随便你找点

308
00:10:15,280 --> 00:10:19,200
我们之前有用过周杰伦的歌词

309
00:10:19,560 --> 00:10:19,880
对吧

310
00:10:19,880 --> 00:10:21,320
周杰伦所谓的歌词

311
00:10:21,320 --> 00:10:22,800
或者用汪峰的歌词也可以

312
00:10:22,800 --> 00:10:23,760
就是说他们歌

313
00:10:23,800 --> 00:10:25,320
周杰伦歌词相对来说复杂一点

314
00:10:25,320 --> 00:10:26,480
汪峰歌词更简单一点

315
00:10:26,480 --> 00:10:27,640
你用汪峰的歌词

316
00:10:27,640 --> 00:10:29,480
你把它歌词全部下下来

317
00:10:29,520 --> 00:10:30,400
然后放进去

318
00:10:30,400 --> 00:10:32,960
GRU还是你中文字

319
00:10:33,080 --> 00:10:34,440
你就把中文的时候

320
00:10:34,440 --> 00:10:35,600
你就把每个字符

321
00:10:35,800 --> 00:10:37,760
就字当做一个Dictionary

322
00:10:37,760 --> 00:10:39,320
所以当然比英文大一点点

323
00:10:39,320 --> 00:10:40,400
但也大不了太多

324
00:10:41,000 --> 00:10:41,879
然后你去训练

325
00:10:41,879 --> 00:10:43,680
还真训练的还是

326
00:10:43,920 --> 00:10:46,200
就这种歌词没有太多

327
00:10:46,200 --> 00:10:49,240
就是看上去没有太多什么

328
00:10:49,240 --> 00:10:50,600
不需要太多逻辑的

329
00:10:50,680 --> 00:10:53,160
所以相对来说效果还是挺不错的

330
00:10:53,160 --> 00:10:54,080
大家可以去试一试

331
00:10:54,400 --> 00:10:56,280
GRU已经是可以做到

332
00:10:56,280 --> 00:10:58,360
相对来说比较长一点的序列了

333
00:10:58,840 --> 00:10:59,360
OK

334
00:10:59,960 --> 00:11:02,360
这就是从零开始实现

335
00:11:02,520 --> 00:11:04,440
当然如果从简洁实现的话

336
00:11:05,560 --> 00:11:06,560
也挺简单的

337
00:11:07,160 --> 00:11:08,160
我们之前有讲过

338
00:11:08,320 --> 00:11:09,639
从简洁实现来的话

339
00:11:09,639 --> 00:11:11,480
你就调用RN的话

340
00:11:11,480 --> 00:11:13,040
就调用NN.RN

341
00:11:13,720 --> 00:11:14,759
如果是GRU的话

342
00:11:15,000 --> 00:11:16,920
你就是调用NN.GRU

343
00:11:16,920 --> 00:11:17,720
就是说V的话

344
00:11:17,720 --> 00:11:18,520
就这个地方

345
00:11:19,120 --> 00:11:20,920
你告诉我你的输入的大小

346
00:11:21,080 --> 00:11:23,360
你的Number of Hintance

347
00:11:23,680 --> 00:11:24,399
然后这样子

348
00:11:24,399 --> 00:11:25,960
我就会构建我的模型

349
00:11:26,519 --> 00:11:29,240
然后就训练是一样的

350
00:11:30,960 --> 00:11:31,720
同样的话

351
00:11:31,759 --> 00:11:32,759
就是说我们的

352
00:11:32,919 --> 00:11:34,800
因为GRU里面

353
00:11:34,800 --> 00:11:36,840
我们有大概做了十几个

354
00:11:36,960 --> 00:11:40,480
将近应该是6个加7个

355
00:11:40,480 --> 00:11:42,919
我们每一次要做7个矩阵乘法

356
00:11:43,120 --> 00:11:44,519
所以相对来说比较慢

357
00:11:44,560 --> 00:11:47,039
然后但是你在框架实现的GRU里面

358
00:11:47,560 --> 00:11:49,240
是尽量把这些矩阵乘法

359
00:11:49,240 --> 00:11:50,680
全部合在一起

360
00:11:50,720 --> 00:11:52,639
所以相对来说性能会快一些

361
00:11:52,639 --> 00:11:54,439
大概能做到25万个

362
00:11:54,480 --> 00:11:56,879
我们对比一下我们之前的

363
00:11:58,960 --> 00:12:00,159
对比一下我们之前的

364
00:12:02,439 --> 00:12:03,799
RN的时间会怎么样

365
00:12:03,799 --> 00:12:04,319
我看一下

366
00:12:06,799 --> 00:12:08,840
RN的时间是3万个

367
00:12:08,840 --> 00:12:11,439
30万每秒能处理

368
00:12:11,799 --> 00:12:13,360
所以我们这个地方是

369
00:12:14,000 --> 00:12:15,519
处理25万个

370
00:12:16,439 --> 00:12:18,200
就是说你可以看到

371
00:12:18,240 --> 00:12:21,200
虽然我们的计算量

372
00:12:21,200 --> 00:12:22,200
就矩阵乘法

373
00:12:22,200 --> 00:12:24,440
基本上是多了个将近

374
00:12:25,240 --> 00:12:26,879
之前的三倍

375
00:12:26,960 --> 00:12:27,680
将近三倍

376
00:12:27,720 --> 00:12:28,960
两点几倍的样子

377
00:12:29,080 --> 00:12:31,720
但是在实际的实现里面

378
00:12:32,280 --> 00:12:33,240
这里面

379
00:12:33,800 --> 00:12:35,560
没有发现它多太多

380
00:12:35,879 --> 00:12:39,080
这是因为在通过很多优化之后

381
00:12:39,560 --> 00:12:41,640
因为我们这个地方

382
00:12:41,640 --> 00:12:42,720
还是相对来说

383
00:12:42,720 --> 00:12:43,560
矩阵乘法

384
00:12:44,080 --> 00:12:46,840
没有打满我们的GPU

385
00:12:47,600 --> 00:12:48,920
就在RN的时候

386
00:12:49,040 --> 00:12:50,640
那矩阵乘法相对来说比较小

387
00:12:50,920 --> 00:12:51,360
现在

388
00:12:51,759 --> 00:12:53,399
我虽然矩阵乘法计算量

389
00:12:53,399 --> 00:12:55,159
比以前多了将近三倍

390
00:12:55,320 --> 00:12:57,240
但是我的性能没有慢

391
00:12:57,240 --> 00:12:58,919
就慢了那么一些些

392
00:12:59,000 --> 00:13:01,080
这是因为我现在的矩阵

393
00:13:02,519 --> 00:13:03,919
虽然计算量大了

394
00:13:03,960 --> 00:13:06,519
但是我这些东西

395
00:13:06,519 --> 00:13:07,879
都是像每个门

396
00:13:08,159 --> 00:13:10,519
就前面两个门是可以并行算的

397
00:13:10,840 --> 00:13:11,360
对吧

398
00:13:11,519 --> 00:13:12,800
虽然你TL打的时候

399
00:13:12,800 --> 00:13:15,360
你也是可以跟之前一个是并行的

400
00:13:15,519 --> 00:13:17,039
所以在这个的情况下

401
00:13:17,759 --> 00:13:20,399
我因为可以通过大量的并行

402
00:13:20,399 --> 00:13:22,840
因为能够更合理的

403
00:13:22,840 --> 00:13:24,840
去利用我GPU的计算单元

404
00:13:24,879 --> 00:13:27,199
所以我并没有慢的太多

405
00:13:27,240 --> 00:13:28,559
所以在LSDN里面

406
00:13:28,559 --> 00:13:30,519
因为大量的小矩阵

407
00:13:30,519 --> 00:13:32,199
所以在实现的时候

408
00:13:32,439 --> 00:13:33,919
会尽量的使用GPU

409
00:13:33,919 --> 00:13:35,799
在并行做这些矩阵计算

410
00:13:36,240 --> 00:13:37,679
所以除非你到之后

411
00:13:37,679 --> 00:13:39,720
你做真的隐藏做比较大

412
00:13:40,559 --> 00:13:44,960
然后所以你可能会看到

413
00:13:45,000 --> 00:13:46,199
性能差别大一点

414
00:13:46,199 --> 00:13:47,600
在这种小数据上

415
00:13:47,600 --> 00:13:49,720
你可能性能看不出太多区别

416
00:13:50,040 --> 00:13:50,560
OK

417
00:13:50,759 --> 00:13:55,600
这就是我们的GRU的实现

