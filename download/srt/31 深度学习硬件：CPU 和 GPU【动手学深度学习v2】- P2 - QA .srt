1
00:00:00,000 --> 00:00:03,520
首先我们讲一下深度学习的硬件

2
00:00:03,520 --> 00:00:07,000
具体来说我们讲一下所谓的CPU和GPU

3
00:00:07,000 --> 00:00:08,359
它到底有什么区别

4
00:00:08,359 --> 00:00:10,080
为什么GPU会快

5
00:00:12,240 --> 00:00:18,359
首先就是说大家基本上可能都有一个GPU的电脑

6
00:00:18,359 --> 00:00:21,039
如果你要学习深度学习的话

7
00:00:21,039 --> 00:00:24,920
我们之前有讲过说怎么样买卡

8
00:00:24,920 --> 00:00:26,760
现在买卡不容易

9
00:00:26,760 --> 00:00:29,320
但是我们大概讲一下

10
00:00:29,320 --> 00:00:31,399
如果你自己装一台机器的话

11
00:00:31,399 --> 00:00:34,159
很有可能是一个这样子的配置

12
00:00:34,640 --> 00:00:36,880
你可能用Intel的芯片

13
00:00:36,880 --> 00:00:39,799
当然现在AMD听说更快

14
00:00:39,799 --> 00:00:41,759
但我很久没有买过电脑

15
00:00:41,759 --> 00:00:42,960
所以不是很清楚

16
00:00:42,960 --> 00:00:50,000
因为CPU你用Intel AMD可能在数值运算上

17
00:00:50,000 --> 00:00:51,640
可能区别也不那么大

18
00:00:52,320 --> 00:00:55,760
然后就假设我们用一个i7的芯片

19
00:00:55,760 --> 00:00:56,880
然后你的内存

20
00:00:57,160 --> 00:00:59,640
假设你是用的DDR4的内存

21
00:00:59,640 --> 00:01:01,520
你大概有32GB的样子

22
00:01:02,200 --> 00:01:06,040
然后你可能会在机器上插一块显卡

23
00:01:07,000 --> 00:01:09,520
我们这里假设你用的是比较老的显卡

24
00:01:09,520 --> 00:01:13,960
就是Titan X也是三四年前的卡了

25
00:01:16,200 --> 00:01:19,359
但是就是说虽然卡CPU在进步

26
00:01:19,359 --> 00:01:20,120
GPU在进步

27
00:01:20,120 --> 00:01:21,800
但实际上也是有规律可言的

28
00:01:21,800 --> 00:01:24,520
所以我们用这两个来举个例子

29
00:01:25,119 --> 00:01:27,079
就首先看一下你的CPU

30
00:01:27,719 --> 00:01:28,599
CPU的话

31
00:01:28,599 --> 00:01:29,439
如果你去算的话

32
00:01:29,439 --> 00:01:31,439
很有可能你大概能算出来

33
00:01:31,439 --> 00:01:34,640
你的每一秒中能计算的伏点运算数

34
00:01:34,920 --> 00:01:36,879
可能是0.15左右T

35
00:01:39,000 --> 00:01:40,119
然后你的GPU

36
00:01:40,879 --> 00:01:41,560
GPU的话

37
00:01:41,560 --> 00:01:43,280
你会看到首先你有一个

38
00:01:44,039 --> 00:01:46,079
你的TFLOPS

39
00:01:46,079 --> 00:01:49,120
就是比CPU看上去会高很多

40
00:01:49,120 --> 00:01:52,159
就是你有从0.15变成了112

41
00:01:52,959 --> 00:01:56,000
就是基本上长了六七十倍的样子

42
00:01:57,319 --> 00:01:58,439
另外一块GPU

43
00:01:58,439 --> 00:02:00,479
可能你的显存会低一点点

44
00:02:00,479 --> 00:02:03,079
就是说你16GB就算不错了

45
00:02:03,359 --> 00:02:06,359
当然现在有32GB的GPU

46
00:02:06,359 --> 00:02:09,359
但是你现在基本上到32GB就到顶了

47
00:02:09,359 --> 00:02:10,759
但是如果你用CPU的话

48
00:02:10,759 --> 00:02:11,759
你可以一直插内存

49
00:02:11,759 --> 00:02:13,840
插到128G或者甚至是一个T

50
00:02:13,840 --> 00:02:15,400
两个T都是有可能的

51
00:02:16,840 --> 00:02:18,800
所以就是说不管怎么样

52
00:02:18,840 --> 00:02:21,719
这个大概就是大家能看到的

53
00:02:22,080 --> 00:02:25,800
一个普通的GPU的电脑的配置

54
00:02:25,800 --> 00:02:26,560
长什么样子

55
00:02:26,560 --> 00:02:29,160
有个CPU会连到你的主内存

56
00:02:29,320 --> 00:02:31,920
CPU也会简单起见

57
00:02:31,920 --> 00:02:33,280
就是可以连到你的GPU

58
00:02:33,280 --> 00:02:34,800
他们之间是可以通讯的

59
00:02:36,800 --> 00:02:38,960
接下来我们来看一下你的

60
00:02:39,400 --> 00:02:41,120
CPU会长什么样子

61
00:02:42,800 --> 00:02:45,439
这个是你的一个

62
00:02:45,479 --> 00:02:48,479
I7 6700K

63
00:02:48,479 --> 00:02:50,079
就是一个也是一个很经典的

64
00:02:50,079 --> 00:02:52,199
性价比当年一直很高的一个

65
00:02:52,400 --> 00:02:55,079
CPU的一个芯片图

66
00:02:56,840 --> 00:02:58,439
就大家可以看到是说

67
00:02:59,639 --> 00:03:01,639
首先你有4个核

68
00:03:01,680 --> 00:03:03,240
就每个是一个核

69
00:03:04,520 --> 00:03:07,319
然后你这一块是你的GPU

70
00:03:07,319 --> 00:03:08,159
你的显卡

71
00:03:08,639 --> 00:03:11,360
就是如果你不用插外接显卡的话

72
00:03:11,360 --> 00:03:14,960
那么你的显示器是GPU的计算

73
00:03:14,960 --> 00:03:16,360
是从这里出去的

74
00:03:16,720 --> 00:03:20,280
但是它是一个不是那么强劲的GPU

75
00:03:20,280 --> 00:03:23,080
就是说做显示

76
00:03:23,080 --> 00:03:25,120
然后打一点简单游戏是行的

77
00:03:25,120 --> 00:03:26,520
但是你要做计算的话

78
00:03:26,520 --> 00:03:28,240
是比较难的一件事情

79
00:03:29,800 --> 00:03:30,680
另外一块就是说

80
00:03:30,680 --> 00:03:32,440
这一块比较大的一些局

81
00:03:32,440 --> 00:03:35,160
是来连接到不同的地方

82
00:03:35,160 --> 00:03:36,720
连接到你的内存

83
00:03:37,000 --> 00:03:38,960
连接到一些东西

84
00:03:38,960 --> 00:03:39,960
然后这里也是一些

85
00:03:39,960 --> 00:03:41,480
连接内存的一些通道

86
00:03:42,480 --> 00:03:44,480
中间就是你的一个显存

87
00:03:44,480 --> 00:03:47,400
就是一个第三级显存

88
00:03:47,560 --> 00:03:49,480
就是share的llc

89
00:03:49,480 --> 00:03:51,040
叫lost level of cache

90
00:03:52,040 --> 00:03:52,600
OK

91
00:03:53,960 --> 00:03:54,840
然后我们来看一下

92
00:03:54,840 --> 00:03:55,680
就是说

93
00:03:56,760 --> 00:04:00,360
你怎么样提升你在CPU上的利用率

94
00:04:01,040 --> 00:04:01,960
我做一个运算

95
00:04:01,960 --> 00:04:02,560
我怎么样

96
00:04:02,560 --> 00:04:04,240
他在CPU做的比较快

97
00:04:04,760 --> 00:04:05,520
特别来说

98
00:04:05,520 --> 00:04:07,680
我们其实只关心数值运算

99
00:04:08,200 --> 00:04:09,680
你做我们的矩阵乘法

100
00:04:09,879 --> 00:04:10,960
做各种线性计算

101
00:04:10,960 --> 00:04:14,000
有些别的我们就先不考虑了

102
00:04:15,319 --> 00:04:16,319
首先我们来看一下

103
00:04:16,319 --> 00:04:18,639
我们如果要计算A加B

104
00:04:19,040 --> 00:04:20,280
就A是一个向量

105
00:04:20,280 --> 00:04:21,319
B也是一个向量

106
00:04:21,319 --> 00:04:22,840
之前需要干什么事情

107
00:04:24,600 --> 00:04:26,519
首先你要看到是说

108
00:04:26,519 --> 00:04:27,480
你的A和B

109
00:04:27,480 --> 00:04:29,759
很有可能是放在你的内存里面的

110
00:04:30,040 --> 00:04:32,000
就放在你的主内存里

111
00:04:33,240 --> 00:04:35,879
然后你要想真的要把A加A和B

112
00:04:35,879 --> 00:04:38,360
里面的元素相加起来的话

113
00:04:38,960 --> 00:04:40,360
CPU要干很多事情

114
00:04:40,879 --> 00:04:43,360
他需要把数据从主内存搬到你的

115
00:04:43,360 --> 00:04:44,160
l3 cache

116
00:04:44,160 --> 00:04:48,199
就是刚刚那一个share的llc

117
00:04:49,040 --> 00:04:52,120
然后我再搬到我的l2的cache

118
00:04:52,120 --> 00:04:55,000
l2cache可能就是在你的核里面那一块

119
00:04:56,280 --> 00:04:58,920
然后再搬到你的l1的cache

120
00:04:59,400 --> 00:05:00,960
最后才到寄存器

121
00:05:01,800 --> 00:05:03,160
就寄存器的话

122
00:05:03,160 --> 00:05:05,520
就是每个CPU大概有几十个寄存器

123
00:05:06,039 --> 00:05:09,159
然后数据只有进入寄存器的时候

124
00:05:09,159 --> 00:05:10,680
才能被参与运算

125
00:05:13,879 --> 00:05:15,359
那么所以就是说你看到说

126
00:05:15,359 --> 00:05:18,159
我一个数据要真的要做计算

127
00:05:18,159 --> 00:05:20,719
其实有要走一条很长的路

128
00:05:21,680 --> 00:05:23,199
然后这条路里面

129
00:05:23,199 --> 00:05:25,039
其实你的性能是不一样的

130
00:05:25,919 --> 00:05:28,680
就是你的l1的cache是比较快

131
00:05:28,680 --> 00:05:30,560
这里面最快的当然是寄存器了

132
00:05:30,560 --> 00:05:33,599
寄存器你可以认为跟你的主频是一样快的

133
00:05:34,439 --> 00:05:38,360
但是l1它比寄存器大那么一点点

134
00:05:38,360 --> 00:05:39,680
寄存器那么就几十个

135
00:05:39,680 --> 00:05:41,520
l1可能是几十K

136
00:05:42,080 --> 00:05:43,400
它比寄存器要大

137
00:05:43,760 --> 00:05:46,400
但是它的访问延迟就是比较高了

138
00:05:46,400 --> 00:05:47,879
是0.5纳秒

139
00:05:49,360 --> 00:05:53,040
然后你的l2的cache又比l1要大那么一点点

140
00:05:53,040 --> 00:05:56,480
可能是几十K或者是甚至可能大一点

141
00:05:56,480 --> 00:05:57,480
达到一个兆了

142
00:05:58,280 --> 00:06:02,000
它是大概是7纳秒的样子

143
00:06:03,000 --> 00:06:04,600
所以可以看到是说

144
00:06:05,199 --> 00:06:10,879
访问一次l2的延时是14倍访问一次l1

145
00:06:12,000 --> 00:06:14,199
同样道理是说你l3的cache更大

146
00:06:14,199 --> 00:06:16,000
l3可以现在做到几十兆

147
00:06:16,519 --> 00:06:18,879
访问l3的cache更大

148
00:06:18,879 --> 00:06:22,079
但主类存现在就是几十G的话

149
00:06:22,079 --> 00:06:24,399
访问主类存的延时更长

150
00:06:24,399 --> 00:06:26,639
大概是100纳秒的样子

151
00:06:27,480 --> 00:06:29,879
就相当于访问200次l1

152
00:06:30,879 --> 00:06:32,480
所以就是说

153
00:06:32,480 --> 00:06:35,480
这里面的你发现就是说

154
00:06:35,480 --> 00:06:37,639
我虽然CPU可能算的比较快

155
00:06:37,639 --> 00:06:38,639
你的频率比较高

156
00:06:38,639 --> 00:06:41,040
但实际上你发现实测下来

157
00:06:41,040 --> 00:06:45,759
你远远的没有达到你的CPU里的算的值

158
00:06:45,759 --> 00:06:46,800
那是为什么

159
00:06:47,079 --> 00:06:49,079
通常是时候

160
00:06:49,120 --> 00:06:51,159
特别是对于数字运算来讲

161
00:06:51,519 --> 00:06:54,240
就是你的类存访问太慢了

162
00:06:56,399 --> 00:06:58,639
所以一般来说我们所谓的加速

163
00:06:59,240 --> 00:07:01,240
一个比较大的关键点

164
00:07:01,240 --> 00:07:05,959
就是用提升我的空间和时间上的类存的本地性

165
00:07:07,199 --> 00:07:10,959
就是说使得我的缓存的效率更高

166
00:07:13,199 --> 00:07:14,199
具体来说

167
00:07:14,839 --> 00:07:15,839
有两种办法

168
00:07:15,839 --> 00:07:17,879
一个是提升时间上的本地性

169
00:07:17,879 --> 00:07:19,879
一个是提升空间上的本地性

170
00:07:20,560 --> 00:07:22,240
时间上的本地性是说

171
00:07:22,519 --> 00:07:24,039
我尽量一个数据

172
00:07:24,039 --> 00:07:25,279
反正你算的话

173
00:07:25,279 --> 00:07:28,319
我也得从主类存一直搬到我的集成器

174
00:07:28,839 --> 00:07:30,839
假设这个数据当前被用了

175
00:07:31,479 --> 00:07:33,439
我希望你下一次还会被用到

176
00:07:34,399 --> 00:07:36,439
就是说如果你数据不用了的话

177
00:07:36,439 --> 00:07:41,079
它CPU会把你从数据一层一层回退回去

178
00:07:41,319 --> 00:07:43,240
如果你下一次数据还被用到

179
00:07:43,279 --> 00:07:46,479
那么就不需要把主类存一直搬过来了

180
00:07:46,680 --> 00:07:48,680
因为你就会重用在你的缓存

181
00:07:48,680 --> 00:07:50,360
要么你可能还在集成器里

182
00:07:50,399 --> 00:07:54,159
要么你就还已经在L1的cache里面

183
00:07:54,399 --> 00:07:57,279
你就不需要去下面再去取数据了

184
00:07:59,120 --> 00:08:00,240
第二个是说

185
00:08:00,279 --> 00:08:03,199
我们希望提升你的数据的空间性

186
00:08:03,680 --> 00:08:04,680
就是说一个数据

187
00:08:04,680 --> 00:08:07,479
如果在类存里面是存在一起的话

188
00:08:07,919 --> 00:08:09,800
类存就CPU读的时候

189
00:08:09,800 --> 00:08:12,240
它其实是一块一块读

190
00:08:12,680 --> 00:08:14,240
它也会去提前去读一点

191
00:08:14,519 --> 00:08:17,599
所以假设你数据我在计算

192
00:08:17,599 --> 00:08:19,159
下一个计算的时候

193
00:08:19,159 --> 00:08:22,039
我用的数据跟前一个是相邻的话

194
00:08:22,879 --> 00:08:25,399
那么CPU会帮你做很多事情

195
00:08:25,399 --> 00:08:26,039
帮你优化

196
00:08:26,040 --> 00:08:29,160
使得你在做之前准备的时候

197
00:08:29,160 --> 00:08:30,640
它就一次性的搬过来了

198
00:08:31,120 --> 00:08:34,960
有点像说你做mini batch的时候

199
00:08:34,960 --> 00:08:36,600
我其实一次是读一个batch

200
00:08:39,440 --> 00:08:41,440
所以我们给样例分析

201
00:08:43,000 --> 00:08:43,920
就是说

202
00:08:46,759 --> 00:08:47,360
具体来说

203
00:08:47,360 --> 00:08:49,800
我们说我们一个矩阵是怎么存的

204
00:08:50,960 --> 00:08:53,600
假设我们一个矩阵是按照

205
00:08:56,159 --> 00:08:57,240
这是按行存

206
00:08:57,360 --> 00:08:58,799
这里我们写错了

207
00:08:58,799 --> 00:09:01,360
就是你不应该是这个地方

208
00:09:01,360 --> 00:09:02,519
不许是按列存

209
00:09:02,639 --> 00:09:04,919
这是按行存

210
00:09:06,240 --> 00:09:07,799
假设我的矩阵是这么存起来的

211
00:09:07,799 --> 00:09:12,199
就是我这一个4×8的一个矩阵

212
00:09:13,079 --> 00:09:16,000
我的数据是说在类存中间

213
00:09:16,000 --> 00:09:17,439
就是012

214
00:09:17,439 --> 00:09:18,360
就是类存地址

215
00:09:18,480 --> 00:09:20,240
假设是一直这么过来

216
00:09:20,240 --> 00:09:22,240
然后这也是89

217
00:09:23,240 --> 00:09:29,440
那么你访问一行会比访问一列要快

218
00:09:30,919 --> 00:09:35,200
这是因为一个CPU一次会读取64个字节

219
00:09:37,320 --> 00:09:38,360
然后就是说

220
00:09:40,039 --> 00:09:42,039
一个float是4个字节

221
00:09:42,080 --> 00:09:46,759
就是说如果你是用的浮点32位的话

222
00:09:46,759 --> 00:09:47,799
那就是一次性

223
00:09:47,840 --> 00:09:52,680
我会读16个浮点数

224
00:09:53,240 --> 00:09:57,640
说白了一次性会把整个这一列给读进去

225
00:09:57,760 --> 00:09:59,040
这两行读进去

226
00:10:01,200 --> 00:10:02,400
那么所以你会

227
00:10:02,400 --> 00:10:04,840
如果你按照行来访问的话

228
00:10:04,960 --> 00:10:06,320
一次性读过去的话

229
00:10:06,320 --> 00:10:08,440
你会发现我就一直

230
00:10:08,880 --> 00:10:10,280
已经在我的

231
00:10:11,560 --> 00:10:13,800
显存里我的缓存里面了

232
00:10:14,160 --> 00:10:15,720
就不需要说我读到下一个

233
00:10:15,720 --> 00:10:16,760
我还得回去看

234
00:10:17,840 --> 00:10:19,440
但是假设你是按列读的话

235
00:10:21,040 --> 00:10:23,000
我读这两个东西还好一点

236
00:10:23,000 --> 00:10:25,520
就是说读完他再去读他的时候

237
00:10:25,520 --> 00:10:28,560
你发现他其实已经在你的显存里面了

238
00:10:28,560 --> 00:10:31,480
因为我一次会读64个字节

239
00:10:32,840 --> 00:10:34,000
但问题是说

240
00:10:34,160 --> 00:10:36,440
我在访问下一个的时候

241
00:10:36,720 --> 00:10:39,320
等于是我前面读的基本上就没用了

242
00:10:39,920 --> 00:10:42,320
我还得再去读一个缓存线

243
00:10:42,320 --> 00:10:43,240
就是cashline

244
00:10:43,240 --> 00:10:47,919
另外一块就是说

245
00:10:48,200 --> 00:10:49,399
这个是说每次读

246
00:10:49,600 --> 00:10:51,440
但CPU也是比较聪明

247
00:10:51,440 --> 00:10:52,159
比较聪明

248
00:10:52,159 --> 00:10:54,519
他就会去读取下一个缓存线

249
00:10:54,519 --> 00:10:56,159
就是说他读完这一个

250
00:10:56,159 --> 00:10:58,240
他觉得你可能下一个还会用

251
00:10:58,240 --> 00:10:59,560
就是说你读完他之后

252
00:10:59,560 --> 00:11:01,600
他会继续去读下一个缓存线

253
00:11:02,360 --> 00:11:05,279
也会说我会把读完他之后

254
00:11:05,279 --> 00:11:07,000
我会把这一块也读进来

255
00:11:08,440 --> 00:11:09,919
但是说我们这个数据比较小

256
00:11:10,039 --> 00:11:11,560
这就是一个4乘8的矩阵

257
00:11:11,560 --> 00:11:12,759
所以怎么样都不

258
00:11:12,799 --> 00:11:14,720
就算按列访问都还行

259
00:11:14,720 --> 00:11:17,279
但如果你真的是一个比较长的的话

260
00:11:17,399 --> 00:11:19,840
就算你说我是会给你预读

261
00:11:19,840 --> 00:11:22,480
那么每一次你都会带来一次的

262
00:11:22,480 --> 00:11:23,600
找不到cash

263
00:11:23,600 --> 00:11:25,799
那么每次会触发你重新预读

264
00:11:25,840 --> 00:11:27,960
所以你按列读会是比较慢

265
00:11:29,559 --> 00:11:32,759
所以说取决于你的矩阵是按行存

266
00:11:32,799 --> 00:11:34,000
还是按照列存

267
00:11:34,000 --> 00:11:36,240
按列存就是在列上面是连续地址

268
00:11:36,799 --> 00:11:37,679
那么你的访问

269
00:11:37,679 --> 00:11:40,559
你按行访问和按列访问是非常的

270
00:11:40,559 --> 00:11:41,759
速度是非常不一样

271
00:11:42,000 --> 00:11:44,360
特别是当你的矩阵比较大的情况下

272
00:11:46,240 --> 00:11:46,720
OK

273
00:11:48,000 --> 00:11:50,799
另外一个是说我们要提升的

274
00:11:50,799 --> 00:11:54,039
CPU的利用率的第二个办法是运行

275
00:11:54,919 --> 00:11:56,600
我们知道因为摩尔定理

276
00:11:56,600 --> 00:11:59,960
所以我们的其实CPU在的频率

277
00:12:00,000 --> 00:12:02,360
不管是CPU的频率还是GPU的频率

278
00:12:02,399 --> 00:12:03,759
在过去一些年

279
00:12:03,759 --> 00:12:05,559
它的涨的都是比较慢的

280
00:12:06,200 --> 00:12:09,480
但是我们的还是按照摩尔定理来

281
00:12:09,480 --> 00:12:11,639
是因为我们加了很多核

282
00:12:12,720 --> 00:12:14,720
就是说比如说高端的CPU

283
00:12:14,759 --> 00:12:15,759
它有几十个核

284
00:12:15,759 --> 00:12:19,720
比如说我们用来这场课程演示的

285
00:12:19,720 --> 00:12:24,240
这台机器上有两个英特尔至强的CPU

286
00:12:24,679 --> 00:12:28,559
然后每一个CPU它是有32个物理核

287
00:12:29,519 --> 00:12:30,480
每一个

288
00:12:31,399 --> 00:12:32,840
所以加起来是64个核

289
00:12:34,439 --> 00:12:37,679
但是英特尔是比较有意思的是说

290
00:12:37,720 --> 00:12:39,759
你看到的核

291
00:12:40,080 --> 00:12:42,279
就是说假设你从芯片上来看

292
00:12:42,279 --> 00:12:44,039
你是有4个区域有4个核

293
00:12:44,039 --> 00:12:47,840
就记得我们之前图片里面有4个区域

294
00:12:47,879 --> 00:12:48,120
对吧

295
00:12:48,120 --> 00:12:49,600
就是4个物理的核

296
00:12:50,879 --> 00:12:52,600
然后但是你在系统里面看

297
00:12:52,600 --> 00:12:54,039
可能是看到是8个

298
00:12:55,159 --> 00:12:57,360
虽然你的物理核是4个

299
00:12:57,360 --> 00:12:59,679
但是英特尔可能会告诉你有8个核

300
00:13:00,159 --> 00:13:01,720
因为他用了超线程

301
00:13:01,960 --> 00:13:06,600
他就把一个CPU超线程的两个核

302
00:13:06,600 --> 00:13:09,759
就等于是有两个超线程在做影响

303
00:13:11,000 --> 00:13:15,200
但是超线程对于我们是没有太多用了

304
00:13:15,720 --> 00:13:19,560
超线程对于比如说计算密集型的应用

305
00:13:19,560 --> 00:13:20,240
没有太多用

306
00:13:20,240 --> 00:13:25,040
是因为这两个超线程共享的是一个

307
00:13:25,040 --> 00:13:25,759
寄存器

308
00:13:27,240 --> 00:13:29,680
其实你寄存器并没有被打捕

309
00:13:30,159 --> 00:13:32,440
你是32个寄存器还是32个

310
00:13:33,440 --> 00:13:37,600
那就是说因为你的做运算的时候

311
00:13:37,600 --> 00:13:38,920
你要把数据放在寄存器里

312
00:13:38,920 --> 00:13:39,320
对吧

313
00:13:40,160 --> 00:13:43,880
所以但是你一个核把寄存器全部用满了的话

314
00:13:43,880 --> 00:13:46,000
另外一个其实也超线程也没用

315
00:13:46,000 --> 00:13:46,720
也得等着

316
00:13:46,920 --> 00:13:51,400
所以说假设你看到你的英特尔CPU上有8个核

317
00:13:51,960 --> 00:13:53,560
系统告诉你8个核

318
00:13:53,600 --> 00:13:55,480
你从4线程变到8线程

319
00:13:55,480 --> 00:13:58,680
可能是不会有太多的性能的提升

320
00:13:59,400 --> 00:14:05,560
是因为超线程其实一般是给不一样的计算人物用的

321
00:14:06,360 --> 00:14:09,440
所以对于我们这种计算密集型其实没太多用的

322
00:14:10,480 --> 00:14:10,920
OK

323
00:14:11,360 --> 00:14:13,520
我们再给一个样例的分析

324
00:14:16,520 --> 00:14:18,080
我们当然可以写说

325
00:14:19,200 --> 00:14:22,160
我们在Python里面有写过这样子的东西

326
00:14:22,280 --> 00:14:26,160
就是说我假设我要计算A加B的话

327
00:14:26,160 --> 00:14:28,000
然后我说我可以for loop一下

328
00:14:28,880 --> 00:14:30,400
就for i等于range

329
00:14:30,400 --> 00:14:31,560
names a

330
00:14:31,560 --> 00:14:34,160
然后ci等于ai加上bi

331
00:14:35,920 --> 00:14:37,160
同样道理是说

332
00:14:37,280 --> 00:14:39,640
同样的话我们可以说C等于A加B

333
00:14:39,640 --> 00:14:40,880
大家用狼牌也好

334
00:14:40,880 --> 00:14:43,360
随便用什么计算框架也好

335
00:14:45,280 --> 00:14:48,080
左边会比右边会慢很多

336
00:14:48,840 --> 00:14:49,840
大家可以去算一下

337
00:14:49,840 --> 00:14:52,400
就我们应该是讲过给大家演示过

338
00:14:52,400 --> 00:14:53,720
慢个几百倍可以是

339
00:14:54,640 --> 00:14:56,160
那是因为有两个原因

340
00:14:57,159 --> 00:15:01,000
第一个原因是说左边调用了n次函数

341
00:15:01,000 --> 00:15:03,879
就假设你n是你的A的长度的话

342
00:15:04,360 --> 00:15:07,120
就每次调用它是有开销的

343
00:15:07,120 --> 00:15:09,439
Python的开销是挺大的

344
00:15:09,719 --> 00:15:11,799
那是因为它的C的API写的

345
00:15:11,799 --> 00:15:17,159
我觉得写的可能是用的技术比较落后

346
00:15:17,799 --> 00:15:19,879
当然号称是说下一个版本

347
00:15:19,959 --> 00:15:23,639
在未来两三年会有百分之多少的提升

348
00:15:23,639 --> 00:15:25,120
或两三倍的提升

349
00:15:25,159 --> 00:15:27,399
但实际上来说还是非常慢的一件事情

350
00:15:27,799 --> 00:15:29,399
就是我代表测一下

351
00:15:29,399 --> 00:15:31,879
我记得python大概每秒钟能够上个

352
00:15:34,159 --> 00:15:37,080
118次方的运算可能就差不多了

353
00:15:37,360 --> 00:15:39,879
但是你CPU的性能远远高于那个对吧

354
00:15:41,480 --> 00:15:42,720
第二个是说

355
00:15:43,879 --> 00:15:46,000
这个运算非常容易做并行

356
00:15:46,720 --> 00:15:51,639
如果你是我把OP加法用在C++来实现的话

357
00:15:51,680 --> 00:15:54,159
那么你可以认为它可以写成一个

358
00:15:54,159 --> 00:15:55,399
这样子的for loop对吧

359
00:15:56,519 --> 00:15:59,879
然后我在下面标记说我用OMP

360
00:15:59,879 --> 00:16:02,839
就是在C++里面用的比较常用的一个

361
00:16:02,839 --> 00:16:03,519
并行的方法

362
00:16:03,759 --> 00:16:07,039
就是说我这个for loop可以被并行执行

363
00:16:07,959 --> 00:16:09,679
那么你可能会多个线程

364
00:16:09,679 --> 00:16:12,439
每个线程会去算一些的元素

365
00:16:12,879 --> 00:16:16,279
这样子你可以来到很好的能够利用你的多核

366
00:16:17,759 --> 00:16:20,519
所以就是说CPU的运算的话

367
00:16:20,559 --> 00:16:22,279
基本是两块

368
00:16:22,519 --> 00:16:25,360
一块是提升你的内存的本地性

369
00:16:25,799 --> 00:16:27,639
包括了你访问内存的时候

370
00:16:27,759 --> 00:16:29,759
时间上空间上

371
00:16:29,759 --> 00:16:33,079
第二个是说你尽量的要用你的多核

372
00:16:33,079 --> 00:16:34,720
你的CPU可能有4个核

373
00:16:34,720 --> 00:16:36,879
或者好一点的服务器的CPU

374
00:16:36,879 --> 00:16:37,959
你可能有32个核

375
00:16:39,039 --> 00:16:39,360
OK

376
00:16:39,360 --> 00:16:44,240
这就是CPU的大概的架构和它的优化的方法

377
00:16:46,720 --> 00:16:48,439
接下来我们来看一下GPU

378
00:16:49,440 --> 00:16:52,480
这个是Titan X的

379
00:16:52,480 --> 00:16:55,480
他的一个Media喜欢给的一个架构图

380
00:16:57,600 --> 00:16:59,600
就可以看到是说

381
00:17:00,760 --> 00:17:01,680
看你怎么想

382
00:17:01,920 --> 00:17:03,960
就是说你可以认为

383
00:17:05,120 --> 00:17:07,200
这个东西是一个核

384
00:17:07,200 --> 00:17:07,640
就

385
00:17:07,960 --> 00:17:10,360
但Media不叫那个东西不叫核叫什么

386
00:17:10,360 --> 00:17:11,640
它有自己的一套说法

387
00:17:11,640 --> 00:17:14,240
但是为了不把事情搞得特别复杂

388
00:17:14,320 --> 00:17:15,440
你可以认为

389
00:17:15,720 --> 00:17:17,720
它是一个核

390
00:17:19,360 --> 00:17:20,960
如果它是一个核的话

391
00:17:21,200 --> 00:17:22,920
你会发现它其实有挺多核的

392
00:17:22,920 --> 00:17:23,400
对吧

393
00:17:23,960 --> 00:17:25,799
它再数一数那个数出来

394
00:17:25,799 --> 00:17:27,680
我也数不出多少

395
00:17:28,559 --> 00:17:29,799
但是说对Media说

396
00:17:29,799 --> 00:17:31,680
他觉得它这是一个大核

397
00:17:31,960 --> 00:17:33,120
就是说这个是一个大核

398
00:17:33,120 --> 00:17:36,360
叫做GPC

399
00:17:36,840 --> 00:17:38,720
然后这里有6个

400
00:17:38,920 --> 00:17:40,279
取决于你的显卡

401
00:17:40,279 --> 00:17:42,519
就是说所谓的你的显卡是说

402
00:17:42,519 --> 00:17:44,920
3080 3060 3070

403
00:17:44,960 --> 00:17:45,880
就是说你的显卡

404
00:17:45,880 --> 00:17:46,960
就是说你的

405
00:17:47,000 --> 00:17:48,559
有些显卡就是低端显卡

406
00:17:48,559 --> 00:17:50,720
3060就是便宜一点

407
00:17:50,720 --> 00:17:51,319
小一点

408
00:17:51,360 --> 00:17:52,519
3080要多一点

409
00:17:52,519 --> 00:17:53,960
说白了也没什么区别

410
00:17:53,960 --> 00:17:56,440
它就是放了不同的大核而已

411
00:17:57,319 --> 00:17:57,759
对吧

412
00:17:57,799 --> 00:17:59,279
3080可能大核多一点

413
00:17:59,279 --> 00:18:01,360
3060大核少一点

414
00:18:02,039 --> 00:18:03,840
然后大核里面当然有很多小核

415
00:18:04,319 --> 00:18:06,000
每个小核每一个绿点

416
00:18:06,240 --> 00:18:07,039
每一个绿点

417
00:18:07,039 --> 00:18:10,480
它其实你可以认为是一个计算单元

418
00:18:11,840 --> 00:18:14,480
就是说你可以在一个绿点上开一个线程

419
00:18:16,960 --> 00:18:17,920
所以你看到是说

420
00:18:17,920 --> 00:18:18,960
你如果是这么看的话

421
00:18:18,960 --> 00:18:20,960
你可以看出这里面有上千个绿点

422
00:18:21,000 --> 00:18:21,440
对吧

423
00:18:22,480 --> 00:18:25,039
所以就是说GPU可以开出上千个线程来

424
00:18:25,440 --> 00:18:28,279
说明它确实是有那么多个计算单元

425
00:18:29,840 --> 00:18:30,360
OK

426
00:18:30,400 --> 00:18:32,160
CPU是说你一个核里面

427
00:18:32,160 --> 00:18:33,120
你可以简单认为

428
00:18:33,120 --> 00:18:36,160
它就是一次算一个指令

429
00:18:36,240 --> 00:18:37,279
但是GPU来讲

430
00:18:37,279 --> 00:18:38,519
那一个是一个绿点

431
00:18:38,519 --> 00:18:39,920
能算一个指令

432
00:18:40,600 --> 00:18:42,319
那么看起来当然是说

433
00:18:42,319 --> 00:18:45,759
你又可以每一次能算个上千个

434
00:18:46,160 --> 00:18:47,519
所以就算每一个绿点

435
00:18:47,519 --> 00:18:49,640
我的计算能力比CPU弱

436
00:18:49,680 --> 00:18:50,680
但是我多

437
00:18:51,519 --> 00:18:52,279
我一多的话

438
00:18:52,279 --> 00:18:57,079
那么就是说我一个比你算个慢个四五倍的样子

439
00:18:57,240 --> 00:19:00,599
但我的计算单元比你多个1000倍

440
00:19:00,640 --> 00:19:02,279
所以我也能比你快100倍

441
00:19:03,200 --> 00:19:04,559
这就是GPU的答法

442
00:19:06,200 --> 00:19:08,000
就我们具体可以来看一下

443
00:19:08,000 --> 00:19:09,920
就是说我们来对比一下

444
00:19:10,039 --> 00:19:15,640
一个CPU和一个GPU的一个区别

445
00:19:16,160 --> 00:19:18,119
首先我们有个有个细线

446
00:19:18,319 --> 00:19:19,440
这个线就是说

447
00:19:19,440 --> 00:19:23,759
线这边是说一般般的CPU和一般的GPU

448
00:19:23,759 --> 00:19:25,960
线这边就是高端一点的

449
00:19:27,839 --> 00:19:29,279
首先看一下CPU的话

450
00:19:29,279 --> 00:19:30,599
你的核一般来说

451
00:19:30,599 --> 00:19:31,759
你就是6核

452
00:19:31,960 --> 00:19:33,359
一般般的CPU

453
00:19:33,519 --> 00:19:35,640
然后好一点的大概是64核

454
00:19:36,720 --> 00:19:38,839
显卡的话一般般的话

455
00:19:38,839 --> 00:19:40,039
你大概就是

456
00:19:40,200 --> 00:19:43,119
因为就是你大核的数目不一样

457
00:19:43,120 --> 00:19:45,880
所以导致你一般般的可能是2000个核

458
00:19:46,280 --> 00:19:47,840
好一点的可以到4000核

459
00:19:49,440 --> 00:19:51,200
就是说你看到

460
00:19:51,880 --> 00:19:54,000
这是一个比较本质的区别

461
00:19:55,000 --> 00:19:58,000
就GPU的核远远的要多于CPU

462
00:19:59,360 --> 00:20:02,000
所以这个就导致说你的TFLOPS

463
00:20:02,160 --> 00:20:04,200
就每秒钟能计算的浮点数

464
00:20:04,520 --> 00:20:05,680
它是要远远的多

465
00:20:06,040 --> 00:20:07,320
每秒计算的浮点数

466
00:20:07,320 --> 00:20:09,440
你可以简单算就是你的核的数目

467
00:20:09,440 --> 00:20:11,560
乘以你的主频

468
00:20:12,039 --> 00:20:14,319
和你每一个计算单元

469
00:20:14,319 --> 00:20:19,720
在每一次时钟周期里面能算多少个

470
00:20:20,240 --> 00:20:22,599
CPU说我有矩阵指令

471
00:20:22,599 --> 00:20:23,679
我可以vector指令

472
00:20:23,679 --> 00:20:25,319
我可以一次可能算个4个

473
00:20:25,319 --> 00:20:26,480
或者6个浮点运算

474
00:20:26,720 --> 00:20:28,440
但是加不住你核少

475
00:20:29,240 --> 00:20:31,960
GPU的话说我每一个单元

476
00:20:31,960 --> 00:20:32,799
我就算一个数

477
00:20:32,799 --> 00:20:34,159
但是我加不住我核多

478
00:20:35,000 --> 00:20:35,440
OK

479
00:20:35,440 --> 00:20:37,200
所以这就是带来了

480
00:20:37,200 --> 00:20:39,759
为什么GPU要比CPU快

481
00:20:40,279 --> 00:20:42,160
是因为它的核多

482
00:20:43,759 --> 00:20:47,680
第二点是说你核多还没有太多用

483
00:20:48,160 --> 00:20:49,279
就是说我们知道

484
00:20:49,279 --> 00:20:52,160
如果你要算一个向量

485
00:20:52,319 --> 00:20:54,079
或者算什么东西的话

486
00:20:54,079 --> 00:20:59,240
其实你很难打满你的计算峰值

487
00:20:59,480 --> 00:21:01,480
是因为你的带宽跟不上

488
00:21:02,160 --> 00:21:04,920
每一次你得去从主内存读东西

489
00:21:07,279 --> 00:21:09,480
就是说你看到是说我的内存带宽

490
00:21:09,480 --> 00:21:10,720
我们先不看内存大小

491
00:21:10,920 --> 00:21:12,039
就内存带宽

492
00:21:12,039 --> 00:21:13,759
就是说我一般的CPU

493
00:21:13,759 --> 00:21:17,039
大概就每秒钟算30个GB

494
00:21:17,039 --> 00:21:21,839
每秒带宽就在内存里面读数据到CPU

495
00:21:22,920 --> 00:21:25,559
你的好一点的也就是100的样子

496
00:21:27,039 --> 00:21:28,480
那么这就意味着是说

497
00:21:28,480 --> 00:21:31,880
我不管我的算得有多快

498
00:21:32,240 --> 00:21:34,440
每次我只能从我的内存里面读

499
00:21:34,440 --> 00:21:36,039
100个GB的数据出来

500
00:21:36,960 --> 00:21:41,440
你想想假设你的神经网络很大的话

501
00:21:41,440 --> 00:21:44,159
我的神经网络可能就十几个GB

502
00:21:44,159 --> 00:21:47,879
模型大小

503
00:21:47,879 --> 00:21:49,279
然后还有很多中间数据

504
00:21:49,399 --> 00:21:51,680
每次算完就把中间数据写来写去了

505
00:21:52,079 --> 00:21:53,839
基本上就导致说

506
00:21:53,960 --> 00:21:55,319
就算你的核很多

507
00:21:55,319 --> 00:21:57,559
我也很有可能被Upper Bound住了

508
00:21:58,960 --> 00:22:03,559
所以GPU需要去把内存带宽加的比较大

509
00:22:04,079 --> 00:22:05,639
就一般般的GPU

510
00:22:05,639 --> 00:22:07,639
它的内存带宽也可以到400GB

511
00:22:09,480 --> 00:22:12,159
就是你看到GPU可能用的是DDR5

512
00:22:13,000 --> 00:22:14,480
CPU可能是DDR4

513
00:22:14,480 --> 00:22:15,159
DDR3

514
00:22:15,720 --> 00:22:17,599
好一点的GPU用的是HBM

515
00:22:17,599 --> 00:22:22,079
就是真的就是有它带宽有N层

516
00:22:22,079 --> 00:22:23,319
然后它通道比较大

517
00:22:23,519 --> 00:22:24,839
可以做到现在好一点

518
00:22:24,839 --> 00:22:25,960
能做到一个T比

519
00:22:26,720 --> 00:22:29,399
就每秒钟我能去读一个T的数据出来

520
00:22:29,919 --> 00:22:31,839
那么就是说你基本上是10倍于

521
00:22:31,839 --> 00:22:33,480
你的高端的CPU的性能

522
00:22:36,480 --> 00:22:40,240
所以就是说GPU通过你的多核和你的带宽

523
00:22:40,240 --> 00:22:42,919
来使得你真的在计算上能做的比较快

524
00:22:42,919 --> 00:22:46,519
就是说那种跟大量并行的数值运算

525
00:22:46,519 --> 00:22:47,279
做的比较快

526
00:22:47,559 --> 00:22:48,879
但它的代价是什么

527
00:22:49,119 --> 00:22:52,439
它的代价是说你的内存大小是做不到很大

528
00:22:53,679 --> 00:22:55,599
现在基本上做到32GB

529
00:22:56,119 --> 00:22:58,079
很好的CPU能做48GB

530
00:22:59,599 --> 00:23:00,679
那你内存的话

531
00:23:00,679 --> 00:23:01,480
你CPU的话

532
00:23:01,480 --> 00:23:04,200
其实你的服务器到一个TB也是很正常的

533
00:23:06,079 --> 00:23:07,200
为什么是因为

534
00:23:07,880 --> 00:23:09,319
不是说我做不上很多时候

535
00:23:09,319 --> 00:23:10,720
是说那个东西很贵

536
00:23:12,519 --> 00:23:16,200
就是就这个东西是挺贵的一个事情

537
00:23:17,240 --> 00:23:20,079
就内存可能是比你的计算还要贵

538
00:23:21,559 --> 00:23:22,799
你可以一般来说

539
00:23:22,799 --> 00:23:26,360
你说一个GB可能你要去自己

540
00:23:26,360 --> 00:23:27,480
你信件厂商

541
00:23:27,480 --> 00:23:29,759
然后我记得价格可能是10美金

542
00:23:30,160 --> 00:23:31,480
所以的话你32GB

543
00:23:31,480 --> 00:23:33,119
那就320块钱就没了

544
00:23:34,160 --> 00:23:35,640
你内存你当然是很便宜

545
00:23:35,720 --> 00:23:36,920
32GB内存

546
00:23:36,920 --> 00:23:41,519
我记得可能一共就几十美金差不多了

547
00:23:42,119 --> 00:23:42,559
或者

548
00:23:43,200 --> 00:23:43,759
到

549
00:23:45,279 --> 00:23:47,480
可能就你是自己零售

550
00:23:47,480 --> 00:23:49,039
你可能也就100美金

551
00:23:49,039 --> 00:23:52,200
这个是说你硬件厂去拿他的货

552
00:23:52,200 --> 00:23:54,200
他可能成本就10块钱了

553
00:23:55,279 --> 00:23:56,480
就他卖给你还卖贵一点

554
00:23:56,480 --> 00:23:56,879
对吧

555
00:23:57,240 --> 00:24:00,240
所以就导致说你的低端的显卡

556
00:24:00,240 --> 00:24:01,360
你的显存很少

557
00:24:01,760 --> 00:24:03,640
但内存通常是大家不会扣你

558
00:24:03,640 --> 00:24:05,840
那显存会扣你是因为显存都是高

559
00:24:05,840 --> 00:24:06,720
带宽的显存

560
00:24:06,720 --> 00:24:07,920
所以它是很贵的

561
00:24:08,800 --> 00:24:09,240
OK

562
00:24:09,600 --> 00:24:12,360
所以就是说你可以看到GPU通过高

563
00:24:12,360 --> 00:24:13,080
类

564
00:24:14,560 --> 00:24:16,400
高的类内存带宽

565
00:24:16,400 --> 00:24:19,680
多核来换取了你的计算

566
00:24:19,920 --> 00:24:20,520
更快

567
00:24:22,160 --> 00:24:24,240
他付出的就是说我的内存不会很大

568
00:24:24,520 --> 00:24:26,120
我另外一个付出的是这个东西

569
00:24:26,680 --> 00:24:28,560
是我的控制流很弱

570
00:24:29,760 --> 00:24:31,680
因为CPU它是一个通用计算

571
00:24:31,680 --> 00:24:34,480
它不是用来给你纯算矩阵乘法

572
00:24:34,720 --> 00:24:38,320
它还得算各种各种所有的应用

573
00:24:38,440 --> 00:24:40,360
就是说我要确认我的HTML

574
00:24:40,360 --> 00:24:41,920
我要做很多别的事情

575
00:24:42,280 --> 00:24:44,760
所以它是一个它有很多if else的

576
00:24:44,760 --> 00:24:46,320
要处理这种控制流

577
00:24:46,320 --> 00:24:47,840
就跳来跳去跳转

578
00:24:48,520 --> 00:24:49,720
盘到这里要盘那里

579
00:24:50,840 --> 00:24:54,800
就这一块CPU是做得非常好的

580
00:24:55,319 --> 00:24:57,119
英特尔的你看到他的芯片里面

581
00:24:57,119 --> 00:24:59,319
可能逻辑单元

582
00:24:59,319 --> 00:25:02,159
它可能一个核里面有一半的空间

583
00:25:02,159 --> 00:25:04,680
可能是做有可能一个核里面一半的是

584
00:25:04,680 --> 00:25:05,240
做缓存

585
00:25:05,240 --> 00:25:08,639
剩下的里面一半是做各种控制流的

586
00:25:08,639 --> 00:25:09,159
一些控制

587
00:25:09,159 --> 00:25:11,200
就是他得去预判你是走哪边

588
00:25:11,599 --> 00:25:12,960
要中断你的流水线

589
00:25:13,119 --> 00:25:13,919
要干嘛干嘛

590
00:25:14,480 --> 00:25:16,480
剩下那么一点点是给你做计算

591
00:25:17,919 --> 00:25:21,119
那么GPU就是说GPU的芯片大小

592
00:25:21,119 --> 00:25:22,559
比你CPU大一点点

593
00:25:23,200 --> 00:25:24,039
就芯片大小

594
00:25:24,039 --> 00:25:25,960
因为大家都是几纳米的情况下

595
00:25:25,960 --> 00:25:28,839
芯片大小就取决你能放多个东西进去

596
00:25:29,639 --> 00:25:31,359
那么就是说你放了几千个核

597
00:25:31,359 --> 00:25:32,079
你又放了

598
00:25:33,240 --> 00:25:34,720
主要是你放了核的话

599
00:25:34,720 --> 00:25:36,519
那么你剩下的东西就不多了

600
00:25:36,919 --> 00:25:38,279
剩下的芯片面积不多了

601
00:25:38,279 --> 00:25:38,799
情况下

602
00:25:38,799 --> 00:25:40,919
他就是把显存弄得少一点点

603
00:25:41,200 --> 00:25:44,200
他GPU的显存没有像CPU那样要几层

604
00:25:44,559 --> 00:25:47,279
因为我的整体我的数字运算

605
00:25:47,279 --> 00:25:48,119
我的内存

606
00:25:48,679 --> 00:25:49,679
那种没那么复杂

607
00:25:49,679 --> 00:25:51,399
所以我不需要做三级显存

608
00:25:52,559 --> 00:25:53,480
另外一块就是说

609
00:25:53,480 --> 00:25:56,279
我把所有做逻辑控制流的这一块单元

610
00:25:56,279 --> 00:25:57,879
逻辑运算单元全部删掉了

611
00:25:58,960 --> 00:25:59,879
这导致他有更

612
00:25:59,879 --> 00:26:01,240
他把所有的芯片面积

613
00:26:01,240 --> 00:26:03,200
几乎是用来做你的计算单元

614
00:26:03,759 --> 00:26:04,440
这也是说

615
00:26:04,879 --> 00:26:06,319
这里并没有什么魔法

616
00:26:06,319 --> 00:26:09,919
说GPU用了什么特殊的

617
00:26:09,919 --> 00:26:11,879
Magic的东西让你变得很快

618
00:26:12,399 --> 00:26:15,440
这里面只有说你的硬件是给谁设计的

619
00:26:16,720 --> 00:26:18,319
就你就那么一块芯片面积

620
00:26:19,200 --> 00:26:20,279
那么你要给谁设计

621
00:26:21,039 --> 00:26:24,519
就是说GPU说我就是给大能够做很好

622
00:26:24,519 --> 00:26:26,639
运行的数字运算做的

623
00:26:26,920 --> 00:26:29,440
所以我的这一块比较好

624
00:26:29,440 --> 00:26:31,079
但我别的事情感觉都不好

625
00:26:31,839 --> 00:26:35,399
OK这就是CPU和GPU的一个区别

626
00:26:36,839 --> 00:26:38,240
那反过来讲就是说

627
00:26:38,519 --> 00:26:41,200
如果我要提升我的GPU的利用率的话

628
00:26:41,200 --> 00:26:41,639
怎么办

629
00:26:43,359 --> 00:26:45,200
其实本质上跟你CPU是一样的

630
00:26:46,200 --> 00:26:47,960
就你GPU你可以认为就是一个

631
00:26:47,960 --> 00:26:50,000
本质上就是一个那个弗洛伊曼架头

632
00:26:50,000 --> 00:26:50,839
就是和多一点

633
00:26:51,359 --> 00:26:53,960
所以那么就是说还是这两个事情

634
00:26:54,599 --> 00:26:55,880
一个是说你得并行

635
00:26:56,880 --> 00:26:59,160
你说你得使用上千个线程

636
00:27:00,880 --> 00:27:02,480
你想一想什么样的情况

637
00:27:02,480 --> 00:27:04,000
你使用上千个线程

638
00:27:04,319 --> 00:27:06,319
那么你这个向量必须有一千维

639
00:27:07,440 --> 00:27:08,319
你没一千维

640
00:27:08,319 --> 00:27:09,839
你怎么使用上千个线程

641
00:27:10,119 --> 00:27:12,640
一个线程至少要做一个算一个值

642
00:27:12,640 --> 00:27:13,039
对吧

643
00:27:13,319 --> 00:27:15,119
假设你个限量是一个100的向量

644
00:27:15,920 --> 00:27:19,079
那我就最多的用100个线程

645
00:27:19,519 --> 00:27:20,319
所以就浪费了

646
00:27:21,319 --> 00:27:22,439
所以就为什么是说

647
00:27:22,439 --> 00:27:24,319
你的一个很小的神级网络

648
00:27:24,679 --> 00:27:27,359
在GPU上其实必行效率不高

649
00:27:27,879 --> 00:27:29,039
你举账惩罚一样的

650
00:27:29,039 --> 00:27:30,839
你一个100乘以百的举证

651
00:27:30,839 --> 00:27:32,639
乘另外一个100乘以百的举证

652
00:27:33,279 --> 00:27:34,399
那你能用多少个线程

653
00:27:34,399 --> 00:27:35,799
你可能就用个几百个线程

654
00:27:35,799 --> 00:27:36,439
就了不得了

655
00:27:38,480 --> 00:27:40,799
另外一个是说内存的本利性了

656
00:27:41,559 --> 00:27:43,679
就是说GPU为了节省面积

657
00:27:43,679 --> 00:27:45,839
他把缓存做的比较小

658
00:27:46,440 --> 00:27:49,560
他也没有那么多一级二级三级的缓存

659
00:27:50,240 --> 00:27:51,680
所以他的架构更加简单

660
00:27:52,200 --> 00:27:53,120
但好处是说

661
00:27:53,120 --> 00:27:55,120
他带内存带的更高一点

662
00:27:55,640 --> 00:27:57,800
所以就是说内存的本地性

663
00:27:57,800 --> 00:27:59,560
其实对他也是非常重要的

664
00:28:01,640 --> 00:28:02,480
第三个是说

665
00:28:02,480 --> 00:28:05,280
你要少用控制语句

666
00:28:06,080 --> 00:28:07,360
他也不是说不能做

667
00:28:08,360 --> 00:28:09,160
他要做的话

668
00:28:09,160 --> 00:28:12,840
就是说你就是几千个核得停下来

669
00:28:12,840 --> 00:28:15,240
就是我说一判断要走这边走那边

670
00:28:15,359 --> 00:28:16,359
那么所有的核停下来

671
00:28:16,680 --> 00:28:19,200
现在新的卡或者CUDA

672
00:28:19,200 --> 00:28:20,599
他当然加入了说

673
00:28:20,599 --> 00:28:22,240
我在一个大核里面做同步

674
00:28:22,240 --> 00:28:24,960
还是说一组合做同步

675
00:28:25,240 --> 00:28:26,200
但实际上来说

676
00:28:26,200 --> 00:28:28,240
他的开销还是非常大

677
00:28:28,640 --> 00:28:30,400
就是说他得几十个

678
00:28:30,400 --> 00:28:32,160
或几百个线程得同步的做

679
00:28:32,759 --> 00:28:35,440
如果就是说我要算Eth

680
00:28:36,039 --> 00:28:37,640
跳转两个字的话

681
00:28:37,640 --> 00:28:39,400
那么他是说你跳转

682
00:28:39,400 --> 00:28:40,799
你也不知道跳转给谁对吧

683
00:28:41,160 --> 00:28:43,440
那就是说首先你有几百个核

684
00:28:43,440 --> 00:28:44,279
几百个线程

685
00:28:44,480 --> 00:28:46,039
先停下来

686
00:28:46,039 --> 00:28:47,319
全部跳这一个

687
00:28:47,599 --> 00:28:50,599
如果不是跳左边那一个的话

688
00:28:50,599 --> 00:28:51,720
我就停掉不算

689
00:28:51,720 --> 00:28:53,519
接下所有的核往那边跳

690
00:28:53,519 --> 00:28:55,240
但如果没有满足那概率的话

691
00:28:55,240 --> 00:28:56,799
那些核就剩下的核就不算

692
00:28:57,000 --> 00:28:59,119
就是说导致你的同步开销很大

693
00:28:59,879 --> 00:29:02,960
所以GPU尽量要少用控制语句

694
00:29:03,639 --> 00:29:04,839
这基本上就是说

695
00:29:05,759 --> 00:29:06,759
核心上来说

696
00:29:06,759 --> 00:29:08,639
就是这三个事情

697
00:29:12,160 --> 00:29:13,480
另外一个是说

698
00:29:13,880 --> 00:29:16,440
你的CPU和GPU之间

699
00:29:16,440 --> 00:29:17,799
他也不是一个独立的

700
00:29:18,120 --> 00:29:21,480
因为你的任务其实是都是跑在CPU上

701
00:29:22,000 --> 00:29:23,960
我们看过就是说你要在GPU做

702
00:29:23,960 --> 00:29:25,559
你得把内存搬过去

703
00:29:26,559 --> 00:29:26,880
对吧

704
00:29:27,440 --> 00:29:29,880
所以这要是导致说你的带宽的问题

705
00:29:31,519 --> 00:29:32,759
首先看到是说

706
00:29:33,319 --> 00:29:36,480
CPU和显存之间带宽

707
00:29:36,480 --> 00:29:38,799
就CPU自己的内存

708
00:29:38,799 --> 00:29:40,200
CPU和内存的带宽

709
00:29:40,720 --> 00:29:42,680
CPU有自己的内存通道

710
00:29:42,720 --> 00:29:43,680
叫memory IO

711
00:29:43,680 --> 00:29:46,720
就基本上也说的大概30GB

712
00:29:46,720 --> 00:29:48,519
当然你可以好一点的核

713
00:29:48,759 --> 00:29:52,240
可以基本上你可以认为CPU多少根针脚

714
00:29:52,240 --> 00:29:54,600
就是说你不是买一个CPU很多针

715
00:29:55,279 --> 00:29:56,440
一个针脚你简单认为

716
00:29:56,440 --> 00:30:00,120
就是可以传输一定大小的数据

717
00:30:00,759 --> 00:30:02,039
就是说你有多少个针脚

718
00:30:02,160 --> 00:30:05,000
你留很多针脚给内存的话

719
00:30:05,120 --> 00:30:06,320
当然你的带宽就高一点

720
00:30:08,039 --> 00:30:10,960
另外一块就是说PCIe 16X

721
00:30:10,960 --> 00:30:13,000
16X也就是说你大概你可以简单认为

722
00:30:13,000 --> 00:30:14,480
是我要连16根针

723
00:30:15,640 --> 00:30:16,279
你16根针

724
00:30:16,279 --> 00:30:18,519
但是你现在这个地方3.0的话

725
00:30:18,680 --> 00:30:20,200
是16GB每秒

726
00:30:20,840 --> 00:30:22,960
当然现在4.0也快要出来了

727
00:30:22,960 --> 00:30:24,960
现在4.0也慢慢的开始要普及

728
00:30:24,960 --> 00:30:26,360
4.0可以到32GB

729
00:30:26,640 --> 00:30:28,200
5.0可以到64GB

730
00:30:28,600 --> 00:30:29,680
但整体来讲

731
00:30:29,840 --> 00:30:31,079
它还是很慢的

732
00:30:31,720 --> 00:30:36,559
就是CPU到GPU之间的带宽是不是很高的

733
00:30:37,400 --> 00:30:39,920
特别是你有多个GPU的情况下

734
00:30:40,320 --> 00:30:43,480
那么你要共享可能是要共享16GB

735
00:30:44,720 --> 00:30:49,360
就导致说你不要频繁的在CPU和GPU之间

736
00:30:49,360 --> 00:30:50,039
搬数据

737
00:30:51,519 --> 00:30:54,800
一是因为我的带宽是受限的

738
00:30:54,800 --> 00:30:57,680
就数据从这个地方搬过来是有受限的

739
00:30:58,960 --> 00:31:00,440
第二个是说你得同步

740
00:31:01,480 --> 00:31:03,640
你每次CPU去同步一下GPU说

741
00:31:03,960 --> 00:31:05,880
停一停我要给你搬数据了

742
00:31:05,880 --> 00:31:07,360
它是有个同步开销的

743
00:31:07,840 --> 00:31:09,039
这是有你的驱动

744
00:31:09,159 --> 00:31:10,200
有很多东西决定了

745
00:31:10,639 --> 00:31:13,799
开销其实是也是不要忽略的一个开销

746
00:31:14,200 --> 00:31:17,879
所以就是说你不要频繁的在CPU和GPU传数据

747
00:31:17,879 --> 00:31:19,359
就尽量一次传过去

748
00:31:19,359 --> 00:31:21,559
第二尽量的少传一点数据过去

749
00:31:23,720 --> 00:31:26,440
所以在CPU和GPU之间

750
00:31:26,759 --> 00:31:28,159
在GPU做运算的时候

751
00:31:28,159 --> 00:31:30,639
经常的一个看到了一个瓶颈

752
00:31:30,639 --> 00:31:33,079
就是说你不小心在算的时候

753
00:31:33,079 --> 00:31:34,599
把一些数据给传回来了

754
00:31:35,599 --> 00:31:35,839
对吧

755
00:31:36,120 --> 00:31:39,160
经常有时候是隐藏在你的代码里面没注意

756
00:31:39,160 --> 00:31:40,320
然后会导致你的

757
00:31:41,200 --> 00:31:43,640
就把你整个这里这个地方打满了

758
00:31:43,640 --> 00:31:45,560
就导致说你根本就算不懂

759
00:31:46,560 --> 00:31:46,880
OK

760
00:31:50,480 --> 00:31:52,960
然后另外一个就是说我们讲的是

761
00:31:54,640 --> 00:31:56,800
Intel CPU和NVIDIA的GPU

762
00:31:57,280 --> 00:32:00,440
实际上来说还有更多的CPU和GPU了

763
00:32:01,080 --> 00:32:03,320
比如说一大一大的话

764
00:32:03,319 --> 00:32:06,759
就是MND的CPU

765
00:32:06,759 --> 00:32:09,079
他现在大家觉得越做越好

766
00:32:09,079 --> 00:32:09,679
就是

767
00:32:10,919 --> 00:32:12,480
苏妈上台之后

768
00:32:12,480 --> 00:32:13,759
现在感觉他们又

769
00:32:15,879 --> 00:32:16,799
又雄起了

770
00:32:17,359 --> 00:32:20,519
然后新的叫线程撕裂者

771
00:32:20,519 --> 00:32:22,039
比如大家说效果不错

772
00:32:22,799 --> 00:32:24,960
MND也做GPU

773
00:32:26,159 --> 00:32:28,240
MND的GPU我们之前有讲过

774
00:32:28,240 --> 00:32:31,639
他我觉得他的技能点在了游戏的上面

775
00:32:32,200 --> 00:32:34,160
就他的游戏性能非常好

776
00:32:34,160 --> 00:32:37,280
游戏性能应该是跟NVIDIA可能是差不多

777
00:32:37,280 --> 00:32:38,920
或者就好像我也不打游戏

778
00:32:38,920 --> 00:32:40,240
我也不是特别清楚

779
00:32:40,240 --> 00:32:44,680
但他的整个对于高性能计算

780
00:32:44,680 --> 00:32:49,040
他的整个那一套编译器没做好

781
00:32:49,040 --> 00:32:52,200
就他没有觉得这一块是要跟NVIDIA去抢

782
00:32:52,200 --> 00:32:56,800
所以就说MND也能做深度学习

783
00:32:56,800 --> 00:32:57,240
但是

784
00:32:57,279 --> 00:33:01,799
你发现可能难用一点点

785
00:33:03,920 --> 00:33:05,079
当然INTEL也有GPU

786
00:33:05,079 --> 00:33:07,400
INTEL有集成显卡

787
00:33:07,400 --> 00:33:09,200
集成显卡太弱了一点

788
00:33:09,200 --> 00:33:11,039
但INTEL也在慢慢的说

789
00:33:11,039 --> 00:33:12,960
也在做一些新的芯片可以做

790
00:33:12,960 --> 00:33:14,519
但是现在还没有完全看到

791
00:33:15,279 --> 00:33:16,839
另外一个比较有意思的是ARM

792
00:33:18,000 --> 00:33:20,279
就ARM的CPU和ARM的GPU

793
00:33:20,839 --> 00:33:22,279
你用手机的话都是ARM

794
00:33:23,440 --> 00:33:25,960
很有可能是CPU当然都是ARM

795
00:33:26,200 --> 00:33:27,880
你的GPU有可能是用ARM

796
00:33:27,880 --> 00:33:29,120
有可能是用别人的Core

797
00:33:29,120 --> 00:33:30,600
看他自己的GPU的设计

798
00:33:32,200 --> 00:33:34,880
所以比较有意思的是说

799
00:33:34,880 --> 00:33:36,360
比如像苹果

800
00:33:36,360 --> 00:33:39,160
苹果自己基于ARM做了一个芯片

801
00:33:39,160 --> 00:33:41,279
就是我们现在直播的机器

802
00:33:41,279 --> 00:33:43,720
就是基于M1就是一个ARM芯片

803
00:33:44,279 --> 00:33:46,600
在SERVER端现在比如说云上面

804
00:33:46,600 --> 00:33:47,480
就AW上面

805
00:33:47,480 --> 00:33:49,319
我们有自己的ARM的芯片

806
00:33:50,400 --> 00:33:53,160
而且是基本上

807
00:33:53,880 --> 00:33:56,240
今年我听看到一个数字是说

808
00:33:56,240 --> 00:33:59,640
今年2020年所有的云计算里面

809
00:33:59,640 --> 00:34:01,800
买的CPU里面有50%的

810
00:34:01,800 --> 00:34:03,200
是自己的ARM芯片

811
00:34:03,759 --> 00:34:05,480
就表示那个已经挺成熟了

812
00:34:06,000 --> 00:34:08,320
所以ARM在能看到是说

813
00:34:08,320 --> 00:34:12,320
他首先在手机借占领地位以后

814
00:34:12,320 --> 00:34:13,800
慢慢的在反杀回来

815
00:34:13,800 --> 00:34:15,360
你的桌面和你的云端

816
00:34:16,519 --> 00:34:18,320
这是因为ARM说我给你一个设计

817
00:34:18,320 --> 00:34:20,559
你自己每个厂家

818
00:34:20,559 --> 00:34:21,880
自己拿着设计去定制

819
00:34:22,680 --> 00:34:24,119
后来大家发现这个东西做起来

820
00:34:24,119 --> 00:34:25,079
也没想象那么难

821
00:34:25,079 --> 00:34:30,079
所以大家都去做

822
00:34:30,079 --> 00:34:31,800
就大厂都在做自己的芯片

823
00:34:31,800 --> 00:34:32,760
如果你去CPU的话

824
00:34:32,760 --> 00:34:34,000
很有可能是基于ARM的

825
00:34:35,280 --> 00:34:36,240
当GPU的话

826
00:34:37,280 --> 00:34:40,320
SERVER端和SERVER的

827
00:34:40,320 --> 00:34:41,519
当时M1的芯片

828
00:34:41,519 --> 00:34:43,920
当时基于他也不一定是基于ARM

829
00:34:43,920 --> 00:34:47,000
M1的GPU芯片我还真没看过

830
00:34:47,000 --> 00:34:49,200
他可能是基于苹果自己的GPU

831
00:34:50,159 --> 00:34:52,039
但是手机上有可能是基于ARM

832
00:34:52,679 --> 00:34:55,359
所以在桌面和SERVER端的ARM的GPU

833
00:34:55,359 --> 00:34:58,399
导致现在还没有特别看到

834
00:34:58,960 --> 00:34:59,359
OK

835
00:34:59,359 --> 00:35:01,199
所以这一块主要是在移动的

836
00:35:01,799 --> 00:35:03,319
移动的GPU的话

837
00:35:03,759 --> 00:35:04,879
性能也还行

838
00:35:04,879 --> 00:35:07,159
就是说比你CPU确实要快一些

839
00:35:07,159 --> 00:35:09,079
也是可以用来移动的GPU

840
00:35:09,079 --> 00:35:11,319
也是能做一些深度学习的应用的

841
00:35:12,559 --> 00:35:12,960
OK

842
00:35:14,319 --> 00:35:15,359
然后接下来我们说

843
00:35:17,359 --> 00:35:19,000
你要在上面高性能编程

844
00:35:19,000 --> 00:35:19,599
你要怎么办

845
00:35:20,599 --> 00:35:21,639
在CPU上的话

846
00:35:21,639 --> 00:35:22,599
你要做开发的话

847
00:35:22,599 --> 00:35:24,239
一般是用C++

848
00:35:24,239 --> 00:35:26,519
我们一般很少用Python来

849
00:35:26,519 --> 00:35:28,239
写各种高性能的东西

850
00:35:28,239 --> 00:35:29,960
就底层框架底层

851
00:35:29,960 --> 00:35:31,199
一般是用C++来写

852
00:35:31,199 --> 00:35:32,639
但你也可以用别的高性能语言

853
00:35:32,639 --> 00:35:33,320
你可以用Fortune

854
00:35:33,320 --> 00:35:33,599
对吧

855
00:35:34,440 --> 00:35:35,079
C++的话

856
00:35:35,079 --> 00:35:36,639
就是说你的编译器是很成熟

857
00:35:36,639 --> 00:35:38,960
就是说你不管在哪个CPU上面

858
00:35:38,960 --> 00:35:40,440
你的编译器都挺成熟的

859
00:35:40,440 --> 00:35:41,440
AMD也好

860
00:35:41,440 --> 00:35:42,679
Intel也好

861
00:35:42,679 --> 00:35:43,559
ARM也好

862
00:35:43,559 --> 00:35:47,639
基本上编译器你用的是LLVM的话

863
00:35:47,639 --> 00:35:48,639
做后端的话

864
00:35:49,400 --> 00:35:50,199
都挺好的做的

865
00:35:51,800 --> 00:35:53,880
在GPU上的话

866
00:35:53,880 --> 00:35:55,280
NVIDIA当然是用CUDA

867
00:35:56,280 --> 00:35:59,079
大家如果可能是写过CUDA的编程

868
00:35:59,079 --> 00:36:00,960
所以它的整个的编辑链

869
00:36:00,960 --> 00:36:02,960
就是说驱动都很成熟

870
00:36:02,960 --> 00:36:04,360
是因为CUDA已经做了

871
00:36:05,559 --> 00:36:07,360
就成熟不成熟

872
00:36:07,360 --> 00:36:09,480
真的就是说取决于你花多少人

873
00:36:09,480 --> 00:36:11,039
花多少时间

874
00:36:11,039 --> 00:36:13,280
就NVIDIA几千人在做CUDA

875
00:36:13,280 --> 00:36:15,159
然后做了十几年了吧

876
00:36:15,159 --> 00:36:17,039
所以整体来讲它是比较成熟

877
00:36:17,039 --> 00:36:18,199
然后性能是比较不错的

878
00:36:19,599 --> 00:36:22,000
另外一个跟CUDA有点类似的一个语言

879
00:36:22,000 --> 00:36:23,880
是叫做OpenCL

880
00:36:23,880 --> 00:36:25,880
就非常像大家可以去看一下

881
00:36:25,880 --> 00:36:27,239
就是OpenCL是一个标准

882
00:36:27,239 --> 00:36:28,719
但CUDA也支持OpenCL

883
00:36:30,320 --> 00:36:31,960
但是OpenCL虽然是个标准

884
00:36:31,960 --> 00:36:34,280
但是你的编译器那种驱动

885
00:36:34,280 --> 00:36:36,719
是根据你的硬件厂商来的

886
00:36:36,719 --> 00:36:39,679
所以不同的硬件厂商支持是不一样的

887
00:36:39,679 --> 00:36:43,360
因为OpenCL打游戏不用OpenCL

888
00:36:43,360 --> 00:36:46,119
打游戏是C是Compute的意思

889
00:36:46,159 --> 00:36:49,880
所以如果你的显卡可以用来打游戏

890
00:36:49,880 --> 00:36:51,239
你想GPU能干嘛

891
00:36:51,239 --> 00:36:52,679
GPU大部分时间用来打游戏

892
00:36:52,679 --> 00:36:55,480
你的手机GPU可能就是给你打游戏用

893
00:36:55,480 --> 00:36:57,480
你的视频回放都可能不用你的GPU了

894
00:36:57,480 --> 00:36:59,920
它是有专用的芯片做的

895
00:36:59,920 --> 00:37:02,920
所以每个硬件厂商对OpenCL的支持

896
00:37:02,920 --> 00:37:04,639
可能它不会花那么多时间

897
00:37:04,639 --> 00:37:06,960
所以可能就是质量不是很好

898
00:37:06,960 --> 00:37:08,480
就算你硬件特别好

899
00:37:08,480 --> 00:37:09,880
你的驱动不行

900
00:37:09,880 --> 00:37:11,039
你的编译器不行

901
00:37:12,400 --> 00:37:14,400
很有可能你就是不行

902
00:37:14,400 --> 00:37:18,320
而且因为我其实是做了很多

903
00:37:18,320 --> 00:37:20,880
最近在公司做了很多编译器的事情

904
00:37:22,160 --> 00:37:24,440
就是说你发现就是说做硬件的人

905
00:37:24,440 --> 00:37:26,880
觉得我做完硬件就完事了

906
00:37:26,880 --> 00:37:28,599
其实反过来讲

907
00:37:28,599 --> 00:37:31,400
特别是你要要很好的性能

908
00:37:31,400 --> 00:37:36,760
你在编译器的投入可能不会要亚于你在硬件投入

909
00:37:36,760 --> 00:37:38,519
假设你投100个人做硬件的话

910
00:37:38,519 --> 00:37:40,320
那你至少要投100个人做编译器

911
00:37:41,760 --> 00:37:43,960
这是我的个人的感觉

912
00:37:43,960 --> 00:37:46,079
很有地取决于你的

913
00:37:46,079 --> 00:37:48,079
你对它的需求

914
00:37:48,079 --> 00:37:50,280
很有可能你还得投更多人做编辑器

915
00:37:51,039 --> 00:37:53,480
所以做硬件人可能会不会有这么觉得

916
00:37:53,480 --> 00:37:55,199
就做硬件人和做软件人

917
00:37:55,199 --> 00:37:57,400
就是做编辑器的人和做硬件人是两拨人

918
00:37:58,000 --> 00:38:02,519
做硬件的人和做软件的人是完全不一样的

919
00:38:02,519 --> 00:38:04,599
就是说思维是不一样的

920
00:38:05,480 --> 00:38:06,000
OK

921
00:38:06,000 --> 00:38:07,400
所以我觉得就是说

922
00:38:07,400 --> 00:38:09,480
大家都说AMD的GPU很好

923
00:38:09,480 --> 00:38:12,320
但做深度学习不见得最近有在起来

924
00:38:12,360 --> 00:38:14,000
但是也是很慢的在起来

925
00:38:14,000 --> 00:38:16,320
但是因为我觉得就是因为它的这一块

926
00:38:16,640 --> 00:38:18,080
不够投入不够多

927
00:38:18,360 --> 00:38:18,720
OK

928
00:38:18,720 --> 00:38:19,960
这就是我的观点了

929
00:38:19,960 --> 00:38:22,480
就是说我不代表官方的观点

930
00:38:22,480 --> 00:38:23,559
也不代表正确性

931
00:38:23,559 --> 00:38:26,280
OK

932
00:38:26,280 --> 00:38:27,360
所以总结一下

933
00:38:27,880 --> 00:38:29,800
总结一下就是说CPU是干嘛

934
00:38:29,800 --> 00:38:31,559
CPU是用来处理通用计算

935
00:38:31,559 --> 00:38:33,200
你所有计算都可以在CPU做

936
00:38:33,559 --> 00:38:35,680
性能的优化主要是说

937
00:38:35,680 --> 00:38:37,320
你的数据读写的本地性

938
00:38:37,760 --> 00:38:39,880
就时间本地性空间本地性

939
00:38:40,800 --> 00:38:42,960
你要合理的利用你的CPU的多核

940
00:38:44,000 --> 00:38:48,280
GPU的话就是它通过更小的核

941
00:38:48,640 --> 00:38:50,160
更多的核

942
00:38:50,320 --> 00:38:51,760
更好的内存带宽

943
00:38:51,760 --> 00:38:55,320
使得它更适合做能够大规模进行的计算任务

944
00:38:55,440 --> 00:39:00,960
所以导致说我们现在用GPU是一个主流的

945
00:39:00,960 --> 00:39:02,960
硬件来做深度学习的开发

946
00:39:03,920 --> 00:39:04,280
OK

947
00:39:04,280 --> 00:39:07,240
这就是CPU和GPU的一个很简单的介绍

948
00:39:07,400 --> 00:39:09,559
我们没有深入到特别到底层

949
00:39:09,559 --> 00:39:11,239
因为我也不是做硬件的

950
00:39:11,239 --> 00:39:13,719
所以我大概也是给大家讲一个

951
00:39:14,400 --> 00:39:15,599
大概的一个idea

952
00:39:15,599 --> 00:39:17,360
不能保证说每个细节都正确

953
00:39:17,360 --> 00:39:19,400
但是说我是一个很简化的版本

954
00:39:19,400 --> 00:39:21,519
让大家理解CPU和GPU的区别

