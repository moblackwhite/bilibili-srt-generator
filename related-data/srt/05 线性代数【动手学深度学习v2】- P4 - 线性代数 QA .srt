1
00:00:00,000 --> 00:00:04,000
好 我们来看一下我们刚刚的一些问题

2
00:00:04,000 --> 00:00:08,679
问题一是说 之前我们有没有什么负面的影响

3
00:00:08,679 --> 00:00:12,480
比如说数值变得特别稀疏

4
00:00:12,480 --> 00:00:15,800
我大概理解是说 我来放大一下字体

5
00:00:15,800 --> 00:00:20,800
我大概理解的意思是说

6
00:00:20,800 --> 00:00:25,199
如果你是一个字符串

7
00:00:25,199 --> 00:00:29,800
然后你说我要把它变成一个数值的话

8
00:00:29,800 --> 00:00:31,679
我可能要把它分成很多很多

9
00:00:31,679 --> 00:00:34,799
比如说我有一列里面有一百个字符串

10
00:00:34,799 --> 00:00:37,000
那么我就会变成一百列 对吧

11
00:00:37,000 --> 00:00:40,799
然后可能绝大部分情况你都是一个零

12
00:00:40,799 --> 00:00:42,280
所以就变得特别稀疏

13
00:00:42,280 --> 00:00:43,640
确实是的

14
00:00:43,640 --> 00:00:47,359
就是说稀疏化会带来很多事情

15
00:00:47,359 --> 00:00:50,000
最简单是说你会

16
00:00:50,000 --> 00:00:51,400
如果你有 举个例子

17
00:00:51,400 --> 00:00:54,840
你有一百 你有一列里面有一百万行

18
00:00:54,840 --> 00:00:56,320
然后一百万个元素

19
00:00:56,320 --> 00:00:58,200
但是它每一个元素长得不一样

20
00:00:58,200 --> 00:00:59,079
它就是一个ID

21
00:00:59,079 --> 00:01:02,079
比如说就是一个标识符

22
00:01:02,079 --> 00:01:03,759
那么你要做稀疏化的话

23
00:01:03,759 --> 00:01:06,719
你会变成一个有一百万个列

24
00:01:06,719 --> 00:01:09,359
然后每一列里面就一个唯一的元素

25
00:01:09,359 --> 00:01:11,200
你会整个变得特别稀疏

26
00:01:11,200 --> 00:01:14,840
就是说如果你还是要正常存的话

27
00:01:14,840 --> 00:01:16,239
那你会存了大量的零

28
00:01:16,239 --> 00:01:17,480
你会导致你的

29
00:01:17,480 --> 00:01:19,799
基本上你的内存就存不下了

30
00:01:19,799 --> 00:01:21,480
所以通常这样的情况下

31
00:01:21,480 --> 00:01:24,239
你需要用一个稀疏矩阵来做存储

32
00:01:24,239 --> 00:01:26,039
但是作为别的负面影响

33
00:01:26,039 --> 00:01:28,120
并没有对机器学习来讲

34
00:01:28,320 --> 00:01:30,240
稀疏的矩阵其实没关系了

35
00:01:30,240 --> 00:01:32,000
不会影响太多

36
00:01:33,359 --> 00:01:34,760
第二个是说

37
00:01:35,200 --> 00:01:38,400
深度学习为什么要用张量来表示

38
00:01:39,920 --> 00:01:40,439
深度

39
00:01:40,439 --> 00:01:42,719
这个是一个挺有意思的问题

40
00:01:44,719 --> 00:01:46,840
因为怎么说呢

41
00:01:48,840 --> 00:01:50,520
深度学就深度学习

42
00:01:50,520 --> 00:01:51,760
你不是说深度学习

43
00:01:51,960 --> 00:01:52,960
整个机器学习

44
00:01:52,960 --> 00:01:54,640
它都是用张量

45
00:01:54,640 --> 00:01:56,960
或者是用数值的矩阵来表示的

46
00:01:57,080 --> 00:01:58,080
这是因为

47
00:01:58,080 --> 00:02:01,200
我觉得是因为这个是一路发展过来

48
00:02:01,200 --> 00:02:03,160
所以首先说什么是机器学习

49
00:02:03,160 --> 00:02:06,120
深度学习是机器学习的一块

50
00:02:06,600 --> 00:02:07,360
机器学习

51
00:02:07,800 --> 00:02:10,960
它其实统计的一个计算版本

52
00:02:11,000 --> 00:02:15,040
统计学家觉得机器学习是

53
00:02:15,680 --> 00:02:18,159
计算机的人

54
00:02:18,200 --> 00:02:19,600
对于统计的理解

55
00:02:19,600 --> 00:02:22,040
就统计学家会更偏数学一点

56
00:02:22,040 --> 00:02:24,200
但是机器学习是同样一个东西

57
00:02:24,200 --> 00:02:27,600
但是是用计算机科学家的一个实现

58
00:02:28,040 --> 00:02:29,480
所以统计那一边

59
00:02:29,720 --> 00:02:32,080
张量这一块是比较常用的

60
00:02:32,360 --> 00:02:35,600
所以这就为什么我们机器学习

61
00:02:35,600 --> 00:02:36,720
用张量的多一点

62
00:02:39,240 --> 00:02:40,360
第三个

63
00:02:40,600 --> 00:02:42,440
Copy和Column的区别

64
00:02:42,480 --> 00:02:44,000
其实

65
00:02:45,360 --> 00:02:48,240
Copy你有可能是不Copy内存的

66
00:02:49,000 --> 00:02:50,720
就是说你的深度Copy和

67
00:02:50,719 --> 00:02:54,479
浅度Copy的区别

68
00:02:54,479 --> 00:02:55,319
Column的话

69
00:02:55,319 --> 00:02:57,800
我理解一定是会你复制内存

70
00:02:59,159 --> 00:02:59,680
OK

71
00:03:00,439 --> 00:03:01,840
第4个问题是说

72
00:03:01,879 --> 00:03:03,599
对哪一维求和

73
00:03:03,599 --> 00:03:05,039
就是消除哪一维

74
00:03:05,039 --> 00:03:06,360
可以这么理解吗

75
00:03:06,599 --> 00:03:07,360
可以这么理解

76
00:03:07,360 --> 00:03:10,079
就是说对定0维求和

77
00:03:10,079 --> 00:03:12,079
那么就把这定0维去掉

78
00:03:12,079 --> 00:03:14,479
把它整个那一个维度的和

79
00:03:14,879 --> 00:03:16,199
Reduce成一个值

80
00:03:16,560 --> 00:03:21,200
第5个问题其实挺好

81
00:03:21,200 --> 00:03:21,800
挺好

82
00:03:21,800 --> 00:03:25,200
Torch不区分航向量和列向量吗

83
00:03:26,960 --> 00:03:28,680
其实是这样的

84
00:03:28,680 --> 00:03:29,560
就是说

85
00:03:30,520 --> 00:03:32,400
它的航向量

86
00:03:32,400 --> 00:03:33,240
就是说

87
00:03:33,440 --> 00:03:35,840
它如果是一维

88
00:03:36,880 --> 00:03:37,720
张量的话

89
00:03:37,720 --> 00:03:39,600
它一定是一个航向量

90
00:03:40,560 --> 00:03:42,320
列向量是什么意思呢

91
00:03:42,480 --> 00:03:44,400
列向量是一个矩阵

92
00:03:45,360 --> 00:03:46,680
它的矩阵

93
00:03:50,879 --> 00:03:52,439
然后就是说

94
00:03:52,439 --> 00:03:54,439
你可以用一个二维的矩阵

95
00:03:54,439 --> 00:03:56,439
来区分航向量和列向量

96
00:03:57,040 --> 00:03:58,599
二维矩阵航向量

97
00:03:58,599 --> 00:04:00,120
那么就意味着是说

98
00:04:00,120 --> 00:04:02,319
我的number of row

99
00:04:02,319 --> 00:04:03,439
就是航数为1

100
00:04:03,439 --> 00:04:05,120
但是列数是一个变化

101
00:04:05,120 --> 00:04:06,960
一个常为n的一个列数

102
00:04:07,240 --> 00:04:08,280
如果是列向量

103
00:04:08,719 --> 00:04:10,640
那就是航数是为n

104
00:04:10,879 --> 00:04:12,439
但是你的列数是为1

105
00:04:12,759 --> 00:04:13,599
所以是说

106
00:04:13,599 --> 00:04:16,120
如果你想区分航向量和列向量

107
00:04:16,120 --> 00:04:18,199
你必须要用一个矩阵来表示

108
00:04:18,399 --> 00:04:20,319
如果你就是一个向量的话

109
00:04:20,319 --> 00:04:21,680
对于一个向量来说

110
00:04:21,680 --> 00:04:22,959
从计算机角度来讲

111
00:04:22,959 --> 00:04:24,399
它就是一个数组

112
00:04:24,399 --> 00:04:24,680
对吧

113
00:04:24,680 --> 00:04:25,600
一个一维数组

114
00:04:25,600 --> 00:04:27,439
你可以访问某一个元素

115
00:04:27,560 --> 00:04:30,159
然后你可以把它来做一个

116
00:04:30,399 --> 00:04:32,120
做累积都是没关系的

117
00:04:34,839 --> 00:04:36,399
就sum等于axis

118
00:04:36,399 --> 00:04:38,360
等于0和1怎么求

119
00:04:39,759 --> 00:04:40,319
怎么求

120
00:04:40,319 --> 00:04:41,159
就是说

121
00:04:43,079 --> 00:04:44,959
怎么解释这个东西

122
00:04:45,360 --> 00:04:46,920
就是说就是把

123
00:04:48,279 --> 00:04:50,839
0维度和1维度的

124
00:04:50,839 --> 00:04:51,879
那一个

125
00:04:51,879 --> 00:04:53,519
一共是一个3D矩阵的话

126
00:04:53,519 --> 00:04:54,399
大家想象一下

127
00:04:54,720 --> 00:04:56,759
如果说你是一个RGB矩阵

128
00:04:56,759 --> 00:04:57,959
一张图的话

129
00:04:57,959 --> 00:05:00,600
那么假设我的第三个维度是RGB

130
00:05:01,199 --> 00:05:02,839
就是说axis等于2的

131
00:05:02,839 --> 00:05:04,600
那是RGB的channel的话

132
00:05:04,600 --> 00:05:06,199
那么0和1就意味着

133
00:05:06,199 --> 00:05:07,319
我把整一个

134
00:05:07,360 --> 00:05:09,480
第2的channel

135
00:05:09,480 --> 00:05:11,120
就是红色整个channel

136
00:05:11,159 --> 00:05:12,240
把它求和了

137
00:05:12,439 --> 00:05:14,040
然后绿色的channel求和

138
00:05:14,079 --> 00:05:16,199
所以就是说对每一个

139
00:05:16,639 --> 00:05:18,600
等于是说每一次求和

140
00:05:18,639 --> 00:05:21,319
是对一个矩阵来说的

141
00:05:21,560 --> 00:05:24,600
矩阵它是由第0维和第1维的

142
00:05:24,639 --> 00:05:26,639
来给的

143
00:05:29,319 --> 00:05:30,720
第7个问题是说

144
00:05:30,720 --> 00:05:34,560
Torch中的L1和L2的正轴

145
00:05:34,560 --> 00:05:35,319
要怎么加入

146
00:05:35,319 --> 00:05:37,199
我们之后会来跟大家讲

147
00:05:37,199 --> 00:05:38,199
怎么样加入

148
00:05:39,199 --> 00:05:42,560
第8个

149
00:05:42,560 --> 00:05:43,599
吸塑的时候

150
00:05:43,599 --> 00:05:45,800
可以把它当成单词

151
00:05:45,800 --> 00:05:46,560
做词

152
00:05:46,560 --> 00:05:48,279
词项量来解决吗

153
00:05:48,599 --> 00:05:50,680
这个是一个我们之后会讲到

154
00:05:50,680 --> 00:05:52,240
这个叫做what embedding

155
00:05:52,240 --> 00:05:53,000
what embedding

156
00:05:53,000 --> 00:05:54,279
确实是你可以认为

157
00:05:54,279 --> 00:05:56,639
是一个吸塑的一个查表

158
00:05:57,159 --> 00:05:58,519
确实你可以认为

159
00:05:58,959 --> 00:06:00,279
如果吸塑的时候

160
00:06:00,279 --> 00:06:02,319
我们可以用来用词项量

161
00:06:02,319 --> 00:06:03,680
来进行查表

162
00:06:03,719 --> 00:06:05,120
但是你不是每一次

163
00:06:05,120 --> 00:06:06,519
都可以用词项量

164
00:06:06,519 --> 00:06:08,719
因为它可能不见得

165
00:06:08,719 --> 00:06:11,639
永远是可以这样做

166
00:06:13,519 --> 00:06:15,279
但是确实对于绝大部分来讲

167
00:06:15,279 --> 00:06:16,719
我们是用一个词项量

168
00:06:16,719 --> 00:06:17,799
或者叫做一个

169
00:06:17,799 --> 00:06:18,719
embedding的layer

170
00:06:18,719 --> 00:06:20,359
来做解决吸塑的问题

171
00:06:20,399 --> 00:06:23,079
我们当然会在做到NLP的情况

172
00:06:23,079 --> 00:06:24,199
会来讲这个事情

173
00:06:25,599 --> 00:06:27,359
所以第9个问题

174
00:06:27,359 --> 00:06:28,719
其实昨天我们也讲过

175
00:06:28,719 --> 00:06:30,199
叫张量的概念

176
00:06:30,479 --> 00:06:33,399
机器学习和数学的区别大吗

177
00:06:33,560 --> 00:06:34,759
机器学习的张量

178
00:06:34,759 --> 00:06:36,240
其实不是张量

179
00:06:36,480 --> 00:06:38,400
就是一个多维数组

180
00:06:39,079 --> 00:06:40,040
大家用Numpy的话

181
00:06:40,160 --> 00:06:41,240
就是一个ND array

182
00:06:41,280 --> 00:06:43,560
它跟数学的张量是不一样的

183
00:06:43,840 --> 00:06:46,960
而且就算是深度学习

184
00:06:47,000 --> 00:06:49,480
我们对于我们大部分的运算

185
00:06:49,480 --> 00:06:50,800
都是一个矩阵的运算

186
00:06:50,800 --> 00:06:52,680
其实都不会用到

187
00:06:52,680 --> 00:06:54,079
数学里面张量的概念

188
00:06:54,079 --> 00:06:55,280
所以我们只

189
00:06:55,400 --> 00:06:56,480
我们就说张量

190
00:06:56,840 --> 00:06:59,040
我们就说的顺口一点而已

191
00:07:01,680 --> 00:07:01,920
好

192
00:07:01,920 --> 00:07:03,560
第10个问题是说

193
00:07:03,720 --> 00:07:06,839
我们是不是只讲

194
00:07:06,839 --> 00:07:09,000
基于PyTorch的实现

195
00:07:09,199 --> 00:07:10,639
如果使用

196
00:07:10,639 --> 00:07:11,800
我觉得理解是说

197
00:07:11,800 --> 00:07:14,439
如果是使用别的框架的话

198
00:07:14,439 --> 00:07:15,920
可不可以听这门课

199
00:07:16,040 --> 00:07:16,759
就是说

200
00:07:17,480 --> 00:07:19,079
其实我觉得这是个挺好的问题

201
00:07:19,079 --> 00:07:19,920
就是说

202
00:07:20,199 --> 00:07:21,160
大家都会去问

203
00:07:21,160 --> 00:07:22,600
我们到底要选谁

204
00:07:22,600 --> 00:07:24,000
就是说你有很多框架

205
00:07:24,000 --> 00:07:25,360
你到底要选谁

206
00:07:25,360 --> 00:07:26,240
比较好一点

207
00:07:26,279 --> 00:07:28,120
其实我的理解是说

208
00:07:29,439 --> 00:07:31,160
这里面有几层意思在里面

209
00:07:31,160 --> 00:07:33,319
一个是说你用一个工具

210
00:07:33,879 --> 00:07:34,399
对吧

211
00:07:34,439 --> 00:07:35,839
你要当你说

212
00:07:35,839 --> 00:07:37,439
我用C++写是可以的

213
00:07:37,439 --> 00:07:39,879
我们在七八年前

214
00:07:39,879 --> 00:07:42,439
我们就用C++来写深度学习

215
00:07:42,759 --> 00:07:46,000
然后但现在随着工具的往前的话

216
00:07:46,000 --> 00:07:48,240
我们有更容易用的工具

217
00:07:48,240 --> 00:07:49,120
这是工具

218
00:07:50,199 --> 00:07:52,800
但是工具和你的学习

219
00:07:52,800 --> 00:07:54,399
我觉得是应该分开的

220
00:07:54,560 --> 00:07:55,519
就举个例子

221
00:07:55,519 --> 00:07:57,800
是说我开车

222
00:07:58,319 --> 00:08:00,160
我用什么车来学车

223
00:08:00,160 --> 00:08:01,160
其实没关系的

224
00:08:01,160 --> 00:08:03,040
车对我来讲就是一个工具

225
00:08:03,600 --> 00:08:05,759
但是每个年代

226
00:08:05,759 --> 00:08:07,680
就是现在过去10年

227
00:08:07,680 --> 00:08:09,439
现在说大家都说电动车

228
00:08:09,800 --> 00:08:12,280
就是说每个时代有不同的流行

229
00:08:12,680 --> 00:08:14,800
就现在大家说我要开电动车

230
00:08:14,800 --> 00:08:17,519
过去可能说我要开不一样的别的车

231
00:08:17,519 --> 00:08:19,480
每个就是说这个是一个fashion

232
00:08:19,759 --> 00:08:20,759
就每隔5年

233
00:08:20,759 --> 00:08:22,720
每隔10年这个fashion会变化

234
00:08:22,840 --> 00:08:25,439
就是说大家会去追求时尚

235
00:08:25,439 --> 00:08:26,600
这个是没错的

236
00:08:26,639 --> 00:08:28,600
就是说因为你下一个

237
00:08:28,600 --> 00:08:30,639
应该总会比前一个有好的地方

238
00:08:30,800 --> 00:08:31,879
但是反过来讲

239
00:08:31,879 --> 00:08:34,039
我觉得你应该把它当成一个工具

240
00:08:34,519 --> 00:08:36,000
你要学习的是说

241
00:08:36,000 --> 00:08:37,159
我怎么样开车

242
00:08:37,519 --> 00:08:38,240
这是第一点

243
00:08:38,240 --> 00:08:39,439
我学会开车

244
00:08:39,480 --> 00:08:41,600
第二点是说车只是一个工具

245
00:08:41,600 --> 00:08:43,000
把我从A运到B

246
00:08:43,399 --> 00:08:44,120
就行了

247
00:08:44,360 --> 00:08:45,200
所以的话

248
00:08:45,200 --> 00:08:47,399
我觉得对工具的选择

249
00:08:47,799 --> 00:08:49,840
其实我觉得第一点是说

250
00:08:49,840 --> 00:08:51,000
你可以说大家用什么

251
00:08:51,000 --> 00:08:51,759
我就用什么

252
00:08:51,759 --> 00:08:52,120
的好

253
00:08:52,120 --> 00:08:53,000
就是说

254
00:08:53,200 --> 00:08:54,679
因为我有问题

255
00:08:54,679 --> 00:08:56,200
我问别人会方便一点

256
00:08:56,879 --> 00:08:58,120
但是反过来讲

257
00:08:58,679 --> 00:09:01,080
你不要把工具限制住你自己

258
00:09:01,080 --> 00:09:02,440
工具永远是一个工具

259
00:09:02,440 --> 00:09:03,280
你用PyTorch也好

260
00:09:03,280 --> 00:09:04,280
你甚至用Python也好

261
00:09:04,280 --> 00:09:04,840
用什么的

262
00:09:04,840 --> 00:09:05,960
它都是一个语言

263
00:09:06,000 --> 00:09:08,160
它现在我们用这个过5年

264
00:09:08,440 --> 00:09:10,080
可能就不存在了

265
00:09:10,080 --> 00:09:11,040
也会新的出来

266
00:09:11,040 --> 00:09:12,160
你像5年前Python

267
00:09:12,160 --> 00:09:13,440
其实也没那么

268
00:09:14,240 --> 00:09:16,040
完全是一个所有人都用Python

269
00:09:16,040 --> 00:09:18,600
但是当然大家用R也行

270
00:09:18,600 --> 00:09:20,400
或者10年前用MathLab也行

271
00:09:21,080 --> 00:09:22,160
所以是说

272
00:09:22,800 --> 00:09:24,440
工具是一个

273
00:09:24,680 --> 00:09:27,320
每5年可能会发生一个变化的事情

274
00:09:27,640 --> 00:09:28,480
同样的话

275
00:09:28,480 --> 00:09:30,080
我们这里讲的

276
00:09:31,680 --> 00:09:33,040
算法

277
00:09:33,040 --> 00:09:35,759
可能10年后也会不是那样子了

278
00:09:37,040 --> 00:09:38,160
就是说我们现在学

279
00:09:38,160 --> 00:09:39,600
我们要学ResNet

280
00:09:39,600 --> 00:09:41,480
我们要学LSTM

281
00:09:41,480 --> 00:09:42,680
可能你可能再过5年

282
00:09:42,680 --> 00:09:44,280
我们就不要学LSTM了

283
00:09:44,600 --> 00:09:46,960
这是说不断会发生变化

284
00:09:47,440 --> 00:09:48,120
当然

285
00:09:48,600 --> 00:09:49,040
在这里

286
00:09:49,040 --> 00:09:50,520
我觉得最关键是说

287
00:09:50,520 --> 00:09:52,360
大家要学会不变的东西

288
00:09:52,520 --> 00:09:53,360
当然不变的东西

289
00:09:53,560 --> 00:09:55,200
变化的本身就是不变的

290
00:09:55,200 --> 00:09:56,640
但反过来讲是说

291
00:09:56,640 --> 00:10:00,400
我希望大家能够通过PyTorch的实现

292
00:10:00,399 --> 00:10:02,840
能够理解一个东西怎么实现的

293
00:10:02,879 --> 00:10:04,000
如果过5年之后

294
00:10:04,000 --> 00:10:05,360
要换一个新的框架

295
00:10:05,360 --> 00:10:07,360
但是我实现的概念还是在那个地方

296
00:10:07,360 --> 00:10:09,360
我可能一样很容易的过去

297
00:10:09,519 --> 00:10:10,279
同样的话

298
00:10:10,279 --> 00:10:11,559
我们学习一个算法

299
00:10:11,559 --> 00:10:13,959
怎么理解它算法是怎么工作的话

300
00:10:13,959 --> 00:10:14,879
我们过5年

301
00:10:14,879 --> 00:10:16,519
过10年新的算法出来

302
00:10:16,519 --> 00:10:17,799
我们学习到的知识

303
00:10:17,799 --> 00:10:19,240
同样可以做到新的算法

304
00:10:19,919 --> 00:10:21,679
所以简单来说

305
00:10:21,679 --> 00:10:23,039
学习其他算法

306
00:10:23,039 --> 00:10:25,199
或其他框架都没关系

307
00:10:25,199 --> 00:10:27,519
就是说你可以基于PyTorch来学

308
00:10:27,519 --> 00:10:29,319
或者基于什么来学都没关系

309
00:10:29,440 --> 00:10:31,400
主要是说你要学会它就行了

310
00:10:31,400 --> 00:10:32,000
学会它

311
00:10:32,000 --> 00:10:33,840
你很容易能够做到别的框架

312
00:10:33,840 --> 00:10:35,040
或者运用到别的地方

313
00:10:36,240 --> 00:10:36,800
OK

314
00:10:37,040 --> 00:10:38,680
第11个问题

315
00:10:38,800 --> 00:10:40,760
病理突变的格式

316
00:10:40,800 --> 00:10:43,600
和医生画的xml的格式

317
00:10:43,600 --> 00:10:44,720
怎么样去处理

318
00:10:45,000 --> 00:10:47,080
这个是一个挺好玩的问题

319
00:10:47,080 --> 00:10:49,320
就是说你对于比如说

320
00:10:49,320 --> 00:10:50,920
对于医疗图像来讲

321
00:10:50,920 --> 00:10:52,200
你有特别的格式

322
00:10:53,440 --> 00:10:55,160
和医生画勾画的区域

323
00:10:55,160 --> 00:10:57,120
比如说它是一个文字

324
00:10:57,160 --> 00:10:58,280
就是说你有两种做法

325
00:10:58,279 --> 00:10:58,799
一个是说

326
00:10:58,799 --> 00:11:00,279
你就把它当成一个图片

327
00:11:00,279 --> 00:11:02,279
用像素级的东西来解决

328
00:11:02,279 --> 00:11:04,120
比如说你用手写文字的识别

329
00:11:04,120 --> 00:11:04,600
来解决

330
00:11:04,600 --> 00:11:05,839
或者是说这个解决

331
00:11:05,879 --> 00:11:06,799
反过来讲

332
00:11:06,799 --> 00:11:08,319
你也可以把它xml

333
00:11:08,480 --> 00:11:09,759
你可以当成是一个

334
00:11:09,759 --> 00:11:11,120
结构化的一个输入

335
00:11:11,159 --> 00:11:12,879
用NLP的手段来解决

336
00:11:13,039 --> 00:11:15,639
就是说你可以通过计算机

337
00:11:15,639 --> 00:11:16,399
视觉的方式

338
00:11:16,399 --> 00:11:17,839
或者NLP的方式都OK

339
00:11:17,839 --> 00:11:19,959
或者是说你可以同样一起来

340
00:11:20,000 --> 00:11:22,399
两个方法同样运用来解决

341
00:11:24,279 --> 00:11:25,319
问题13

342
00:11:25,959 --> 00:11:27,399
后面讲的算法

343
00:11:27,399 --> 00:11:29,759
可以着重讲一下

344
00:11:29,799 --> 00:11:31,879
算法提出的过程的

345
00:11:31,879 --> 00:11:33,279
直觉和数学吗

346
00:11:33,559 --> 00:11:34,879
我们尽量的讲

347
00:11:35,120 --> 00:11:35,600
why

348
00:11:35,600 --> 00:11:37,199
就是背后是什么样子的

349
00:11:37,399 --> 00:11:38,919
但是无法保证

350
00:11:38,919 --> 00:11:40,559
是说我们讲的是对的

351
00:11:40,840 --> 00:11:42,319
就是说我尽量的是说

352
00:11:42,319 --> 00:11:44,199
大家要去说

353
00:11:45,319 --> 00:11:46,480
到底是怎么回事

354
00:11:46,519 --> 00:11:48,799
我们尽量往外那边走

355
00:11:48,840 --> 00:11:50,439
但是反过来讲

356
00:11:50,480 --> 00:11:52,079
我们讲的可能是错的

357
00:11:52,199 --> 00:11:54,600
因为今天我们说读论文上

358
00:11:54,600 --> 00:11:55,360
是这样子的

359
00:11:55,360 --> 00:11:56,319
明天可能就变了

360
00:11:56,320 --> 00:11:58,000
后天可能就告诉你说

361
00:11:58,040 --> 00:11:58,760
打脸了

362
00:11:58,760 --> 00:11:59,480
不是这样子

363
00:11:59,520 --> 00:12:01,160
所以大家是说

364
00:12:01,160 --> 00:12:03,160
我们尽量去按照当前

365
00:12:03,160 --> 00:12:04,760
我们的理解来讲

366
00:12:04,960 --> 00:12:06,879
我们确实会尽量多讲一会

367
00:12:06,879 --> 00:12:08,320
这样子的内容

368
00:12:08,360 --> 00:12:08,920
OK

369
00:12:09,200 --> 00:12:09,480
我们

