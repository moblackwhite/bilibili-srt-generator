1
00:00:00,000 --> 00:00:02,000
问题一

2
00:00:02,000 --> 00:00:05,000
number steps是干嘛的

3
00:00:05,000 --> 00:00:07,000
number steps是干嘛的

4
00:00:07,000 --> 00:00:09,000
就是那个t那个时间维度

5
00:00:09,000 --> 00:00:11,000
时间维度是什么东西啊

6
00:00:11,000 --> 00:00:15,000
就是我给大家看一下啊

7
00:00:15,000 --> 00:00:17,000
时间维度是什么呀

8
00:00:17,000 --> 00:00:19,000
假设我在语言模型里面干嘛

9
00:00:19,000 --> 00:00:22,000
我的语言模型说你好世界给你一句话

10
00:00:22,000 --> 00:00:25,000
然后呢每一次呢你要去去预测

11
00:00:25,000 --> 00:00:26,000
我给你一个你

12
00:00:26,000 --> 00:00:28,000
你要去预测他下一个词好

13
00:00:28,000 --> 00:00:30,000
给个好预测下一个都好

14
00:00:30,000 --> 00:00:33,000
所以呢假设我的输入是一个句子的话

15
00:00:33,000 --> 00:00:36,000
那么就是你好世界那是六个词的话

16
00:00:36,000 --> 00:00:38,000
那么number step就是六

17
00:00:38,000 --> 00:00:42,000
就是你那个样本的一个句子的长度

18
00:00:42,000 --> 00:00:43,000
就输到小批量里面

19
00:00:43,000 --> 00:00:45,000
那个句子的长度是number

20
00:00:45,000 --> 00:00:48,000
number steps就是那个t

21
00:00:48,000 --> 00:00:49,000
ok

22
00:00:49,000 --> 00:00:52,000
所以反过来讲你可以认为

23
00:00:52,000 --> 00:00:54,000
这里面是一个六个样本的分类问题

24
00:00:54,000 --> 00:00:55,000
对吧

25
00:00:55,000 --> 00:00:57,000
对每一个词我都要预测下一个词

26
00:00:57,000 --> 00:00:59,000
就下一个词的预测是一个多分类问题

27
00:00:59,000 --> 00:01:02,000
所以呢虽然我告诉你这是一个样本

28
00:01:02,000 --> 00:01:03,000
就是一个句子啊

29
00:01:03,000 --> 00:01:05,000
但是他因为长度是六

30
00:01:05,000 --> 00:01:07,000
所以我要做六次分类

31
00:01:07,000 --> 00:01:09,000
所以就基本上可以等在我们自己mlp

32
00:01:09,000 --> 00:01:12,000
一个六个样本了

33
00:01:12,000 --> 00:01:13,000
对吧

34
00:01:16,000 --> 00:01:17,000
ok

35
00:01:17,000 --> 00:01:19,000
所以这个是干这个事情了

36
00:01:20,000 --> 00:01:22,000
你问我touch serve

37
00:01:24,000 --> 00:01:26,000
touch serve

38
00:01:26,000 --> 00:01:28,000
这个东西我还真熟

39
00:01:29,000 --> 00:01:31,000
这个东西我还真熟

40
00:01:31,000 --> 00:01:33,000
这东西最早是

41
00:01:33,000 --> 00:01:37,000
对这个touch serve最早是给msnet做的serving

42
00:01:37,000 --> 00:01:39,000
然后呢但是他很诡异的是

43
00:01:39,000 --> 00:01:41,000
他是用java实现了

44
00:01:41,000 --> 00:01:43,000
其实这个事情啊

45
00:01:43,000 --> 00:01:46,000
反正我也是跟touch serve团队也是讨论很久很久

46
00:01:46,000 --> 00:01:48,000
我说你为什么用java

47
00:01:48,000 --> 00:01:50,000
因为我是一个python的包

48
00:01:50,000 --> 00:01:51,000
我是一个python的包

49
00:01:51,000 --> 00:01:52,000
类似用c++实现

50
00:01:52,000 --> 00:01:54,000
为什么你做serving的时候

51
00:01:54,000 --> 00:01:56,000
为什么你用java实现了

52
00:01:56,000 --> 00:01:59,000
反正也没有说服我谁

53
00:01:59,000 --> 00:02:01,000
最后就变成了一个java实现

54
00:02:01,000 --> 00:02:03,000
最后这个包反正做serving嘛

55
00:02:03,000 --> 00:02:05,000
serving的话你什么框也行

56
00:02:05,000 --> 00:02:08,000
后来就把这个改吧改吧改成了支持pytouch

57
00:02:08,000 --> 00:02:11,000
就把它也merge到pytouch里面

58
00:02:11,000 --> 00:02:12,000
现在叫touch serve

59
00:02:12,000 --> 00:02:14,000
但是我不知道我不知道怎么用啊

60
00:02:14,000 --> 00:02:15,000
其实说真话

61
00:02:15,000 --> 00:02:18,000
我觉得那个设计有点不是很理解

62
00:02:18,000 --> 00:02:20,000
就为什么要java

63
00:02:20,000 --> 00:02:22,000
而且里面设计我一直觉得不那么理解

64
00:02:23,000 --> 00:02:28,000
如果你现在其实市面上非常多的serving的框架

65
00:02:28,000 --> 00:02:30,000
你比如说Amedia那个tryton

66
00:02:30,000 --> 00:02:32,000
你可以去看一下Amedia tryton

67
00:02:32,000 --> 00:02:33,000
虽然我没用过tryton啊

68
00:02:33,000 --> 00:02:36,000
但是我知道Amedia tryton的性能是非常好的

69
00:02:36,000 --> 00:02:38,000
Amedia他们做了大量的优化

70
00:02:38,000 --> 00:02:40,000
我知道那个其实用的更多一点

71
00:02:40,000 --> 00:02:41,000
你可以去试试

72
00:02:41,000 --> 00:02:43,000
那个照是c++系的

73
00:02:43,000 --> 00:02:46,000
就不用不用装jvm

74
00:02:47,000 --> 00:02:50,000
OK

75
00:02:50,000 --> 00:02:51,000
问题三

76
00:02:51,000 --> 00:02:53,000
528那里不转制可以吗

77
00:02:53,000 --> 00:02:56,000
转制是为了符合接口要求吗

78
00:02:56,000 --> 00:02:59,000
528那里不转制可以

79
00:02:59,000 --> 00:03:00,000
但你不你这里不转制

80
00:03:00,000 --> 00:03:01,000
你之后要转制

81
00:03:01,000 --> 00:03:03,000
就是说你之后就是你

82
00:03:03,000 --> 00:03:05,000
你其实你不转制都没关系啊

83
00:03:05,000 --> 00:03:08,000
之后就取决于你怎么去从x里面拿这个

84
00:03:08,000 --> 00:03:10,000
因为你对每个时间不完

85
00:03:10,000 --> 00:03:12,000
你要把那个p量乘以那个啊

86
00:03:12,000 --> 00:03:14,000
我capsize那个小p量

87
00:03:14,000 --> 00:03:15,000
那个拿出来

88
00:03:15,000 --> 00:03:16,000
你怎么拿

89
00:03:16,000 --> 00:03:17,000
你不转制的话呢

90
00:03:17,000 --> 00:03:20,000
那么你的时间维度应该是在中间位

91
00:03:20,000 --> 00:03:23,000
所以每一次就是说你对中间位便利

92
00:03:23,000 --> 00:03:25,000
然后拿前面位后面位的东西

93
00:03:25,000 --> 00:03:27,000
这个东西会有性能问题

94
00:03:27,000 --> 00:03:29,000
当然可能也问题不大了

95
00:03:29,000 --> 00:03:30,000
就是说主要是你写起来啊

96
00:03:30,000 --> 00:03:32,000
因为你在GPU去拿的话

97
00:03:32,000 --> 00:03:34,000
等于是说你是一个不连续的啊

98
00:03:34,000 --> 00:03:35,000
东西你再去拿

99
00:03:35,000 --> 00:03:37,000
所以你在前面转制之后

100
00:03:37,000 --> 00:03:39,000
之后你去拿的话可以是连续的

101
00:03:39,000 --> 00:03:41,000
所以其实是一个接口问题啊

102
00:03:41,000 --> 00:03:42,000
不是一个

103
00:03:43,000 --> 00:03:44,000
不是说必须要这么做

104
00:03:44,000 --> 00:03:45,000
但是反过来讲

105
00:03:45,000 --> 00:03:47,000
你为了达到你为了去拿那个东西呢

106
00:03:47,000 --> 00:03:49,000
你前面转制后面就变成连续的

107
00:03:49,000 --> 00:03:51,000
而且python写起来更方便一点

108
00:03:54,000 --> 00:03:55,000
time等于0

109
00:03:55,000 --> 00:03:57,000
就dimension等于0是什么呢

110
00:03:57,000 --> 00:03:59,000
dimension等于0就是我有

111
00:03:59,000 --> 00:04:00,000
我有三个矩阵啊

112
00:04:00,000 --> 00:04:01,000
我有三个矩阵

113
00:04:01,000 --> 00:04:02,000
我dimension等于0怎么空开呢

114
00:04:02,000 --> 00:04:04,000
就是啊在0度维度啊

115
00:04:04,000 --> 00:04:07,000
就是把它啊数值的堆在一起

116
00:04:07,000 --> 00:04:10,000
堆成一个长长的一个就高高的一个矩阵

117
00:04:10,000 --> 00:04:12,000
就是按在0那个维度上啊

118
00:04:12,000 --> 00:04:13,000
空开了起来

119
00:04:16,000 --> 00:04:17,000
Rn的normal函数干嘛

120
00:04:17,000 --> 00:04:19,000
Rn的normal函数就是对你的w

121
00:04:19,000 --> 00:04:21,000
做初始化全数用的啊

122
00:04:21,000 --> 00:04:24,000
记得我们mlp里面是怎么初始化的

123
00:04:24,000 --> 00:04:27,000
就是w就是初始化成normal distribution啊

124
00:04:27,000 --> 00:04:29,000
就是那个random n

125
00:04:29,000 --> 00:04:31,000
然后这个地方我就把它

126
00:04:31,000 --> 00:04:32,000
因为你不断去调用那个东西啊

127
00:04:32,000 --> 00:04:35,000
所以我把它啊记在normal里面啊

128
00:04:35,000 --> 00:04:37,000
这样子之后写起来简单一点

129
00:04:37,000 --> 00:04:39,000
这个函数主要是一个记的用的

130
00:04:41,000 --> 00:04:42,000
问题六

131
00:04:42,000 --> 00:04:44,000
为什么是批量大小乘以时间长度啊

132
00:04:44,000 --> 00:04:45,000
这个东西对

133
00:04:45,000 --> 00:04:47,000
这个其实一直是sequence的东西

134
00:04:47,000 --> 00:04:49,000
你要要绕过去的一个东西

135
00:04:49,000 --> 00:04:50,000
就是你要想一下

136
00:04:50,000 --> 00:04:53,000
就是说啊批量大小

137
00:04:53,000 --> 00:04:54,000
为什么乘以时间长度

138
00:04:54,000 --> 00:04:56,000
是因为你每一个批量里面

139
00:04:56,000 --> 00:04:57,000
每一个样本啊

140
00:04:57,000 --> 00:04:59,000
你的长度是t

141
00:04:59,000 --> 00:05:00,000
就是那个时间长度

142
00:05:00,000 --> 00:05:03,000
然后你实际上是你要做t次分类

143
00:05:03,000 --> 00:05:04,000
对吧

144
00:05:04,000 --> 00:05:07,000
从分如果从一个多分类的角度来讲

145
00:05:07,000 --> 00:05:09,000
你给我个小批量里面

146
00:05:09,000 --> 00:05:12,000
其实我要做的分类次数是批量大小

147
00:05:12,000 --> 00:05:13,000
乘以时间长度

148
00:05:13,000 --> 00:05:14,000
就是对任何一个样本

149
00:05:14,000 --> 00:05:15,000
在任何一个时间点

150
00:05:15,000 --> 00:05:16,000
我都要做一次分类

151
00:05:16,000 --> 00:05:17,000
所以你做分类的

152
00:05:17,000 --> 00:05:19,000
所以最后等价是一个

153
00:05:19,000 --> 00:05:20,000
你这个小批量

154
00:05:20,000 --> 00:05:22,000
其实里面就是有批量大小

155
00:05:22,000 --> 00:05:24,000
乘以时间长度啊分类样本

156
00:05:27,000 --> 00:05:29,000
持续而判的内存会炸吗

157
00:05:29,000 --> 00:05:31,000
当然会炸了

158
00:05:32,000 --> 00:05:35,000
但取决于你取决于你有多长吗

159
00:05:35,000 --> 00:05:36,000
你不会特别长

160
00:05:36,000 --> 00:05:37,000
你不会预测个

161
00:05:39,000 --> 00:05:46,000
你不会预测个特别特别长的东西

162
00:05:46,000 --> 00:05:49,000
就说你最后的那个判断出来的东西

163
00:05:49,000 --> 00:05:53,000
是一个批量大小乘以时间长度

164
00:05:53,000 --> 00:05:54,000
乘以我cap size

165
00:05:54,000 --> 00:05:56,000
就我cap那东西你可以做很大

166
00:05:56,000 --> 00:05:58,000
可以做到100万1000万

167
00:05:58,000 --> 00:05:59,000
但是你的长度呢

168
00:05:59,000 --> 00:06:00,000
你预测的长度啊

169
00:06:00,000 --> 00:06:02,000
你的长度可能是1000

170
00:06:02,000 --> 00:06:04,000
那批量大小是如果是32的话

171
00:06:04,000 --> 00:06:07,000
那就是一个32乘以1000

172
00:06:07,000 --> 00:06:08,000
乘以100万

173
00:06:08,000 --> 00:06:11,000
那就是那我觉得还行啊

174
00:06:11,000 --> 00:06:15,000
那就是这个100万

175
00:06:15,000 --> 00:06:16,000
那也就不到

176
00:06:18,000 --> 00:06:21,000
我就就100万乘以1000

177
00:06:21,000 --> 00:06:22,000
那就一个billion一个billion

178
00:06:22,000 --> 00:06:23,000
32个billion的

179
00:06:23,000 --> 00:06:24,000
我觉得也还行啊

180
00:06:24,000 --> 00:06:27,000
就是说也没有那么大的问题

181
00:06:29,000 --> 00:06:30,000
一般你能做到

182
00:06:30,000 --> 00:06:31,000
就是说啊

183
00:06:31,000 --> 00:06:33,000
如果你要做那么大问题的

184
00:06:34,000 --> 00:06:36,000
那个language model的话

185
00:06:36,000 --> 00:06:39,000
你根本就不会是pand那里爆内存

186
00:06:39,000 --> 00:06:41,000
你是你那个真正的模型

187
00:06:41,000 --> 00:06:45,000
那个最后那个输入层和输出层的模型会炸

188
00:06:45,000 --> 00:06:48,000
而pand那个地方可能炸的概率还没

189
00:06:48,000 --> 00:06:49,000
你模型炸的概率到啊

190
00:06:49,000 --> 00:06:50,000
所以现在知道啊

191
00:06:50,000 --> 00:06:51,000
现在大家都在说

192
00:06:51,000 --> 00:06:52,000
我要跑一个billion

193
00:06:52,000 --> 00:06:54,000
或者10个billion

194
00:06:54,000 --> 00:06:56,000
或者100个billion的语言模型

195
00:06:56,000 --> 00:06:57,000
GPT-3那种模型啊

196
00:06:57,000 --> 00:06:59,000
内存就是一个巨大的瓶颈

197
00:06:59,000 --> 00:07:03,000
你得用很多手法来降低内存啊

198
00:07:04,000 --> 00:07:07,000
H是一个batch更新一次吗

199
00:07:07,000 --> 00:07:08,000
刚看到代码

200
00:07:08,000 --> 00:07:10,000
H是每个batch会覆盖一次

201
00:07:10,000 --> 00:07:12,000
但是H不是每一个step的变化

202
00:07:12,000 --> 00:07:13,000
对的

203
00:07:13,000 --> 00:07:15,000
H就是隐藏段

204
00:07:15,000 --> 00:07:16,000
是每一个step

205
00:07:16,000 --> 00:07:19,000
就是每一个时间维度会更新一次

206
00:07:19,000 --> 00:07:21,000
如果你一个batch里面

207
00:07:21,000 --> 00:07:23,000
一个样本长度是t的话

208
00:07:23,000 --> 00:07:26,000
那么在batch里面会h会被更新t次

209
00:07:26,000 --> 00:07:29,000
但是说只是说根据你的采样不一样

210
00:07:29,000 --> 00:07:31,000
我这个当前batch的h

211
00:07:31,000 --> 00:07:33,000
要不要丢给下一个batch

212
00:07:33,000 --> 00:07:34,000
还是我就砍断了

213
00:07:34,000 --> 00:07:36,000
就是说根据你真的下一个batch的样本

214
00:07:36,000 --> 00:07:37,000
和前一个batch的样本

215
00:07:37,000 --> 00:07:39,000
是不是接在一起来判断

216
00:07:43,000 --> 00:07:46,000
5285个时间部署

217
00:07:46,000 --> 00:07:48,000
2不是background

218
00:07:48,000 --> 00:07:50,000
2是我的p量大小

219
00:07:51,000 --> 00:07:53,000
就20p量大小

220
00:07:53,000 --> 00:07:55,000
8是你的vocab size

221
00:07:55,000 --> 00:07:58,000
就是你的那个叫

222
00:07:58,000 --> 00:08:00,000
one-hot encoding那个长度啊

223
00:08:01,000 --> 00:08:03,000
batch size等于是一个文本

224
00:08:03,000 --> 00:08:04,000
就是我做预测的时候

225
00:08:04,000 --> 00:08:05,000
就一个序列对吧

226
00:08:05,000 --> 00:08:06,000
batch size等于

227
00:08:07,000 --> 00:08:10,000
batch size和时间的区别是什么

228
00:08:10,000 --> 00:08:12,000
这个东西其实比较有意思

229
00:08:12,000 --> 00:08:13,000
就是说

230
00:08:15,000 --> 00:08:17,000
时间是什么

231
00:08:17,000 --> 00:08:19,000
时间是句子的长度

232
00:08:20,000 --> 00:08:21,000
是每一次一个样本

233
00:08:21,000 --> 00:08:22,000
一个sequence

234
00:08:22,000 --> 00:08:23,000
一个样本里面

235
00:08:23,000 --> 00:08:24,000
那个句子有多长

236
00:08:24,000 --> 00:08:25,000
我们做语言模型

237
00:08:25,000 --> 00:08:26,000
就是每次我一个句子

238
00:08:26,000 --> 00:08:27,000
一个句子进去

239
00:08:27,000 --> 00:08:29,000
就是你那个样本的那个长度

240
00:08:29,000 --> 00:08:31,000
batch size就是batch size

241
00:08:31,000 --> 00:08:32,000
就是我一次小批量的时候

242
00:08:32,000 --> 00:08:34,000
都同时训练多少个样本

243
00:08:35,000 --> 00:08:37,000
所以你反过来讲

244
00:08:37,000 --> 00:08:38,000
这个time呢

245
00:08:38,000 --> 00:08:39,000
有点像谁呢

246
00:08:39,000 --> 00:08:40,000
有点像那个image大小啊

247
00:08:40,000 --> 00:08:42,000
在就是跟你数据相关

248
00:08:42,000 --> 00:08:43,000
这是数据上

249
00:08:43,000 --> 00:08:44,000
这是优化算法的东西啊

250
00:08:44,000 --> 00:08:46,000
这个是数据的东西

251
00:08:46,000 --> 00:08:47,000
数据是说

252
00:08:47,000 --> 00:08:48,000
你我的image里面

253
00:08:48,000 --> 00:08:49,000
那个是什么

254
00:08:49,000 --> 00:08:50,000
image是高宽嘛

255
00:08:50,000 --> 00:08:51,000
高宽和channel嘛

256
00:08:51,000 --> 00:08:53,000
就是那个图片大小啊

257
00:08:53,000 --> 00:08:54,000
所以这个time

258
00:08:54,000 --> 00:08:55,000
有点像那个东西

259
00:08:55,000 --> 00:08:56,000
问题12

260
00:08:56,000 --> 00:08:57,000
预测这段代码

261
00:08:57,000 --> 00:08:58,000
对于prefix处理

262
00:08:58,000 --> 00:09:00,000
好像是直接放到output里面

263
00:09:00,000 --> 00:09:02,000
没有把它拿过来再做训练

264
00:09:02,000 --> 00:09:03,000
是不是可以把prefix

265
00:09:03,000 --> 00:09:05,000
也用起来训练一下更好

266
00:09:08,000 --> 00:09:09,000
你这个问题很有意思啊

267
00:09:09,000 --> 00:09:10,000
就是说

268
00:09:11,000 --> 00:09:12,000
这个问题是说

269
00:09:12,000 --> 00:09:13,000
我们做预测的时候

270
00:09:13,000 --> 00:09:14,000
不是有prefix吗

271
00:09:14,000 --> 00:09:15,000
prefix的话

272
00:09:16,000 --> 00:09:17,000
就是说

273
00:09:18,000 --> 00:09:21,000
我们就就就用来true true state啊

274
00:09:21,000 --> 00:09:22,000
没有用它来训练

275
00:09:22,000 --> 00:09:24,000
我们就就就用来true true state啊

276
00:09:24,000 --> 00:09:26,000
没有用它来更新我们的模型啊

277
00:09:27,000 --> 00:09:28,000
没有更新模型啊

278
00:09:28,000 --> 00:09:29,000
就是说

279
00:09:29,000 --> 00:09:30,000
这个问题是说

280
00:09:30,000 --> 00:09:31,000
你是不是也可以

281
00:09:31,000 --> 00:09:32,000
prefix就是你的ground

282
00:09:32,000 --> 00:09:33,000
就是你的label对吧

283
00:09:33,000 --> 00:09:34,000
你反正有个

284
00:09:34,000 --> 00:09:35,000
有个序列对吧

285
00:09:35,000 --> 00:09:37,000
我也可以用它来更新我的模型啊

286
00:09:38,000 --> 00:09:40,000
不这么做主要是用来简单性啊

287
00:09:40,000 --> 00:09:42,000
就这么做估计你也不会

288
00:09:43,000 --> 00:09:44,000
就一般啊

289
00:09:44,000 --> 00:09:46,000
一般你为什么不这么做呢

290
00:09:47,000 --> 00:09:48,000
是因为预测的时候

291
00:09:48,000 --> 00:09:49,000
我不要更新模型

292
00:09:49,000 --> 00:09:50,000
为什么是因为

293
00:09:50,000 --> 00:09:52,000
比如说你想象一个场景

294
00:09:52,000 --> 00:09:53,000
就是说我训练好一个模型

295
00:09:54,000 --> 00:09:55,000
上线了

296
00:09:55,000 --> 00:09:56,000
上线了之后

297
00:09:56,000 --> 00:09:58,000
那么假设我用户给我

298
00:09:59,000 --> 00:10:00,000
提高啊

299
00:10:00,000 --> 00:10:01,000
我说你给我写一段话

300
00:10:01,000 --> 00:10:02,000
什么东西

301
00:10:02,000 --> 00:10:03,000
我用户给你下东西

302
00:10:03,000 --> 00:10:06,000
你这个模型会根据用户的输入变

303
00:10:06,000 --> 00:10:07,000
那就会出问题

304
00:10:08,000 --> 00:10:09,000
对吧用户

305
00:10:09,000 --> 00:10:11,000
比如说我给你写很多脏话给你

306
00:10:11,000 --> 00:10:12,000
那你的模型就会学会脏话了

307
00:10:12,000 --> 00:10:14,000
当年记得微软小兵

308
00:10:14,000 --> 00:10:16,000
那个啊小兵

309
00:10:16,000 --> 00:10:18,000
那个那个虚虚你助手啊

310
00:10:18,000 --> 00:10:20,000
就是被被被很多人吐槽

311
00:10:20,000 --> 00:10:22,000
说他竟然会说脏话

312
00:10:22,000 --> 00:10:24,000
这个是一个巨大的PR事件啊

313
00:10:24,000 --> 00:10:25,000
就是巨大的公关事件啊

314
00:10:25,000 --> 00:10:27,000
所以这个东西你的模型

315
00:10:27,000 --> 00:10:30,000
千万不能被用户的数据所带偏

316
00:10:31,000 --> 00:10:32,000
所以就是说

317
00:10:32,000 --> 00:10:34,000
你就算你的pre去劝一劝prefix

318
00:10:34,000 --> 00:10:36,000
肯定可以带来好处啊

319
00:10:36,000 --> 00:10:38,000
但是呢你的危害是巨大的

320
00:10:39,000 --> 00:10:40,000
所以你是啊

321
00:10:40,000 --> 00:10:41,000
最好不要干这个事情

322
00:10:43,000 --> 00:10:46,000
这里依赖的长度是通过什么控制的

323
00:10:46,000 --> 00:10:47,000
t吗

324
00:10:47,000 --> 00:10:49,000
对就依赖长度就是那个sequence

325
00:10:49,000 --> 00:10:50,000
说35啊

326
00:10:50,000 --> 00:10:51,000
我们就随便取了

327
00:10:52,000 --> 00:10:53,000
就是你可以去长一点

328
00:10:53,000 --> 00:10:54,000
去短一点都没关系

329
00:10:54,000 --> 00:10:55,000
其实啊

330
00:10:56,000 --> 00:10:57,000
问题是4

331
00:10:57,000 --> 00:11:01,000
用RN做多站点的气温预测输入式啊

332
00:11:01,000 --> 00:11:02,000
什么什么

333
00:11:04,000 --> 00:11:07,000
啊用RN做多站点的气温预测输入式

334
00:11:07,000 --> 00:11:08,000
BNTF

335
00:11:08,000 --> 00:11:09,000
N是站点数

336
00:11:09,000 --> 00:11:11,000
T是时间长度

337
00:11:11,000 --> 00:11:13,000
F是特征

338
00:11:13,000 --> 00:11:15,000
现在问题是

339
00:11:15,000 --> 00:11:17,000
对你多了一个站点个数

340
00:11:18,000 --> 00:11:19,000
怎么做

341
00:11:24,000 --> 00:11:25,000
就站点啊

342
00:11:28,000 --> 00:11:29,000
就我觉得你这个问题挺好

343
00:11:29,000 --> 00:11:30,000
挺有意思的啊

344
00:11:30,000 --> 00:11:31,000
就是说

345
00:11:32,000 --> 00:11:33,000
在啊

346
00:11:34,000 --> 00:11:35,000
比如说地球物理里面啊

347
00:11:35,000 --> 00:11:36,000
就地球科学里面啊

348
00:11:36,000 --> 00:11:38,000
比如说你要预测一个啊

349
00:11:38,000 --> 00:11:39,000
你有很多个

350
00:11:39,000 --> 00:11:42,000
比如说比如说你做股票预测吧

351
00:11:42,000 --> 00:11:43,000
股票预测呢

352
00:11:43,000 --> 00:11:44,000
你有很多只股票

353
00:11:44,000 --> 00:11:45,000
你要做这个事情

354
00:11:45,000 --> 00:11:46,000
你怎么办

355
00:11:46,000 --> 00:11:47,000
其实你是可以做的

356
00:11:47,000 --> 00:11:48,000
为什么是说

357
00:11:50,000 --> 00:11:53,000
你一个单个的时间点啊

358
00:11:53,000 --> 00:11:56,000
里面之前我们是一个句子

359
00:11:56,000 --> 00:11:59,000
现在你变成了一个矩阵

360
00:11:59,000 --> 00:12:01,000
就单个时间点里面就是一个

361
00:12:01,000 --> 00:12:03,000
一个位都是站点啊

362
00:12:05,000 --> 00:12:07,000
不不不不我讲错了啊

363
00:12:09,000 --> 00:12:10,000
就我们现在一个句子

364
00:12:10,000 --> 00:12:12,000
就是一个时间点是一个词

365
00:12:12,000 --> 00:12:14,000
你现在变成了一个时间点

366
00:12:14,000 --> 00:12:17,000
是一个常为一个n的一个向量

367
00:12:17,000 --> 00:12:19,000
就是你的n就是你的站点数

368
00:12:19,000 --> 00:12:20,000
然后呢

369
00:12:20,000 --> 00:12:21,000
你要再做的话

370
00:12:21,000 --> 00:12:22,000
其实你是可以做的

371
00:12:22,000 --> 00:12:24,000
就是说你一样的就做啊

372
00:12:24,000 --> 00:12:25,000
做到one hot里面

373
00:12:25,000 --> 00:12:27,000
比如说我们之后可以啊

374
00:12:27,000 --> 00:12:28,000
不过你这里

375
00:12:28,000 --> 00:12:30,000
你这就不需要one hot了

376
00:12:30,000 --> 00:12:31,000
其实说白了

377
00:12:31,000 --> 00:12:32,000
你这就是一个史述

378
00:12:32,000 --> 00:12:33,000
你不要做one hot

379
00:12:33,000 --> 00:12:34,000
就是你这个史述进去

380
00:12:34,000 --> 00:12:36,000
史述进去直接进mlp就行了

381
00:12:36,000 --> 00:12:38,000
就是说你就是把那个one hot

382
00:12:38,000 --> 00:12:40,000
那一步给干掉就行了

383
00:12:40,000 --> 00:12:41,000
OK

384
00:13:11,000 --> 00:13:12,000
再复杂一点

385
00:13:12,000 --> 00:13:13,000
你可以用图顺就网络啊

386
00:13:13,000 --> 00:13:15,000
或者是你用当图片来做

387
00:13:16,000 --> 00:13:17,000
这一块呢

388
00:13:17,000 --> 00:13:18,000
你可以去看一下啊

389
00:13:18,000 --> 00:13:21,000
就是说啊天气预测里面啊

390
00:13:21,000 --> 00:13:23,000
用RN做天气测啊

391
00:13:23,000 --> 00:13:25,000
就行建的实行建设的

392
00:13:25,000 --> 00:13:26,000
最最早的一篇文章啊

393
00:13:26,000 --> 00:13:28,000
最近Google也在做一些

394
00:13:28,000 --> 00:13:29,000
这样子的文章

395
00:13:29,000 --> 00:13:30,000
有很多这样子工作啊

396
00:13:30,000 --> 00:13:32,000
你就说啊不是啊

397
00:13:32,000 --> 00:13:34,000
气象预测是一个

398
00:13:34,000 --> 00:13:36,000
最近做的还挺热的一个话题

399
00:13:36,000 --> 00:13:37,000
你去去看一下论文啊

400
00:13:38,000 --> 00:13:40,000
Number steps可以理解成

401
00:13:40,000 --> 00:13:41,000
隐藏层的层数吗

402
00:13:41,000 --> 00:13:43,000
那你不能这么理解啊

403
00:13:43,000 --> 00:13:45,000
Number steps就等于是说

404
00:13:45,000 --> 00:13:47,000
run了多少次

405
00:13:47,000 --> 00:13:49,000
就是说同时run了多少次

406
00:13:49,000 --> 00:13:50,000
但他不是隐藏层层数

407
00:13:50,000 --> 00:13:51,000
隐藏层层数是

408
00:13:51,000 --> 00:13:53,000
当然是说算backward的时候

409
00:13:53,000 --> 00:13:55,000
你可以有点像隐藏层层数

410
00:13:55,000 --> 00:13:57,000
从啊计算角度来讲

411
00:13:57,000 --> 00:13:58,000
但是从啊模型角度来讲

412
00:13:58,000 --> 00:13:59,000
他不等同

413
00:14:01,000 --> 00:14:03,000
如果用RN做视频处理

414
00:14:03,000 --> 00:14:04,000
N个视频M帧

415
00:14:04,000 --> 00:14:06,000
我考虑时间长度T远小于M

416
00:14:07,000 --> 00:14:09,000
我需要每一帧都输出

417
00:14:09,000 --> 00:14:10,000
做一个分类结果

418
00:14:10,000 --> 00:14:11,000
我改写数据读取

419
00:14:11,000 --> 00:14:13,000
我是不是把random

420
00:14:16,000 --> 00:14:18,000
用RN做视频啊

421
00:14:18,000 --> 00:14:19,000
RN做视频

422
00:14:19,000 --> 00:14:20,000
你可以去看一下

423
00:14:20,000 --> 00:14:21,000
就是说这里面有很多

424
00:14:21,000 --> 00:14:22,000
这样子的工作

425
00:14:22,000 --> 00:14:23,000
一般最常见的做法

426
00:14:23,000 --> 00:14:25,000
RN怎么做视频呢

427
00:14:25,000 --> 00:14:27,000
就是每一个帧用CN抽特征

428
00:14:27,000 --> 00:14:28,000
抽特征之后呢

429
00:14:28,000 --> 00:14:30,000
每一个帧啊就变成了

430
00:14:30,000 --> 00:14:32,000
啊一个向量啊

431
00:14:32,000 --> 00:14:33,000
然后你会采样帧啊

432
00:14:33,000 --> 00:14:34,000
就关键是采样

433
00:14:34,000 --> 00:14:35,000
最后你一个视频

434
00:14:35,000 --> 00:14:36,000
就表示成了

435
00:14:36,000 --> 00:14:38,000
比如说我抽了100帧出来

436
00:14:38,000 --> 00:14:40,000
那么每一帧那个图片呢

437
00:14:40,000 --> 00:14:42,000
用CN抽了一个特征啊

438
00:14:42,000 --> 00:14:43,000
啊然后就是比如说

439
00:14:43,000 --> 00:14:44,000
512长度特征

440
00:14:44,000 --> 00:14:46,000
就变成一个100×512的啊

441
00:14:46,000 --> 00:14:47,000
东西

442
00:14:47,000 --> 00:14:48,000
然后直接做到RN里面

443
00:14:48,000 --> 00:14:49,000
等于是1号的一样的

444
00:14:49,000 --> 00:14:50,000
1号的不用了

445
00:14:50,000 --> 00:14:52,000
因为你现在已经把你的

446
00:14:52,000 --> 00:14:53,000
东西表示成向量了啊

447
00:14:53,000 --> 00:14:55,000
所以就不需要1号的了

448
00:14:55,000 --> 00:14:56,000
所以你是可以啊

449
00:14:57,000 --> 00:14:58,000
你可以就是说

450
00:14:58,000 --> 00:14:59,000
通常来说啊

451
00:14:59,000 --> 00:15:00,000
做做小视频啊

452
00:15:00,000 --> 00:15:01,000
一般会把它切成

453
00:15:01,000 --> 00:15:03,000
比较短一块一块的

454
00:15:04,000 --> 00:15:05,000
就你不会做一个

455
00:15:05,000 --> 00:15:06,000
一个小时的视频

456
00:15:06,000 --> 00:15:08,000
一般你切成几秒钟几秒钟啊

457
00:15:08,000 --> 00:15:11,000
或者是说你几秒钟里面采样一帧

458
00:15:12,000 --> 00:15:13,000
所以呢你要random

459
00:15:13,000 --> 00:15:14,000
或者不random

460
00:15:14,000 --> 00:15:16,000
我是觉得没关系啊

461
00:15:16,000 --> 00:15:18,000
一般来说RN不能处理

462
00:15:19,000 --> 00:15:21,000
就RN不能处理特别长的序列

463
00:15:21,000 --> 00:15:23,000
35已经算还不错了

464
00:15:23,000 --> 00:15:24,000
你处理个上百的话

465
00:15:24,000 --> 00:15:26,000
是做不了的RN

466
00:15:26,000 --> 00:15:27,000
我们之后会讲

467
00:15:27,000 --> 00:15:28,000
LSTM和GRU

468
00:15:28,000 --> 00:15:29,000
给大家看一看

469
00:15:29,000 --> 00:15:31,000
怎么样处理更长的一些序列

470
00:15:32,000 --> 00:15:33,000
以及transformer

471
00:15:33,000 --> 00:15:35,000
transformer能处理到更长的序列

472
00:15:37,000 --> 00:15:38,000
Detach

473
00:15:38,000 --> 00:15:39,000
Detach

474
00:15:39,000 --> 00:15:40,000
就是你不理解Detach的话

475
00:15:40,000 --> 00:15:41,000
你可以去看一下

476
00:15:41,000 --> 00:15:42,000
就是说啊

477
00:15:42,000 --> 00:15:43,000
可以去看一下

478
00:15:43,000 --> 00:15:45,000
我们之前讲T2计算的时候

479
00:15:45,000 --> 00:15:46,000
怎么意思

480
00:15:46,000 --> 00:15:48,000
就是说因为我的state啊

481
00:15:49,000 --> 00:15:51,000
在前面做的时候呢

482
00:15:51,000 --> 00:15:52,000
做计算时候呢

483
00:15:52,000 --> 00:15:54,000
他会去记录说

484
00:15:54,000 --> 00:15:56,000
在前一个batch里面的

485
00:15:56,000 --> 00:15:58,000
那些操作

486
00:15:58,000 --> 00:15:59,000
如果这个state

487
00:15:59,000 --> 00:16:01,000
我没有重新创建新的的话

488
00:16:01,000 --> 00:16:03,000
我还是重用他的话

489
00:16:03,000 --> 00:16:05,000
他会记住前面那些东西

490
00:16:05,000 --> 00:16:07,000
然后你做误差反传的时候

491
00:16:07,000 --> 00:16:09,000
他可能会多算东西

492
00:16:10,000 --> 00:16:11,000
所以你把他说

493
00:16:11,000 --> 00:16:12,000
我在前面那一个

494
00:16:12,000 --> 00:16:14,000
iteration和midbatch里面的东西

495
00:16:14,000 --> 00:16:15,000
就不要了

496
00:16:15,000 --> 00:16:17,000
就那些计算就不要记住了

497
00:16:17,000 --> 00:16:18,000
就丢掉它

498
00:16:18,000 --> 00:16:19,000
这样子的话

499
00:16:19,000 --> 00:16:20,000
在backward的时候

500
00:16:20,000 --> 00:16:22,000
我只会关注当前做的东西

501
00:16:24,000 --> 00:16:25,000
批量随不随机取

502
00:16:25,000 --> 00:16:26,000
应该看批量之间

503
00:16:26,000 --> 00:16:28,000
有没有时间关联吧

504
00:16:28,000 --> 00:16:30,000
要有关联就不能随机取

505
00:16:30,000 --> 00:16:31,000
其实也不是的

506
00:16:31,000 --> 00:16:32,000
就是说

507
00:16:33,000 --> 00:16:34,000
就是说当然了

508
00:16:34,000 --> 00:16:35,000
如果有关联的话

509
00:16:35,000 --> 00:16:37,000
你可以不随机取

510
00:16:37,000 --> 00:16:38,000
不随机取

511
00:16:38,000 --> 00:16:40,000
我们看到了他的问题是说

512
00:16:40,000 --> 00:16:43,000
他的随机性变差了

513
00:16:43,000 --> 00:16:44,000
随机性变差容易overfitting

514
00:16:44,000 --> 00:16:45,000
这是第一点

515
00:16:45,000 --> 00:16:46,000
第二点呢

516
00:16:46,000 --> 00:16:49,000
Rn他做不了那么长的序列

517
00:16:49,000 --> 00:16:50,000
其实呢

518
00:16:50,000 --> 00:16:51,000
其实你应该随机取

519
00:16:52,000 --> 00:16:54,000
大家很少用不随机取

520
00:16:54,000 --> 00:16:55,000
因为为什么

521
00:16:55,000 --> 00:16:57,000
是因为虽然你确实

522
00:16:57,000 --> 00:16:58,000
你给我一个很长的序列

523
00:16:58,000 --> 00:16:59,000
是一件很好的事情

524
00:16:59,000 --> 00:17:02,000
但是我的Rn不足以去记住

525
00:17:02,000 --> 00:17:04,000
那么长的序列

526
00:17:04,000 --> 00:17:06,000
Rn通常我觉得

527
00:17:06,000 --> 00:17:09,000
这个100以内的还行

528
00:17:09,000 --> 00:17:11,000
超过100就比较悬了

529
00:17:12,000 --> 00:17:13,000
就为什么要随机

530
00:17:13,000 --> 00:17:14,000
还是这个问题

531
00:17:14,000 --> 00:17:15,000
就随机

532
00:17:15,000 --> 00:17:17,000
随机性更好

533
00:17:17,000 --> 00:17:18,000
对模型没那么overfitting

534
00:17:18,000 --> 00:17:20,000
第二点是说Rn做不了很长

535
00:17:22,000 --> 00:17:23,000
好 问题二是

536
00:17:23,000 --> 00:17:25,000
怎么让他打标点换行

537
00:17:25,000 --> 00:17:26,000
另起一段停顿

538
00:17:26,000 --> 00:17:27,000
你可以做了

539
00:17:27,000 --> 00:17:29,000
这东西之所以他没学会

540
00:17:29,000 --> 00:17:31,000
是因为我们把标点换行

541
00:17:31,000 --> 00:17:35,000
全部把它变成了一个空格了

542
00:17:36,000 --> 00:17:37,000
就是为了简单

543
00:17:37,000 --> 00:17:39,000
并不是他做不了

544
00:17:39,000 --> 00:17:40,000
就是说我们为了简单

545
00:17:40,000 --> 00:17:42,000
把workup弄小一点

546
00:17:42,000 --> 00:17:43,000
计算起来简单一点

547
00:17:43,000 --> 00:17:45,000
但是你如果你在处理的时候

548
00:17:45,000 --> 00:17:47,000
不把标点做掉是没事的

549
00:17:47,000 --> 00:17:48,000
我们在机器翻译的时候

550
00:17:48,000 --> 00:17:49,000
我们之后会讲

551
00:17:49,000 --> 00:17:51,000
说标点我们是留在那里的

552
00:17:51,000 --> 00:17:52,000
就是标点换行

553
00:17:52,000 --> 00:17:53,000
我们都不会去掉

554
00:17:53,000 --> 00:17:54,000
所以呢

555
00:17:54,000 --> 00:17:57,000
你就把在workup里保存下来就行了

556
00:17:59,000 --> 00:18:00,000
问题21

557
00:18:02,000 --> 00:18:03,000
为什么预测字符

558
00:18:03,000 --> 00:18:05,000
而不是预测一个单词呢

559
00:18:07,000 --> 00:18:11,000
是因为单词预测起来比较简单

560
00:18:11,000 --> 00:18:12,000
因为你的work

561
00:18:12,000 --> 00:18:14,000
如果用单词做的话

562
00:18:14,000 --> 00:18:16,000
workupsize就是28

563
00:18:16,000 --> 00:18:18,000
我们是28对吧

564
00:18:18,000 --> 00:18:19,000
workup是28

565
00:18:19,000 --> 00:18:20,000
因为你是

566
00:18:20,000 --> 00:18:22,000
如果用字符的话

567
00:18:22,000 --> 00:18:23,000
是workup是28

568
00:18:23,000 --> 00:18:24,000
用单词的话

569
00:18:24,000 --> 00:18:26,000
你可能要做到上千了

570
00:18:26,000 --> 00:18:28,000
那就是做一个

571
00:18:28,000 --> 00:18:30,000
你workout出去的

572
00:18:30,000 --> 00:18:32,000
就是输入就变成一个

573
00:18:32,000 --> 00:18:33,000
从一个28长的向量

574
00:18:33,000 --> 00:18:35,000
变成了一个上千的向量

575
00:18:35,000 --> 00:18:38,000
你的输出要做一个上千类的预测

576
00:18:39,000 --> 00:18:41,000
我们样本撑不起来

577
00:18:41,000 --> 00:18:43,000
首先我们这个我们就个几万个

578
00:18:43,000 --> 00:18:45,000
我们这里面就几千个词吧

579
00:18:45,000 --> 00:18:48,000
几千个词要做一个几千个分类的

580
00:18:48,000 --> 00:18:50,000
东西是做不了的

581
00:18:50,000 --> 00:18:51,000
样本太小

582
00:18:51,000 --> 00:18:52,000
第二个计算太大

583
00:18:52,000 --> 00:18:54,000
所以用字符会好一点

584
00:18:55,000 --> 00:18:56,000
就是为了简单起见

585
00:18:58,000 --> 00:19:01,000
如何判断当前batch和下一个batch

586
00:19:01,000 --> 00:19:02,000
样本是不是接在一起的

587
00:19:02,000 --> 00:19:04,000
是根据时间长度吗

588
00:19:04,000 --> 00:19:05,000
不是的

589
00:19:05,000 --> 00:19:06,000
这个是你要去看一下

590
00:19:06,000 --> 00:19:07,000
我们上一周的视频回顾

591
00:19:07,000 --> 00:19:10,000
就是我们定了两种读取数据的方法

592
00:19:10,000 --> 00:19:12,000
一种是每次随机采样一段

593
00:19:12,000 --> 00:19:14,000
另外一种是保证上一个batch

594
00:19:14,000 --> 00:19:16,000
下一个batch的样本是接在一起

595
00:19:16,000 --> 00:19:18,000
所以我们定义了两个函数

596
00:19:18,000 --> 00:19:24,000
它分别对两个不同的那一个东西

597
00:19:24,000 --> 00:19:27,000
分别对了两种不同的采样的方式

598
00:19:32,000 --> 00:19:38,000
Rn处理不了长序列的原因是

599
00:19:38,000 --> 00:19:40,000
原因是

600
00:19:44,000 --> 00:19:45,000
原因是什么

601
00:19:45,000 --> 00:19:47,000
原因其实就是说

602
00:19:47,000 --> 00:19:48,000
也不是说原因

603
00:19:48,000 --> 00:19:51,000
就是说我们原因是什么

604
00:19:51,000 --> 00:19:53,000
原因是我们每次传的时候

605
00:19:53,000 --> 00:19:55,000
我们时间性是从个h来传的

606
00:19:55,000 --> 00:20:00,000
就放在一个长辈512或者256的向量里面

607
00:20:00,000 --> 00:20:02,000
这个向量一常的话

608
00:20:02,000 --> 00:20:05,000
就是说我一个长辈256的

609
00:20:05,000 --> 00:20:07,000
长辈256的向量

610
00:20:07,000 --> 00:20:10,000
如果我要记录一个

611
00:20:10,000 --> 00:20:12,000
时序长为1000的东西

612
00:20:12,000 --> 00:20:13,000
是很难记录对吧

613
00:20:13,000 --> 00:20:14,000
你想一想就是说

614
00:20:14,000 --> 00:20:15,000
时序1000

615
00:20:15,000 --> 00:20:17,000
假设每一个时间不要记一个元素的话

616
00:20:17,000 --> 00:20:19,000
那么我这个向量不够长对吧

617
00:20:19,000 --> 00:20:21,000
但你可以做到很长

618
00:20:21,000 --> 00:20:23,000
你可以把影变量做很长

619
00:20:23,000 --> 00:20:25,000
做很长的话就变成了一个MLP的问题了

620
00:20:25,000 --> 00:20:28,000
就是MLP你可以把影变大

621
00:20:28,000 --> 00:20:30,000
但是很容易over fitting

622
00:20:30,000 --> 00:20:31,000
OK

623
00:20:31,000 --> 00:20:32,000
所以就是说

624
00:20:32,000 --> 00:20:35,000
你可认为Rn有点像

625
00:20:35,000 --> 00:20:36,000
有点像什么

626
00:20:36,000 --> 00:20:38,000
有点像我们最早的MLP

627
00:20:40,000 --> 00:20:43,000
所以你会发现在做比较简单任务上还可以

628
00:20:43,000 --> 00:20:45,000
但是做复杂任务比较难

629
00:20:45,000 --> 00:20:48,000
就是说之后我们需要设计更精巧的

630
00:20:48,000 --> 00:20:49,000
比如说我们MLP说

631
00:20:49,000 --> 00:20:50,000
我要做图像的话

632
00:20:50,000 --> 00:20:51,000
我会用卷机

633
00:20:51,000 --> 00:20:54,000
用ResNet或者ResNet可以做得更深

634
00:20:54,000 --> 00:20:55,000
同样的话

635
00:20:55,000 --> 00:20:59,000
Rn是最简单的做时序序列的模型

636
00:20:59,000 --> 00:21:01,000
但我们之后会有一系列模型

637
00:21:01,000 --> 00:21:02,000
比如说Transformer

638
00:21:02,000 --> 00:21:03,000
整个架构都不一样了

639
00:21:03,000 --> 00:21:07,000
然后或者是GRU LSTM

640
00:21:07,000 --> 00:21:10,000
然后使得或者加了Tension

641
00:21:10,000 --> 00:21:14,000
使得你在处理时间上面更加智能一点

642
00:21:16,000 --> 00:21:17,000
24

643
00:21:17,000 --> 00:21:20,000
动手学深度学习这本书的载原处理

644
00:21:20,000 --> 00:21:21,000
大部分是什么时候看到

645
00:21:21,000 --> 00:21:24,000
我们肯定是会在

646
00:21:24,000 --> 00:21:25,000
我看一下我们

647
00:21:25,000 --> 00:21:26,000
好

648
00:21:26,000 --> 00:21:28,000
我们肯定会在我们的直播

649
00:21:28,000 --> 00:21:30,000
讲到那一章的时候会更新

650
00:21:30,000 --> 00:21:32,000
我们确实没有更新吗

651
00:21:32,000 --> 00:21:35,000
我记得翻译我们差不多也翻完了

652
00:21:35,000 --> 00:21:36,000
载原处理

653
00:21:36,000 --> 00:21:37,000
我们现在还没有更新

654
00:21:37,000 --> 00:21:39,000
我们只更新到

655
00:21:40,000 --> 00:21:42,000
对我们的基本上我们的

656
00:21:42,000 --> 00:21:45,000
这个东西是因为我们英文版也还在定稿

657
00:21:45,000 --> 00:21:47,000
然后我们要等英文版定稿了之后

658
00:21:47,000 --> 00:21:49,000
再翻译到中文版

659
00:21:49,000 --> 00:21:52,000
所以我们基本上能保证的是说

660
00:21:52,000 --> 00:21:55,000
尽量保证在我们讲这一章的时候

661
00:21:55,000 --> 00:21:56,000
讲载原处理的时候

662
00:21:56,000 --> 00:21:59,000
在这个之前我们应该是好了

663
00:21:59,000 --> 00:22:01,000
所以我们现在中文版翻译到了Transformer

664
00:22:01,000 --> 00:22:03,000
就这一刻到8月7号之前

665
00:22:03,000 --> 00:22:04,000
我们应该翻译完了

666
00:22:04,000 --> 00:22:06,000
中文版的翻译还在

667
00:22:06,000 --> 00:22:09,000
应该下周开始做NLP的那一块

668
00:22:10,000 --> 00:22:12,000
当然你如果特别想急的话

669
00:22:12,000 --> 00:22:13,000
你就是看英文版

670
00:22:13,000 --> 00:22:14,000
英文版的话

671
00:22:14,000 --> 00:22:16,000
那英文版是全的

672
00:22:16,000 --> 00:22:19,000
英文版的NLP是全的

673
00:22:19,000 --> 00:22:22,000
就是比如说这一块是有的

674
00:22:22,000 --> 00:22:23,000
OK

675
00:22:23,000 --> 00:22:25,000
就是英文版是有的

676
00:22:31,000 --> 00:22:35,000
现在端测模型部署前景如何

677
00:22:35,000 --> 00:22:38,000
因为如果觉得深度学习是不是有点瓶颈

678
00:22:38,000 --> 00:22:41,000
想从事端测模型部署应该学什么

679
00:22:41,000 --> 00:22:42,000
有什么学视频

680
00:22:42,000 --> 00:22:44,000
或者哪个公司的框就会好一点

681
00:22:46,000 --> 00:22:47,000
端测

682
00:22:47,000 --> 00:22:49,000
端测两块

683
00:22:49,000 --> 00:22:52,000
一块是说你工具上的优化

684
00:22:52,000 --> 00:22:54,000
比如说工具上

685
00:22:54,000 --> 00:22:56,000
我觉得还算挺成熟的

686
00:22:57,000 --> 00:23:02,000
不管是比如TensorFlow有TFlight是吧

687
00:23:02,000 --> 00:23:06,000
然后ONNX它也有一点端测的模型

688
00:23:07,000 --> 00:23:09,000
Torch不是也在做了一些

689
00:23:09,000 --> 00:23:12,000
就Facebook也做了一些东西

690
00:23:12,000 --> 00:23:14,000
国内的话还有挺多公司也做了端测的东西

691
00:23:14,000 --> 00:23:16,000
不管是阿里小米

692
00:23:16,000 --> 00:23:17,000
他们都做了一些端测

693
00:23:17,000 --> 00:23:20,000
手机上就是基本上硬件厂商都要做一点端测上的优化

694
00:23:20,000 --> 00:23:22,000
就针对自己硬件的优化

695
00:23:22,000 --> 00:23:24,000
所以框架上来说这一块

696
00:23:24,000 --> 00:23:25,000
另外一块

697
00:23:25,000 --> 00:23:27,000
比如说TVN也能做一些端测上的东西

698
00:23:29,000 --> 00:23:32,000
这端测上东西的框架上来说还行

699
00:23:32,000 --> 00:23:34,000
就是说比较碎片化一点

700
00:23:34,000 --> 00:23:36,000
但是基本上也差不多

701
00:23:36,000 --> 00:23:38,000
各个硬件都cover到了

702
00:23:38,000 --> 00:23:41,000
另外一块就是说主要是

703
00:23:42,000 --> 00:23:43,000
主要是什么呢

704
00:23:43,000 --> 00:23:44,000
主要是你这个模型

705
00:23:44,000 --> 00:23:46,000
你得把它弄得特别小

706
00:23:46,000 --> 00:23:49,000
所以就是说也挺多的research工作

707
00:23:49,000 --> 00:23:52,000
就是说做整点化

708
00:23:52,000 --> 00:23:53,000
定点化处理

709
00:23:53,000 --> 00:23:55,000
把模型弄得特别小

710
00:23:55,000 --> 00:23:56,000
比如说MobileNet这种

711
00:23:56,000 --> 00:23:58,000
从架构上使用的特别小

712
00:23:58,000 --> 00:24:01,000
现在说把Transformer这种大的东西改得特别小

713
00:24:01,000 --> 00:24:03,000
就是说整个这一块

714
00:24:04,000 --> 00:24:08,000
我曾经挺看好这一块

715
00:24:08,000 --> 00:24:10,000
我在4年前挺看好这一块

716
00:24:10,000 --> 00:24:13,000
所以我们公司是有产品做这一块的

717
00:24:13,000 --> 00:24:15,000
但是整个端测

718
00:24:15,000 --> 00:24:18,000
其实没我想象那么发展那么快

719
00:24:18,000 --> 00:24:20,000
是因为确实硬件

720
00:24:20,000 --> 00:24:22,000
就是说端测的硬件

721
00:24:22,000 --> 00:24:24,000
大家对成本很关心

722
00:24:24,000 --> 00:24:26,000
你买个手机贵个100块钱

723
00:24:26,000 --> 00:24:28,000
你还是会考虑对吧

724
00:24:28,000 --> 00:24:30,000
所以端测的话

725
00:24:30,000 --> 00:24:33,000
大家对于成本是比较关心的

726
00:24:33,000 --> 00:24:36,000
另外一块是端测那边发热量是一块

727
00:24:36,000 --> 00:24:38,000
就是说你不能用特别好的芯片

728
00:24:38,000 --> 00:24:39,000
特别好芯片

729
00:24:39,000 --> 00:24:40,000
就是说你一直run的话

730
00:24:40,000 --> 00:24:42,000
你的电池撑不住

731
00:24:42,000 --> 00:24:44,000
除非你可以说

732
00:24:44,000 --> 00:24:45,000
我可以插电用

733
00:24:45,000 --> 00:24:46,000
可以

734
00:24:46,000 --> 00:24:47,000
但是反过来讲

735
00:24:47,000 --> 00:24:50,000
你比如说各种语言

736
00:24:50,000 --> 00:24:51,000
什么音箱

737
00:24:51,000 --> 00:24:52,000
智能音箱

738
00:24:52,000 --> 00:24:54,000
智能音箱是插电的

739
00:24:54,000 --> 00:24:56,000
但是你做不了很好的深度学习

740
00:24:56,000 --> 00:24:58,000
是因为你要卖99

741
00:24:58,000 --> 00:24:59,000
你要卖79的话

742
00:24:59,000 --> 00:25:02,000
我的芯片一加起码就几十块钱没了

743
00:25:02,000 --> 00:25:03,000
对吧

744
00:25:03,000 --> 00:25:04,000
成本撑不住

745
00:25:04,000 --> 00:25:07,000
所以这一块都是现在还是会云上路

746
00:25:07,000 --> 00:25:09,000
我觉得这一块

747
00:25:09,000 --> 00:25:12,000
我当时候没想到发展会比我想象慢一点

748
00:25:12,000 --> 00:25:14,000
就硬件迭代确实

749
00:25:14,000 --> 00:25:17,000
买的而且端测

750
00:25:17,000 --> 00:25:19,000
就做A级厂商

751
00:25:19,000 --> 00:25:21,000
大厂对成本还是挺关心的

752
00:25:21,000 --> 00:25:23,000
就是这个东西

753
00:25:23,000 --> 00:25:27,000
如果你没有特别大的用户需求的话

754
00:25:27,000 --> 00:25:30,000
其实他是不愿意花太多钱

755
00:25:30,000 --> 00:25:32,000
太多时间去做这个事情了

756
00:25:32,000 --> 00:25:34,000
因为现在特别5G出来

757
00:25:34,000 --> 00:25:36,000
你整个网络不再是瓶颈的话

758
00:25:36,000 --> 00:25:37,000
我会云也不错

759
00:25:37,000 --> 00:25:40,000
所以这就是为什么有发展

760
00:25:40,000 --> 00:25:43,000
但是我没有我当时候预测那么快

761
00:25:45,000 --> 00:25:46,000
问题26

762
00:25:46,000 --> 00:25:48,000
对高频字符需不需要处理

763
00:25:48,000 --> 00:25:49,000
或者怎么处理

764
00:25:49,000 --> 00:25:52,000
我们这里没有处理高频字符

765
00:25:52,000 --> 00:25:54,000
我们在之后会给大家讲一讲

766
00:25:54,000 --> 00:25:56,000
怎么样处理高频字符

767
00:25:56,000 --> 00:25:57,000
比如说采样

768
00:25:57,000 --> 00:25:59,000
就你对高频字符采样

769
00:26:00,000 --> 00:26:01,000
就每一次的话我采样的时候

770
00:26:01,000 --> 00:26:04,000
我就说你如果你一个根据你的频率采样

771
00:26:04,000 --> 00:26:06,000
就是说如果你的频率特别高

772
00:26:06,000 --> 00:26:09,000
那么我们我就把一些中间一些高频字去掉

773
00:26:09,000 --> 00:26:12,000
我们我在想我们之后会不会讲这个事情

774
00:26:12,000 --> 00:26:13,000
如果我们不讲的话

775
00:26:13,000 --> 00:26:14,000
我给你讲一下

776
00:26:14,000 --> 00:26:16,000
就是说我给到文本出来

777
00:26:16,000 --> 00:26:19,000
我把所有的词的频率算一算

778
00:26:19,000 --> 00:26:21,000
对高频词我把这个概率往下拉一拉

779
00:26:21,000 --> 00:26:24,000
就是说做一个比如说开个根号

780
00:26:24,000 --> 00:26:26,000
或者我把频率开个

781
00:26:26,000 --> 00:26:28,000
把这个就调一调

782
00:26:28,000 --> 00:26:29,000
就把它压低一点

783
00:26:29,000 --> 00:26:30,000
然后再根据

784
00:26:30,000 --> 00:26:31,000
然后根据概率

785
00:26:31,000 --> 00:26:34,000
把中间一些高频词丢掉

786
00:26:34,000 --> 00:26:38,000
这样子我就对高频字符可以做低采样

787
00:26:38,000 --> 00:26:39,000
OK

788
00:26:39,000 --> 00:26:43,000
所以我看看我们还有最后两分钟

789
00:26:43,000 --> 00:26:46,000
我看一下大家的问题

790
00:26:46,000 --> 00:26:51,000
还有智能座舱和车外视觉

791
00:26:52,000 --> 00:26:54,000
其实我两个都不懂

792
00:26:54,000 --> 00:26:55,000
智能座舱是什么意思

793
00:26:55,000 --> 00:26:57,000
车外视觉是什么东西

794
00:26:57,000 --> 00:27:00,000
但我觉得车倒是有意思的一方面

795
00:27:00,000 --> 00:27:02,000
无人车这个东西

796
00:27:02,000 --> 00:27:04,000
就未来的车

797
00:27:07,000 --> 00:27:10,000
我觉得端测的深度学习

798
00:27:10,000 --> 00:27:11,000
未来在端测

799
00:27:11,000 --> 00:27:13,000
主要是在车上面

800
00:27:13,000 --> 00:27:18,000
车是一个非常强劲的智能设备

801
00:27:18,000 --> 00:27:23,000
就是说未来可能我想象中的未来

802
00:27:23,000 --> 00:27:24,000
因为你无人驾驶

803
00:27:24,000 --> 00:27:26,000
车你的计算量得够

804
00:27:26,000 --> 00:27:28,000
所以你的最后你的车里面

805
00:27:28,000 --> 00:27:31,000
可能是它的算力是非常可怕的

806
00:27:31,000 --> 00:27:33,000
就是说我们现在可以做到

807
00:27:33,000 --> 00:27:34,000
把那些可以做专用芯片

808
00:27:34,000 --> 00:27:35,000
做进车里面

809
00:27:35,000 --> 00:27:37,000
所以车可能会等于

810
00:27:37,000 --> 00:27:39,000
等于你现在买10台

811
00:27:39,000 --> 00:27:40,000
10个GPU

812
00:27:40,000 --> 00:27:41,000
可能是这个等级

813
00:27:41,000 --> 00:27:43,000
肯定是在这个之上

814
00:27:43,000 --> 00:27:45,000
所以未来在车上面

815
00:27:45,000 --> 00:27:46,000
因为有那么强的计算量

816
00:27:46,000 --> 00:27:47,000
所以我觉得未来

817
00:27:47,000 --> 00:27:49,000
所谓这些深度学习模型

818
00:27:49,000 --> 00:27:51,000
都可以在车上面跑

819
00:27:51,000 --> 00:27:53,000
而且车可以设为是层面

820
00:27:53,000 --> 00:27:54,000
你家的一个

821
00:27:54,000 --> 00:27:56,000
在国内我还真不知道

822
00:27:56,000 --> 00:27:57,000
在平均大家

823
00:27:57,000 --> 00:28:01,000
如果大家车库跟家里各多元

824
00:28:01,000 --> 00:28:03,000
就是说如果你

825
00:28:03,000 --> 00:28:05,000
如果你家车库有一台

826
00:28:05,000 --> 00:28:08,000
有一台计算很好的车的话

827
00:28:08,000 --> 00:28:10,000
那么你家里所有的那些智能需求

828
00:28:10,000 --> 00:28:11,000
你都可以在车上面做运算

829
00:28:11,000 --> 00:28:13,000
就你家里就不需要买机器了

830
00:28:13,000 --> 00:28:14,000
对吧

831
00:28:14,000 --> 00:28:15,000
你也不要像云游营私问题

832
00:28:15,000 --> 00:28:17,000
你把自己的数据传到云端

833
00:28:17,000 --> 00:28:19,000
你谁知道你们公司会

834
00:28:19,000 --> 00:28:20,000
你会不会乱用你的数据

835
00:28:20,000 --> 00:28:21,000
对吧

836
00:28:21,000 --> 00:28:22,000
想想都可怕

837
00:28:22,000 --> 00:28:23,000
所以我家是没有任何智能设备的

838
00:28:23,000 --> 00:28:25,000
我想想都可怕

839
00:28:25,000 --> 00:28:26,000
因为我讲中文

840
00:28:26,000 --> 00:28:28,000
美国的设备

841
00:28:28,000 --> 00:28:30,000
不讲中文

842
00:28:30,000 --> 00:28:31,000
然后我

843
00:28:31,000 --> 00:28:32,000
中国的设备

844
00:28:32,000 --> 00:28:34,000
我也不知道

845
00:28:34,000 --> 00:28:36,000
会不会保护隐私

846
00:28:36,000 --> 00:28:38,000
所以我觉得在

847
00:28:38,000 --> 00:28:40,000
现在国家不是出台数据

848
00:28:40,000 --> 00:28:41,000
那是法规

849
00:28:41,000 --> 00:28:42,000
就一旦规范之后

850
00:28:42,000 --> 00:28:43,000
这个可能还是好一点

851
00:28:43,000 --> 00:28:44,000
但没规范之前

852
00:28:44,000 --> 00:28:46,000
我是不敢用的

853
00:28:46,000 --> 00:28:47,000
所以但是如果我的东西

854
00:28:47,000 --> 00:28:48,000
可以去车里跑

855
00:28:48,000 --> 00:28:50,000
那我就是放心了

856
00:28:50,000 --> 00:28:51,000
对吧

857
00:28:51,000 --> 00:28:52,000
所有东西可能

858
00:28:52,000 --> 00:28:53,000
我家里甚至机器人

859
00:28:53,000 --> 00:28:55,000
什么东西都可以跟我到我车结合

860
00:28:55,000 --> 00:28:56,000
另外车里面

861
00:28:56,000 --> 00:28:57,000
如果你坐车的话

862
00:28:57,000 --> 00:28:59,000
确实娱乐是一块

863
00:28:59,000 --> 00:29:01,000
娱乐你怎么样VR

864
00:29:01,000 --> 00:29:04,000
这东西都可以在车上走

865
00:29:04,000 --> 00:29:05,000
我觉得

866
00:29:05,000 --> 00:29:07,000
而且车另外一个好处是

867
00:29:07,000 --> 00:29:09,000
车厂现在都挺有钱的

868
00:29:09,000 --> 00:29:12,000
不像那些做中端

869
00:29:12,000 --> 00:29:14,000
中端很多公司都没什么钱

870
00:29:14,000 --> 00:29:16,000
你

871
00:29:16,000 --> 00:29:18,000
就真正做中端芯片的公司

872
00:29:18,000 --> 00:29:19,000
不见得特别有钱

873
00:29:19,000 --> 00:29:21,000
现在做车厂的

874
00:29:21,000 --> 00:29:22,000
钱多一点

875
00:29:22,000 --> 00:29:24,000
因为车贵一些

876
00:29:24,000 --> 00:29:25,000
就你一个人买个手机

877
00:29:25,000 --> 00:29:26,000
一千块钱买个车

878
00:29:26,000 --> 00:29:27,000
要十万块钱

879
00:29:27,000 --> 00:29:28,000
对吧

880
00:29:28,000 --> 00:29:29,000
所以车厂的钱多一些

881
00:29:29,000 --> 00:29:30,000
所以钱多一些的话

882
00:29:30,000 --> 00:29:32,000
他在上面能投的钱会更多

883
00:29:32,000 --> 00:29:33,000
所以我

884
00:29:33,000 --> 00:29:34,000
我以前看

885
00:29:34,000 --> 00:29:36,000
手机那一块

886
00:29:36,000 --> 00:29:38,000
摄像头那一块

887
00:29:38,000 --> 00:29:40,000
但我现在又关注

888
00:29:40,000 --> 00:29:42,000
车上面的智能的那一块

889
00:29:42,000 --> 00:29:45,000
就是说车作为未来的超级计算机

890
00:29:45,000 --> 00:29:47,000
怎么样在上面做

891
00:29:47,000 --> 00:29:49,000
最好的智能算法

892
00:29:49,000 --> 00:29:51,000
这个是我觉得是一个非常有意思的话题

893
00:29:51,000 --> 00:29:52,000
如果你现在选方向的话

894
00:29:52,000 --> 00:29:54,000
不妨关注

895
00:30:01,000 --> 00:30:04,000
你说车内的视觉人物和车外的视觉人物

896
00:30:04,000 --> 00:30:06,000
就是说车内视觉人物

897
00:30:06,000 --> 00:30:07,000
有点像娱乐对吧

898
00:30:07,000 --> 00:30:08,000
就给人做互动

899
00:30:08,000 --> 00:30:10,000
车外就是无人驾驶

900
00:30:10,000 --> 00:30:11,000
对吧

901
00:30:12,000 --> 00:30:14,000
未来我觉得是说

902
00:30:14,000 --> 00:30:16,000
车外就是无人

903
00:30:16,000 --> 00:30:17,000
就是说你关心看你怎么算

904
00:30:17,000 --> 00:30:19,000
就是说我觉得两个都有前提

905
00:30:19,000 --> 00:30:21,000
现在是大家关心的是车外的视觉人物

906
00:30:21,000 --> 00:30:23,000
就是说无人驾驶那一块

907
00:30:23,000 --> 00:30:25,000
但是无人驾驶一旦开始成熟之后

908
00:30:25,000 --> 00:30:26,000
就硬件跟上去了

909
00:30:26,000 --> 00:30:28,000
无人驾驶真的出来之后

910
00:30:28,000 --> 00:30:30,000
大家会越来越关心车内的娱乐

911
00:30:30,000 --> 00:30:32,000
我觉得这个是

912
00:30:32,000 --> 00:30:33,000
可能会同步进行

913
00:30:33,000 --> 00:30:35,000
在这个会比车外

914
00:30:35,000 --> 00:30:38,000
可能被无人驾驶会晚那么一点点

