1
00:00:00,000 --> 00:00:03,000
问题一,这个地方挺好的

2
00:00:03,000 --> 00:00:06,000
就是说图和公式是不是不一致

3
00:00:06,000 --> 00:00:09,000
图的x只和h相关

4
00:00:09,000 --> 00:00:15,000
图里面的x和h以及跟xt也一相关

5
00:00:15,000 --> 00:00:17,000
我觉得你这个问题挺好的

6
00:00:19,000 --> 00:00:20,000
就是说

7
00:00:22,000 --> 00:00:27,000
所以我们图里画的是一个相对来说比较通用一点的情况

8
00:00:27,000 --> 00:00:29,000
所以就是说我们图里面画的

9
00:00:29,000 --> 00:00:33,000
预测当前的x需要当前的前边量h

10
00:00:33,000 --> 00:00:35,000
也需要过去的xt-1

11
00:00:35,000 --> 00:00:38,000
这个是我们图是这么画的

12
00:00:38,000 --> 00:00:43,000
为什么这么画是因为很多模型确实是这么假设的

13
00:00:43,000 --> 00:00:45,000
但我们公式里面确实没这么写

14
00:00:45,000 --> 00:00:47,000
公式里面就写的是

15
00:00:47,000 --> 00:00:51,000
h已经很好的能够track住了所有的过去的信息

16
00:00:51,000 --> 00:00:53,000
所以它x只跟h相关

17
00:00:53,000 --> 00:00:56,000
我觉得这是一个看的挺好的一个点

18
00:00:56,000 --> 00:01:00,000
可能我们下一次我们可能在做slice的时候

19
00:01:00,000 --> 00:01:02,000
稍微可能把这个改掉

20
00:01:02,000 --> 00:01:04,000
就是说不要大家confuse了

21
00:01:07,000 --> 00:01:10,000
前边量是不是直接影响rn的构造

22
00:01:10,000 --> 00:01:14,000
或者rn的引单元也是个前边量单元

23
00:01:17,000 --> 00:01:19,000
就是说我们

24
00:01:21,000 --> 00:01:22,000
你这个问题挺好的

25
00:01:22,000 --> 00:01:25,000
我这个问题我在想是我在这里回答

26
00:01:25,000 --> 00:01:27,000
还是在之后我们讲rn的时候再回答

27
00:01:27,000 --> 00:01:29,000
我们之后讲rn再回答

28
00:01:29,000 --> 00:01:31,000
就是说我们会

29
00:01:31,000 --> 00:01:35,000
就是说rn的隐藏单元和前边量

30
00:01:35,000 --> 00:01:38,000
其实你可以认为隐藏单元

31
00:01:38,000 --> 00:01:40,000
隐藏单元是前边的一种

32
00:01:40,000 --> 00:01:43,000
我们说我们之前有看到hinder variable

33
00:01:43,000 --> 00:01:45,000
就是说隐藏的variable

34
00:01:45,000 --> 00:01:48,000
就是我们在讲MLP的时候

35
00:01:48,000 --> 00:01:50,000
有讲过隐藏层什么层

36
00:01:50,000 --> 00:01:51,000
然后呢

37
00:01:52,000 --> 00:01:54,000
潜变量就是latent的variable

38
00:01:54,000 --> 00:01:56,000
在英语上是latent的hinder

39
00:01:56,000 --> 00:01:57,000
就是说潜变量

40
00:01:57,000 --> 00:01:59,000
你也可以翻译成隐变量

41
00:01:59,000 --> 00:02:01,000
就中文我们前几天刚才讨论这个事情

42
00:02:01,000 --> 00:02:06,000
跟周志华老师几位李航老师在讨论这个问题

43
00:02:06,000 --> 00:02:08,000
就是说在统计上来讲

44
00:02:08,000 --> 00:02:10,000
其实有一点点区别

45
00:02:10,000 --> 00:02:12,000
就是说潜隐变量

46
00:02:12,000 --> 00:02:17,000
一般是说我是一个真实存在的东西

47
00:02:17,000 --> 00:02:19,000
只是我没有被观察到

48
00:02:21,000 --> 00:02:25,000
就是说我的数据采集不够好

49
00:02:25,000 --> 00:02:27,000
实际上它那个东西真实存在

50
00:02:27,000 --> 00:02:30,000
但潜变量包括了隐变量

51
00:02:30,000 --> 00:02:35,000
这个假设和说它可以是真实不存在的东西

52
00:02:35,000 --> 00:02:37,000
你根本就观察不到

53
00:02:37,000 --> 00:02:40,000
hinder就是表示没看到

54
00:02:40,000 --> 00:02:42,000
但实际它藏在那个地方

55
00:02:42,000 --> 00:02:48,000
latent就表示说它既然包括了hinder这个概念

56
00:02:48,000 --> 00:02:50,000
又包括了说这个东西真的不存在

57
00:02:50,000 --> 00:02:53,000
比如说latent variable一个著名的模型

58
00:02:53,000 --> 00:02:55,000
就是LDA或者就是剧类

59
00:02:55,000 --> 00:02:57,000
就是说一个数据的类别

60
00:02:57,000 --> 00:03:01,000
这个数据是类别是一个人造的概念

61
00:03:01,000 --> 00:03:04,000
没有现实生活中可能没有类别的东西

62
00:03:04,000 --> 00:03:06,000
就是说我说猫猫狗狗是一类

63
00:03:06,000 --> 00:03:09,000
这个东西这个类别我随便你给你怎么做

64
00:03:09,000 --> 00:03:12,000
这个东西观察不一定是能可能

65
00:03:12,000 --> 00:03:14,000
就是人为的加进去的东西

66
00:03:14,000 --> 00:03:17,000
所以类别信息就是说剧类的类信息

67
00:03:17,000 --> 00:03:19,000
也可以是一个latent variable

68
00:03:19,000 --> 00:03:21,000
但是你不能把它叫做hinder variable

69
00:03:21,000 --> 00:03:24,000
因为它不是它现实生活就不存在

70
00:03:24,000 --> 00:03:27,000
你怎么样你改进你的sensor

71
00:03:27,000 --> 00:03:29,000
你也观察不到它

72
00:03:29,000 --> 00:03:32,000
所以就是说我们具体跟RNN的隐藏单元

73
00:03:32,000 --> 00:03:34,000
我们之后再来讲

74
00:03:35,000 --> 00:03:38,000
在常规中是不是越大越好

75
00:03:38,000 --> 00:03:40,000
刚刚的total是不是比4好

76
00:03:40,000 --> 00:03:43,000
当然是比4好了

77
00:03:43,000 --> 00:03:45,000
就是说

78
00:03:46,000 --> 00:03:48,000
当然你说我

79
00:03:48,000 --> 00:03:50,000
以Markov假设

80
00:03:50,000 --> 00:03:54,000
我当然是说我说我能观察到更长的数据更好

81
00:03:54,000 --> 00:03:57,000
但是你要知道说这里有局限性

82
00:03:57,000 --> 00:03:58,000
就是你要权衡

83
00:03:58,000 --> 00:04:01,000
就是说如果你的total设的特别大

84
00:04:01,000 --> 00:04:03,000
那你的训练样本就没了

85
00:04:03,000 --> 00:04:06,000
假设你的total设成跟你的训练数据一样长的话

86
00:04:06,000 --> 00:04:08,000
那么就一个样本

87
00:04:08,000 --> 00:04:11,000
你就一个样本怎么训练

88
00:04:11,000 --> 00:04:15,000
第二个是说你total变得很大的时候

89
00:04:15,000 --> 00:04:17,000
你的计算量会大一些

90
00:04:17,000 --> 00:04:19,000
就是说你total变大

91
00:04:19,000 --> 00:04:20,000
你的样本个数变少

92
00:04:20,000 --> 00:04:21,000
然后你total变大

93
00:04:21,000 --> 00:04:23,000
然后你的模型得更强

94
00:04:23,000 --> 00:04:24,000
对吧

95
00:04:24,000 --> 00:04:25,000
你的模型要是fit那么长的一个序列

96
00:04:25,000 --> 00:04:27,000
就是你的数位度增加了

97
00:04:27,000 --> 00:04:28,000
那么你的模型变复杂

98
00:04:28,000 --> 00:04:29,000
你数据变少了

99
00:04:29,000 --> 00:04:30,000
模型变复杂了

100
00:04:30,000 --> 00:04:31,000
那就更麻烦

101
00:04:31,000 --> 00:04:34,000
所以total不是最越大越好

102
00:04:34,000 --> 00:04:35,000
total也不能太小

103
00:04:35,000 --> 00:04:36,000
也不能太大

104
00:04:36,000 --> 00:04:38,000
它是有一个权衡的

105
00:04:39,000 --> 00:04:44,000
浅变量和Emark复模型有什么区别吗

106
00:04:44,000 --> 00:04:49,000
就是说他们之间是没有太多联系的

107
00:04:49,000 --> 00:04:51,000
就是说两个不一样的观点

108
00:04:51,000 --> 00:04:52,000
但是他们可以相互借鉴

109
00:04:52,000 --> 00:04:57,000
就是说浅变量模型是可以使用Emark复假设的

110
00:04:58,000 --> 00:04:59,000
OK

111
00:04:59,000 --> 00:05:04,000
就是说我们之后的RN其实都是用了Emark复假设

112
00:05:05,000 --> 00:05:06,000
就是说浅变量

113
00:05:06,000 --> 00:05:08,000
浅变量就是说我们怎么去更新它的时候

114
00:05:08,000 --> 00:05:09,000
可以用Emark复假设

115
00:05:10,000 --> 00:05:14,000
Emark复只是说你这个数据跟之前多少个数据相关

116
00:05:14,000 --> 00:05:17,000
但浅变量模型更多是说建模的时候

117
00:05:18,000 --> 00:05:19,000
我怎么样对它建模

118
00:05:19,000 --> 00:05:21,000
所以这两个是有一点的不一样

119
00:05:23,000 --> 00:05:24,000
问题五

120
00:05:24,000 --> 00:05:26,000
若预测一个月total等于30

121
00:05:26,000 --> 00:05:29,000
若预测7天total等于7

122
00:05:29,000 --> 00:05:30,000
是不是有这种关系

123
00:05:30,000 --> 00:05:31,000
还是有别的约定

124
00:05:31,000 --> 00:05:33,000
没有太多约定

125
00:05:33,000 --> 00:05:35,000
就是说还是一样

126
00:05:35,000 --> 00:05:38,000
我们之前这个total怎么取

127
00:05:38,000 --> 00:05:41,000
真的取决于你的对你的数据的理解

128
00:05:41,000 --> 00:05:43,000
就是说你total不能太小

129
00:05:43,000 --> 00:05:45,000
你说我要预测未来7天

130
00:05:45,000 --> 00:05:47,000
你如果total等于一二

131
00:05:47,000 --> 00:05:48,000
那就比较悬

132
00:05:48,000 --> 00:05:49,000
对吧

133
00:05:49,000 --> 00:05:51,000
就是total你觉得多多少少

134
00:05:51,000 --> 00:05:55,000
你可能要比预测的点数要多一点

135
00:05:55,000 --> 00:05:56,000
可能是有这个

136
00:05:56,000 --> 00:05:57,000
你这么假设是没错的

137
00:05:58,000 --> 00:05:59,000
所以total就是说

138
00:05:59,000 --> 00:06:03,000
你要取一个你觉得比较足够

139
00:06:03,000 --> 00:06:06,000
用来预测你想要的未来的一个值

140
00:06:06,000 --> 00:06:08,000
但是你也不能取太大

141
00:06:08,000 --> 00:06:09,000
就使得你模型太复杂

142
00:06:09,000 --> 00:06:11,000
或者说你数据要么变少

143
00:06:11,000 --> 00:06:12,000
OK

144
00:06:12,000 --> 00:06:13,000
所以现实生活中

145
00:06:13,000 --> 00:06:14,000
怎么取total这个东西

146
00:06:14,000 --> 00:06:16,000
其实是比较tricky的

147
00:06:16,000 --> 00:06:19,000
所以你可以看到

148
00:06:19,000 --> 00:06:21,000
接下来我们有很多

149
00:06:21,000 --> 00:06:24,000
我们的RN和transformer这种模型

150
00:06:24,000 --> 00:06:25,000
就是说尽量是说

151
00:06:25,000 --> 00:06:26,000
让你不要去想这个事情

152
00:06:26,000 --> 00:06:28,000
就尽量有一个比较soft的格式

153
00:06:28,000 --> 00:06:29,000
方法

154
00:06:29,000 --> 00:06:30,000
就是说让我去

155
00:06:30,000 --> 00:06:32,000
自己去找我想要的东西

156
00:06:32,000 --> 00:06:33,000
另外一块就是说

157
00:06:33,000 --> 00:06:34,000
我们也很多kernel

158
00:06:34,000 --> 00:06:35,000
就是说核方法

159
00:06:35,000 --> 00:06:37,000
就是说smooth的方法

160
00:06:37,000 --> 00:06:40,000
就是说我是给你一个weight decay

161
00:06:40,000 --> 00:06:41,000
就是说我给你一个

162
00:06:41,000 --> 00:06:43,000
每个数据给一个权重

163
00:06:43,000 --> 00:06:46,000
就是说跟我近的权重会大一点

164
00:06:46,000 --> 00:06:50,000
跟我很远的权重就会衰减到快没了

165
00:06:50,000 --> 00:06:52,000
所以就直观上来说

166
00:06:52,000 --> 00:06:55,000
是一个比较平滑的时间窗

167
00:06:58,000 --> 00:07:00,000
问题六图上看这里

168
00:07:00,000 --> 00:07:03,000
当前环境的影响只能从过去来吗

169
00:07:03,000 --> 00:07:05,000
还是可以加一个当前因素

170
00:07:07,000 --> 00:07:09,000
对对就是说你可以说

171
00:07:09,000 --> 00:07:13,000
我当前观察观察观察到的xt

172
00:07:13,000 --> 00:07:16,000
就跟当前的是有关系

173
00:07:16,000 --> 00:07:18,000
就是我们只是没这么写而已

174
00:07:18,000 --> 00:07:21,000
我们就是说

175
00:07:21,000 --> 00:07:22,000
就是说你当然可以说

176
00:07:22,000 --> 00:07:24,000
我有一个还有一个

177
00:07:24,000 --> 00:07:25,000
就是我们的前面的模型

178
00:07:25,000 --> 00:07:26,000
多多少少

179
00:07:26,000 --> 00:07:28,000
你会认为是有这样子的一个东西

180
00:07:28,000 --> 00:07:29,000
就是说你当前的x

181
00:07:29,000 --> 00:07:31,000
不仅是跟过去相关

182
00:07:31,000 --> 00:07:33,000
还有根据当前的

183
00:07:33,000 --> 00:07:35,000
潜变量的状态相关

184
00:07:35,000 --> 00:07:37,000
就h你这个东西

185
00:07:37,000 --> 00:07:40,000
ht既可以包含说我过去的历史信息

186
00:07:40,000 --> 00:07:41,000
我也可以去说去预测

187
00:07:41,000 --> 00:07:42,000
根据那个历史信息

188
00:07:42,000 --> 00:07:44,000
它的背后的东西的变化

189
00:07:44,000 --> 00:07:45,000
这是可以的

190
00:07:45,000 --> 00:07:47,000
就是说当然你这个模型

191
00:07:47,000 --> 00:07:49,000
我们可以加更多的信息进去

192
00:07:49,000 --> 00:07:52,000
当然就最简单的这一块

193
00:07:52,000 --> 00:07:54,000
我们也我觉得统计上

194
00:07:54,000 --> 00:07:55,000
这一块是比较重要

195
00:07:55,000 --> 00:07:57,000
叫做cosality

196
00:07:57,000 --> 00:07:59,000
cosality的中文怎么翻

197
00:07:59,000 --> 00:08:04,000
就是cosality中文怎么翻

198
00:08:04,000 --> 00:08:06,000
anyway就是cosality的东西干嘛呢

199
00:08:06,000 --> 00:08:09,000
就是说去看每一个随机变量

200
00:08:09,000 --> 00:08:11,000
之间是怎么样相互影响的

201
00:08:11,000 --> 00:08:14,000
就是说你所观察的一个事情

202
00:08:14,000 --> 00:08:16,000
这个东西到底是被谁影响的

203
00:08:16,000 --> 00:08:18,000
所以它也是个时序的

204
00:08:18,000 --> 00:08:19,000
但是它会去看说

205
00:08:19,000 --> 00:08:21,000
到底是你有多少个因素

206
00:08:21,000 --> 00:08:23,000
你的所有的环境因素是谁

207
00:08:23,000 --> 00:08:25,000
谁引起了谁

208
00:08:25,000 --> 00:08:26,000
这个东西是做这个分析

209
00:08:26,000 --> 00:08:28,000
我觉得这一块

210
00:08:28,000 --> 00:08:31,000
在最近在整个机学界

211
00:08:31,000 --> 00:08:32,000
统计界

212
00:08:32,000 --> 00:08:34,000
机学界都非常的

213
00:08:34,000 --> 00:08:37,000
还是挺火的一个套路

214
00:08:42,000 --> 00:08:44,000
就这里有个小八卦是说

215
00:08:44,000 --> 00:08:50,000
我们不是说想秋天去斯坦开门课

216
00:08:50,000 --> 00:08:52,000
然后我们就打算讲

217
00:08:52,000 --> 00:08:53,000
我们还没定

218
00:08:53,000 --> 00:08:54,000
我们还在讨论

219
00:08:54,000 --> 00:08:55,000
就是说要不要开这个事情

220
00:08:55,000 --> 00:09:00,000
我们在去斯坦福跟老师见见面

221
00:09:00,000 --> 00:09:01,000
然后聊一聊这个东西

222
00:09:01,000 --> 00:09:04,000
我们碰到了Robert Tepesrani

223
00:09:04,000 --> 00:09:06,000
就是统计界大神

224
00:09:06,000 --> 00:09:10,000
写的统计机学习那本书的大神

225
00:09:10,000 --> 00:09:12,000
跟他吃饭

226
00:09:12,000 --> 00:09:13,000
他就说

227
00:09:13,000 --> 00:09:14,000
他说看了一下你的课表

228
00:09:14,000 --> 00:09:15,000
他觉得说

229
00:09:15,000 --> 00:09:18,000
我们当时打算是讲两节课的cosality

230
00:09:18,000 --> 00:09:20,000
可能一节课或者两节课

231
00:09:20,000 --> 00:09:21,000
因为斯坦福的课很少

232
00:09:21,000 --> 00:09:23,000
就量20课时

233
00:09:23,000 --> 00:09:24,000
我们这个课已经讲了20

234
00:09:24,000 --> 00:09:25,000
今天是26天了

235
00:09:25,000 --> 00:09:26,000
就是说我们这个课

236
00:09:26,000 --> 00:09:28,000
已经比斯坦福课要长多了

237
00:09:28,000 --> 00:09:30,000
我们未来还有可能有15天

238
00:09:30,000 --> 00:09:31,000
斯坦福一共就20天

239
00:09:31,000 --> 00:09:34,000
然后其中去掉考试

240
00:09:34,000 --> 00:09:35,000
项目presentation

241
00:09:35,000 --> 00:09:38,000
你大概能够讲个十几天

242
00:09:38,000 --> 00:09:40,000
18天或15天的样子

243
00:09:40,000 --> 00:09:42,000
所以我们在想

244
00:09:42,000 --> 00:09:44,000
我们本来是预测讲一天的cosality

245
00:09:44,000 --> 00:09:48,000
Tepesrani大神说

246
00:09:48,000 --> 00:09:49,000
你这个不行

247
00:09:49,000 --> 00:09:50,000
得多讲一点

248
00:09:50,000 --> 00:09:52,000
因为他是统计大佬

249
00:09:52,000 --> 00:09:54,000
他说这个东西太重要了

250
00:09:54,000 --> 00:09:55,000
你应该多讲一点

251
00:09:55,000 --> 00:09:56,000
OK

252
00:09:56,000 --> 00:09:58,000
但那个东西

253
00:09:58,000 --> 00:10:01,000
现在也是在学术界是比较火

254
00:10:01,000 --> 00:10:05,000
但是还是在早期阶段也是比较难

255
00:10:05,000 --> 00:10:06,000
好

256
00:10:06,000 --> 00:10:07,000
问题七

257
00:10:07,000 --> 00:10:09,000
在预测未来方面

258
00:10:09,000 --> 00:10:11,000
现在SOTA模型做的多好

259
00:10:11,000 --> 00:10:15,000
看你说怎么未来吧

260
00:10:15,000 --> 00:10:18,000
现在比如说GPT-3

261
00:10:18,000 --> 00:10:20,000
GPT-3让你写文章

262
00:10:20,000 --> 00:10:22,000
写的有模有样的

263
00:10:22,000 --> 00:10:24,000
就是说给你

264
00:10:24,000 --> 00:10:26,000
框框可以写一个很长的文章出来

265
00:10:26,000 --> 00:10:27,000
就是说写文章是预测未来

266
00:10:27,000 --> 00:10:28,000
对吧

267
00:10:28,000 --> 00:10:29,000
我给你一句话

268
00:10:29,000 --> 00:10:31,000
然后你框框把后面给我写出来

269
00:10:31,000 --> 00:10:33,000
GPT-3写的很不错

270
00:10:33,000 --> 00:10:35,000
最近上线了GitHub上面

271
00:10:35,000 --> 00:10:36,000
帮你写代码

272
00:10:36,000 --> 00:10:37,000
对吧

273
00:10:37,000 --> 00:10:38,000
它也是预测未来

274
00:10:38,000 --> 00:10:39,000
就是说我说写个comment

275
00:10:39,000 --> 00:10:41,000
说我要实现一个这样子函数

276
00:10:41,000 --> 00:10:42,000
你把我的函数写出来

277
00:10:42,000 --> 00:10:44,000
也写的有模有样的

278
00:10:44,000 --> 00:10:45,000
对吧

279
00:10:45,000 --> 00:10:46,000
所以在一些地方

280
00:10:46,000 --> 00:10:47,000
预测的还挺准的

281
00:10:47,000 --> 00:10:49,000
但一些地方预测不小

282
00:10:49,000 --> 00:10:50,000
股票预测

283
00:10:50,000 --> 00:10:51,000
我们至今没有看到

284
00:10:51,000 --> 00:10:53,000
特别好的股票预测算法

285
00:10:53,000 --> 00:10:54,000
如果有的话

286
00:10:54,000 --> 00:10:56,000
估计也不会发出来

287
00:10:56,000 --> 00:10:57,000
如果我有一个

288
00:10:57,000 --> 00:10:58,000
很好的股票预测算法

289
00:10:58,000 --> 00:10:59,000
我也不会出来讲

290
00:10:59,000 --> 00:11:00,000
对吧

291
00:11:00,000 --> 00:11:02,000
我就用它赚钱就了不得了

292
00:11:02,000 --> 00:11:04,000
我先赚了钱

293
00:11:04,000 --> 00:11:05,000
我再出来讲

294
00:11:05,000 --> 00:11:06,000
对吧

295
00:11:06,000 --> 00:11:09,000
所以现在我们没看到

296
00:11:09,000 --> 00:11:10,000
特别好的股票预测算法

297
00:11:10,000 --> 00:11:11,000
可能是一

298
00:11:11,000 --> 00:11:12,000
可能有

299
00:11:12,000 --> 00:11:13,000
但是没有公开

300
00:11:13,000 --> 00:11:15,000
二可能确实很难

301
00:11:16,000 --> 00:11:17,000
问题八

302
00:11:17,000 --> 00:11:18,000
可不可以认为

303
00:11:18,000 --> 00:11:20,000
MLP记住了过去的数据的模式

304
00:11:20,000 --> 00:11:22,000
然后又在模式续测未来

305
00:11:22,000 --> 00:11:23,000
可以

306
00:11:23,000 --> 00:11:24,000
就是说

307
00:11:24,000 --> 00:11:26,000
MLP是当然可以记住过去

308
00:11:26,000 --> 00:11:28,000
就是MLP可以把你所有的噪点

309
00:11:28,000 --> 00:11:29,000
给你记住

310
00:11:29,000 --> 00:11:30,000
当然是没有问题的

311
00:11:30,000 --> 00:11:31,000
但是我们没有把它

312
00:11:31,000 --> 00:11:32,000
Loss去到零

313
00:11:32,000 --> 00:11:35,000
所以你无法说它记住了过去

314
00:11:35,000 --> 00:11:36,000
最简单

315
00:11:36,000 --> 00:11:37,000
我们有一个

316
00:11:37,000 --> 00:11:39,000
我们这个课不讲

317
00:11:39,000 --> 00:11:40,000
但是

318
00:11:40,000 --> 00:11:42,000
就RNN刚出来的时候

319
00:11:42,000 --> 00:11:44,000
就是说我们可以用RNN来排序

320
00:11:45,000 --> 00:11:46,000
什么叫排序

321
00:11:46,000 --> 00:11:47,000
就是说

322
00:11:47,000 --> 00:11:49,000
我都给你一个序列

323
00:11:49,000 --> 00:11:50,000
用快排

324
00:11:50,000 --> 00:11:52,000
就是说我可以从大排到小

325
00:11:52,000 --> 00:11:53,000
然后

326
00:11:53,000 --> 00:11:54,000
当然这个算法很简单

327
00:11:54,000 --> 00:11:56,000
计算机大概都会实现

328
00:11:56,000 --> 00:11:57,000
对吧

329
00:11:57,000 --> 00:11:58,000
最简单的冒泡排

330
00:11:58,000 --> 00:11:59,000
你不会快排

331
00:11:59,000 --> 00:12:00,000
你会冒泡排

332
00:12:00,000 --> 00:12:02,000
然后你可以用RNN

333
00:12:02,000 --> 00:12:04,000
RNN的话说给你一个乱序的序列

334
00:12:04,000 --> 00:12:05,000
然后给是作为输入

335
00:12:05,000 --> 00:12:06,000
然后你的输出

336
00:12:06,000 --> 00:12:08,000
就是你的排好的序列

337
00:12:08,000 --> 00:12:10,000
然后你RNN去做的事情

338
00:12:10,000 --> 00:12:12,000
他也能做

339
00:12:12,000 --> 00:12:14,000
就是他就把你尽量的东西

340
00:12:14,000 --> 00:12:15,000
把你记起来

341
00:12:15,000 --> 00:12:17,000
就RNN强大的RNN是能够记住掉

342
00:12:17,000 --> 00:12:19,000
所有的序列

343
00:12:19,000 --> 00:12:21,000
就是MLP也可以记住

344
00:12:21,000 --> 00:12:22,000
所有的序列

345
00:12:22,000 --> 00:12:24,000
就MLP记起来成本大一点

346
00:12:24,000 --> 00:12:26,000
RNN记起来成本小一点

347
00:12:26,000 --> 00:12:27,000
是可以这样子

348
00:12:27,000 --> 00:12:29,000
但是这个记住所有的序列

349
00:12:29,000 --> 00:12:30,000
不见得是一件很好的事情

350
00:12:30,000 --> 00:12:31,000
就是说

351
00:12:31,000 --> 00:12:32,000
如果你只是记住的话

352
00:12:32,000 --> 00:12:33,000
你没有泛滑性

353
00:12:33,000 --> 00:12:35,000
你看到真实的数据就很难做

354
00:12:35,000 --> 00:12:36,000
而且你

355
00:12:36,000 --> 00:12:37,000
就像你记住的话

356
00:12:37,000 --> 00:12:39,000
我用你训练模型干嘛

357
00:12:39,000 --> 00:12:40,000
我就把你记住就行了

358
00:12:40,000 --> 00:12:42,000
就每一个来一个新序列

359
00:12:42,000 --> 00:12:44,000
我就去匹配过去的序列

360
00:12:44,000 --> 00:12:45,000
匹配序列是一个很简单的事情

361
00:12:45,000 --> 00:12:46,000
ON算复杂度

362
00:12:46,000 --> 00:12:48,000
就扫一遍就完事了

363
00:12:48,000 --> 00:12:50,000
而且你可以用大量的

364
00:12:50,000 --> 00:12:51,000
大量的这种

365
00:12:51,000 --> 00:12:53,000
Soccer那边的bucketing

366
00:12:53,000 --> 00:12:54,000
这种操作

367
00:12:54,000 --> 00:12:56,000
让你复杂度很低

368
00:12:56,000 --> 00:13:00,000
所以只是为了记住序列的MLP

369
00:13:00,000 --> 00:13:01,000
或者RNN是没用的

370
00:13:01,000 --> 00:13:03,000
但他可以记住是真的

371
00:13:05,000 --> 00:13:06,000
问题九

372
00:13:06,000 --> 00:13:08,000
输入特征和输出的关系

373
00:13:09,000 --> 00:13:10,000
是怎么去订入的

374
00:13:10,000 --> 00:13:11,000
输入的是

375
00:13:12,000 --> 00:13:13,000
对

376
00:13:14,000 --> 00:13:15,000
对

377
00:13:15,000 --> 00:13:16,000
就这个问题是说

378
00:13:16,000 --> 00:13:17,000
我们这个数据怎么构造的

379
00:13:17,000 --> 00:13:18,000
我们这数据构造

380
00:13:18,000 --> 00:13:19,000
就是说

381
00:13:19,000 --> 00:13:20,000
给定

382
00:13:21,000 --> 00:13:22,000
我在我一个序列

383
00:13:22,000 --> 00:13:23,000
对吧

384
00:13:23,000 --> 00:13:24,000
我有个序列

385
00:13:24,000 --> 00:13:25,000
这个东西在之后

386
00:13:25,000 --> 00:13:26,000
我们会一直看到

387
00:13:26,000 --> 00:13:28,000
所以我们再讲一遍

388
00:13:28,000 --> 00:13:29,000
给一个序列

389
00:13:30,000 --> 00:13:32,000
每一次我在中间

390
00:13:33,000 --> 00:13:36,000
抽出连续的Tog数据点

391
00:13:37,000 --> 00:13:38,000
做一个样本

392
00:13:38,000 --> 00:13:40,000
他的Label是预测

393
00:13:41,000 --> 00:13:43,000
Tog数据点和下一个数据点

394
00:13:45,000 --> 00:13:46,000
OK

395
00:13:46,000 --> 00:13:47,000
所以这就是

396
00:13:47,000 --> 00:13:50,000
你的特征和你的Label的关系

397
00:13:51,000 --> 00:13:52,000
所以就说特征就是

398
00:13:53,000 --> 00:13:54,000
常为Tog的一个序列

399
00:13:54,000 --> 00:13:56,000
那Label就这个序列后面那一个点

400
00:13:57,000 --> 00:13:58,000
OK

401
00:13:58,000 --> 00:14:00,000
这就是预测下一个未来

402
00:14:01,000 --> 00:14:03,000
这就是我们是这么构造的

403
00:14:03,000 --> 00:14:04,000
我们之后的语言模型

404
00:14:04,000 --> 00:14:05,000
也是这么构造的

405
00:14:05,000 --> 00:14:06,000
我们基本上

406
00:14:07,000 --> 00:14:09,000
基本上给这LP多多少少

407
00:14:09,000 --> 00:14:10,000
都是这么构造的

408
00:14:11,000 --> 00:14:12,000
OK

409
00:14:12,000 --> 00:14:13,000
这是一个

410
00:14:13,000 --> 00:14:14,000
这是一个怎么样

411
00:14:14,000 --> 00:14:16,000
持续序列来构造一个

412
00:14:16,000 --> 00:14:19,000
可以训练的特征和标号的关系

413
00:14:21,000 --> 00:14:22,000
问题十

414
00:14:22,000 --> 00:14:24,000
Tog能随着XT变化而变化吗

415
00:14:24,000 --> 00:14:26,000
这样更符合实际情况

416
00:14:26,000 --> 00:14:28,000
比如说XT与前五个变相关

417
00:14:32,000 --> 00:14:33,000
对

418
00:14:33,000 --> 00:14:34,000
就是说你

419
00:14:34,000 --> 00:14:35,000
你当然可以这么做

420
00:14:35,000 --> 00:14:37,000
就是说你可以固定Tog

421
00:14:37,000 --> 00:14:38,000
Tog就是无限长

422
00:14:38,000 --> 00:14:40,000
就是说你不用以Markov假设

423
00:14:40,000 --> 00:14:42,000
你说我可以说你XT

424
00:14:42,000 --> 00:14:44,000
就是跟前面的所有相关

425
00:14:44,000 --> 00:14:46,000
就是说或者你可以选择

426
00:14:46,000 --> 00:14:47,000
任何的格式都行

427
00:14:48,000 --> 00:14:49,000
但东西你不好算

428
00:14:49,000 --> 00:14:51,000
就是说你为什么觉得

429
00:14:52,000 --> 00:14:53,000
他应该跟

430
00:14:54,000 --> 00:14:55,000
XT变化而变化

431
00:14:55,000 --> 00:14:57,000
就是说你就像看我们刚刚

432
00:14:57,000 --> 00:14:58,000
那个Sign函数

433
00:14:59,000 --> 00:15:01,000
Sign函数你不需要去特别长

434
00:15:01,000 --> 00:15:03,000
就是说你根本不需要

435
00:15:03,000 --> 00:15:05,000
记住整个Sign函数的曲线

436
00:15:05,000 --> 00:15:07,000
你就记住局部一块

437
00:15:07,000 --> 00:15:09,000
曲线怎么变化就行了

438
00:15:09,000 --> 00:15:10,000
因为我们给你的训练是一个

439
00:15:10,000 --> 00:15:12,000
完整一个Sign的周期

440
00:15:12,000 --> 00:15:13,000
说白了

441
00:15:13,000 --> 00:15:15,000
所以你不需要记住完整周期

442
00:15:15,000 --> 00:15:16,000
你只要知道局部

443
00:15:16,000 --> 00:15:18,000
大概曲线什么样子

444
00:15:18,000 --> 00:15:19,000
下层的局部曲线

445
00:15:19,000 --> 00:15:20,000
大概是你能预测的

446
00:15:21,000 --> 00:15:23,000
所以另外我们可以看到

447
00:15:23,000 --> 00:15:26,000
就是说之后我们会讲很多模型

448
00:15:26,000 --> 00:15:27,000
让你更智能一点

449
00:15:27,000 --> 00:15:28,000
就不要选Tog

450
00:15:28,000 --> 00:15:29,000
让你自动去看

451
00:15:29,000 --> 00:15:30,000
说到底跟谁相关

452
00:15:30,000 --> 00:15:31,000
比如说Transformer

453
00:15:31,000 --> 00:15:32,000
就自动去看

454
00:15:32,000 --> 00:15:35,000
说你到底是跟之前哪些数据相关

455
00:15:38,000 --> 00:15:39,000
问题11

456
00:15:39,000 --> 00:15:42,000
发动机或者电动车电池

457
00:15:42,000 --> 00:15:44,000
上有很多参数传感器

458
00:15:44,000 --> 00:15:45,000
在预测这些参数

459
00:15:45,000 --> 00:15:47,000
为了变化需要采取Markov

460
00:15:47,000 --> 00:15:48,000
假设要单步预测也可以

461
00:15:48,000 --> 00:15:51,000
但长步预测结果极差

462
00:15:51,000 --> 00:15:54,000
请问有很好的其他解决方案吗

463
00:15:55,000 --> 00:15:56,000
嗯

464
00:16:00,000 --> 00:16:02,000
这个你问到的是一个

465
00:16:02,000 --> 00:16:03,000
一大类问题

466
00:16:03,000 --> 00:16:04,000
这个叫做Maintenance

467
00:16:04,000 --> 00:16:06,000
Maintenance

468
00:16:06,000 --> 00:16:09,000
这个中文怎么翻

469
00:16:09,000 --> 00:16:10,000
Maintenance

470
00:16:10,000 --> 00:16:11,000
维护吧

471
00:16:11,000 --> 00:16:12,000
就维护这一块

472
00:16:12,000 --> 00:16:13,000
就包括了比如说

473
00:16:14,000 --> 00:16:15,000
最早用在哪里呢

474
00:16:15,000 --> 00:16:18,000
最早用的是波音的飞机上面

475
00:16:18,000 --> 00:16:19,000
就是说火箭上面

476
00:16:19,000 --> 00:16:22,000
就是说你说飞机上那么多传感数

477
00:16:22,000 --> 00:16:24,000
它去预测一个

478
00:16:24,000 --> 00:16:26,000
每个传感数就看一下东西

479
00:16:26,000 --> 00:16:27,000
看一个东西去监测一个东西

480
00:16:27,000 --> 00:16:29,000
它得去预测说

481
00:16:29,000 --> 00:16:31,000
你这个东西会不会出问题

482
00:16:31,000 --> 00:16:32,000
对吧

483
00:16:32,000 --> 00:16:33,000
所以就是说

484
00:16:33,000 --> 00:16:35,000
最早最早是波音那边

485
00:16:35,000 --> 00:16:36,000
我记得很早很早

486
00:16:36,000 --> 00:16:37,000
以前我当时在CMU的时候

487
00:16:37,000 --> 00:16:39,000
波音资助了很多

488
00:16:39,000 --> 00:16:40,000
我们当时实验室的

489
00:16:40,000 --> 00:16:41,000
不是我们实验室

490
00:16:41,000 --> 00:16:42,000
隔壁实验室的很多

491
00:16:42,000 --> 00:16:44,000
这样子的一个科研研究

492
00:16:44,000 --> 00:16:46,000
就是说它有上千个传感器

493
00:16:46,000 --> 00:16:47,000
怎么样去预测

494
00:16:47,000 --> 00:16:49,000
传感器之间是有相互关联的

495
00:16:49,000 --> 00:16:50,000
怎么去预测说

496
00:16:50,000 --> 00:16:51,000
未来哪个

497
00:16:51,000 --> 00:16:53,000
要么传感器可能会出错

498
00:16:53,000 --> 00:16:54,000
要么就是

499
00:16:55,000 --> 00:16:56,000
你真的出错了

500
00:16:57,000 --> 00:16:59,000
但现在就是说

501
00:16:59,000 --> 00:17:02,000
我记得两年前碰到

502
00:17:04,000 --> 00:17:05,000
碰到很多

503
00:17:05,000 --> 00:17:09,000
当时是富士康的老大

504
00:17:09,000 --> 00:17:10,000
就他问了一个说

505
00:17:10,000 --> 00:17:12,000
我们能不能做电子尺来预测

506
00:17:12,000 --> 00:17:14,000
因为前阵子两年前

507
00:17:14,000 --> 00:17:16,000
我觉得三星电池炸过对吧

508
00:17:16,000 --> 00:17:18,000
所以说电池你要有个传感器

509
00:17:18,000 --> 00:17:20,000
预测说电池要不要爆炸

510
00:17:20,000 --> 00:17:21,000
爆炸了

511
00:17:21,000 --> 00:17:22,000
赶紧关机或者怎么样

512
00:17:22,000 --> 00:17:23,000
然后说

513
00:17:25,000 --> 00:17:26,000
然后

514
00:17:26,000 --> 00:17:28,000
所以这一块

515
00:17:28,000 --> 00:17:30,000
就是说你运测硬盘什么时候出错

516
00:17:30,000 --> 00:17:32,000
然后车上面传感器

517
00:17:32,000 --> 00:17:33,000
怎么样

518
00:17:33,000 --> 00:17:35,000
然后电池怎么样

519
00:17:36,000 --> 00:17:37,000
就是说这个东西

520
00:17:37,000 --> 00:17:41,000
其实你可以认为

521
00:17:42,000 --> 00:17:44,000
你做单步预测

522
00:17:44,000 --> 00:17:46,000
就是说你可能想知道

523
00:17:46,000 --> 00:17:47,000
是说我一个东西

524
00:17:47,000 --> 00:17:49,000
大概是

525
00:17:50,000 --> 00:17:52,000
你不是说下一个时间不晚

526
00:17:52,000 --> 00:17:53,000
你可能说明天或者说

527
00:17:53,000 --> 00:17:54,000
今天会不会有问题

528
00:17:54,000 --> 00:17:55,000
或几个小时后

529
00:17:55,000 --> 00:17:56,000
或怎么样子

530
00:17:56,000 --> 00:17:57,000
我觉得最简单的

531
00:17:57,000 --> 00:17:58,000
其实还是说

532
00:18:02,000 --> 00:18:03,000
你得采集很多数据

533
00:18:05,000 --> 00:18:07,000
我觉得这个东西持续到

534
00:18:07,000 --> 00:18:08,000
所以真话

535
00:18:09,000 --> 00:18:11,000
不那么的关键

536
00:18:11,000 --> 00:18:13,000
就是说它不是那么的一个

537
00:18:13,000 --> 00:18:14,000
持续的一个东西

538
00:18:14,000 --> 00:18:16,000
就是说它这里面最难的地方

539
00:18:16,000 --> 00:18:18,000
我觉得最难的地方是说

540
00:18:18,000 --> 00:18:21,000
你采集不到很多的负类要门

541
00:18:21,000 --> 00:18:23,000
就是假设你正类是没问题

542
00:18:23,000 --> 00:18:24,000
负类是出问题的话

543
00:18:24,000 --> 00:18:26,000
那么你采集不到

544
00:18:26,000 --> 00:18:27,000
很多出问题的东西

545
00:18:27,000 --> 00:18:29,000
就意味着说你的负类很少

546
00:18:29,000 --> 00:18:31,000
就是说你可能有几万个

547
00:18:31,000 --> 00:18:32,000
很多车在跑

548
00:18:32,000 --> 00:18:34,000
然后你有几百万输出点

549
00:18:34,000 --> 00:18:35,000
可能就几百个输出点是负类

550
00:18:36,000 --> 00:18:37,000
所以这样子的话

551
00:18:37,000 --> 00:18:39,000
你其实比较难做了

552
00:18:40,000 --> 00:18:42,000
一般来说你的做法是说

553
00:18:42,000 --> 00:18:44,000
你通过对负类进行大量采样

554
00:18:45,000 --> 00:18:47,000
去使得你的平衡战略和负类

555
00:18:48,000 --> 00:18:50,000
另外一块就模型上来讲

556
00:18:50,000 --> 00:18:52,000
就是说你可以用

557
00:18:52,000 --> 00:18:54,000
我们最简单自回归模型

558
00:18:54,000 --> 00:18:55,000
或者你可以

559
00:18:55,000 --> 00:18:56,000
但是一般来说

560
00:18:56,000 --> 00:18:58,000
现在你可以确实用RN

561
00:18:58,000 --> 00:18:59,000
之后的RN会好一些

562
00:18:59,000 --> 00:19:01,000
或者甚至是formal模型

563
00:19:01,000 --> 00:19:02,000
可能更好一点

564
00:19:02,000 --> 00:19:04,000
但是我觉得在解决模型之前

565
00:19:04,000 --> 00:19:07,000
你得去搞你的负类

566
00:19:07,000 --> 00:19:09,000
就是说你得有足够多的负类才行

567
00:19:09,000 --> 00:19:10,000
你没有负类

568
00:19:10,000 --> 00:19:12,000
那你模型再强没用

569
00:19:12,000 --> 00:19:14,000
就你都学到是正类

570
00:19:14,000 --> 00:19:15,000
正类没去用对吧

571
00:19:17,000 --> 00:19:20,000
模型能学习多个连续输入

572
00:19:20,000 --> 00:19:21,000
比如ABC

573
00:19:21,000 --> 00:19:23,000
以及它们之间的联系吗

574
00:19:24,000 --> 00:19:25,000
这个东西我觉得

575
00:19:25,000 --> 00:19:27,000
我大概理解是说

576
00:19:27,000 --> 00:19:28,000
你其实想说

577
00:19:28,000 --> 00:19:29,000
我的随机变量之间的关系

578
00:19:29,000 --> 00:19:30,000
是什么样子

579
00:19:31,000 --> 00:19:32,000
这个比较难

580
00:19:32,000 --> 00:19:34,000
我们这个课不会深入

581
00:19:34,000 --> 00:19:36,000
就是说我们之前提过

582
00:19:36,000 --> 00:19:38,000
Causality那一门学科

583
00:19:38,000 --> 00:19:39,000
多多少少是去学说

584
00:19:39,000 --> 00:19:42,000
我给你观察到了很多东西

585
00:19:42,000 --> 00:19:44,000
就是说假设我有三个变量ABC

586
00:19:45,000 --> 00:19:46,000
ABC三个随机变量

587
00:19:46,000 --> 00:19:48,000
我能观察到每个随机变量

588
00:19:48,000 --> 00:19:49,000
它的一些值

589
00:19:49,000 --> 00:19:51,000
然后我去预测

590
00:19:51,000 --> 00:19:52,000
我去推测

591
00:19:52,000 --> 00:19:54,000
到底是A引起了B和C

592
00:19:54,000 --> 00:19:55,000
还是B引起了A和C

593
00:19:55,000 --> 00:19:57,000
它们之间是什么相互引起的关系

594
00:19:57,000 --> 00:19:59,000
这里面就是说

595
00:19:59,000 --> 00:20:00,000
这里面是Causality

596
00:20:00,000 --> 00:20:02,000
Causality那一块要解决的问题

597
00:20:05,000 --> 00:20:07,000
时间序列函数有个著名的例子

598
00:20:08,000 --> 00:20:10,000
谷底观察到的太阳系的位置

599
00:20:10,000 --> 00:20:11,000
观察数据

600
00:20:11,000 --> 00:20:12,000
这个数据是不是整理公开过

601
00:20:12,000 --> 00:20:14,000
用这个数据进行时间预测

602
00:20:15,000 --> 00:20:17,000
这个问题我不知道

603
00:20:17,000 --> 00:20:18,000
你问了个很好的问题

604
00:20:18,000 --> 00:20:20,000
这个是我的指示盲点

605
00:20:21,000 --> 00:20:22,000
我还真不知道

606
00:20:22,000 --> 00:20:24,000
他观察到的数据

607
00:20:24,000 --> 00:20:26,000
就是说我觉得你整体来讲

608
00:20:26,000 --> 00:20:28,000
就是说你要去用一个物理

609
00:20:28,000 --> 00:20:30,000
观察到的数据

610
00:20:30,000 --> 00:20:31,000
预测物理模型

611
00:20:31,000 --> 00:20:32,000
这个东西挺难的

612
00:20:33,000 --> 00:20:34,000
为什么

613
00:20:34,000 --> 00:20:35,000
为什么是说

614
00:20:36,000 --> 00:20:40,000
为什么是因为数据点比较少

615
00:20:41,000 --> 00:20:43,000
就是说你预测物理公式

616
00:20:43,000 --> 00:20:46,000
就是说你用这东西预测物理公式

617
00:20:46,000 --> 00:20:48,000
是一件有人在做

618
00:20:48,000 --> 00:20:49,000
但是挺难

619
00:20:49,000 --> 00:20:50,000
因为你数据点不够

620
00:20:50,000 --> 00:20:54,000
我觉得在用几个很小的点

621
00:20:54,000 --> 00:20:55,000
猜出里面的规律

622
00:20:55,000 --> 00:20:57,000
是人类最擅长的事情

623
00:20:58,000 --> 00:21:00,000
机械系目前还没有那么厉害

624
00:21:00,000 --> 00:21:02,000
我觉得是挺难的一个事情

625
00:21:02,000 --> 00:21:03,000
但你可以试一下

626
00:21:05,000 --> 00:21:07,000
有个想法对时序数据分类

627
00:21:07,000 --> 00:21:08,000
可以做一幅图

628
00:21:08,000 --> 00:21:09,000
然后用CN去做图片分类

629
00:21:09,000 --> 00:21:11,000
我觉得这个你

630
00:21:13,000 --> 00:21:14,000
这个挺好的

631
00:21:14,000 --> 00:21:15,000
这个想法

632
00:21:16,000 --> 00:21:17,000
我们之后会看

633
00:21:17,000 --> 00:21:19,000
用CN怎么做时序序列

634
00:21:19,000 --> 00:21:20,000
说一句真话

635
00:21:20,000 --> 00:21:22,000
说说白了就是一个异地的选集

636
00:21:22,000 --> 00:21:26,000
就是说CN就是观察到一个

637
00:21:26,000 --> 00:21:28,000
高和宽的两个维度的空间信息

638
00:21:28,000 --> 00:21:29,000
对吧

639
00:21:29,000 --> 00:21:30,000
确实时序的话

640
00:21:30,000 --> 00:21:31,000
就是一个异围的空间信息

641
00:21:31,000 --> 00:21:32,000
对吧

642
00:21:32,000 --> 00:21:33,000
就是说你

643
00:21:33,000 --> 00:21:34,000
它也是空间信息

644
00:21:34,000 --> 00:21:35,000
也是个时序信息

645
00:21:35,000 --> 00:21:36,000
就是说空间信息

646
00:21:36,000 --> 00:21:37,000
也是一个信息

647
00:21:37,000 --> 00:21:38,000
对吧

648
00:21:38,000 --> 00:21:39,000
就空间和时空在物理上

649
00:21:39,000 --> 00:21:40,000
是一个统一的概念

650
00:21:40,000 --> 00:21:41,000
对吧

651
00:21:41,000 --> 00:21:42,000
所以就你可以认为

652
00:21:42,000 --> 00:21:43,000
一个时序序列

653
00:21:43,000 --> 00:21:45,000
就是一个异围的一个

654
00:21:45,000 --> 00:21:47,000
或者时序就语音

655
00:21:47,000 --> 00:21:48,000
这东西都看成一个

656
00:21:48,000 --> 00:21:49,000
异围的一个信号量

657
00:21:49,000 --> 00:21:51,000
就是它有之间的相互点

658
00:21:51,000 --> 00:21:52,000
之间有关系

659
00:21:52,000 --> 00:21:54,000
空间也是相互像素有关系

660
00:21:54,000 --> 00:21:55,000
所以的话

661
00:21:55,000 --> 00:21:57,000
你用一个异围的卷迹就行了

662
00:21:57,000 --> 00:21:59,000
你不需要做一个二D图片

663
00:21:59,000 --> 00:22:00,000
就做这个异围的东西

664
00:22:00,000 --> 00:22:02,000
丢进去一个异地卷迹就能做出来

665
00:22:02,000 --> 00:22:04,000
但我们之后会给大家讲

666
00:22:04,000 --> 00:22:06,000
例子怎么要用CNN做文本分类

667
00:22:06,000 --> 00:22:08,000
就是处理异围数据

668
00:22:09,000 --> 00:22:11,000
效果也挺好的

669
00:22:11,000 --> 00:22:13,000
它不见得比RNN差

