1
00:00:00,000 --> 00:00:04,560
好 接下来我们来看一下全卷积神经网络的实现

2
00:00:04,560 --> 00:00:08,040
我们的导入的包还是跟之前是一样的

3
00:00:10,359 --> 00:00:15,800
首先我们来看一下说我们在ImageNet上用的是ResNet18这个模型

4
00:00:15,800 --> 00:00:17,320
我们用它来抽取特征

5
00:00:17,320 --> 00:00:19,640
回忆一下我们之前讲过这个模型的

6
00:00:19,640 --> 00:00:24,760
我们这个地方就是拿到从Model2里面拿到这个模型

7
00:00:24,760 --> 00:00:27,719
要把PreTrend开开就可以拿到它的权重

8
00:00:28,320 --> 00:00:32,560
然后我们看一下最后就是把所有的层列出来

9
00:00:32,560 --> 00:00:34,240
最后的几层长什么样子

10
00:00:34,240 --> 00:00:35,719
最后三层长什么样子

11
00:00:37,000 --> 00:00:38,320
首先看到最后一层

12
00:00:39,079 --> 00:00:40,519
最后一层是线性层对吧

13
00:00:40,519 --> 00:00:41,519
这个好理解

14
00:00:41,519 --> 00:00:43,280
这是我的输出层

15
00:00:43,600 --> 00:00:45,280
我的输入是5比2

16
00:00:45,439 --> 00:00:48,640
因为是通道数输出就是100 1000

17
00:00:48,640 --> 00:00:51,799
这是因为ImageNet上那个类别数是1000

18
00:00:52,439 --> 00:00:56,039
接下来就是一个全局的平均齿化层

19
00:00:56,479 --> 00:00:59,640
这个层的作用就是把我的7x7的高宽变成1x1

20
00:00:59,640 --> 00:01:00,879
通道数不变

21
00:01:01,280 --> 00:01:04,680
那么在后面就是一些ResNet的block了

22
00:01:04,680 --> 00:01:06,000
我们就不仔细看了

23
00:01:06,519 --> 00:01:08,359
所以我们知道倒数两层

24
00:01:08,359 --> 00:01:10,959
我们刚刚讲过这是我们不需要的

25
00:01:12,200 --> 00:01:12,759
OK

26
00:01:12,920 --> 00:01:18,039
所以可以看到是说我们用来做全FCN的模型是干嘛呢

27
00:01:18,039 --> 00:01:20,039
就是把PreTrend的Net拿过来

28
00:01:20,039 --> 00:01:22,239
把最后的两层去掉

29
00:01:22,560 --> 00:01:24,319
就只拿前面的

30
00:01:24,440 --> 00:01:26,160
然后把它转成一个Personal list

31
00:01:26,160 --> 00:01:28,880
然后传过去Google搜索一个新的Net出来

32
00:01:29,320 --> 00:01:30,720
这就是我们要做

33
00:01:31,400 --> 00:01:35,160
从做Finetune的时候拿过来的东西

34
00:01:35,840 --> 00:01:41,160
有意思的是说我们记得我们之前羽翼分割的图片

35
00:01:41,320 --> 00:01:44,440
是一个320x480的一个图片

36
00:01:44,640 --> 00:01:46,920
就它跟我们的ImageNet训练是不一样的

37
00:01:46,920 --> 00:01:48,640
ImageNet是24x24

38
00:01:48,640 --> 00:01:49,600
这个图片更大

39
00:01:49,680 --> 00:01:52,520
因为羽翼就是得像素级别

40
00:01:52,520 --> 00:01:54,200
所以你图片相对来说比较大

41
00:01:55,320 --> 00:01:57,480
卷积是三星网络最好的一个地方

42
00:01:57,480 --> 00:01:59,480
就是说我这个东西

43
00:01:59,480 --> 00:02:01,880
你不管用多大的输入我都能算

44
00:02:02,040 --> 00:02:03,080
不像全连接

45
00:02:03,080 --> 00:02:04,680
全连接你的一旦定了

46
00:02:04,680 --> 00:02:06,320
你的输入的大小是不能变的

47
00:02:06,320 --> 00:02:07,520
卷积没关系

48
00:02:07,640 --> 00:02:09,800
因为我可以学的权重

49
00:02:09,960 --> 00:02:10,760
Curl

50
00:02:10,760 --> 00:02:11,319
窗

51
00:02:11,920 --> 00:02:13,000
就卷积核

52
00:02:13,280 --> 00:02:16,000
是跟你输入大小是无关的

53
00:02:16,159 --> 00:02:18,600
是跟我的卷积层的定义是相关的

54
00:02:18,879 --> 00:02:19,680
所以OK

55
00:02:19,680 --> 00:02:21,480
所以我们把它弄一个比较大的图片

56
00:02:21,480 --> 00:02:22,480
你就可以看到

57
00:02:22,719 --> 00:02:24,280
也就是缩小32倍

58
00:02:24,319 --> 00:02:26,759
变成一个10x15的

59
00:02:27,159 --> 00:02:29,000
窗口大小出来

60
00:02:29,039 --> 00:02:29,759
然后通道数

61
00:02:29,879 --> 00:02:31,799
当然是从3变成了512

62
00:02:32,120 --> 00:02:32,599
OK

63
00:02:32,599 --> 00:02:35,639
这就是我们从ResNet里面拿出来

64
00:02:36,239 --> 00:02:38,359
Trofeo的模块是长这个样子

65
00:02:40,599 --> 00:02:43,280
接下来我们要把我们的

66
00:02:45,879 --> 00:02:47,919
FCN构造出来

67
00:02:48,439 --> 00:02:51,400
首先我们知道VOC一共是21类

68
00:02:51,400 --> 00:02:53,479
所以我们把它存在Number of Class里面

69
00:02:54,319 --> 00:02:57,000
接下来我们用一个1x1的卷积层

70
00:02:57,639 --> 00:02:59,319
所以我们知道输入是512

71
00:03:00,159 --> 00:03:01,959
有意思的是说你看一下输出

72
00:03:02,840 --> 00:03:05,000
输出我们选的是21

73
00:03:06,239 --> 00:03:06,680
为什么

74
00:03:07,479 --> 00:03:10,639
是因为最后的分类数是21

75
00:03:12,759 --> 00:03:14,280
然后我们之所以选21

76
00:03:14,280 --> 00:03:16,199
是因为我们这样子的话

77
00:03:16,199 --> 00:03:18,120
能够把我的计算变小

78
00:03:18,319 --> 00:03:19,639
我们先看一下后面

79
00:03:19,639 --> 00:03:20,719
我们再回过头来讲

80
00:03:20,719 --> 00:03:21,759
为什么选21

81
00:03:22,759 --> 00:03:24,719
后面就是我们的转制卷积层

82
00:03:25,439 --> 00:03:26,799
转制卷积层就是输入

83
00:03:26,799 --> 00:03:29,359
就是通道数是我们选好了21

84
00:03:29,359 --> 00:03:30,879
输出当然是一定是21

85
00:03:31,039 --> 00:03:32,159
因为我们输出需要

86
00:03:33,120 --> 00:03:34,399
接下来看一下Stripe

87
00:03:35,039 --> 00:03:37,679
因为我们要把图片放大32

88
00:03:38,599 --> 00:03:41,039
所以我们Stripe就选了32

89
00:03:41,759 --> 00:03:43,159
我们知道就是说

90
00:03:43,159 --> 00:03:44,759
如果你Stripe选32的话

91
00:03:44,759 --> 00:03:45,959
那么你的Kernel Size

92
00:03:45,959 --> 00:03:46,639
和你的Padding

93
00:03:47,000 --> 00:03:48,239
就尽量是说

94
00:03:48,239 --> 00:03:49,719
在没有Stripe的情况下

95
00:03:49,719 --> 00:03:51,719
尽量保存高宽不变

96
00:03:52,759 --> 00:03:54,879
我们知道在卷积里面

97
00:03:54,879 --> 00:03:57,199
如果你的Kernel Size是K的话

98
00:03:57,199 --> 00:03:58,079
那么你的Padding

99
00:03:58,560 --> 00:03:59,719
假设你K是奇数

100
00:03:59,719 --> 00:04:00,799
你的Padding就等于

101
00:04:01,079 --> 00:04:02,159
K-1除以2

102
00:04:02,679 --> 00:04:03,519
顺序效果数的话

103
00:04:03,519 --> 00:04:05,000
你Padding就等于K除以2

104
00:04:05,000 --> 00:04:06,799
就可以保持你的高宽不变

105
00:04:08,399 --> 00:04:09,239
但实际上来说

106
00:04:10,159 --> 00:04:11,000
会有一点的区别

107
00:04:11,000 --> 00:04:12,000
我们来仔细看一下

108
00:04:12,479 --> 00:04:15,280
我们这里取的Kernel Size是64

109
00:04:16,240 --> 00:04:16,560
为什么

110
00:04:16,680 --> 00:04:18,240
是因为我们Stripe等于32

111
00:04:18,719 --> 00:04:21,279
我们取一个稍微大一点的窗口

112
00:04:21,480 --> 00:04:23,560
使得窗口每跳一次

113
00:04:23,800 --> 00:04:25,320
还只跳过了半个窗口

114
00:04:26,640 --> 00:04:26,800
OK

115
00:04:26,800 --> 00:04:28,600
这就是我们使得我们窗口

116
00:04:28,600 --> 00:04:30,400
有一定的重叠度在里面

117
00:04:31,480 --> 00:04:31,920
Padding

118
00:04:32,640 --> 00:04:34,840
就是你这里应该按照卷积的说法

119
00:04:34,840 --> 00:04:36,240
你应该是取32对吧

120
00:04:37,920 --> 00:04:39,440
但是32

121
00:04:39,440 --> 00:04:40,760
其实你可以一直往下减

122
00:04:40,760 --> 00:04:42,280
因为我们知道卷积的

123
00:04:42,280 --> 00:04:43,600
你要罗的时候

124
00:04:43,600 --> 00:04:45,440
你是往跳跳跳

125
00:04:45,440 --> 00:04:46,120
跳到最后

126
00:04:46,760 --> 00:04:47,720
不能再往下跳了

127
00:04:47,720 --> 00:04:49,160
即使还剩一些值

128
00:04:49,160 --> 00:04:50,640
我也不会再往下跳了

129
00:04:51,039 --> 00:04:53,599
所以其实你是可以往下罗的

130
00:04:54,079 --> 00:04:55,839
就是说可以取到16

131
00:04:55,839 --> 00:04:58,120
16其实你在卷积上

132
00:04:58,120 --> 00:05:01,159
是使得你高宽不变的最小值

133
00:05:02,759 --> 00:05:05,159
然后所以我们这里取了16

134
00:05:05,159 --> 00:05:08,599
就是让你的计算量更加简单一点

135
00:05:08,599 --> 00:05:10,279
取了一个最小的值

136
00:05:10,279 --> 00:05:11,360
这里是取了16

137
00:05:11,360 --> 00:05:12,599
这是16的由来

138
00:05:14,680 --> 00:05:17,079
再回过头来看我的Number of Class

139
00:05:17,680 --> 00:05:19,039
就为什么我们这个地方

140
00:05:19,040 --> 00:05:20,920
其实你可以取个任意值都可以

141
00:05:20,920 --> 00:05:23,280
就是说你大概取个512到21

142
00:05:23,280 --> 00:05:24,280
之间的值都行

143
00:05:24,879 --> 00:05:26,480
就是说你这里取个K

144
00:05:26,480 --> 00:05:27,840
如果取个K的话

145
00:05:27,840 --> 00:05:29,360
这里我就替换成K就行了

146
00:05:29,840 --> 00:05:31,560
就我们为什么这里取了

147
00:05:31,560 --> 00:05:32,600
直接取到21

148
00:05:32,800 --> 00:05:34,360
纯粹是为了计算简单

149
00:05:35,000 --> 00:05:36,720
因为你可以看一下最后那个层

150
00:05:36,960 --> 00:05:39,400
那个层其实很计算不小

151
00:05:40,000 --> 00:05:41,280
颗额是很大的

152
00:05:41,280 --> 00:05:42,240
一个64的颗

153
00:05:43,120 --> 00:05:45,240
然后我们知道计算量

154
00:05:45,240 --> 00:05:48,240
跟你的输出通道数

155
00:05:48,240 --> 00:05:50,560
输入通道数和你克诺平方

156
00:05:51,120 --> 00:05:52,120
基本上是

157
00:05:53,519 --> 00:05:56,040
当然你stripe还是有除掉stripe

158
00:05:56,600 --> 00:05:59,000
跟它是有成正比关系

159
00:05:59,280 --> 00:06:00,160
所以的话

160
00:06:00,160 --> 00:06:02,199
你如果能够把这个东西尽量减

161
00:06:02,199 --> 00:06:03,680
因为减小的话

162
00:06:03,680 --> 00:06:05,040
让我这一层的计算量

163
00:06:05,040 --> 00:06:05,960
会降的比较低

164
00:06:06,079 --> 00:06:08,720
所以我们就直接取了最快捷的

165
00:06:08,720 --> 00:06:11,040
就是说能降到最小的选法

166
00:06:11,199 --> 00:06:13,920
直接前面直接降到21位

167
00:06:14,280 --> 00:06:16,120
当然会带来一点的精度损失

168
00:06:16,360 --> 00:06:17,960
但是计算量会比较快一些

169
00:06:18,920 --> 00:06:20,680
好

170
00:06:21,160 --> 00:06:22,000
我们就

171
00:06:22,759 --> 00:06:24,280
在讲完模型之后

172
00:06:24,280 --> 00:06:25,720
我们来讲一个说

173
00:06:26,000 --> 00:06:27,439
转制卷积层

174
00:06:27,439 --> 00:06:29,800
怎么样做有效的初始化

175
00:06:30,319 --> 00:06:32,199
最简单你就是做随机

176
00:06:32,920 --> 00:06:33,800
做一个随机式

177
00:06:34,000 --> 00:06:35,720
就把它随机初始化

178
00:06:35,720 --> 00:06:36,519
跟之前一样

179
00:06:36,960 --> 00:06:39,040
但我们昨天同学有问过

180
00:06:39,040 --> 00:06:40,360
说转制卷积层

181
00:06:40,360 --> 00:06:43,000
是不是可以用一个什么线性差值

182
00:06:43,000 --> 00:06:43,840
来实现了

183
00:06:44,800 --> 00:06:46,079
这是个很好的思路

184
00:06:46,600 --> 00:06:47,759
就是说一句真话

185
00:06:47,759 --> 00:06:49,480
你干的工作

186
00:06:49,480 --> 00:06:50,439
很多时候就想说

187
00:06:50,560 --> 00:06:51,439
我就把一个图片

188
00:06:51,439 --> 00:06:54,039
从7.7拉大32倍

189
00:06:55,199 --> 00:06:56,560
拉大有很多种做法

190
00:06:56,920 --> 00:06:57,839
在图片里面

191
00:06:57,839 --> 00:06:59,319
就是说你把这张图片拉大

192
00:06:59,319 --> 00:07:01,319
你可以用比如说插纸的方法

193
00:07:02,159 --> 00:07:04,199
比如说我可以用双线性插纸

194
00:07:04,199 --> 00:07:05,120
就是高框

195
00:07:05,360 --> 00:07:06,399
在高框上

196
00:07:07,000 --> 00:07:09,319
同时插纸

197
00:07:09,839 --> 00:07:11,159
所以这个函数是干嘛

198
00:07:11,360 --> 00:07:12,439
这个函数是说

199
00:07:12,439 --> 00:07:13,399
实现了一个

200
00:07:13,399 --> 00:07:16,480
用来实现双线性插纸的一个核

201
00:07:16,960 --> 00:07:18,520
然后你告诉我一个核的大小

202
00:07:18,520 --> 00:07:20,759
然后我要把每一个通道数

203
00:07:20,759 --> 00:07:21,879
都填满了核

204
00:07:21,879 --> 00:07:23,000
我们就不仔细讲

205
00:07:23,000 --> 00:07:24,160
这个是怎么回事了

206
00:07:24,840 --> 00:07:26,120
大家可以去看一下代码

207
00:07:26,520 --> 00:07:28,920
这个也是最简单的图片处理

208
00:07:28,920 --> 00:07:31,840
里面的双线性插值的一个核的实现

209
00:07:33,640 --> 00:07:36,280
就是说接下来这个函数是说

210
00:07:36,280 --> 00:07:39,600
假设我们构造出一个转制的卷积层

211
00:07:40,680 --> 00:07:41,520
比如说你看

212
00:07:41,800 --> 00:07:43,759
从3的RGB通道

213
00:07:43,759 --> 00:07:44,720
输出也是3

214
00:07:44,879 --> 00:07:45,879
还是RGB

215
00:07:46,120 --> 00:07:48,000
然后 kernel34

216
00:07:48,000 --> 00:07:49,040
然后padding的1

217
00:07:49,040 --> 00:07:49,959
stride2

218
00:07:49,959 --> 00:07:51,120
stride2的意思

219
00:07:51,120 --> 00:07:51,519
就是说

220
00:07:51,519 --> 00:07:54,360
我就把高宽放大两倍

221
00:07:56,480 --> 00:08:00,800
就假设我对构造一个这样子的转制卷积层

222
00:08:00,800 --> 00:08:04,839
然后我用一个双线性的核

223
00:08:05,159 --> 00:08:06,079
出来的矩阵

224
00:08:06,079 --> 00:08:08,800
来初始化它的权重的话

225
00:08:09,759 --> 00:08:11,000
会发生什么效果

226
00:08:11,560 --> 00:08:12,319
那就会

227
00:08:12,319 --> 00:08:13,680
它就真的就变成一个

228
00:08:13,680 --> 00:08:15,759
双线性插值的一个操作了

229
00:08:16,480 --> 00:08:16,600
好

230
00:08:16,600 --> 00:08:17,560
我们来看一下怎么回事

231
00:08:18,199 --> 00:08:19,680
我们就不仔细讲这个代码

232
00:08:19,680 --> 00:08:20,519
这个代码就很简单

233
00:08:20,519 --> 00:08:21,839
就把一个图片读进来

234
00:08:22,000 --> 00:08:25,159
转成一个就multiple slice的图片读进来

235
00:08:25,199 --> 00:08:28,680
就转成我们pytorch能用的一个tensor形式

236
00:08:29,040 --> 00:08:34,279
然后对x做一次转制卷积的操作

237
00:08:34,279 --> 00:08:35,080
得到y

238
00:08:35,120 --> 00:08:36,200
然后print一下

239
00:08:37,439 --> 00:08:38,320
可以看到

240
00:08:38,519 --> 00:08:40,279
输入的图片是我们读进来的

241
00:08:40,279 --> 00:08:42,759
就是561x728的高宽

242
00:08:43,759 --> 00:08:45,200
然后输出的话

243
00:08:45,200 --> 00:08:46,280
你会看到是double了

244
00:08:46,280 --> 00:08:46,759
对吧

245
00:08:46,800 --> 00:08:48,360
就561变成122

246
00:08:48,360 --> 00:08:50,680
然后728变成了14256

247
00:08:51,240 --> 00:08:53,400
就说输出是被拉大了

248
00:08:53,759 --> 00:08:56,040
最后我们就打印一下输出的图片

249
00:08:56,640 --> 00:08:59,480
基本上看到是跟原图是一样的

250
00:08:59,520 --> 00:09:03,759
因为放大再缩小打印出来

251
00:09:03,840 --> 00:09:05,280
就基本上你都看不出

252
00:09:05,280 --> 00:09:06,879
跟原图的毛骨的区别

253
00:09:07,200 --> 00:09:07,960
所以

254
00:09:08,920 --> 00:09:10,160
这个意思是说

255
00:09:10,200 --> 00:09:13,160
假设我构造了一个转制的卷积层

256
00:09:13,439 --> 00:09:14,879
这个卷积层的作用

257
00:09:14,879 --> 00:09:16,679
是把高宽变大两倍

258
00:09:17,279 --> 00:09:20,839
而且我用了一个双线性的差值的核

259
00:09:20,839 --> 00:09:23,079
来初始化它的权重的话

260
00:09:23,279 --> 00:09:24,120
那么它的效果

261
00:09:24,120 --> 00:09:25,480
就真的就变成了一个

262
00:09:25,480 --> 00:09:27,240
把这个图片拉大效果

263
00:09:27,759 --> 00:09:28,439
OK

264
00:09:28,919 --> 00:09:31,639
我们可以用它干嘛呢

265
00:09:31,639 --> 00:09:34,360
我觉得这个是一个很不错的

266
00:09:34,360 --> 00:09:36,719
用来初始我们转制卷积层的

267
00:09:36,719 --> 00:09:39,439
一个初始化的一个方法

268
00:09:39,839 --> 00:09:41,439
所以这个地方就是说

269
00:09:41,440 --> 00:09:43,680
我们就构造出我们的

270
00:09:43,720 --> 00:09:47,640
21 21 64的一个对应的一个核

271
00:09:48,080 --> 00:09:52,600
把它直接写到我们的FCN里面

272
00:09:52,600 --> 00:09:55,080
最后一层的权重初始化里面

273
00:09:56,280 --> 00:09:57,880
对别的层的一层一的卷积

274
00:09:57,920 --> 00:09:58,880
就是默认的

275
00:09:58,880 --> 00:10:01,120
随机初始制了

276
00:10:02,240 --> 00:10:02,760
所以这样子

277
00:10:02,760 --> 00:10:04,960
我们就完成了我们的初始化

278
00:10:05,400 --> 00:10:06,720
所以这个地方就是说

279
00:10:06,760 --> 00:10:09,400
你看到主要是用一个优化小优化

280
00:10:09,399 --> 00:10:10,799
使得用一个双线性

281
00:10:10,799 --> 00:10:12,840
来初始化我们的转制卷积层

282
00:10:12,840 --> 00:10:14,360
使得我们之后的训练

283
00:10:14,360 --> 00:10:15,480
可能更快一点

284
00:10:17,199 --> 00:10:17,559
好

285
00:10:17,559 --> 00:10:19,159
接下来我们就是跟之前一样

286
00:10:19,279 --> 00:10:20,240
读取数据

287
00:10:20,399 --> 00:10:23,039
就是P2大小是32

288
00:10:23,079 --> 00:10:24,879
然后我们的Crop Size

289
00:10:24,879 --> 00:10:26,159
就是我们昨天有讲过

290
00:10:26,279 --> 00:10:27,799
就是320×480

291
00:10:28,079 --> 00:10:30,879
最后我们读取一个训练机

292
00:10:30,879 --> 00:10:31,959
和一个测试机

293
00:10:32,199 --> 00:10:34,399
就这个是我们昨天讲过的函数

294
00:10:34,480 --> 00:10:35,480
大家没过

295
00:10:35,480 --> 00:10:36,679
如果没有来的话

296
00:10:36,679 --> 00:10:37,319
可以去看一下

297
00:10:37,319 --> 00:10:39,079
我们昨天的视频

298
00:10:40,399 --> 00:10:41,159
好

299
00:10:41,159 --> 00:10:42,000
这个是训练

300
00:10:42,279 --> 00:10:44,360
就训练第一个不一样的

301
00:10:44,360 --> 00:10:45,439
就是说我们的Loss

302
00:10:45,439 --> 00:10:46,799
Loss的话

303
00:10:46,799 --> 00:10:49,319
因为我们之前算Loss都是

304
00:10:49,319 --> 00:10:50,959
就是一个Loss

305
00:10:50,959 --> 00:10:52,919
就是一个就是一个值

306
00:10:52,919 --> 00:10:55,039
就对一个标号的一个值

307
00:10:55,120 --> 00:10:56,399
现在是我们的Loss

308
00:10:56,399 --> 00:10:57,600
会稍微多一点点

309
00:10:57,720 --> 00:11:00,319
就是我们还有个

310
00:11:00,319 --> 00:11:03,559
我们对我们需要对每一个高和每个宽

311
00:11:04,399 --> 00:11:06,279
之前我们就直接Cross Entropy

312
00:11:06,279 --> 00:11:08,879
会拿到我们的

313
00:11:08,879 --> 00:11:09,679
那个

314
00:11:10,799 --> 00:11:12,120
Cross Entropy的值

315
00:11:12,240 --> 00:11:13,519
但现在我们要加一个什么

316
00:11:13,519 --> 00:11:14,879
我们要对

317
00:11:15,839 --> 00:11:17,360
我们要对高

318
00:11:17,919 --> 00:11:18,919
做一个平均

319
00:11:19,039 --> 00:11:19,399
就是说

320
00:11:19,399 --> 00:11:21,079
因为我们现在每个图片是

321
00:11:21,079 --> 00:11:22,000
它有高宽里面

322
00:11:22,000 --> 00:11:24,000
所有的像素都要做预测

323
00:11:24,039 --> 00:11:24,879
所以是一个

324
00:11:24,879 --> 00:11:25,959
以前是一个标量

325
00:11:25,959 --> 00:11:27,199
现在是一个矩阵

326
00:11:27,240 --> 00:11:28,959
所以我们要对矩阵做均值

327
00:11:29,079 --> 00:11:29,679
就是说白了

328
00:11:29,679 --> 00:11:31,799
就是在高上做一下均值

329
00:11:31,799 --> 00:11:33,120
在宽上做一下均值

330
00:11:33,120 --> 00:11:34,399
就是我们要做效果

331
00:11:34,439 --> 00:11:35,399
这样子每一个图片

332
00:11:35,399 --> 00:11:37,279
我们可以损失会拿到一个值

333
00:11:37,439 --> 00:11:39,240
所以这个是损失函数

334
00:11:39,240 --> 00:11:40,279
跟之前的不一样

335
00:11:40,279 --> 00:11:41,399
之前图片分类

336
00:11:41,399 --> 00:11:42,439
损失出来

337
00:11:42,439 --> 00:11:44,120
就是每个样本是一个值

338
00:11:44,120 --> 00:11:45,519
现在每个样本是一个矩阵

339
00:11:45,519 --> 00:11:48,120
所以我们对每一个像素做一下均值

340
00:11:49,120 --> 00:11:50,159
别的都是一样的

341
00:11:50,240 --> 00:11:51,959
别的我们就不仔细讲了

342
00:11:52,000 --> 00:11:54,639
就是说我们用的SGD

343
00:11:54,759 --> 00:11:56,959
然后我们用的是

344
00:11:57,159 --> 00:11:59,559
我们之前定义的函数来训练

345
00:11:59,559 --> 00:12:00,639
因为别的

346
00:12:00,759 --> 00:12:01,960
反正都是一个

347
00:12:02,199 --> 00:12:03,120
进行神经网络

348
00:12:03,720 --> 00:12:05,240
虽然你的数据会长得不一样

349
00:12:05,240 --> 00:12:07,159
但是从代码上来讲

350
00:12:07,159 --> 00:12:08,080
其实没区别

351
00:12:08,759 --> 00:12:10,320
看一下我们的训练效果

352
00:12:10,560 --> 00:12:12,600
就是训练效果可以看到是说

353
00:12:12,639 --> 00:12:13,639
我们的精度

354
00:12:13,639 --> 00:12:15,320
大概是0.85的样子

355
00:12:17,159 --> 00:12:19,120
就0.85精度

356
00:12:19,720 --> 00:12:20,600
怎么去看

357
00:12:21,720 --> 00:12:24,320
我们知道图片就像素级别

358
00:12:25,960 --> 00:12:27,639
绝大部分像素是比较简单的

359
00:12:27,639 --> 00:12:28,240
就背景

360
00:12:28,680 --> 00:12:30,399
就你背景中间那一块

361
00:12:30,560 --> 00:12:31,320
比如说分人

362
00:12:31,480 --> 00:12:32,399
人中间那一块

363
00:12:32,399 --> 00:12:34,120
其实是相对来说比较简单的

364
00:12:34,279 --> 00:12:37,080
难的是边缘是比较难的

365
00:12:37,360 --> 00:12:38,399
所以的话

366
00:12:38,480 --> 00:12:41,039
在绝大部分东西比较简单情况下

367
00:12:41,039 --> 00:12:43,480
所以你的精度相对来说会比较高

368
00:12:44,000 --> 00:12:46,120
但是你这里也就84%

369
00:12:46,120 --> 00:12:46,720
意味着就是说

370
00:12:46,720 --> 00:12:48,279
我们其实在边缘的处理上

371
00:12:48,279 --> 00:12:49,600
应该就做的不是那么好

372
00:12:50,320 --> 00:12:50,840
OK

373
00:12:51,120 --> 00:12:52,639
所以就是等会我们会来

374
00:12:53,200 --> 00:12:54,720
视觉上来看一下效果

375
00:12:54,720 --> 00:12:57,879
在这里我们可以大概是理解一下

376
00:12:57,879 --> 00:13:00,000
这个精度就还行

377
00:13:00,000 --> 00:13:00,960
但不会特别好

378
00:13:01,680 --> 00:13:03,360
另外一个是我们的训练比较慢

379
00:13:03,600 --> 00:13:06,080
就是因为我们之前

380
00:13:06,080 --> 00:13:07,919
ResNet的一时8的话

381
00:13:07,919 --> 00:13:10,560
在4个GPU上训练个几千张图片

382
00:13:10,560 --> 00:13:11,800
每秒是可以的

383
00:13:12,200 --> 00:13:13,360
这里就不是很行

384
00:13:13,600 --> 00:13:15,960
主要是说图片一图片更大了

385
00:13:16,200 --> 00:13:18,120
第二是大的卷

386
00:13:19,360 --> 00:13:21,039
转制局卷集层

387
00:13:21,080 --> 00:13:22,200
计算量还是挺大的

388
00:13:22,960 --> 00:13:25,840
所以这就是为什么速度相对来说

389
00:13:25,840 --> 00:13:26,440
比较慢

390
00:13:26,960 --> 00:13:29,000
当然另外一个是说我们精度

391
00:13:29,240 --> 00:13:30,800
就是上升比较缓慢

392
00:13:30,879 --> 00:13:32,399
虽然损失就在降

393
00:13:32,879 --> 00:13:33,759
上市比较缓慢

394
00:13:33,759 --> 00:13:36,279
就是确实一开始就很容易

395
00:13:36,279 --> 00:13:38,399
把背景这些中间部分分好

396
00:13:38,959 --> 00:13:41,319
边缘那一块确实是一直损失

397
00:13:41,439 --> 00:13:42,319
一直在往下降

398
00:13:42,480 --> 00:13:45,600
所以你可能再多带多叠带几个

399
00:13:45,600 --> 00:13:47,240
可能效果更好一点

400
00:13:50,199 --> 00:13:51,399
接下来是预测

401
00:13:51,639 --> 00:13:53,879
预测跟之前也没什么太大区别

402
00:13:53,879 --> 00:13:54,600
可以看一下

403
00:13:55,439 --> 00:13:56,720
首先一个图片进来

404
00:13:56,720 --> 00:14:00,639
我们要用测试级的Data Set的

405
00:14:01,639 --> 00:14:02,639
就是Normalization

406
00:14:02,639 --> 00:14:04,519
就是RGB做Normalize

407
00:14:04,679 --> 00:14:06,519
就调那个函数来做它

408
00:14:06,799 --> 00:14:09,279
做完之后就copy到GPU上

409
00:14:09,799 --> 00:14:11,279
一点不一样的是说

410
00:14:11,279 --> 00:14:12,720
我做ArcMax的时候

411
00:14:12,720 --> 00:14:15,080
是在通道位是走ArcMax

412
00:14:16,039 --> 00:14:18,679
因为我要得到每一个

413
00:14:18,679 --> 00:14:21,120
就是说它的输出是每一个像素

414
00:14:21,559 --> 00:14:22,840
它都会有个多通道

415
00:14:22,840 --> 00:14:23,080
对吧

416
00:14:23,080 --> 00:14:24,159
11个通道

417
00:14:24,279 --> 00:14:26,360
然后在通道位做ArcMax

418
00:14:26,399 --> 00:14:28,120
就会得到对每一个像素

419
00:14:28,120 --> 00:14:29,879
它的预测的标号

420
00:14:31,039 --> 00:14:32,360
所以predict出来

421
00:14:32,360 --> 00:14:33,720
在reshape之后

422
00:14:33,720 --> 00:14:34,720
就变成一个

423
00:14:34,720 --> 00:14:35,960
跟你的输入的高宽

424
00:14:35,960 --> 00:14:37,199
是一样的一个矩阵

425
00:14:37,759 --> 00:14:39,000
之前我们做图片分类

426
00:14:39,000 --> 00:14:40,159
是一个标号出来

427
00:14:40,159 --> 00:14:41,639
就是一个单的值

428
00:14:41,679 --> 00:14:42,799
现在会变成一个

429
00:14:42,840 --> 00:14:44,360
像素级别的一个值

430
00:14:44,559 --> 00:14:45,360
就是一个

431
00:14:45,879 --> 00:14:48,720
跟原图片高宽等同的一个矩阵

432
00:14:51,080 --> 00:14:51,399
好

433
00:14:51,399 --> 00:14:52,600
最后我们可以

434
00:14:52,639 --> 00:14:54,159
只可以画一下这个函数

435
00:14:54,759 --> 00:14:55,879
第一个函数说

436
00:14:55,879 --> 00:14:57,639
我给你每个像素的预测值

437
00:14:57,639 --> 00:14:59,279
我怎么样把它变成image

438
00:14:59,360 --> 00:14:59,839
说白了

439
00:14:59,839 --> 00:15:02,240
就是把你每个类别

440
00:15:02,240 --> 00:15:03,600
它的RGB值

441
00:15:03,799 --> 00:15:04,679
做成一个tensor

442
00:15:04,679 --> 00:15:05,480
然后把它

443
00:15:06,279 --> 00:15:08,559
你的预测值做成一个index

444
00:15:08,559 --> 00:15:09,319
拿进去拿

445
00:15:09,319 --> 00:15:11,439
就会拿出你预测的

446
00:15:12,120 --> 00:15:13,360
RGB的值可以画

447
00:15:14,199 --> 00:15:15,159
接下来这个函数

448
00:15:15,159 --> 00:15:15,480
就是说

449
00:15:15,480 --> 00:15:18,480
我们把tested image拿出来

450
00:15:18,720 --> 00:15:21,480
然后把前面几个图

451
00:15:22,759 --> 00:15:23,959
首先做一次剪裁

452
00:15:23,959 --> 00:15:26,959
在左上角剪裁成我们要的大小

453
00:15:26,960 --> 00:15:30,560
然后把它做一次预测

454
00:15:30,560 --> 00:15:31,960
然后转成我们的图片

455
00:15:31,960 --> 00:15:32,960
然后再print一下

456
00:15:33,519 --> 00:15:35,680
我们就代码不太仔细讲

457
00:15:35,879 --> 00:15:36,920
可以看一下结果

458
00:15:38,759 --> 00:15:39,480
结果上来讲

459
00:15:39,480 --> 00:15:40,720
你可以看到是说

460
00:15:41,400 --> 00:15:43,040
第一行是我的原始图片

461
00:15:43,240 --> 00:15:44,720
第二行是我的预测

462
00:15:44,759 --> 00:15:46,040
第三行是标号

463
00:15:46,639 --> 00:15:48,200
这基本上可以看到是说

464
00:15:49,360 --> 00:15:51,759
在主体上还行

465
00:15:51,840 --> 00:15:53,120
就类没搞错

466
00:15:53,440 --> 00:15:54,680
是飞机还是飞机

467
00:15:55,000 --> 00:15:56,759
是火车还是火车

468
00:15:56,759 --> 00:15:59,919
你看大类别没搞错

469
00:16:00,120 --> 00:16:01,439
主体也还行

470
00:16:01,439 --> 00:16:04,159
就主体你大概是能够画出来

471
00:16:04,159 --> 00:16:04,639
对吧

472
00:16:04,840 --> 00:16:06,200
但是仔细看的话

473
00:16:06,200 --> 00:16:07,879
它的边缘不行

474
00:16:08,679 --> 00:16:09,559
它的边缘你看

475
00:16:09,799 --> 00:16:10,559
就是说

476
00:16:10,639 --> 00:16:11,799
你看飞机的边缘

477
00:16:11,799 --> 00:16:13,000
我们做的确实不行

478
00:16:13,399 --> 00:16:16,600
这个火车应该没有连起来的地方

479
00:16:16,600 --> 00:16:17,480
你把它连起来了

480
00:16:17,679 --> 00:16:19,039
这个地方你缺了一块

481
00:16:20,399 --> 00:16:21,360
所以就是说

482
00:16:21,360 --> 00:16:23,360
大概就是给大家一个印象

483
00:16:23,360 --> 00:16:23,600
就是说

484
00:16:23,600 --> 00:16:24,960
85%的精度

485
00:16:25,000 --> 00:16:25,879
这是在

486
00:16:26,879 --> 00:16:27,840
整体上还行

487
00:16:27,840 --> 00:16:29,480
就是大块的地方还行

488
00:16:29,519 --> 00:16:30,560
但是在边缘地方

489
00:16:30,680 --> 00:16:31,960
做的确实不那么好

490
00:16:31,960 --> 00:16:34,639
所以你丢掉了15%的精度

491
00:16:35,280 --> 00:16:37,000
主要是在边缘地方丢掉了

492
00:16:37,160 --> 00:16:37,720
OK

493
00:16:38,400 --> 00:16:39,360
当然是说

494
00:16:39,360 --> 00:16:41,160
我们还可以通过说

495
00:16:41,440 --> 00:16:43,759
把Number of Epoch增大一点

496
00:16:43,800 --> 00:16:45,000
然后把网络的参数

497
00:16:45,000 --> 00:16:45,840
再调好一点

498
00:16:45,840 --> 00:16:47,360
来做得更好

499
00:16:47,680 --> 00:16:50,160
但我们这里主要是一个演示目的

500
00:16:50,160 --> 00:16:51,759
大家可以去尝试

501
00:16:51,759 --> 00:16:53,519
调一调它的槽参数

502
00:16:53,559 --> 00:16:55,639
可以尝试去提升它的精度

503
00:16:56,399 --> 00:16:56,759
OK

504
00:16:56,759 --> 00:16:58,720
这就是FCN

505
00:16:58,759 --> 00:16:59,559
所以总结一下

506
00:17:00,279 --> 00:17:02,879
它就是一个卷积成绩网络拿过来

507
00:17:03,079 --> 00:17:04,400
把最后两层

508
00:17:04,839 --> 00:17:07,759
全连接层和全剧的持花针去掉

509
00:17:08,039 --> 00:17:09,359
加入一个

510
00:17:09,400 --> 00:17:12,519
核心是加入一个转制的卷积层

511
00:17:13,119 --> 00:17:14,720
如果你前面的卷积层

512
00:17:14,720 --> 00:17:17,319
让你缩小了32倍的话

513
00:17:17,319 --> 00:17:18,599
这个转制卷积层

514
00:17:18,599 --> 00:17:20,400
就让你扩了32倍

515
00:17:20,440 --> 00:17:22,279
可以得到每个像素的预测

516
00:17:22,440 --> 00:17:23,359
让你的通道数

517
00:17:23,359 --> 00:17:25,879
就是你的标号的个数

518
00:17:26,240 --> 00:17:27,160
然后你每个像素

519
00:17:27,160 --> 00:17:28,759
会得到一个类别的预测

520
00:17:29,279 --> 00:17:30,960
然后当然你中间可以加

521
00:17:30,960 --> 00:17:32,720
前面可以加一个一乘一的卷积层

522
00:17:32,920 --> 00:17:35,000
把你最后一层的计算量减低一点

523
00:17:35,119 --> 00:17:37,559
这也是一个常用的技巧

524
00:17:37,639 --> 00:17:38,160
OK

525
00:17:38,160 --> 00:17:39,920
这就是FCN

