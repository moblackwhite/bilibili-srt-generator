1
00:00:00,000 --> 00:00:06,160
OK 我们今天的正题是给大家快速的过一下

2
00:00:06,160 --> 00:00:09,240
目标检测里面的一些常用算法

3
00:00:10,000 --> 00:00:14,160
首先我们看到的是区域卷积神经网络

4
00:00:14,160 --> 00:00:16,960
叫做region convolutional neural network

5
00:00:18,879 --> 00:00:21,640
最早那个模型叫做R-CNN

6
00:00:21,640 --> 00:00:23,559
就是region based

7
00:00:23,559 --> 00:00:26,480
就是基于区域的CNN

8
00:00:27,320 --> 00:00:29,400
这么看一下这个模型到底长什么样

9
00:00:29,640 --> 00:00:31,760
这也是电机性工作

10
00:00:33,039 --> 00:00:34,200
首先它干嘛呢

11
00:00:35,280 --> 00:00:40,040
它首先用一个启发式的搜索算法来选择模框

12
00:00:40,880 --> 00:00:42,000
就给大家画一下

13
00:00:42,359 --> 00:00:43,040
大概是

14
00:00:44,359 --> 00:00:45,480
就首先在这个地方

15
00:00:46,120 --> 00:00:48,439
它就做selective search

16
00:00:48,439 --> 00:00:51,400
就是一个挺复杂的算法

17
00:00:51,400 --> 00:00:55,000
就是最早是来自于整个目标检测

18
00:00:55,000 --> 00:00:58,439
在神经网络还没那么出来的时候

19
00:00:58,439 --> 00:01:00,879
之前大家是用那一套过来的

20
00:01:01,399 --> 00:01:03,920
这个也不是工作真的提出来的

21
00:01:03,920 --> 00:01:05,319
就是说这一块之前

22
00:01:05,319 --> 00:01:07,400
大家都是这么样去选择模框的

23
00:01:07,959 --> 00:01:11,280
另外一个我们今天主要讲的是基于模框的算法

24
00:01:11,480 --> 00:01:13,799
非模框的算法我们就暂时不讲了

25
00:01:13,799 --> 00:01:14,959
因为相对来说比较新

26
00:01:14,959 --> 00:01:16,159
工作也不那么多

27
00:01:17,840 --> 00:01:20,400
然后你选出了很多模框之后

28
00:01:20,959 --> 00:01:22,959
就是说你对每一个模框

29
00:01:24,280 --> 00:01:25,959
就是说当做一张图片

30
00:01:26,960 --> 00:01:30,240
然后用一个预训练好的模型

31
00:01:30,240 --> 00:01:32,360
就是比如说你在imagenet上

32
00:01:32,360 --> 00:01:35,080
圈好的一个模型来抽feature

33
00:01:35,080 --> 00:01:36,960
就比如说VGG了

34
00:01:36,960 --> 00:01:37,560
那个年代

35
00:01:38,840 --> 00:01:39,920
或者AlexNet了

36
00:01:40,640 --> 00:01:41,880
抽出来feature之后

37
00:01:42,760 --> 00:01:47,800
他训练一个SVM来对类别进行分类

38
00:01:48,440 --> 00:01:49,440
这也是我们说过的

39
00:01:49,440 --> 00:01:50,720
在计算机视觉里面

40
00:01:50,720 --> 00:01:51,920
在神经网络之前

41
00:01:52,120 --> 00:01:54,400
大家的分类器主要用的是SVM

42
00:01:54,680 --> 00:01:56,320
就是说神经网络就深度学习

43
00:01:56,320 --> 00:01:57,080
这一波之前

44
00:01:57,280 --> 00:01:59,080
就分类器主要是SVM

45
00:02:00,719 --> 00:02:01,640
另外一个就是说

46
00:02:01,640 --> 00:02:05,480
他在上面用一个线性回归模型

47
00:02:05,480 --> 00:02:07,880
来预测边缘框的偏移

48
00:02:07,880 --> 00:02:09,319
就是这个模框

49
00:02:09,400 --> 00:02:10,879
我们选出来这个模框

50
00:02:10,879 --> 00:02:15,520
到我们真实的bounded box之间的一个偏移

51
00:02:17,520 --> 00:02:18,080
OK

52
00:02:19,719 --> 00:02:21,480
然后我们要做

53
00:02:22,520 --> 00:02:23,319
讲这个模型的时候

54
00:02:23,319 --> 00:02:25,159
我们会讲到一个很重要的概念

55
00:02:25,159 --> 00:02:27,000
是说你这个模框

56
00:02:27,159 --> 00:02:30,400
每一次选到的大小是不一样的

57
00:02:31,039 --> 00:02:31,359
对吧

58
00:02:31,359 --> 00:02:32,799
你可能比如说这个模框

59
00:02:33,039 --> 00:02:33,959
一选在这个地方

60
00:02:33,959 --> 00:02:35,199
二选在这个地方

61
00:02:35,879 --> 00:02:37,400
不一样的情况下

62
00:02:37,439 --> 00:02:41,599
我怎么样来使得这些模框

63
00:02:41,599 --> 00:02:43,560
它最后可以变成一个batch

64
00:02:44,479 --> 00:02:46,039
他这么使用的一个算法

65
00:02:46,039 --> 00:02:48,479
叫做IOI pooling

66
00:02:49,319 --> 00:02:52,199
叫做region of interest

67
00:02:52,200 --> 00:02:54,480
就是兴趣区域的持话

68
00:02:55,480 --> 00:02:56,440
它是个什么样想法

69
00:02:56,560 --> 00:02:59,080
就是说我给定一个模框

70
00:02:59,640 --> 00:03:03,360
我会均匀的把它切成n乘以n块

71
00:03:04,840 --> 00:03:07,280
然后输出每一块里面的对答值

72
00:03:08,120 --> 00:03:09,440
比如说这里有个模框

73
00:03:10,200 --> 00:03:12,600
比如说我们圈住了这三个的话

74
00:03:13,360 --> 00:03:15,880
那么说我假设我要做一个2x2的

75
00:03:15,880 --> 00:03:19,360
IOI pooling的话

76
00:03:19,960 --> 00:03:21,640
那么他就会把它切成一个2x2的

77
00:03:21,640 --> 00:03:22,160
一个框

78
00:03:22,960 --> 00:03:24,880
到这个地方就是说我会这么切开

79
00:03:25,600 --> 00:03:27,440
它这个地方是说你不好均匀切

80
00:03:27,440 --> 00:03:28,920
因为你是个3x3的东西

81
00:03:29,160 --> 00:03:31,680
它当然会去round到一个边界

82
00:03:31,680 --> 00:03:32,800
就是说取个整

83
00:03:33,080 --> 00:03:34,480
取个整就变成了说

84
00:03:34,800 --> 00:03:36,240
那么这一块就是

85
00:03:37,120 --> 00:03:40,680
那么就是说我这一块就是块1

86
00:03:40,680 --> 00:03:41,920
然后这一块是块2

87
00:03:41,920 --> 00:03:43,360
这一块是块3块4

88
00:03:44,640 --> 00:03:46,440
然后你在做pooling的时候

89
00:03:47,000 --> 00:03:49,000
就是说这一块里面

90
00:03:49,000 --> 00:03:50,319
第一块里面最大值是几

91
00:03:50,479 --> 00:03:51,639
是5这个值

92
00:03:51,639 --> 00:03:52,120
对吧

93
00:03:52,120 --> 00:03:52,919
放到这个地方

94
00:03:53,639 --> 00:03:56,000
那么接下来这一块就是9最大值

95
00:03:56,240 --> 00:03:57,000
最开始10

96
00:03:57,159 --> 00:03:58,240
这一块是2和8

97
00:03:58,560 --> 00:03:59,639
那就2和6

98
00:03:59,639 --> 00:04:00,319
那就是6

99
00:04:01,039 --> 00:04:03,479
所以就是说它的好处是说

100
00:04:03,479 --> 00:04:06,960
你不管你的模框是怎么样形状的

101
00:04:07,960 --> 00:04:10,400
我就要给定n和m

102
00:04:11,560 --> 00:04:14,919
那么总会对这个模框输出nm

103
00:04:14,919 --> 00:04:16,199
n乘以m的值

104
00:04:17,160 --> 00:04:18,839
这样的话我就有不同的模框

105
00:04:18,839 --> 00:04:20,800
我都会变成同样的一个大小

106
00:04:20,800 --> 00:04:22,199
可以去做batching了

107
00:04:22,399 --> 00:04:23,959
就可以做一个小批量了

108
00:04:24,600 --> 00:04:25,439
那就之后的话

109
00:04:25,439 --> 00:04:27,079
我们就处理起来比较方便了

110
00:04:28,079 --> 00:04:28,439
OK

111
00:04:29,040 --> 00:04:31,279
所以就是说这个也是

112
00:04:32,560 --> 00:04:35,800
RCA里面一个很关键的一个新的一个层

113
00:04:35,800 --> 00:04:38,519
叫做IOI持话层

114
00:04:39,680 --> 00:04:42,680
所以这个东西的目的是让你每个模框

115
00:04:42,680 --> 00:04:46,399
都可以变成一个自己想要的一个形状

116
00:04:46,560 --> 00:04:52,120
另外一个是说

117
00:04:52,399 --> 00:04:53,639
第二个模型

118
00:04:53,800 --> 00:04:55,199
RCN是最早的

119
00:04:55,199 --> 00:04:57,600
这个RCN系列的最早的一个模型

120
00:04:58,160 --> 00:04:59,639
之后他们又做了一个算法

121
00:04:59,639 --> 00:05:01,279
叫做fast RCN

122
00:05:03,560 --> 00:05:05,519
fast RCN的主要的问题

123
00:05:05,879 --> 00:05:06,720
就是说

124
00:05:07,040 --> 00:05:08,360
对之前的改进

125
00:05:08,360 --> 00:05:09,360
主要是说

126
00:05:09,360 --> 00:05:11,279
你每一次哪一张图片

127
00:05:11,279 --> 00:05:13,399
我都要去抽特征

128
00:05:13,439 --> 00:05:14,279
然后就是说

129
00:05:14,280 --> 00:05:15,960
我假设一张图片里面

130
00:05:15,960 --> 00:05:17,160
抽100个

131
00:05:17,160 --> 00:05:18,120
模框还比较小

132
00:05:18,240 --> 00:05:19,640
我抽1000个的话

133
00:05:19,680 --> 00:05:22,680
那么岂不是我要做1000次的一个

134
00:05:23,320 --> 00:05:24,440
用CN抽feature

135
00:05:27,040 --> 00:05:28,080
这样子就比较麻烦了

136
00:05:28,080 --> 00:05:28,560
对吧

137
00:05:29,480 --> 00:05:30,280
因为

138
00:05:32,400 --> 00:05:33,080
你等于是说

139
00:05:33,080 --> 00:05:33,920
我一张图片

140
00:05:33,920 --> 00:05:36,280
我变成了1000张小图片

141
00:05:36,280 --> 00:05:38,320
这个东西的计算量太大

142
00:05:38,880 --> 00:05:40,120
所以fast RCN

143
00:05:40,120 --> 00:05:42,960
就是说我在RCN上面把它做快

144
00:05:44,960 --> 00:05:46,840
就是说他的想法是说

145
00:05:46,880 --> 00:05:50,600
我首先我对一个图片

146
00:05:51,000 --> 00:05:52,680
用CN抽特征

147
00:05:53,600 --> 00:05:54,600
抽完特征之后

148
00:05:54,600 --> 00:05:55,000
就是说

149
00:05:55,000 --> 00:05:56,480
我不会对每个

150
00:05:58,080 --> 00:05:58,640
anchor

151
00:05:58,640 --> 00:06:00,040
就是毛框抽特征

152
00:06:00,040 --> 00:06:01,880
我现在整张图片抽特征

153
00:06:02,120 --> 00:06:04,880
而且你不要头

154
00:06:05,080 --> 00:06:06,160
就是说中间那一节

155
00:06:06,160 --> 00:06:06,840
那么就会出来

156
00:06:06,840 --> 00:06:08,120
比如说出来一个7x7

157
00:06:08,280 --> 00:06:10,360
或者一个是14x14的

158
00:06:10,360 --> 00:06:11,440
一个feature map

159
00:06:12,439 --> 00:06:14,199
抽完之后

160
00:06:14,639 --> 00:06:19,560
然后你再对它做一个

161
00:06:19,560 --> 00:06:20,519
毛框的抽取

162
00:06:20,519 --> 00:06:23,959
就是用选择性的搜索

163
00:06:24,120 --> 00:06:25,240
selective search

164
00:06:25,279 --> 00:06:27,240
在上面去搜一个毛框

165
00:06:27,240 --> 00:06:29,079
比如说我在上面

166
00:06:29,120 --> 00:06:31,600
搜到这两个毛框

167
00:06:33,519 --> 00:06:35,079
搜到毛框之后

168
00:06:35,240 --> 00:06:36,360
在原始图片

169
00:06:36,360 --> 00:06:39,360
我把它映射到CN的输出上面

170
00:06:39,360 --> 00:06:39,720
比如说

171
00:06:39,760 --> 00:06:41,720
假设我的CN输出的是一个

172
00:06:41,720 --> 00:06:42,520
我在这个地方

173
00:06:42,680 --> 00:06:43,760
输出了一个这样子的

174
00:06:43,760 --> 00:06:46,160
一个feature map

175
00:06:46,920 --> 00:06:48,480
那么可能是比图片小一点

176
00:06:48,640 --> 00:06:49,560
就是说

177
00:06:49,560 --> 00:06:50,040
多了

178
00:06:50,040 --> 00:06:50,840
14x14

179
00:06:50,840 --> 00:06:51,600
30x30

180
00:06:51,600 --> 00:06:52,320
32

181
00:06:52,760 --> 00:06:56,040
然后我就会把我们刚刚选的毛框

182
00:06:56,240 --> 00:06:59,280
按照比例的同样在里面找出来

183
00:07:00,760 --> 00:07:01,920
比如说是

184
00:07:02,680 --> 00:07:04,000
在小的尺寸

185
00:07:04,160 --> 00:07:05,240
是这两个毛框

186
00:07:06,680 --> 00:07:08,440
在这两个毛框里面

187
00:07:08,439 --> 00:07:12,680
然后我再用ROI pooling

188
00:07:13,079 --> 00:07:16,040
对每个毛框抽取它的特征

189
00:07:16,519 --> 00:07:17,519
那么就是说

190
00:07:17,560 --> 00:07:18,560
意味着说

191
00:07:18,560 --> 00:07:20,560
比如说毛框可能会变成一个

192
00:07:20,560 --> 00:07:21,279
比如说

193
00:07:21,639 --> 00:07:22,839
二乘二的

194
00:07:23,160 --> 00:07:25,120
比如说我们把它拉成一条项链

195
00:07:25,199 --> 00:07:26,720
变成一个长纹4的一个项链

196
00:07:27,079 --> 00:07:29,360
那么毛框也会变成一个长纹4的

197
00:07:29,360 --> 00:07:29,800
项链

198
00:07:31,879 --> 00:07:35,079
所以这一块黄色这一块

199
00:07:35,279 --> 00:07:36,959
就是说对你这个图片来讲

200
00:07:37,000 --> 00:07:39,400
最后它会把一个图片变成了

201
00:07:39,440 --> 00:07:41,520
假设你有100个毛框的话

202
00:07:41,520 --> 00:07:45,080
那么它就会变成一个100×1个4的

203
00:07:45,080 --> 00:07:45,640
一个项链

204
00:07:45,640 --> 00:07:46,080
对吧

205
00:07:46,720 --> 00:07:47,960
当然你还有个通道数

206
00:07:48,280 --> 00:07:49,480
你通道数我们先不管

207
00:07:51,600 --> 00:07:52,680
变成这样之后

208
00:07:52,680 --> 00:07:55,640
然后我们再进入你的全连阶层

209
00:07:57,000 --> 00:07:58,400
那么它就是一个

210
00:07:58,680 --> 00:08:00,680
就是说你这就不需要一个SVM

211
00:08:00,880 --> 00:08:02,640
就是说不需要一个一个去做了

212
00:08:02,840 --> 00:08:04,240
我就是一次性的进去

213
00:08:04,880 --> 00:08:06,320
进入一个全连阶层之后

214
00:08:06,319 --> 00:08:09,959
然后他在上面再做一个

215
00:08:09,959 --> 00:08:12,040
比如说对每一个毛框

216
00:08:12,040 --> 00:08:13,599
那么100就是你的样本

217
00:08:14,120 --> 00:08:15,040
就100个样本

218
00:08:15,399 --> 00:08:17,439
然后再做一个预测

219
00:08:17,560 --> 00:08:19,600
就是说你是哪一个类

220
00:08:19,680 --> 00:08:23,199
和你的真实的bond box的偏移

221
00:08:26,079 --> 00:08:28,039
所以它为什么比前面快

222
00:08:28,800 --> 00:08:32,559
这是因为主要是这一块CN这一块

223
00:08:33,200 --> 00:08:36,360
它不再是对每一个毛框抽取特征

224
00:08:37,640 --> 00:08:39,920
它是对整个图片进行了抽取

225
00:08:41,920 --> 00:08:43,040
它当然有一定的好处

226
00:08:43,040 --> 00:08:43,480
对吧

227
00:08:43,800 --> 00:08:49,000
因为很多时候你毛框其实是重叠在一起的

228
00:08:49,000 --> 00:08:50,120
所以你把它比如说

229
00:08:50,120 --> 00:08:51,760
另外还有一个毛框是长这样子的

230
00:08:52,080 --> 00:08:54,000
如果你对它只抽一次的话

231
00:08:54,000 --> 00:08:55,840
那么重复的那些毛框

232
00:08:55,840 --> 00:08:59,080
他们那些地方就不需要再重复做N次了

233
00:08:59,600 --> 00:09:02,360
所以fastascm主要是说

234
00:09:03,280 --> 00:09:05,720
针对亚细安的加强是说

235
00:09:05,720 --> 00:09:08,440
不再对每一个毛框做CN的抽取

236
00:09:08,800 --> 00:09:10,840
然后一次抽取完

237
00:09:10,880 --> 00:09:14,520
然后再在抽取的特征的上面

238
00:09:14,600 --> 00:09:16,840
再去把毛框相对数给你找出来

239
00:09:16,840 --> 00:09:17,400
抽feature

240
00:09:17,400 --> 00:09:19,000
然后进入你做预测了

241
00:09:19,800 --> 00:09:21,640
这就是fastascm的做法

242
00:09:24,720 --> 00:09:25,960
fastascm之后

243
00:09:26,560 --> 00:09:30,440
它还有一个叫做fasterascm

244
00:09:31,440 --> 00:09:33,440
就是说它说我还不够快

245
00:09:33,440 --> 00:09:36,000
就fastascm其实还是挺慢的

246
00:09:36,640 --> 00:09:38,880
fasterascm还快那么一点点

247
00:09:39,640 --> 00:09:40,960
它对它的改进什么样子

248
00:09:41,560 --> 00:09:44,080
就是说选择性的搜索

249
00:09:44,280 --> 00:09:46,200
它就是一个heuristic算法

250
00:09:46,200 --> 00:09:47,720
就是一堆代码在里面

251
00:09:48,080 --> 00:09:50,680
我说这么根据它的特征来看

252
00:09:50,920 --> 00:09:53,200
应该是可能这一块应该这么做

253
00:09:53,200 --> 00:09:54,000
那一块这么做

254
00:09:55,200 --> 00:09:57,240
然后它fastascm是干嘛

255
00:09:57,399 --> 00:10:00,680
就是说我是用一个神经网络

256
00:10:00,680 --> 00:10:04,480
来替代我们之前选择性搜索的算法

257
00:10:05,240 --> 00:10:07,840
它叫rpn

258
00:10:07,840 --> 00:10:10,240
叫做region proposal network

259
00:10:12,919 --> 00:10:15,360
我们可以大概看一眼

260
00:10:15,360 --> 00:10:16,639
这个是长什么样子

261
00:10:16,840 --> 00:10:19,200
就是刚刚就是说之前这一块

262
00:10:19,200 --> 00:10:21,159
跟之前是ascm是一样的

263
00:10:21,399 --> 00:10:23,039
主要是刚刚selective

264
00:10:23,240 --> 00:10:24,960
search那一块有变化了

265
00:10:25,920 --> 00:10:26,639
我们可以看一下

266
00:10:26,639 --> 00:10:27,800
这是干什么样子

267
00:10:29,519 --> 00:10:32,240
首先CN进去

268
00:10:33,240 --> 00:10:34,720
然后把CN的输出

269
00:10:35,759 --> 00:10:36,879
这一块就是说

270
00:10:36,879 --> 00:10:38,960
ROI的pooling

271
00:10:38,960 --> 00:10:40,200
需要有CN的feature

272
00:10:40,200 --> 00:10:41,200
和你的模框

273
00:10:41,200 --> 00:10:41,680
对不对

274
00:10:41,920 --> 00:10:44,440
就是说rpn就是说

275
00:10:44,440 --> 00:10:46,360
我把CN的feature拿进来

276
00:10:46,360 --> 00:10:48,440
然后它的输出就是一堆

277
00:10:48,680 --> 00:10:51,240
我需要的比较高质量的模框

278
00:10:52,120 --> 00:10:53,280
它其实干什么事情

279
00:10:53,279 --> 00:10:54,839
它其实就是做一个

280
00:10:55,159 --> 00:10:58,480
一个超一点的一个目标检测了

281
00:10:59,759 --> 00:11:00,279
你看一下

282
00:11:01,039 --> 00:11:02,439
它一个CN进去

283
00:11:03,199 --> 00:11:06,439
它再做一层卷积层

284
00:11:06,639 --> 00:11:11,199
然后它又弄出一堆模框来

285
00:11:11,199 --> 00:11:12,959
这个模框你可以是selective

286
00:11:12,959 --> 00:11:13,519
search

287
00:11:13,519 --> 00:11:15,439
也可以是我们刚刚说的那种

288
00:11:15,559 --> 00:11:16,759
我们上一周说的那种

289
00:11:16,759 --> 00:11:18,039
就生成很多出来

290
00:11:18,639 --> 00:11:20,679
一些初始的模框

291
00:11:21,000 --> 00:11:24,040
然后你在这里面去念一个

292
00:11:24,840 --> 00:11:26,160
二分类的问题

293
00:11:26,320 --> 00:11:28,080
就是说它去预测说

294
00:11:28,080 --> 00:11:31,120
你这个模框是不是质量还不错

295
00:11:31,360 --> 00:11:32,800
就是说里面有没有框

296
00:11:32,800 --> 00:11:34,040
就你真实的物体

297
00:11:35,400 --> 00:11:37,000
和你说你这个predict

298
00:11:37,000 --> 00:11:39,840
你的真实的bound box

299
00:11:39,840 --> 00:11:41,200
是一个offset

300
00:11:41,480 --> 00:11:42,480
就是一个偏移

301
00:11:43,080 --> 00:11:44,160
就是说我就是说

302
00:11:44,200 --> 00:11:45,360
这个网络干嘛

303
00:11:45,440 --> 00:11:47,800
就是说我给你一堆

304
00:11:47,840 --> 00:11:48,720
很多的

305
00:11:48,720 --> 00:11:51,920
但是结果很差的一些模框

306
00:11:51,920 --> 00:11:53,200
我去预测说

307
00:11:53,759 --> 00:11:54,600
我的

308
00:11:54,720 --> 00:11:57,720
我需要输出一些比较好的

309
00:11:57,720 --> 00:11:58,240
模框

310
00:11:58,240 --> 00:11:59,840
给后面的大网络用

311
00:12:00,920 --> 00:12:02,000
就是说我们就预测

312
00:12:02,000 --> 00:12:02,840
这个模框好不好

313
00:12:02,840 --> 00:12:04,279
就是说你有没有真的圈住

314
00:12:04,519 --> 00:12:05,600
我感兴趣的物体

315
00:12:05,639 --> 00:12:07,120
和如果你圈住了

316
00:12:07,160 --> 00:12:08,720
是不是你还可以

317
00:12:08,759 --> 00:12:13,040
往真实的变形框更靠近一点

318
00:12:13,040 --> 00:12:15,399
使得你圈的更准一点

319
00:12:15,879 --> 00:12:17,120
然后在这个预测上面

320
00:12:17,120 --> 00:12:18,080
你会去说

321
00:12:18,360 --> 00:12:20,440
根据它的预测值

322
00:12:20,840 --> 00:12:23,240
根据你的offset用NAMS

323
00:12:23,400 --> 00:12:24,400
我们上周有讲过

324
00:12:24,960 --> 00:12:27,040
NAMS就是把一些

325
00:12:27,080 --> 00:12:30,759
类似的模框给你消掉去重

326
00:12:30,800 --> 00:12:32,520
使得你的数量变少

327
00:12:33,160 --> 00:12:34,360
所以最后的话

328
00:12:34,400 --> 00:12:36,759
它预测出来的好的模框

329
00:12:36,759 --> 00:12:38,480
会进入IOI的pooling

330
00:12:38,520 --> 00:12:40,080
然后再做一个

331
00:12:40,639 --> 00:12:42,040
但每一个类的一个预测

332
00:12:42,040 --> 00:12:43,040
再这样子过去

333
00:12:43,680 --> 00:12:44,720
所以基本上你可以认为

334
00:12:44,720 --> 00:12:46,360
RPM其实就是一个

335
00:12:46,400 --> 00:12:47,680
比较小一点的

336
00:12:47,720 --> 00:12:48,480
相对来说

337
00:12:48,480 --> 00:12:50,480
超一点的一个目标检测算法

338
00:12:51,040 --> 00:12:52,520
它会给你一堆

339
00:12:52,920 --> 00:12:53,880
这样子的

340
00:12:55,400 --> 00:12:56,520
anchor box的预测

341
00:12:56,520 --> 00:12:58,920
然后你把它做到主网络里面

342
00:13:00,120 --> 00:13:00,760
同样的话

343
00:13:02,360 --> 00:13:03,760
这个网络通常叫做

344
00:13:03,760 --> 00:13:04,640
two stage

345
00:13:04,640 --> 00:13:06,760
就是说有两块

346
00:13:06,760 --> 00:13:08,120
一块是这一块

347
00:13:08,280 --> 00:13:09,600
这是个小的网络

348
00:13:09,920 --> 00:13:11,000
另外一块是大的网络

349
00:13:11,000 --> 00:13:13,000
它就是做两次预测

350
00:13:13,120 --> 00:13:15,960
通常被认为是两个

351
00:13:16,000 --> 00:13:17,800
就是说先做一个超一点的预测

352
00:13:17,800 --> 00:13:19,639
然后再做一个更精准的预测

353
00:13:20,080 --> 00:13:22,200
就是两个stage

354
00:13:23,639 --> 00:13:25,080
fast RCA

355
00:13:25,120 --> 00:13:25,759
目前来说

356
00:13:25,759 --> 00:13:28,120
是用的比较多的一个算法

357
00:13:28,240 --> 00:13:28,680
相对来说

358
00:13:28,680 --> 00:13:30,639
它是准序率还挺高的

359
00:13:30,680 --> 00:13:31,320
但是相对来说

360
00:13:31,320 --> 00:13:32,480
它还是挺慢的

361
00:13:32,519 --> 00:13:34,240
虽然叫做faster RCA

362
00:13:34,240 --> 00:13:35,960
但实际上相对来说

363
00:13:35,960 --> 00:13:37,280
还是比较慢的一个算法

364
00:13:38,600 --> 00:13:39,200
另外一个

365
00:13:39,440 --> 00:13:42,360
它的之后的一个改进

366
00:13:42,360 --> 00:13:43,720
叫做mask RCA

367
00:13:44,720 --> 00:13:45,840
这mask RCA

368
00:13:45,840 --> 00:13:47,200
其实基本上就是说

369
00:13:47,560 --> 00:13:48,399
跟fast RCA

370
00:13:48,399 --> 00:13:49,320
没什么太多区别

371
00:13:49,320 --> 00:13:50,000
就是说

372
00:13:50,040 --> 00:13:51,879
你们可以看到这一块是一样的

373
00:13:51,879 --> 00:13:52,920
这一块就是

374
00:13:52,960 --> 00:13:54,840
fast RCA里面的那一块

375
00:13:55,600 --> 00:13:57,840
RPN就是你fast RCA的

376
00:13:57,840 --> 00:13:58,680
那一个网络

377
00:13:59,120 --> 00:14:00,759
但它又加了一个新的东西

378
00:14:01,160 --> 00:14:01,920
就是说

379
00:14:02,160 --> 00:14:06,720
假设你有每一个像素的编号

380
00:14:07,279 --> 00:14:08,519
我们之后会来讲

381
00:14:08,759 --> 00:14:10,639
就我们在下一个星期

382
00:14:10,639 --> 00:14:12,040
会给大家讲这个事情

383
00:14:12,319 --> 00:14:14,199
就假设你有每一个像素

384
00:14:14,199 --> 00:14:15,199
它的编号的话

385
00:14:15,240 --> 00:14:17,759
那么我可以对每个像素做预测

386
00:14:18,319 --> 00:14:19,360
比如很多数据集是有的

387
00:14:19,559 --> 00:14:22,759
coco数据集是有一些像素级的编号

388
00:14:23,039 --> 00:14:25,319
你看像在像素级的那些

389
00:14:26,319 --> 00:14:27,559
就叫做semantic experimentation

390
00:14:27,679 --> 00:14:28,559
我们之后会讲

391
00:14:28,559 --> 00:14:29,279
予以分割

392
00:14:30,679 --> 00:14:32,719
它如果你有这个信息的话

393
00:14:32,759 --> 00:14:34,519
它在你的ROI

394
00:14:35,599 --> 00:14:36,439
出来东西里面

395
00:14:37,120 --> 00:14:40,879
然后再进去一个叫FCM

396
00:14:40,879 --> 00:14:42,439
FCM我们之后会讲

397
00:14:42,480 --> 00:14:43,639
先不给大家讲了

398
00:14:43,639 --> 00:14:45,240
就是说说说白了

399
00:14:45,240 --> 00:14:48,360
就是对每一个像素去预测的编号

400
00:14:48,399 --> 00:14:49,799
然后再加上它的

401
00:14:50,000 --> 00:14:52,439
额外的 mask prediction的一个loss

402
00:14:52,759 --> 00:14:53,720
就等于是说

403
00:14:53,759 --> 00:14:55,799
它的这一块出去之后

404
00:14:55,799 --> 00:14:58,120
能够去拿到

405
00:14:59,679 --> 00:15:00,600
因为更多的编号

406
00:15:00,720 --> 00:15:01,960
所以我用这个编号

407
00:15:01,960 --> 00:15:03,039
这一块做的预测

408
00:15:03,039 --> 00:15:05,799
能够反过来提升我这一块的性能

409
00:15:05,960 --> 00:15:07,200
整个CM的性能

410
00:15:08,679 --> 00:15:10,639
当然另外一块你能看到是说

411
00:15:11,039 --> 00:15:13,399
这里以前叫做

412
00:15:13,919 --> 00:15:15,759
ROI

413
00:15:16,759 --> 00:15:17,879
就是ROI pooling

414
00:15:17,919 --> 00:15:19,639
现在变成ROI align

415
00:15:20,840 --> 00:15:21,240
为什么

416
00:15:21,240 --> 00:15:22,480
他改了一下这个地方

417
00:15:23,200 --> 00:15:24,720
之前的pooling是说

418
00:15:24,720 --> 00:15:25,360
回忆一下

419
00:15:25,360 --> 00:15:26,919
我们假设你是一个

420
00:15:26,919 --> 00:15:28,559
三乘三的像素的话

421
00:15:29,320 --> 00:15:32,120
我要你的区是一个三乘三的话

422
00:15:32,159 --> 00:15:33,679
我的pooling是二乘二的话

423
00:15:33,720 --> 00:15:36,799
那么第一块它不是放在正中间了

424
00:15:36,799 --> 00:15:37,759
不是像素正中间

425
00:15:37,759 --> 00:15:40,120
因为你的像素不能整除了

426
00:15:40,560 --> 00:15:42,120
所以它第一块就是二

427
00:15:42,320 --> 00:15:42,960
第二块是一

428
00:15:42,960 --> 00:15:44,759
所以它的边框是不对的

429
00:15:46,080 --> 00:15:48,480
这个东西对于目标检测没问题

430
00:15:48,480 --> 00:15:49,120
目标检测

431
00:15:49,120 --> 00:15:51,560
你的框都是像素级别的

432
00:15:51,919 --> 00:15:54,360
就是说你那么一点点问题不大

433
00:15:54,519 --> 00:15:57,159
但是对于像素级别的标号

434
00:15:57,360 --> 00:15:58,440
这个是很大问题的

435
00:15:58,480 --> 00:16:00,240
因为一个像素

436
00:16:00,240 --> 00:16:02,879
你说我标的像素是属于人

437
00:16:02,919 --> 00:16:04,039
而不是属于背景

438
00:16:04,039 --> 00:16:06,519
然后你在ROI的时候

439
00:16:06,519 --> 00:16:08,200
你不断的rounding

440
00:16:08,200 --> 00:16:09,759
搞到最后

441
00:16:09,919 --> 00:16:11,639
可能会带来一些误差

442
00:16:12,159 --> 00:16:13,799
误差可能会带来你像素级

443
00:16:13,799 --> 00:16:14,519
一个像素两个

444
00:16:14,519 --> 00:16:15,720
你累积很多的话

445
00:16:16,000 --> 00:16:17,960
会带来像素级的偏移

446
00:16:18,240 --> 00:16:19,080
像素级的偏移

447
00:16:19,080 --> 00:16:21,439
会导致你说你在边界的地方

448
00:16:21,439 --> 00:16:23,120
你的标号是预测不准的

449
00:16:23,360 --> 00:16:26,519
所以就说ROI align的意思是说

450
00:16:26,519 --> 00:16:27,879
我就不切了

451
00:16:28,559 --> 00:16:29,679
我就是

452
00:16:30,279 --> 00:16:32,159
我就是按照

453
00:16:33,439 --> 00:16:34,120
就画一下

454
00:16:34,919 --> 00:16:36,240
就假设我是一个三乘三

455
00:16:37,759 --> 00:16:38,759
ROI的话

456
00:16:38,840 --> 00:16:39,720
就是说

457
00:16:40,120 --> 00:16:41,679
之前我们是要这么切

458
00:16:41,679 --> 00:16:42,200
对吧

459
00:16:42,679 --> 00:16:44,279
就是说是这么切二乘二的话

460
00:16:44,279 --> 00:16:45,200
就是说align的话

461
00:16:45,200 --> 00:16:47,120
我就是直接在中间切开了

462
00:16:47,679 --> 00:16:48,399
中间切开

463
00:16:48,399 --> 00:16:50,240
那么就是说你在算值的时候

464
00:16:50,759 --> 00:16:51,759
看切在什么地方

465
00:16:52,279 --> 00:16:53,439
最后算值的时候

466
00:16:53,439 --> 00:16:54,439
每一个值

467
00:16:54,439 --> 00:16:55,919
每一个它的像素值

468
00:16:56,319 --> 00:16:57,840
是整个东西的一个

469
00:16:57,840 --> 00:16:59,399
你可以认为是一个加权

470
00:16:59,639 --> 00:17:02,879
就是说把一个像素真的给你切开

471
00:17:02,879 --> 00:17:04,799
然后里面加上weight

472
00:17:04,839 --> 00:17:05,839
就看你切在什么地方

473
00:17:05,839 --> 00:17:07,480
所以这个地方拿到了值

474
00:17:07,519 --> 00:17:09,839
是你像素的那一部分

475
00:17:10,839 --> 00:17:11,200
OK

476
00:17:11,200 --> 00:17:14,400
就是说你在做max的时候

477
00:17:14,680 --> 00:17:16,000
所以它的就是说

478
00:17:16,000 --> 00:17:17,519
或者在做sum的时候

479
00:17:17,799 --> 00:17:18,680
这个像素当然是说

480
00:17:18,680 --> 00:17:19,759
因为你只拿了一块

481
00:17:19,920 --> 00:17:21,400
所以你只拿到这一像素

482
00:17:21,400 --> 00:17:24,039
它对应的那一块的一个一小块值

483
00:17:24,279 --> 00:17:26,000
这就是大概的思想

484
00:17:26,160 --> 00:17:30,680
它主要是为了你在做像素级别预测时候

485
00:17:30,680 --> 00:17:32,200
你在边界的时候

486
00:17:32,200 --> 00:17:35,000
你回去再回来的时候

487
00:17:35,440 --> 00:17:37,079
不要发生太多的错位

488
00:17:37,279 --> 00:17:37,599
OK

489
00:17:37,599 --> 00:17:41,000
这也是它的一个主要的改进

490
00:17:43,240 --> 00:17:44,359
然后我们来看一下

491
00:17:44,359 --> 00:17:45,039
就是说

492
00:17:46,119 --> 00:17:48,279
这个是我们的

493
00:17:48,279 --> 00:17:50,759
比如我们收集的一些模型的

494
00:17:50,759 --> 00:17:52,799
一些精度的比较

495
00:17:53,559 --> 00:17:55,439
Axle是你的样本

496
00:17:55,439 --> 00:17:56,159
per second

497
00:17:56,159 --> 00:17:57,639
就是说你跑得多快

498
00:17:57,919 --> 00:17:59,559
越这边是跑得越快的

499
00:17:59,839 --> 00:18:01,519
越左边是跑得越慢

500
00:18:01,639 --> 00:18:05,399
就是说这个只是每秒钟能够处理多少个样本

501
00:18:06,400 --> 00:18:09,759
Y轴就在MAP

502
00:18:10,240 --> 00:18:11,519
就MAP你可以简单认为

503
00:18:11,519 --> 00:18:17,240
就是你的边界框的预测的精度

504
00:18:18,759 --> 00:18:21,000
然后当然是越高越好了

505
00:18:21,000 --> 00:18:21,680
就是说

506
00:18:21,680 --> 00:18:23,320
所以你最好的地方

507
00:18:23,320 --> 00:18:25,360
应该是这个点是最好的

508
00:18:25,800 --> 00:18:27,200
就跑得越快

509
00:18:27,320 --> 00:18:28,600
你精度越高

510
00:18:29,320 --> 00:18:30,160
但实际上来说

511
00:18:30,160 --> 00:18:30,960
你很难做到

512
00:18:32,080 --> 00:18:34,080
所以看到是说fast RCM

513
00:18:34,839 --> 00:18:35,720
它有很多变种

514
00:18:36,000 --> 00:18:38,439
就是说还是要能以框的大小

515
00:18:38,439 --> 00:18:40,199
表示你的内存的使用

516
00:18:40,199 --> 00:18:43,199
然后这一块就是说

517
00:18:43,199 --> 00:18:45,960
可以认为fast RCM是相对来说

518
00:18:46,199 --> 00:18:47,159
精度比较高

519
00:18:47,159 --> 00:18:48,359
因为越高越好

520
00:18:48,559 --> 00:18:50,559
别的模型的精度都没到这个地方

521
00:18:50,559 --> 00:18:52,439
所以它可以做到特别高

522
00:18:53,000 --> 00:18:54,119
但是它的问题是说

523
00:18:54,119 --> 00:18:55,759
你精度最高的模型

524
00:18:56,319 --> 00:18:58,240
它的计算是非常贵的

525
00:18:58,279 --> 00:19:00,799
所以你可能每秒钟能处理一个

526
00:19:00,799 --> 00:19:03,519
我想想能够几张样本的样子

527
00:19:04,359 --> 00:19:07,480
但是说当你可以把你的backbone

528
00:19:07,759 --> 00:19:09,960
就是你的CNN的网络搞简单一点

529
00:19:09,960 --> 00:19:10,879
然后里面的东西

530
00:19:11,199 --> 00:19:13,439
那些毛框的生成搞简单一点

531
00:19:13,439 --> 00:19:16,639
你可以把性能提升

532
00:19:17,240 --> 00:19:19,679
就是说每秒钟处理的样本数会增加

533
00:19:19,799 --> 00:19:22,000
但是它的精度会下降

534
00:19:22,000 --> 00:19:24,079
就是说下降的还是不慢

535
00:19:25,319 --> 00:19:27,079
所以到这个点的时候

536
00:19:27,079 --> 00:19:28,199
你可以发现说

537
00:19:29,599 --> 00:19:30,559
比你精度

538
00:19:30,919 --> 00:19:32,159
就是说比你速快很多

539
00:19:32,159 --> 00:19:33,599
三有可能精度跟你差不多

540
00:19:33,680 --> 00:19:35,520
所以FastR-CNN

541
00:19:35,520 --> 00:19:37,760
主要应用在你对精度

542
00:19:37,760 --> 00:19:39,280
特别关心的时候

543
00:19:39,280 --> 00:19:40,000
应用场景

544
00:19:40,280 --> 00:19:42,120
大家会用FastR-CNN这个系列

545
00:19:42,120 --> 00:19:44,280
比如说你要特别关心

546
00:19:44,280 --> 00:19:45,080
比如说你要刷

547
00:19:45,080 --> 00:19:46,080
刷刷宝

548
00:19:46,200 --> 00:19:46,960
刷刷paper

549
00:19:47,320 --> 00:19:50,680
刷刷比如说某些数据的榜案

550
00:19:50,800 --> 00:19:52,400
或者是说我要达到精算

551
00:19:52,800 --> 00:19:54,600
FastR-CNN还是用的比较多

552
00:19:54,760 --> 00:19:56,480
但在工业界的话

553
00:19:56,480 --> 00:19:58,040
FastR-CNN就是说

554
00:19:58,080 --> 00:19:58,920
在很多情况下

555
00:19:58,920 --> 00:20:00,240
大家会关心速度

556
00:20:00,240 --> 00:20:02,160
因为目标检测算法

557
00:20:02,160 --> 00:20:04,720
远远的比图片分类算法要贵很多

558
00:20:05,920 --> 00:20:06,320
OK

559
00:20:06,320 --> 00:20:10,720
这就是一个非常简单的

560
00:20:10,960 --> 00:20:12,840
R-CNN系列的介绍

561
00:20:13,400 --> 00:20:14,080
总结一下

562
00:20:14,080 --> 00:20:14,800
就是说

563
00:20:15,360 --> 00:20:18,320
R-CNN是最早

564
00:20:18,320 --> 00:20:20,840
也是最有名的一类

565
00:20:20,840 --> 00:20:22,440
基于模框的

566
00:20:22,519 --> 00:20:24,440
和CNN的目标检测算法

567
00:20:25,640 --> 00:20:26,360
就是R-CNN

568
00:20:26,360 --> 00:20:27,480
就是说你可以认为是

569
00:20:27,480 --> 00:20:29,920
用神经网络来做目标检测的

570
00:20:29,920 --> 00:20:31,200
电极性工作之一

571
00:20:31,759 --> 00:20:33,240
然后之后也是说

572
00:20:33,279 --> 00:20:36,400
作者们在持续对它进行改进

573
00:20:36,960 --> 00:20:38,000
Fast系列

574
00:20:38,039 --> 00:20:38,640
FastR

575
00:20:38,640 --> 00:20:39,319
Mask

576
00:20:39,360 --> 00:20:40,480
一直是这个系列

577
00:20:40,519 --> 00:20:42,039
也就是一直在对它改进

578
00:20:42,640 --> 00:20:45,319
然后做这一系列的大神

579
00:20:45,840 --> 00:20:48,160
也是整个

580
00:20:48,799 --> 00:20:50,279
就是说在目标检测系列

581
00:20:50,279 --> 00:20:51,759
最厉害的一个组了

582
00:20:53,000 --> 00:20:54,440
就是说R-CNN出来之后

583
00:20:54,559 --> 00:20:56,240
之后的Fast和FastR

584
00:20:56,240 --> 00:20:58,319
都是在持续的提升性了

585
00:20:58,839 --> 00:21:01,759
而且FastR-CNN和MaskR-CNN

586
00:21:01,759 --> 00:21:03,480
现在主要用在是说

587
00:21:03,519 --> 00:21:05,559
高精度场景下的算法

588
00:21:05,720 --> 00:21:07,399
而且Mask这个系列

589
00:21:07,399 --> 00:21:08,399
需要拥有

590
00:21:08,879 --> 00:21:10,679
每个像素级别的标号

591
00:21:10,679 --> 00:21:11,480
所以相对来说

592
00:21:11,480 --> 00:21:13,279
它的局限性也大一点

593
00:21:13,319 --> 00:21:14,079
但反过来讲

594
00:21:14,079 --> 00:21:14,919
在无人车领域

595
00:21:15,159 --> 00:21:16,119
就是说你可以

596
00:21:16,119 --> 00:21:17,879
你无人车通常会标

597
00:21:17,879 --> 00:21:19,200
每个像素的标号

598
00:21:19,200 --> 00:21:21,960
所以MaskR-CNN在无人车这一块

599
00:21:21,960 --> 00:21:23,439
拥用是用的比较多的

600
00:21:24,000 --> 00:21:24,559
OK

601
00:21:28,480 --> 00:21:29,200
我们做了一个

602
00:21:29,200 --> 00:21:31,159
很简单的R-CNN系列的介绍

603
00:21:31,439 --> 00:21:33,599
接下来我们再介绍

604
00:21:33,599 --> 00:21:34,960
另外两个系列

605
00:21:35,399 --> 00:21:37,399
然后我们再来做同一个QA

606
00:21:38,839 --> 00:21:40,240
另外一个系列叫做

607
00:21:41,559 --> 00:21:43,399
Single Shot Detection

608
00:21:44,599 --> 00:21:45,599
就这个翻译

609
00:21:46,000 --> 00:21:47,799
我们上个星期跟

610
00:21:48,159 --> 00:21:49,720
周志华老师李航老师

611
00:21:49,759 --> 00:21:50,279
有讨论

612
00:21:50,279 --> 00:21:51,480
就Shot这个东西

613
00:21:51,480 --> 00:21:53,039
我翻译成发是不对的

614
00:21:53,439 --> 00:21:55,079
就Single Shot Detection

615
00:21:55,079 --> 00:21:55,839
就Single Shot

616
00:21:55,839 --> 00:21:56,480
就Single Shot

617
00:21:56,480 --> 00:21:58,039
当你去看翻译的话

618
00:21:58,159 --> 00:22:00,039
就是单发的步枪

619
00:22:00,240 --> 00:22:01,279
但实际上Shot

620
00:22:01,720 --> 00:22:03,039
这东西就可以认为是

621
00:22:04,680 --> 00:22:05,599
看一遍的意思

622
00:22:05,599 --> 00:22:06,839
就是跑一遍的意思

623
00:22:08,000 --> 00:22:11,119
就是说它的核心思想是说

624
00:22:11,119 --> 00:22:12,799
你们R-CNN系列

625
00:22:13,079 --> 00:22:14,960
就是主要是要做两个

626
00:22:14,960 --> 00:22:16,440
就是说有个RPN

627
00:22:16,680 --> 00:22:18,039
你还有一个主的网络

628
00:22:18,039 --> 00:22:19,000
就是说给一个图片过来

629
00:22:19,000 --> 00:22:20,920
我得做两次预测

630
00:22:21,039 --> 00:22:21,879
SSD就是说

631
00:22:21,879 --> 00:22:23,319
我就一次就过去了

632
00:22:23,319 --> 00:22:25,240
就不要再做两个stage了

633
00:22:25,240 --> 00:22:26,920
就只要做Single Stage

634
00:22:27,480 --> 00:22:29,519
它也就取名叫Single Shot

635
00:22:29,840 --> 00:22:32,000
所以SSD这个名字

636
00:22:32,000 --> 00:22:32,880
也是坑了很多人

637
00:22:32,880 --> 00:22:36,279
就是说我知道很多人分不清楚

638
00:22:36,279 --> 00:22:38,080
我们大家SSD这个东西

639
00:22:38,080 --> 00:22:39,560
就说大家一般是

640
00:22:40,360 --> 00:22:42,240
是想的是硬盘

641
00:22:42,240 --> 00:22:43,080
固态硬盘

642
00:22:43,279 --> 00:22:45,600
所以经常会我们一起开会说

643
00:22:45,600 --> 00:22:46,440
我们再说这个

644
00:22:46,440 --> 00:22:47,360
别人再说那个

645
00:22:47,360 --> 00:22:48,480
但是很几年前了

646
00:22:48,480 --> 00:22:50,200
现在的SSD用的不那么多

647
00:22:52,840 --> 00:22:54,960
首先SSD它的主要的一个思想

648
00:22:54,960 --> 00:22:56,120
是说我们

649
00:22:56,920 --> 00:22:57,759
之前有讲过

650
00:22:57,759 --> 00:22:59,160
就是说它对每个像素

651
00:22:59,279 --> 00:23:02,360
生成以它为中心的多个模框

652
00:23:03,400 --> 00:23:05,480
假设给你N个大小

653
00:23:05,480 --> 00:23:06,759
S1到SN的话

654
00:23:06,759 --> 00:23:08,279
N个高宽比的话

655
00:23:08,279 --> 00:23:09,200
就是Ratio的话

656
00:23:09,200 --> 00:23:11,759
它会生成N加M减一个模框

657
00:23:12,000 --> 00:23:13,360
对每个像素为中心

658
00:23:13,759 --> 00:23:15,600
所以它大小比分别是这样子

659
00:23:15,600 --> 00:23:17,960
我们在上个星期有讲过这个模型

660
00:23:17,960 --> 00:23:21,080
我们就不给大家再重复介绍了

661
00:23:21,200 --> 00:23:23,600
就是说它的生成模框就很简单

662
00:23:24,000 --> 00:23:26,560
就是说跟RCNN系列比

663
00:23:27,640 --> 00:23:32,080
然后它就是说给定那么多模框

664
00:23:32,080 --> 00:23:34,560
它就对那么多模框直接做预测了

665
00:23:34,560 --> 00:23:36,519
就不需要再做两个stage了

666
00:23:37,240 --> 00:23:38,120
具体来看

667
00:23:38,840 --> 00:23:40,800
就是说它说一个

668
00:23:43,080 --> 00:23:44,000
一个

669
00:23:46,519 --> 00:23:47,519
图片过来

670
00:23:48,600 --> 00:23:50,039
它先抽特征

671
00:23:50,080 --> 00:23:52,000
就是说有个比如说有个base的

672
00:23:52,000 --> 00:23:54,039
一个网络抽特征

673
00:23:54,039 --> 00:23:56,240
就是一个简单的一个CNN抽特征

674
00:23:56,680 --> 00:23:57,480
抽完之后

675
00:23:58,480 --> 00:24:00,759
然后对它每个特征的话

676
00:24:00,759 --> 00:24:01,680
就是说它也是一个

677
00:24:01,720 --> 00:24:04,680
比如说比如说NxN的一个网络

678
00:24:06,680 --> 00:24:07,480
一个网络的话

679
00:24:07,480 --> 00:24:08,519
那么就是说

680
00:24:08,920 --> 00:24:11,720
它对每一个像素里面的每一个像素

681
00:24:11,759 --> 00:24:14,200
它就会按照刚才算法

682
00:24:14,240 --> 00:24:16,000
去生成它的模框

683
00:24:17,160 --> 00:24:18,319
对每个模框的话

684
00:24:18,319 --> 00:24:19,200
就会变成一个样本

685
00:24:19,200 --> 00:24:19,720
对吧

686
00:24:20,400 --> 00:24:21,400
它每个模框的话

687
00:24:21,400 --> 00:24:23,240
那就是会去预测它类

688
00:24:24,000 --> 00:24:25,680
它是不是圈出了背景

689
00:24:25,680 --> 00:24:27,120
还是圈出了某个类

690
00:24:27,400 --> 00:24:28,720
然后以及说这个模框

691
00:24:28,720 --> 00:24:32,120
到真实边界框的一个预测

692
00:24:34,480 --> 00:24:36,120
就为什么你说

693
00:24:36,160 --> 00:24:37,480
FastRCNN系列

694
00:24:37,480 --> 00:24:38,440
你要做两次

695
00:24:38,600 --> 00:24:39,799
你SSC只要做一次

696
00:24:40,240 --> 00:24:41,360
是因为是说

697
00:24:41,400 --> 00:24:45,360
SSC说我通过做多个层的

698
00:24:45,360 --> 00:24:47,320
就是说做多个

699
00:24:47,360 --> 00:24:49,400
分辨率下的一个检测

700
00:24:49,400 --> 00:24:51,240
来提升我的一些效果

701
00:24:51,360 --> 00:24:52,680
就是说下面这个网络

702
00:24:52,840 --> 00:24:55,600
相对来说是比较底层的网络

703
00:24:55,600 --> 00:24:57,360
它拿到的

704
00:24:57,640 --> 00:24:58,480
就feature map

705
00:24:58,480 --> 00:24:59,400
就是你那抽出来

706
00:24:59,400 --> 00:25:00,600
特征相对是比较大的

707
00:25:00,640 --> 00:25:01,960
比如说会有那么大

708
00:25:03,840 --> 00:25:05,000
那么在上一层

709
00:25:05,120 --> 00:25:07,000
你就不断的网络进去的话

710
00:25:07,000 --> 00:25:07,480
我们知道

711
00:25:07,480 --> 00:25:09,480
我们会通常会喜欢把它减半

712
00:25:09,480 --> 00:25:10,400
减半再减半

713
00:25:10,520 --> 00:25:11,720
所以拿到它的时候

714
00:25:12,200 --> 00:25:13,920
它可能它的变小了

715
00:25:13,920 --> 00:25:14,880
它可能会变得更小

716
00:25:14,880 --> 00:25:15,840
它的输出

717
00:25:16,560 --> 00:25:18,800
所以在这个上面做的话

718
00:25:18,800 --> 00:25:19,800
这个可能就变成一个

719
00:25:19,800 --> 00:25:21,160
比如说4×4的

720
00:25:21,400 --> 00:25:23,800
这是比如说16×16的

721
00:25:24,119 --> 00:25:25,680
或者是比如说

722
00:25:26,279 --> 00:25:28,159
64×64

723
00:25:29,200 --> 00:25:30,919
就是说你在这个上面

724
00:25:31,159 --> 00:25:32,039
标毛框的话

725
00:25:32,039 --> 00:25:33,159
比如说我在这个地方

726
00:25:33,159 --> 00:25:34,279
标一些毛框

727
00:25:36,000 --> 00:25:37,720
我在这个地方也标毛框

728
00:25:38,359 --> 00:25:40,559
假设毛框的大小都差不多的话

729
00:25:41,159 --> 00:25:42,559
那么你可以认为是说

730
00:25:43,279 --> 00:25:44,720
在底层的话

731
00:25:44,720 --> 00:25:48,079
它通常会去检测一些小的物体

732
00:25:48,440 --> 00:25:48,759
对吧

733
00:25:48,759 --> 00:25:50,079
因为你相对来说图片

734
00:25:50,079 --> 00:25:51,119
你是狗狗

735
00:25:51,119 --> 00:25:52,240
比如说你这里有个

736
00:25:52,240 --> 00:25:53,159
真的有个物体的话

737
00:25:53,160 --> 00:25:55,080
它对检测小物体比较在行

738
00:25:56,000 --> 00:25:57,640
你越往上面走的话

739
00:25:57,680 --> 00:25:59,519
你的东西越小的话

740
00:25:59,519 --> 00:26:01,400
你的图片被压得越狠的话

741
00:26:01,400 --> 00:26:02,640
那么你的毛框相对来说

742
00:26:02,640 --> 00:26:04,759
还是不那么小

743
00:26:04,759 --> 00:26:05,640
毛框你不能太小

744
00:26:05,640 --> 00:26:05,840
对吧

745
00:26:05,840 --> 00:26:07,240
你总得有一两个像素

746
00:26:07,240 --> 00:26:07,720
对吧

747
00:26:07,920 --> 00:26:09,600
所以它就可以去做

748
00:26:09,600 --> 00:26:11,320
比较大的物体的检测了

749
00:26:12,920 --> 00:26:14,440
所以它的一个主要的思想

750
00:26:14,440 --> 00:26:15,320
在于是说

751
00:26:15,800 --> 00:26:18,560
我会做一个多个

752
00:26:18,920 --> 00:26:20,440
多个分辨率下来

753
00:26:20,440 --> 00:26:21,360
就越底层

754
00:26:21,360 --> 00:26:22,880
它会和一些小物体

755
00:26:22,880 --> 00:26:23,960
越到顶部来

756
00:26:23,960 --> 00:26:25,800
去看那些大物体

757
00:26:26,600 --> 00:26:29,360
这就是SSD的

758
00:26:29,360 --> 00:26:30,600
它的主要的想法

759
00:26:31,200 --> 00:26:32,680
然后另外一个是

760
00:26:32,680 --> 00:26:34,240
它跟之前主要的区别

761
00:26:34,680 --> 00:26:35,520
就是说

762
00:26:35,720 --> 00:26:38,040
它不再是有一个RPN的网络

763
00:26:38,040 --> 00:26:40,880
它就是整所有的Encodebox

764
00:26:40,880 --> 00:26:43,640
就是有100万个

765
00:26:43,800 --> 00:26:45,200
可能会生成你图片比较大的

766
00:26:45,200 --> 00:26:47,520
我们有上个星期有看到

767
00:26:47,560 --> 00:26:49,080
可能一张图片

768
00:26:49,080 --> 00:26:52,440
可以生成100万个样本

769
00:26:52,440 --> 00:26:54,400
然后在每个样本上

770
00:26:54,400 --> 00:26:55,400
直接去预测

771
00:26:55,400 --> 00:26:57,400
它是不是还有我的物体

772
00:26:57,440 --> 00:26:59,200
以及它如果是的话

773
00:26:59,200 --> 00:27:01,039
它到真实的边界框的

774
00:27:02,440 --> 00:27:03,440
是怎么过去的

775
00:27:04,840 --> 00:27:06,559
这就是SSD的算法

776
00:27:08,160 --> 00:27:09,559
SSD这个算法

777
00:27:09,720 --> 00:27:12,039
就是说可以看到是

778
00:27:12,279 --> 00:27:13,559
在这个地方

779
00:27:16,600 --> 00:27:18,160
SSD是绿色的点

780
00:27:19,920 --> 00:27:21,320
绿色的点是SSD

781
00:27:21,519 --> 00:27:22,319
可以看到是说

782
00:27:22,319 --> 00:27:24,359
它相对来说是比较快的

783
00:27:24,519 --> 00:27:25,279
相对来说

784
00:27:25,279 --> 00:27:27,200
FastRCN是这个地方

785
00:27:27,519 --> 00:27:28,240
它相对来说

786
00:27:28,240 --> 00:27:29,439
速度是比较快的

787
00:27:29,919 --> 00:27:31,319
但是它的精度

788
00:27:31,679 --> 00:27:33,200
不是很怎么样

789
00:27:33,200 --> 00:27:34,319
就是绿色这一块

790
00:27:35,399 --> 00:27:36,240
它有很多原因

791
00:27:36,439 --> 00:27:37,879
主要是它其实做的

792
00:27:37,879 --> 00:27:39,759
比较早的一个网络

793
00:27:39,879 --> 00:27:40,839
SSD出来的时候

794
00:27:40,839 --> 00:27:42,720
还是很早以前

795
00:27:43,200 --> 00:27:44,240
然后它出来之后

796
00:27:44,359 --> 00:27:45,559
作者出来之后

797
00:27:45,559 --> 00:27:47,839
就没有再去做过了

798
00:27:48,279 --> 00:27:49,039
就是说

799
00:27:49,079 --> 00:27:50,000
你可以认为

800
00:27:50,319 --> 00:27:51,559
同样一个东西

801
00:27:51,839 --> 00:27:53,839
在

802
00:27:54,440 --> 00:27:56,799
你几年前做出来的话

803
00:27:56,799 --> 00:27:58,159
因为在过去几年里面

804
00:27:58,159 --> 00:28:00,119
各种细节有大量的出来

805
00:28:00,240 --> 00:28:01,799
就是说比如说

806
00:28:01,839 --> 00:28:02,799
Batch Normalization

807
00:28:03,079 --> 00:28:03,720
以及各种

808
00:28:03,720 --> 00:28:04,799
比如说我们今天

809
00:28:05,119 --> 00:28:06,639
给大家讲到一些比赛里面

810
00:28:06,639 --> 00:28:07,359
各种trick

811
00:28:07,879 --> 00:28:09,159
这些trick是说

812
00:28:09,759 --> 00:28:10,920
比如说你在5年前

813
00:28:10,920 --> 00:28:11,759
我给你一个数据机

814
00:28:11,759 --> 00:28:12,559
你一个PhD

815
00:28:12,559 --> 00:28:14,279
你能刷到98% 99%

816
00:28:14,279 --> 00:28:14,879
你可以写一篇

817
00:28:14,879 --> 00:28:16,399
很好的CVPR的文章了

818
00:28:16,559 --> 00:28:17,720
现在大家基本上

819
00:28:18,120 --> 00:28:18,799
这些技术

820
00:28:18,799 --> 00:28:19,799
可以随便拿过来用

821
00:28:19,799 --> 00:28:20,880
就是说基本上

822
00:28:20,880 --> 00:28:22,519
很多人可以做到98% 99%

823
00:28:22,519 --> 00:28:23,720
如果你再把它写论文

824
00:28:23,720 --> 00:28:25,039
可能是不会有人理你了

825
00:28:25,480 --> 00:28:26,360
所以是说

826
00:28:26,360 --> 00:28:28,120
在过去那么多年里面

827
00:28:28,640 --> 00:28:30,759
细节上有特别多提升

828
00:28:31,440 --> 00:28:33,720
所以SSD你想要提升的话

829
00:28:33,720 --> 00:28:34,680
你需要作者

830
00:28:34,680 --> 00:28:35,880
或需要有人

831
00:28:35,920 --> 00:28:36,839
去持续的

832
00:28:36,839 --> 00:28:38,519
把那些新的技术加进来

833
00:28:38,519 --> 00:28:42,720
叫SSD V2 V3 V4

834
00:28:42,720 --> 00:28:43,600
就是说你会

835
00:28:43,600 --> 00:28:44,360
你这样子的话

836
00:28:44,360 --> 00:28:46,720
能够在核心的思想下面

837
00:28:46,720 --> 00:28:47,799
持续的提升

838
00:28:47,839 --> 00:28:49,839
但是SSD的作者

839
00:28:50,680 --> 00:28:51,600
也是个中国小哥

840
00:28:52,079 --> 00:28:52,880
就是

841
00:28:53,920 --> 00:28:55,480
你就做完就走了

842
00:28:55,839 --> 00:28:56,920
所以就是说

843
00:28:56,920 --> 00:28:58,960
所以你现在再反过来看SSD

844
00:28:58,960 --> 00:29:00,160
它跟别人比

845
00:29:00,160 --> 00:29:02,200
精度是比较划不来的

846
00:29:02,640 --> 00:29:03,279
但反过来讲

847
00:29:03,279 --> 00:29:04,960
SSD它是一个

848
00:29:04,960 --> 00:29:06,279
确实是一个

849
00:29:06,680 --> 00:29:08,839
把之前的模型做了淡然减缓

850
00:29:08,839 --> 00:29:11,279
启发了后面一系列的工作

851
00:29:11,279 --> 00:29:12,279
所以就是为什么

852
00:29:12,279 --> 00:29:13,640
我们也给大家讲一下

853
00:29:13,640 --> 00:29:14,960
这个工作

854
00:29:14,960 --> 00:29:17,240
甚至说我们会给大家去实现

855
00:29:17,240 --> 00:29:18,720
SSD是怎么实现的

856
00:29:19,079 --> 00:29:20,559
主要是因为它相对来说

857
00:29:20,559 --> 00:29:21,400
比较简单

858
00:29:21,960 --> 00:29:24,799
而RCN系列实现就非常的难

859
00:29:25,160 --> 00:29:26,720
大家可以看一下代码

860
00:29:26,960 --> 00:29:28,840
就是弄起来是非常难的

861
00:29:29,120 --> 00:29:31,039
SSD相对来说是比较简单的

862
00:29:31,720 --> 00:29:34,680
而且是可以用Python来实现的

863
00:29:35,120 --> 00:29:36,240
这就是SSD

864
00:29:38,120 --> 00:29:40,640
OK我们就是讲了SSD之后

865
00:29:40,640 --> 00:29:42,160
我们还会再讲

866
00:29:42,440 --> 00:29:44,000
今天的最后一个算法

867
00:29:44,039 --> 00:29:44,720
就是ULO

868
00:29:45,279 --> 00:29:47,119
可能ULO对就是说

869
00:29:47,559 --> 00:29:49,039
在讲之前我们再总结一下

870
00:29:49,880 --> 00:29:52,000
SSD通过一个单的

871
00:29:52,000 --> 00:29:53,680
神奇网络来检测模型

872
00:29:54,119 --> 00:29:55,440
来检测物体

873
00:29:55,799 --> 00:29:57,160
所以它叫single shot

874
00:29:57,160 --> 00:29:59,519
也叫做single stage

875
00:29:59,519 --> 00:30:00,640
就区分于之前

876
00:30:00,640 --> 00:30:01,519
你要有两个

877
00:30:02,200 --> 00:30:03,319
它是对每个像素

878
00:30:03,319 --> 00:30:05,039
为中心产生多个毛框

879
00:30:05,039 --> 00:30:08,000
然后在不同的stage上的输出

880
00:30:08,000 --> 00:30:10,000
来进行多尺度的检测

881
00:30:10,000 --> 00:30:11,599
就是说下面的检测小物体

882
00:30:11,799 --> 00:30:12,880
上面的检测大物体

883
00:30:13,320 --> 00:30:14,880
这是它的三个核心思想

884
00:30:15,400 --> 00:30:16,840
当然是说肯定有同学说

885
00:30:17,120 --> 00:30:17,800
感觉

886
00:30:18,720 --> 00:30:21,560
说你这个讲的太快了

887
00:30:21,560 --> 00:30:23,080
就是很多细节不懂

888
00:30:23,080 --> 00:30:24,640
我们会在明天

889
00:30:24,920 --> 00:30:26,440
给大家讲一下代码实现

890
00:30:26,440 --> 00:30:27,920
所以大家能够理解说

891
00:30:28,720 --> 00:30:30,240
因为它跟物体

892
00:30:30,400 --> 00:30:32,040
就是说跟我们之前的图片分类

893
00:30:32,040 --> 00:30:33,120
还是会很不一样

894
00:30:33,640 --> 00:30:37,080
所以我们会再给大家代码来讲一下

895
00:30:37,360 --> 00:30:37,880
但反过来讲

896
00:30:37,880 --> 00:30:39,960
我们没有时间给大家

897
00:30:39,960 --> 00:30:41,960
真的把所有RCM系列讲

898
00:30:42,160 --> 00:30:43,519
实现ULO再实现一遍

899
00:30:43,519 --> 00:30:43,960
因为

900
00:30:44,519 --> 00:30:45,400
目标解的算法

901
00:30:45,400 --> 00:30:47,319
实际真的是在实现上

902
00:30:47,319 --> 00:30:48,960
会比之前复杂很多

903
00:30:49,000 --> 00:30:50,279
所以我们就没有时间

904
00:30:50,279 --> 00:30:52,279
给大家再给所有的算法过一遍了

905
00:30:54,640 --> 00:30:55,120
OK

906
00:30:55,120 --> 00:30:58,519
我们讲最后个就做ULO

907
00:30:58,960 --> 00:31:02,200
ULO本身其实是一个口头禅

908
00:31:03,840 --> 00:31:04,680
就是说

909
00:31:04,680 --> 00:31:06,440
You only live once

910
00:31:06,480 --> 00:31:08,120
就是说你只活一次

911
00:31:08,279 --> 00:31:09,720
你不要太

912
00:31:09,720 --> 00:31:11,920
就是什么事情都没什么大事情

913
00:31:11,960 --> 00:31:12,680
就是说

914
00:31:13,319 --> 00:31:14,799
就是说你不要有太有压力

915
00:31:14,799 --> 00:31:17,000
就是你应该冷静一点

916
00:31:17,840 --> 00:31:19,680
因为你生命只有一次

917
00:31:19,680 --> 00:31:20,759
所以大家要珍惜

918
00:31:20,840 --> 00:31:23,200
所以作者就把这个东西

919
00:31:23,200 --> 00:31:26,319
把live改成look

920
00:31:27,160 --> 00:31:28,519
You only look once

921
00:31:28,519 --> 00:31:29,759
就是说你只看一遍

922
00:31:29,759 --> 00:31:30,160
这样子

923
00:31:30,160 --> 00:31:30,960
他是

924
00:31:31,039 --> 00:31:33,360
这个小哥的作者的主要思想

925
00:31:33,360 --> 00:31:34,840
是说要特别快

926
00:31:34,840 --> 00:31:36,640
他就是要追求快

927
00:31:38,000 --> 00:31:38,600
OK

928
00:31:38,759 --> 00:31:39,519
就是说ULO

929
00:31:39,519 --> 00:31:40,360
你要

930
00:31:40,360 --> 00:31:42,360
他意思就是说你只看一次

931
00:31:43,000 --> 00:31:46,640
就是说他其实是从SSD那边过来

932
00:31:46,920 --> 00:31:49,400
他也是一个single stage的一个算法

933
00:31:49,880 --> 00:31:51,640
就是说我只看

934
00:31:51,640 --> 00:31:53,920
首先我只有一个单神经网络

935
00:31:53,920 --> 00:31:56,640
来跟你做预测

936
00:31:57,160 --> 00:31:58,480
另外一个也是跟ULO一样

937
00:31:58,480 --> 00:31:59,760
我需要有模框

938
00:31:59,920 --> 00:32:01,760
但他这里会不一样的是说

939
00:32:03,200 --> 00:32:04,520
因为SSD我们发现

940
00:32:04,600 --> 00:32:07,800
对每一个像素为中心生成模框

941
00:32:08,040 --> 00:32:09,960
对隔壁的像素我们也会生成

942
00:32:10,160 --> 00:32:11,880
所以绝大部分情况下

943
00:32:11,880 --> 00:32:14,840
你的两个相邻像素之间的

944
00:32:14,840 --> 00:32:17,279
模框的重叠率是非常高的

945
00:32:18,440 --> 00:32:19,720
重叠率非常高

946
00:32:19,720 --> 00:32:20,600
实际上你要干嘛

947
00:32:20,600 --> 00:32:22,680
因为你每一个模框是一个样板

948
00:32:22,840 --> 00:32:24,480
你得真的要去

949
00:32:25,160 --> 00:32:26,680
你要去做分类

950
00:32:26,840 --> 00:32:27,600
做计算

951
00:32:27,759 --> 00:32:29,799
这东西都会给你带来很大

952
00:32:29,840 --> 00:32:31,160
很大的计算量

953
00:32:31,960 --> 00:32:34,559
所以说ULO就是说

954
00:32:34,759 --> 00:32:39,200
我实际上模框都没有重叠

955
00:32:39,720 --> 00:32:41,799
我尽量让模框不重叠

956
00:32:44,200 --> 00:32:45,160
他怎么做呢

957
00:32:45,559 --> 00:32:47,360
就是说他把一张图片

958
00:32:48,440 --> 00:32:49,920
就是均匀的分开

959
00:32:49,920 --> 00:32:51,240
比如说这里均匀的分成

960
00:32:51,559 --> 00:32:53,039
行是分成了4块

961
00:32:53,039 --> 00:32:54,759
你的列是分成了6块

962
00:32:54,759 --> 00:32:57,480
就把均匀图片切成了4×6

963
00:32:58,039 --> 00:33:01,160
然后每一个每一块就是一个模框

964
00:33:01,160 --> 00:33:03,559
就是说比如说这就是一个模框

965
00:33:04,519 --> 00:33:06,080
所以就是说你的模框

966
00:33:06,120 --> 00:33:07,279
我快换一个颜色

967
00:33:09,319 --> 00:33:11,440
就是说每个里面都是一个模框

968
00:33:12,200 --> 00:33:14,480
所以你的模框当然是不会重叠了

969
00:33:15,400 --> 00:33:16,600
而且你的

970
00:33:17,000 --> 00:33:18,920
那么你也不会浪费计算量

971
00:33:18,920 --> 00:33:20,440
因为你一共其实说白了

972
00:33:20,440 --> 00:33:23,799
你这里就4×6

973
00:33:24,279 --> 00:33:25,759
但实际上说它是均匀分

974
00:33:25,920 --> 00:33:27,319
它不会像我们这个图一样

975
00:33:27,319 --> 00:33:28,000
分成4×6

976
00:33:28,000 --> 00:33:29,960
它是分成一个S×S的模框

977
00:33:30,319 --> 00:33:31,720
就是说你最后达到

978
00:33:31,720 --> 00:33:33,160
达到S平方的模框

979
00:33:33,319 --> 00:33:35,680
那就计时到几百的

980
00:33:36,240 --> 00:33:38,600
还不是你们SSD当中

981
00:33:38,600 --> 00:33:39,200
几百万

982
00:33:40,960 --> 00:33:43,280
接下来就是说

983
00:33:43,280 --> 00:33:46,440
它会去每一个模框

984
00:33:46,440 --> 00:33:47,800
它会去预测

985
00:33:47,800 --> 00:33:49,280
B个边缘框

986
00:33:50,360 --> 00:33:51,640
就为什么是因为

987
00:33:52,640 --> 00:33:54,360
如果我一个模框

988
00:33:54,360 --> 00:33:55,120
就这个地方

989
00:33:55,960 --> 00:33:58,120
只预测一个边缘框的话

990
00:33:58,120 --> 00:34:01,440
就是预测一个真实物体的框的话

991
00:34:01,520 --> 00:34:03,120
如果你这有两个物体怎么办

992
00:34:03,120 --> 00:34:03,800
那就会出问题

993
00:34:03,800 --> 00:34:04,080
对吧

994
00:34:04,080 --> 00:34:05,320
假设我这里有个物体

995
00:34:05,320 --> 00:34:06,160
这有个物体

996
00:34:06,279 --> 00:34:07,480
刚好它都这个模框

997
00:34:07,480 --> 00:34:08,639
刚好都圈中了

998
00:34:08,840 --> 00:34:09,960
我肯定会丢掉一个物体

999
00:34:09,960 --> 00:34:10,400
对不对

1000
00:34:10,840 --> 00:34:13,159
所以他就说我就多预测几个

1001
00:34:13,599 --> 00:34:15,000
就对每个模框

1002
00:34:15,000 --> 00:34:17,720
我会去预测B个边缘框

1003
00:34:18,760 --> 00:34:19,599
In case的时候

1004
00:34:19,599 --> 00:34:22,159
我有B个物体

1005
00:34:22,159 --> 00:34:23,720
都跟这个模框很近

1006
00:34:25,039 --> 00:34:25,840
所以最后的话

1007
00:34:25,840 --> 00:34:26,920
它比SSD要快

1008
00:34:26,920 --> 00:34:27,159
对吧

1009
00:34:27,159 --> 00:34:29,200
因为它只生成

1010
00:34:29,360 --> 00:34:30,119
它的预测

1011
00:34:30,480 --> 00:34:32,680
它样本数就是S的平方乘以B

1012
00:34:33,320 --> 00:34:35,119
你B的话就5或者几的话

1013
00:34:35,119 --> 00:34:36,559
你S可能就几的话

1014
00:34:36,559 --> 00:34:37,759
那你可能就是几百

1015
00:34:38,159 --> 00:34:40,119
或者1000个的样子

1016
00:34:40,559 --> 00:34:42,039
就说跟你的几百万比

1017
00:34:42,039 --> 00:34:42,759
当然是说

1018
00:34:42,759 --> 00:34:44,719
虽然每次预测都很便宜

1019
00:34:44,960 --> 00:34:46,039
但是实际上

1020
00:34:46,119 --> 00:34:49,359
它这种量级上的改变

1021
00:34:49,359 --> 00:34:50,719
确实可以做得更快一点

1022
00:34:52,559 --> 00:34:54,440
但ULOT的是最原始的想法

1023
00:34:54,440 --> 00:34:54,920
是这样子

1024
00:34:55,400 --> 00:34:57,079
后续还有一系列改进

1025
00:34:57,079 --> 00:34:59,239
就是VR V3

1026
00:34:59,400 --> 00:35:00,279
V3的小

1027
00:35:00,279 --> 00:35:01,639
做到V3的时候

1028
00:35:01,639 --> 00:35:03,440
那小哥是UW一个小哥

1029
00:35:03,440 --> 00:35:05,079
就是那个小哥还挺有个性的

1030
00:35:05,279 --> 00:35:06,719
就说他不干了

1031
00:35:07,319 --> 00:35:07,639
不干了

1032
00:35:07,639 --> 00:35:09,039
就说你们拿我的算法

1033
00:35:09,039 --> 00:35:10,239
天天去监测人

1034
00:35:10,239 --> 00:35:11,599
就说目标检测

1035
00:35:11,920 --> 00:35:13,679
在摄像头里面

1036
00:35:13,679 --> 00:35:15,679
监控摄像头里用的特别多

1037
00:35:16,039 --> 00:35:16,719
监控摄像头

1038
00:35:16,719 --> 00:35:19,839
你真的去看是谁来的

1039
00:35:19,839 --> 00:35:20,239
对吧

1040
00:35:20,839 --> 00:35:22,119
就经常去监控人

1041
00:35:22,119 --> 00:35:23,519
他说你们这个算法

1042
00:35:23,920 --> 00:35:25,639
都是拿我去监控人

1043
00:35:25,920 --> 00:35:27,599
甚至是有军事使用用途

1044
00:35:27,599 --> 00:35:28,599
就说这个东西

1045
00:35:29,039 --> 00:35:30,079
我就不开心

1046
00:35:30,079 --> 00:35:30,679
不干了

1047
00:35:30,679 --> 00:35:32,639
所以他就说我quit了

1048
00:35:32,920 --> 00:35:33,599
但quit之后

1049
00:35:33,599 --> 00:35:34,400
他的合作者

1050
00:35:34,719 --> 00:35:36,039
后来又做了个V4出来

1051
00:35:36,039 --> 00:35:39,039
就说再有一些改进

1052
00:35:39,039 --> 00:35:42,039
就是说核心思想没有变

1053
00:35:42,239 --> 00:35:43,799
但是它的细节上有改进

1054
00:35:43,960 --> 00:35:44,839
比如说

1055
00:35:45,559 --> 00:35:46,199
举几个例子

1056
00:35:46,360 --> 00:35:48,880
我们就不会给大家特别去重复了

1057
00:35:49,079 --> 00:35:49,679
举几个例子

1058
00:35:49,679 --> 00:35:50,480
就是说

1059
00:35:51,559 --> 00:35:53,880
大家发现说你真实的边缘框

1060
00:35:54,039 --> 00:35:56,239
它不会随机的出现

1061
00:35:56,279 --> 00:35:57,319
它通常来说

1062
00:35:57,319 --> 00:35:58,559
它的那些形状

1063
00:35:59,360 --> 00:36:00,159
就是说

1064
00:36:00,159 --> 00:36:02,719
它就是说你的真实的边框

1065
00:36:02,720 --> 00:36:03,960
一个物体很难是一个

1066
00:36:03,960 --> 00:36:05,080
那么一个长长的东西

1067
00:36:05,080 --> 00:36:05,560
对吧

1068
00:36:06,080 --> 00:36:08,680
你很难是一个那么长长的东西

1069
00:36:08,680 --> 00:36:09,160
对吧

1070
00:36:09,480 --> 00:36:11,920
而且它可能在一个它的比例

1071
00:36:12,160 --> 00:36:13,040
它的大小

1072
00:36:13,560 --> 00:36:16,880
它的在图片里面出现的形状

1073
00:36:17,000 --> 00:36:18,400
在每个数据集里面

1074
00:36:18,400 --> 00:36:19,840
是有一定的规律的

1075
00:36:21,160 --> 00:36:22,560
就假设你有

1076
00:36:26,440 --> 00:36:28,640
就假设你有一定的规律的时候

1077
00:36:30,000 --> 00:36:32,600
那么你可以去用一个剧烈的算法

1078
00:36:32,599 --> 00:36:33,559
去看它

1079
00:36:34,039 --> 00:36:35,639
把这个规律给

1080
00:36:36,000 --> 00:36:37,480
给你找出来

1081
00:36:37,839 --> 00:36:39,119
所以就说我给一个数据集

1082
00:36:39,119 --> 00:36:40,159
我先去分析一下

1083
00:36:40,159 --> 00:36:43,000
你的这些边框的这些

1084
00:36:44,519 --> 00:36:45,719
统计信息

1085
00:36:45,759 --> 00:36:47,599
然后将它找出来

1086
00:36:48,279 --> 00:36:49,279
找出来

1087
00:36:49,480 --> 00:36:50,159
这样子的话

1088
00:36:50,159 --> 00:36:51,639
我在之后再去说

1089
00:36:51,639 --> 00:36:53,519
我要怎么样生成模框

1090
00:36:53,519 --> 00:36:54,480
生成时候

1091
00:36:54,920 --> 00:36:57,079
就会有鲜艳知识了

1092
00:36:57,079 --> 00:36:58,960
就可以让你再进一步的优化

1093
00:36:58,960 --> 00:36:59,960
就是说这是一个例子

1094
00:37:00,000 --> 00:37:02,519
所以就是说

1095
00:37:02,519 --> 00:37:05,360
VRV3V4是持续这一些细节上的改进

1096
00:37:05,360 --> 00:37:07,800
它会不断去看在数据集上应用

1097
00:37:07,800 --> 00:37:08,880
然后做了很多

1098
00:37:08,880 --> 00:37:11,119
我觉得还挺工程上的改进

1099
00:37:11,960 --> 00:37:14,240
就是说大家可以去看论文

1100
00:37:14,440 --> 00:37:15,400
V3这个

1101
00:37:15,400 --> 00:37:18,280
就ULAV3可以认为是史上写的

1102
00:37:18,639 --> 00:37:19,679
最差的论文

1103
00:37:19,880 --> 00:37:20,400
可以去看一下

1104
00:37:20,400 --> 00:37:21,240
根本就不算一个论文

1105
00:37:21,240 --> 00:37:22,679
但是它citation还挺高的

1106
00:37:22,920 --> 00:37:24,280
就是说很多时候

1107
00:37:24,280 --> 00:37:26,599
就是说你只要你这个东西

1108
00:37:27,800 --> 00:37:28,840
真的work

1109
00:37:28,960 --> 00:37:29,800
有效果

1110
00:37:29,920 --> 00:37:31,280
你写的再差

1111
00:37:31,280 --> 00:37:32,240
你就写一篇blog

1112
00:37:32,240 --> 00:37:33,240
大家也会赢你

1113
00:37:33,560 --> 00:37:35,480
这个也是挺好玩的一个事情

1114
00:37:35,960 --> 00:37:37,720
这也是ULA这个作者

1115
00:37:37,720 --> 00:37:39,080
也是学术界的

1116
00:37:39,440 --> 00:37:41,440
比较特立图形的一个作者

1117
00:37:42,039 --> 00:37:44,000
我们就不会再给大家

1118
00:37:44,000 --> 00:37:46,680
特别去讲这里面是怎么样子了

1119
00:37:47,039 --> 00:37:47,760
细节什么样子

1120
00:37:47,760 --> 00:37:49,000
我们就不给大家过了

1121
00:37:49,000 --> 00:37:49,920
就是说给大家知道

1122
00:37:50,080 --> 00:37:51,320
ULA确实是在

1123
00:37:51,320 --> 00:37:52,400
目前在官员界用的

1124
00:37:52,400 --> 00:37:53,680
还挺多的一个算法

1125
00:37:54,760 --> 00:37:55,600
但我们可以看一下

1126
00:37:55,600 --> 00:37:57,120
就是说我们看一下

1127
00:37:57,120 --> 00:37:59,760
ULAV3的一个性能

1128
00:38:00,000 --> 00:38:01,720
ULAV3就是说你可以看到

1129
00:38:02,560 --> 00:38:04,880
这个点是它真实的在论文

1130
00:38:04,880 --> 00:38:06,880
如果你就是说它的Darknet

1131
00:38:07,280 --> 00:38:07,920
它的实现

1132
00:38:08,080 --> 00:38:10,360
如果你真的用它的实现的话

1133
00:38:10,360 --> 00:38:12,200
你的精度其实并不高

1134
00:38:12,320 --> 00:38:14,640
但是我们发现是说你V3

1135
00:38:14,880 --> 00:38:17,120
就是说我可以把别的那些地方的

1136
00:38:17,120 --> 00:38:18,039
那些trick

1137
00:38:18,560 --> 00:38:19,960
就不管是图片分类的trick

1138
00:38:20,200 --> 00:38:21,840
也是RCM各种trick

1139
00:38:21,840 --> 00:38:22,920
都搬过来之后

1140
00:38:23,480 --> 00:38:24,880
就是说你其实是能够

1141
00:38:24,880 --> 00:38:26,440
性能搬到这个地方了

1142
00:38:27,200 --> 00:38:28,360
我们对V3就是说

1143
00:38:28,360 --> 00:38:30,240
你把性能像搬过来之后

1144
00:38:30,240 --> 00:38:32,519
其实跟你V4可能性能是差不多了

1145
00:38:32,519 --> 00:38:34,720
V4就是在V3上一些细节的改变

1146
00:38:35,160 --> 00:38:35,760
就是说

1147
00:38:35,760 --> 00:38:37,680
所以就是说我们现在这个指

1148
00:38:37,840 --> 00:38:40,400
不是ULAV3原始论文的结果

1149
00:38:40,400 --> 00:38:41,480
而是说对它

1150
00:38:41,480 --> 00:38:43,280
我们对它进行了一些改进之后

1151
00:38:43,280 --> 00:38:45,800
它的精度在性能不变的情况下

1152
00:38:45,800 --> 00:38:47,120
精度可以做到这个地方

1153
00:38:48,079 --> 00:38:48,800
就这个地方

1154
00:38:50,320 --> 00:38:51,160
就基本上可以看到

1155
00:38:51,320 --> 00:38:54,079
它还是把SSD给远远的甩开了

1156
00:38:55,000 --> 00:38:56,760
SSD在这个绿点的地方

1157
00:38:57,040 --> 00:38:58,640
而且可以看到是说

1158
00:38:59,000 --> 00:39:02,080
在同样的精度的情况下

1159
00:39:02,200 --> 00:39:03,600
像同样的精度的情况下

1160
00:39:04,240 --> 00:39:05,680
它确实是比

1161
00:39:08,400 --> 00:39:09,760
FastRCM系列

1162
00:39:10,480 --> 00:39:11,520
要贵要便宜

1163
00:39:12,040 --> 00:39:14,120
就是说在达到同样的精度的情况下

1164
00:39:14,400 --> 00:39:16,320
我这个是个log级别

1165
00:39:16,440 --> 00:39:18,200
你可以看到是这个地方大概是

1166
00:39:19,080 --> 00:39:20,440
10可能就是

1167
00:39:20,440 --> 00:39:21,480
这个是16个

1168
00:39:21,720 --> 00:39:23,320
可能每秒钟处理16个

1169
00:39:23,320 --> 00:39:25,320
这里大概可以处理到100个的样子

1170
00:39:25,720 --> 00:39:27,960
所以就是5倍的性能提升

1171
00:39:28,320 --> 00:39:30,640
所以ULAV3和之后的V4

1172
00:39:30,640 --> 00:39:32,920
确实是一个挺快的

1173
00:39:32,920 --> 00:39:34,360
性能还不错的一个算法

1174
00:39:34,360 --> 00:39:37,160
也是在工业界被大量使用的一个算法

1175
00:39:39,200 --> 00:39:39,680
OK

1176
00:39:40,360 --> 00:39:44,120
最后就是说我们没有讲

1177
00:39:45,120 --> 00:39:48,000
就是说基于非毛框的做法

1178
00:39:48,160 --> 00:39:48,559
非毛框

1179
00:39:48,559 --> 00:39:50,280
我们这里有个例子叫做Centelette

1180
00:39:50,280 --> 00:39:51,360
Centelette在这个地方

1181
00:39:51,640 --> 00:39:52,519
给大家看一下

1182
00:39:52,840 --> 00:39:53,680
就在

1183
00:39:54,079 --> 00:39:55,119
我用个什么颜色

1184
00:39:55,440 --> 00:39:56,279
我用个紫色

1185
00:39:56,440 --> 00:39:56,960
就是说

1186
00:39:57,799 --> 00:39:58,279
这个地方

1187
00:40:00,079 --> 00:40:02,599
就是说这是Centelette的一个

1188
00:40:03,480 --> 00:40:04,960
就是性能和精度对比

1189
00:40:04,960 --> 00:40:07,599
就是这根紫红色的线

1190
00:40:08,039 --> 00:40:09,359
可以看到是说它还不错

1191
00:40:09,359 --> 00:40:09,679
对吧

1192
00:40:09,679 --> 00:40:14,239
就是说在这一块进展也是挺迅速的

1193
00:40:14,440 --> 00:40:16,799
大家一直在最近在发论文说

1194
00:40:17,399 --> 00:40:19,079
希望可能在未来有一天

1195
00:40:19,079 --> 00:40:22,759
它确实能够超越掉基于毛框的这一类算法

1196
00:40:23,080 --> 00:40:24,960
这样因为它的好处是

1197
00:40:26,360 --> 00:40:28,480
它真的会简单很多

1198
00:40:28,480 --> 00:40:30,600
就我们你看上个星期

1199
00:40:30,600 --> 00:40:32,880
我们花那么多时间来讲各种毛框事情

1200
00:40:33,800 --> 00:40:34,920
所以它没有

1201
00:40:34,960 --> 00:40:36,720
不用那么去处理毛框的时候

1202
00:40:36,720 --> 00:40:38,000
它确实比较简单

1203
00:40:38,440 --> 00:40:39,560
另外它的主要思路

1204
00:40:39,560 --> 00:40:40,760
给大家稍微介绍一下

1205
00:40:40,760 --> 00:40:43,080
就是说它其实是用到的是

1206
00:40:43,080 --> 00:40:44,560
我们之后会讲到的细节

1207
00:40:44,600 --> 00:40:46,440
就它会对每个像素

1208
00:40:47,520 --> 00:40:48,600
做一个预测

1209
00:40:49,400 --> 00:40:50,640
就它是像素级别预测

1210
00:40:50,639 --> 00:40:52,440
我们之后会讲fully connected的

1211
00:40:52,440 --> 00:40:53,519
那个convolution

1212
00:40:53,519 --> 00:40:54,400
就FCN

1213
00:40:54,599 --> 00:40:55,960
就是说在预测的时候

1214
00:40:55,960 --> 00:40:57,480
我们对每个像素做表号

1215
00:40:57,559 --> 00:40:59,239
那么非毛框的算法

1216
00:40:59,239 --> 00:41:02,400
就是说它对图片每个用也是用FCN

1217
00:41:02,400 --> 00:41:04,119
对每个像素做预测

1218
00:41:04,639 --> 00:41:06,199
然后预测什么东西

1219
00:41:07,119 --> 00:41:08,519
预测的就是说

1220
00:41:08,719 --> 00:41:10,319
比如说你这个点

1221
00:41:10,319 --> 00:41:13,679
是不是你真实bounded box的中心点

1222
00:41:13,920 --> 00:41:14,440
这些的东西

1223
00:41:14,440 --> 00:41:18,639
就是说看你是怎么样把你的目标

1224
00:41:18,639 --> 00:41:20,199
检测那些bounded box

1225
00:41:20,239 --> 00:41:25,440
换算成基于你每个像素的一个标号

1226
00:41:25,599 --> 00:41:27,440
就你看是怎么换算过去的

1227
00:41:27,480 --> 00:41:28,759
那么你换成一个标号之后

1228
00:41:28,759 --> 00:41:31,239
那么对每个像素做预测

1229
00:41:31,239 --> 00:41:33,319
所以就不会去有太多

1230
00:41:33,319 --> 00:41:35,480
这样子毛框的一些操作了

1231
00:41:35,559 --> 00:41:36,119
OK

1232
00:41:36,400 --> 00:41:38,239
我们就没有时间给大家自己讲了

1233
00:41:38,440 --> 00:41:40,079
大家可以去关注一下

1234
00:41:40,079 --> 00:41:41,920
这一块的新进展

1235
00:41:44,319 --> 00:41:44,679
OK

1236
00:41:44,679 --> 00:41:47,159
所以我们目标检测算法

1237
00:41:47,559 --> 00:41:49,599
给大家非常简单的介绍了一遍

1238
00:41:49,759 --> 00:41:52,119
我们没有时间给大家去仔细讲

1239
00:41:52,920 --> 00:41:54,000
RCN系列

1240
00:41:54,000 --> 00:41:54,719
EULA系列

1241
00:41:54,719 --> 00:41:56,599
其实我觉得是非常值得

1242
00:41:56,599 --> 00:41:58,199
大家去读一读细节的

1243
00:41:58,519 --> 00:41:59,480
但是你一去讲的话

1244
00:41:59,480 --> 00:42:01,039
可能要几节课就没了

1245
00:42:01,039 --> 00:42:04,319
所以我们就之后就直接跳到实现了

