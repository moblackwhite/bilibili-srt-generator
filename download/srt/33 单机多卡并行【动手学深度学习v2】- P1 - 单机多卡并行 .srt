1
00:00:00,000 --> 00:00:03,240
就问题17我有4块GPU训练

2
00:00:03,240 --> 00:00:06,040
我后来我有两块更大显存的GPU

3
00:00:06,040 --> 00:00:07,160
那么我什么都不变

4
00:00:07,160 --> 00:00:10,279
换成两块大显存GPU训练会什么影响

5
00:00:10,519 --> 00:00:13,679
就是说你显存大小

6
00:00:13,960 --> 00:00:15,679
那么就是说你有4块GPU

7
00:00:15,679 --> 00:00:17,839
然后你两块显存小

8
00:00:17,839 --> 00:00:19,000
两块显存大

9
00:00:19,000 --> 00:00:20,679
然后如果计算性都一样的话

10
00:00:20,679 --> 00:00:21,640
那也没办法

11
00:00:21,679 --> 00:00:24,760
那就是说那你就只能训练

12
00:00:24,800 --> 00:00:27,480
你有小GPU显存决定的东西

13
00:00:28,320 --> 00:00:29,080
再反过来讲

14
00:00:29,080 --> 00:00:31,440
如果你的GPU大的显存GPU的话

15
00:00:31,440 --> 00:00:33,119
它的计算性更强的话

16
00:00:33,119 --> 00:00:35,000
那么你可以把小批量

17
00:00:35,039 --> 00:00:36,280
相对来说多给点样本

18
00:00:36,280 --> 00:00:36,960
给大GPU

19
00:00:37,159 --> 00:00:39,799
假设你有一个GPU

20
00:00:39,799 --> 00:00:41,960
是另外一个GPU的计算量是两倍的话

21
00:00:42,000 --> 00:00:45,280
那么你每一次给强一点的GPU

22
00:00:45,280 --> 00:00:47,880
那就是两倍于小GPU的样本数

23
00:00:48,280 --> 00:00:50,560
就是说你得去判一下是可以的

24
00:00:50,679 --> 00:00:51,400
一般来说

25
00:00:51,400 --> 00:00:53,280
框架都支持你干这个事情

26
00:00:53,480 --> 00:00:57,880
小批量分到多GPU计算和模型

27
00:00:57,880 --> 00:00:59,120
结果怎么合并到一起

28
00:00:59,160 --> 00:01:01,760
这一般是说你把梯度给你加起来

29
00:01:02,160 --> 00:01:03,359
就梯度加起来之后

30
00:01:03,359 --> 00:01:04,719
就会得到完整梯度

31
00:01:04,760 --> 00:01:05,960
在模型更新的时候

32
00:01:05,960 --> 00:01:07,120
模型其实只有一份

33
00:01:07,120 --> 00:01:08,640
就是只有模型

34
00:01:08,640 --> 00:01:09,840
只在一个地方被更新

35
00:01:10,000 --> 00:01:13,319
就说模型你基本上可以保证是一致的

36
00:01:15,599 --> 00:01:17,520
问题是有数据拆分并行后

37
00:01:17,520 --> 00:01:19,640
中间要存储的数据量会增加吗

38
00:01:19,640 --> 00:01:20,599
会不会降低性能

39
00:01:20,600 --> 00:01:23,680
你要存的数据量

40
00:01:23,680 --> 00:01:25,240
其实是你要存的东西

41
00:01:25,240 --> 00:01:28,320
一个是你的模型和你的梯度

42
00:01:28,760 --> 00:01:29,680
这个是增加了

43
00:01:29,680 --> 00:01:31,440
就是说你有4个GPU的话

44
00:01:31,440 --> 00:01:33,080
那么就每个GPU得存一份

45
00:01:33,160 --> 00:01:35,640
但是你中间数据量是不会增加了

46
00:01:35,680 --> 00:01:39,760
中间数据量的大小是取决于你的

47
00:01:41,200 --> 00:01:44,320
中间数据量的大小

48
00:01:44,320 --> 00:01:46,640
去限系于你的批量大小

49
00:01:47,320 --> 00:01:52,239
因为你每个GPU拿的样本变少了

50
00:01:52,239 --> 00:01:53,960
所以你的中间存取量会变低

51
00:01:54,840 --> 00:01:57,400
所以他性能会低

52
00:01:57,400 --> 00:01:58,040
确实会的

53
00:01:58,040 --> 00:02:00,120
我们会在下一次给大家演示

54
00:02:00,120 --> 00:02:01,760
他为什么性能会低

55
00:02:01,760 --> 00:02:02,920
是因为你批量变小了

56
00:02:02,920 --> 00:02:04,719
你的整个矩阵运算变小了

57
00:02:04,760 --> 00:02:05,599
性能会低

58
00:02:07,400 --> 00:02:09,039
数据必须显示不同GPU

59
00:02:09,039 --> 00:02:11,360
也是拷贝到同一个模型吗

60
00:02:11,520 --> 00:02:15,480
就是说是的

61
00:02:15,480 --> 00:02:17,400
不同GPU是拷贝的同一个模型

62
00:02:17,400 --> 00:02:18,680
是真正的并行

63
00:02:18,720 --> 00:02:20,000
模型并行

64
00:02:20,040 --> 00:02:24,000
模型并行可以做到一定程度的并行

65
00:02:24,000 --> 00:02:25,640
就是说他可以在

66
00:02:26,680 --> 00:02:28,800
另外一个GPU在算的时候

67
00:02:28,800 --> 00:02:31,080
他可以前面可以往前做一点点运算

68
00:02:31,240 --> 00:02:32,600
所以模型并行

69
00:02:32,600 --> 00:02:34,760
它的并行程度会低一点是真的

70
00:02:36,520 --> 00:02:38,640
问题是一个集成显卡加一个独立显卡

71
00:02:38,640 --> 00:02:40,000
可以做这样数据并行实验吗

72
00:02:40,000 --> 00:02:40,600
可以

73
00:02:40,840 --> 00:02:42,239
你可以这么做但很麻烦

74
00:02:42,280 --> 00:02:44,120
就是说显卡很慢

75
00:02:44,479 --> 00:02:47,439
显卡独立显卡可能比集成显卡快10倍

76
00:02:47,479 --> 00:02:50,079
所以这等于是说你加上集成显卡

77
00:02:50,079 --> 00:02:51,159
也就快个10%

78
00:02:51,159 --> 00:02:52,079
所以意义不大

79
00:02:52,120 --> 00:02:53,879
而且让你的东西变得更复杂

80
00:02:54,000 --> 00:02:55,799
所以我不建议你看这个事情

81
00:02:55,799 --> 00:02:57,519
除非你独立显卡特别糟糕

82
00:02:57,519 --> 00:02:59,240
就跟你集成显卡差不多

83
00:02:59,280 --> 00:03:00,240
那你可以试一下

84
00:03:00,240 --> 00:03:01,199
不然的话没必要

85
00:03:02,639 --> 00:03:04,359
无人车都用什么样的硬件芯片

86
00:03:04,519 --> 00:03:05,639
有高的要求吗

87
00:03:05,799 --> 00:03:07,159
无人车关系的是功耗

88
00:03:07,840 --> 00:03:10,240
无人车对功耗关系很大的

89
00:03:10,320 --> 00:03:11,520
你放一个GPU上去

90
00:03:11,520 --> 00:03:13,360
300瓦一下电池就没了

91
00:03:14,920 --> 00:03:16,800
所以无人车跟手机有点像

92
00:03:16,840 --> 00:03:18,159
就无人车

93
00:03:18,320 --> 00:03:20,560
无人车是说比手机要强的

94
00:03:20,560 --> 00:03:22,360
无人车的希望是拿到

95
00:03:22,360 --> 00:03:25,040
server端的强劲的芯片

96
00:03:25,040 --> 00:03:27,280
但是功耗要比server端还低很多

97
00:03:28,719 --> 00:03:30,160
这无人车要干的事情

98
00:03:30,320 --> 00:03:31,920
问题23我们就不回答了

99
00:03:31,920 --> 00:03:33,680
cycleGAN batch cycle1

100
00:03:33,680 --> 00:03:34,680
怎么样多Gb训练

101
00:03:34,680 --> 00:03:36,719
我们就不具体解释

102
00:03:36,719 --> 00:03:39,040
因为我们没有讲过GAN这个东西怎么做

103
00:03:40,360 --> 00:03:43,760
所以我们就不去

104
00:03:43,760 --> 00:03:45,400
你如果batch是唯一的话

105
00:03:45,400 --> 00:03:46,760
你就模型变形

106
00:03:47,400 --> 00:03:49,560
这个就你数据变形切分不了

107
00:03:49,560 --> 00:03:50,439
那就没办法

108
00:03:50,680 --> 00:03:53,640
而且GAN现在也能做的batch size比较大了

109
00:03:53,640 --> 00:03:55,400
所以有新的上方可以做了

