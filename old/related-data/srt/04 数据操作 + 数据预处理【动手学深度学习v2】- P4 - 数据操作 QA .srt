1
00:00:00,000 --> 00:00:02,000
OK 我们来回答这个问题

2
00:00:07,360 --> 00:00:09,919
好 这个问题就是说还有

3
00:00:12,720 --> 00:00:14,080
比如说第一个问题是说

4
00:00:14,080 --> 00:00:16,879
请问reshape和view函数的区别

5
00:00:18,080 --> 00:00:20,719
reshape和view其实是不一样

6
00:00:20,719 --> 00:00:22,480
就是说reshape也会创建一个view

7
00:00:22,480 --> 00:00:24,000
就是说reshape它不会

8
00:00:24,000 --> 00:00:26,640
就是说这里面有一点点奇怪

9
00:00:26,640 --> 00:00:27,839
是当拍透气很奇怪

10
00:00:27,839 --> 00:00:28,640
当拍也很奇怪

11
00:00:28,640 --> 00:00:31,440
就是说你把一个元素

12
00:00:31,440 --> 00:00:33,679
你把一个数组把它reshape了

13
00:00:33,679 --> 00:00:35,759
或者是做一些运算之后

14
00:00:35,759 --> 00:00:40,000
它是它并没有帮你的地址给你改了

15
00:00:40,000 --> 00:00:42,960
就是说比如说B等于A的reshape

16
00:00:42,960 --> 00:00:44,640
举个例子就是说

17
00:00:45,519 --> 00:00:46,719
所以这个就是

18
00:00:48,320 --> 00:00:53,040
我觉得用Jupyter的好处是说我可以

19
00:00:53,040 --> 00:00:54,240
我可以

20
00:00:56,719 --> 00:00:57,920
好 我来举个例子

21
00:00:59,200 --> 00:01:00,880
等于是说

22
00:01:00,880 --> 00:01:05,280
A等于torch

23
00:01:05,280 --> 00:01:07,280
比如说点个ray

24
00:01:07,280 --> 00:01:08,640
arrange

25
00:01:08,640 --> 00:01:09,840
一下

26
00:01:09,840 --> 00:01:11,599
那我可以有生成给A

27
00:01:11,599 --> 00:01:12,960
然后B点

28
00:01:12,960 --> 00:01:15,039
B等于A点reshape

29
00:01:15,039 --> 00:01:17,519
23 34

30
00:01:17,519 --> 00:01:19,439
然后A和B

31
00:01:19,439 --> 00:01:22,480
就是说但是如果我把B改了的话

32
00:01:22,480 --> 00:01:25,439
我就全部把它改了吧

33
00:01:25,439 --> 00:01:26,480
然后打印A

34
00:01:27,359 --> 00:01:27,920
就是说

35
00:01:28,640 --> 00:01:32,480
你可以看到我创建了一个东西在A里面

36
00:01:32,480 --> 00:01:34,800
然后把它reshape到B

37
00:01:34,800 --> 00:01:36,480
我把B的元素一改

38
00:01:36,480 --> 00:01:38,320
其实B它并没有复制A

39
00:01:38,320 --> 00:01:40,159
它B是创建了一个A的view

40
00:01:40,159 --> 00:01:43,600
就是一个数据库里面有一个view

41
00:01:43,600 --> 00:01:44,719
然后就形状变了

42
00:01:44,719 --> 00:01:45,359
但元素没变

43
00:01:45,359 --> 00:01:46,640
然后我把B改了

44
00:01:47,280 --> 00:01:49,840
A其实它就把A给改了

45
00:01:49,840 --> 00:01:50,640
所以这个也是

46
00:01:51,680 --> 00:01:54,080
这里面也有一些很奇怪的地方

47
00:01:54,159 --> 00:01:58,239
就是说大家可能要不断的在使用的时候会去了解

48
00:01:58,239 --> 00:02:01,200
就是说尽量大家不要去改东西

49
00:02:01,200 --> 00:02:03,439
就是说不要去说你改了B

50
00:02:03,439 --> 00:02:05,759
可能说你A如果之后用A的话

51
00:02:05,759 --> 00:02:07,599
那你就把A给改掉了

52
00:02:07,599 --> 00:02:10,079
就是说不能一句话就讲清楚

53
00:02:10,079 --> 00:02:12,479
大家可以去看一下资料

54
00:02:12,479 --> 00:02:14,719
然后里面大家很多经验的总结

55
00:02:14,719 --> 00:02:16,960
但一般来说我们很少去做这个操作

56
00:02:16,960 --> 00:02:18,319
所以大家也不用太担心

57
00:02:19,199 --> 00:02:20,719
我这种操作我们做的比较少

58
00:02:21,280 --> 00:02:25,359
第二个是说数组计算这里跟不上了

59
00:02:25,359 --> 00:02:28,080
是要去补充Python还是线性代数

60
00:02:28,080 --> 00:02:29,919
其实你不用太补充

61
00:02:29,919 --> 00:02:31,439
我等会会讲线性代数

62
00:02:31,439 --> 00:02:35,199
就是你不用太去管线性代数了

63
00:02:35,199 --> 00:02:38,159
我觉得你可以去学一下Numpy

64
00:02:38,159 --> 00:02:40,400
最简单学一下Numpy的一些很多教材

65
00:02:40,400 --> 00:02:44,159
Numpy因为它是一个老牌的一个Python里面的一个库

66
00:02:44,159 --> 00:02:46,719
它能大量的Numpy的教材

67
00:02:46,719 --> 00:02:47,680
大家可以去学一下

68
00:02:47,680 --> 00:02:50,000
我们这就很简单就讲了10分钟就过去了

69
00:02:50,159 --> 00:02:52,560
就说大家给一个大家一个idea

70
00:02:52,560 --> 00:02:55,439
如果说你不是第一次接触这个的话

71
00:02:55,439 --> 00:02:57,520
你去学一下Numpy的一些知识

72
00:03:00,240 --> 00:03:03,439
第三个是怎么快速区分维度

73
00:03:03,439 --> 00:03:05,280
就是说你可以快速区分维度

74
00:03:05,280 --> 00:03:06,800
你可以a点Shape

75
00:03:06,800 --> 00:03:10,800
然后你看一下它长度就知道它多长

76
00:03:10,800 --> 00:03:13,199
当你可以有a它有个n定

77
00:03:13,199 --> 00:03:15,439
它可以达到所有的维度的个数

78
00:03:16,079 --> 00:03:21,919
第四个问题说Torch的Tensor和Numpy的array类似吗

79
00:03:21,919 --> 00:03:22,719
不类似

80
00:03:22,719 --> 00:03:23,759
不很遗憾

81
00:03:23,759 --> 00:03:25,039
就是它不类似

82
00:03:25,039 --> 00:03:27,199
就PyTorch是从Torch来的

83
00:03:27,199 --> 00:03:30,240
Torch是一个Lua的一个最早是一个框架

84
00:03:30,240 --> 00:03:34,000
所以它其实跟Numpy之间很像

85
00:03:34,000 --> 00:03:35,120
但是它不一样

86
00:03:35,120 --> 00:03:38,000
所以说大家可以去搜一下PyTorch和Numpy的区别

87
00:03:38,000 --> 00:03:39,439
如果你真想要跟

88
00:03:39,439 --> 00:03:41,360
如果你懂Numpy真想要Numpy的话

89
00:03:41,360 --> 00:03:44,400
我建议你可以去看我们对应的MSNet的章节

90
00:03:44,400 --> 00:03:46,800
MSNet的API跟Numpy是一样的

91
00:03:46,800 --> 00:03:51,439
第五个是说Tensor和array有什么区别

92
00:03:51,439 --> 00:03:52,879
这个是很好的问题

93
00:03:52,879 --> 00:03:55,520
就是说Tensor其实是说

94
00:03:55,520 --> 00:03:57,599
Tensor是一个数学上的概念

95
00:03:57,599 --> 00:03:58,560
是一个张量

96
00:03:58,560 --> 00:04:01,360
就是说真的是有数学上明确定义

97
00:04:01,360 --> 00:04:04,159
array它是一个计算机的一个里面一个语言

98
00:04:04,159 --> 00:04:06,400
就是说数组我们都是说数组

99
00:04:06,400 --> 00:04:10,159
所以Numpy其实是说叫NDarray

100
00:04:10,159 --> 00:04:11,680
就N-dimensional array

101
00:04:11,680 --> 00:04:13,200
它就是一个多元素组

102
00:04:13,280 --> 00:04:15,360
它属于是一个计算机的概念

103
00:04:15,360 --> 00:04:16,879
它没有数学上定义

104
00:04:16,879 --> 00:04:22,319
但是PyTorch和TensorFlow它就用了Tensor这个概念

105
00:04:22,319 --> 00:04:25,200
它存在了数学的张量的概念

106
00:04:25,759 --> 00:04:28,560
然后这就导致说

107
00:04:28,560 --> 00:04:32,720
你其实我们所谓的Tensor和数组是没有本质区别的

108
00:04:32,720 --> 00:04:34,000
就没有任何区别

109
00:04:34,000 --> 00:04:37,600
但是大家不要去纠结数学上的定义

110
00:04:37,600 --> 00:04:41,520
因为我们数学就写深度学学框架人

111
00:04:41,519 --> 00:04:43,199
数学没学特别好

112
00:04:43,199 --> 00:04:44,879
所以大家是混着用的

113
00:04:44,879 --> 00:04:47,039
当然所以其实是一个东西

114
00:04:48,719 --> 00:04:53,439
有第6个问题说有图形化的Torch编程方案吗

115
00:04:55,120 --> 00:04:59,680
这种用二维数学表达计算多元数据感觉效率不高

116
00:04:59,680 --> 00:05:03,759
没有太多好的数可视化的工具

117
00:05:03,759 --> 00:05:06,719
当然是我们未来我们可能会

118
00:05:06,719 --> 00:05:10,079
也许最后的最后我们会讲一下一些AutoML的东西

119
00:05:10,079 --> 00:05:12,560
就是说大家可以不用太担心底层

120
00:05:12,560 --> 00:05:14,719
但是确实没有别的办法

121
00:05:14,719 --> 00:05:17,680
就是说如果你没有接触过多维数组

122
00:05:17,680 --> 00:05:21,120
这是一个很大的思维上的改变

123
00:05:21,120 --> 00:05:24,639
你要去从一个高维数组去想这个事情

124
00:05:24,639 --> 00:05:25,599
想它的Shape

125
00:05:25,599 --> 00:05:26,719
想它的各种东西

126
00:05:26,719 --> 00:05:29,039
你得去花很多时间去做这个事情

127
00:05:29,039 --> 00:05:31,839
我建议大家反正多多的去运行代码

128
00:05:31,839 --> 00:05:33,919
多多参加我们的一些Hackathon

129
00:05:33,919 --> 00:05:37,680
大家来理解这个概念上是什么东西

130
00:05:38,639 --> 00:05:41,759
第7个问题是说新分配了Y的内存

131
00:05:41,759 --> 00:05:44,400
那么之前的Y对应的内存会自动释放吗

132
00:05:44,400 --> 00:05:47,360
如果这个内存是Python的会自动释放

133
00:05:47,360 --> 00:05:50,800
就是说如果这个内存没有被别的地方用的话

134
00:05:50,800 --> 00:05:52,560
Python会帮你自动释放

135
00:05:52,560 --> 00:05:54,879
所以你不用太担心内存的事情

136
00:05:54,879 --> 00:06:00,720
第8个问题是PyTorch MSet这些框架中实现梯度反传是

137
00:06:00,720 --> 00:06:03,439
这个算法我们会之后会讲

138
00:06:03,439 --> 00:06:05,199
我们先不用说

139
00:06:05,599 --> 00:06:08,560
第9个问题能使用JAX来替代Numpy吗

140
00:06:08,560 --> 00:06:09,360
可以的

141
00:06:09,360 --> 00:06:15,120
JAX的话就是说我们确实JAX团队在跟我们合作

142
00:06:15,120 --> 00:06:17,680
来推出一个JAX的版本

143
00:06:17,680 --> 00:06:21,120
JAX是Google做的另外一个框架了

144
00:06:21,120 --> 00:06:24,240
跟TensorFlow是隔壁的团队做的

145
00:06:24,240 --> 00:06:26,480
它跟Numpy很像

146
00:06:26,480 --> 00:06:29,279
但是它还没那么成熟

147
00:06:29,279 --> 00:06:31,599
所以我们确实在跟JAX团队在合作

148
00:06:31,599 --> 00:06:33,039
在推出JAX版本

149
00:06:33,039 --> 00:06:34,719
你可以用JAX可以

150
00:06:34,720 --> 00:06:38,400
但是目前我觉得它在深度学习里面

151
00:06:38,400 --> 00:06:41,120
它的还是不那么成熟

152
00:06:41,120 --> 00:06:42,560
所以我不建议你现在用

153
00:06:42,560 --> 00:06:45,600
也许一两年之后我其实挺看好的JAX框架

154
00:06:48,640 --> 00:06:50,480
就是说问题10

155
00:06:50,480 --> 00:06:54,080
上一个版本用了View改变形状且共用内存

156
00:06:54,080 --> 00:06:56,240
第2个版本都在用Reshape

157
00:06:56,240 --> 00:06:57,840
Reshape和View其实是一回事

158
00:06:57,840 --> 00:06:59,360
Reshape它也是改变形状

159
00:06:59,360 --> 00:07:00,080
它创建一个View

160
00:07:00,080 --> 00:07:01,280
刚刚我们演示了

161
00:07:01,280 --> 00:07:04,400
所以大家是说都没它的关系

162
00:07:04,400 --> 00:07:06,720
View和Reshape没有本质区别

163
00:07:06,720 --> 00:07:07,600
OK

164
00:07:07,600 --> 00:07:12,720
所以这个是最简单的多元数组

165
00:07:15,040 --> 00:07:16,560
我们来看一下

166
00:07:18,000 --> 00:07:20,880
然后线性代数

167
00:07:20,880 --> 00:07:25,200
我们讲一下线性代数

168
00:07:25,200 --> 00:07:29,760
还有最后10分钟就讲一下它的数学

169
00:07:29,760 --> 00:07:34,320
然后我们在明天我们再讲一下它的实现

170
00:07:34,319 --> 00:07:36,240
线性代数是说

