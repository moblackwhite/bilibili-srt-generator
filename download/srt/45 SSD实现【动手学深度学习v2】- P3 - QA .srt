1
00:00:00,000 --> 00:00:02,720
所以我们接下来是SSD的实现

2
00:00:03,399 --> 00:00:05,679
我们首先干什么事情

3
00:00:05,799 --> 00:00:07,560
我们首先去定义是说

4
00:00:07,560 --> 00:00:11,160
你到底是它具体怎么样去实现

5
00:00:11,400 --> 00:00:16,879
识别每一个某框里面的类别和偏移的

6
00:00:17,280 --> 00:00:18,320
我们首先看一下

7
00:00:20,600 --> 00:00:21,839
就说我们import的东西

8
00:00:21,839 --> 00:00:23,480
我们先忽略掉了

9
00:00:23,480 --> 00:00:26,160
就说我们其实就是跟之前import的东西

10
00:00:26,640 --> 00:00:27,800
接下来这个函数

11
00:00:27,800 --> 00:00:30,080
叫做class predictor

12
00:00:30,800 --> 00:00:33,679
就是去预测一个某框的类别

13
00:00:35,799 --> 00:00:37,480
所以你告诉我number of inputs

14
00:00:37,480 --> 00:00:40,439
就是你的数物的通道数

15
00:00:41,359 --> 00:00:42,960
然后我告诉你说

16
00:00:43,000 --> 00:00:44,799
我有多少个某框

17
00:00:45,439 --> 00:00:47,240
和我有多少类

18
00:00:47,640 --> 00:00:49,079
就假设我就是一个banana

19
00:00:49,079 --> 00:00:49,960
然后一个香蕉

20
00:00:49,960 --> 00:00:50,719
然后就是一类

21
00:00:50,719 --> 00:00:54,560
假设我有比如说我要识别5种车的话

22
00:00:54,679 --> 00:00:55,560
当然是5类

23
00:00:56,560 --> 00:00:58,480
那么它这干个什么事情

24
00:00:58,800 --> 00:00:59,840
就我们可以仔细看一下

25
00:00:59,840 --> 00:01:01,040
就是说代码很简单

26
00:01:01,040 --> 00:01:03,000
就是我们要理解它到底什么意思

27
00:01:04,159 --> 00:01:06,320
首先我们这个是输入的通道数

28
00:01:06,320 --> 00:01:08,840
我们不管先放在这个地方

29
00:01:09,320 --> 00:01:10,240
接下来就是说

30
00:01:10,240 --> 00:01:12,280
我们看它的输出的通道数

31
00:01:14,159 --> 00:01:15,640
输出通道数等于什么

32
00:01:15,800 --> 00:01:16,680
它等于

33
00:01:17,040 --> 00:01:21,439
某框的个数乘以你的类别数加1

34
00:01:22,159 --> 00:01:24,079
首先说加1是什么意思

35
00:01:24,319 --> 00:01:26,439
1这个是一个背景类的意思

36
00:01:27,000 --> 00:01:28,159
我要预测你这个毛框

37
00:01:28,159 --> 00:01:29,000
是不是一个背景

38
00:01:29,039 --> 00:01:29,439
对吧

39
00:01:29,560 --> 00:01:30,400
所以你告诉我

40
00:01:30,400 --> 00:01:31,959
你有多少类物体

41
00:01:32,000 --> 00:01:32,959
那么加1就是说

42
00:01:32,959 --> 00:01:35,359
我还加一类背景类在这个地方

43
00:01:36,679 --> 00:01:36,959
OK

44
00:01:37,000 --> 00:01:38,560
所以我要加个1

45
00:01:39,079 --> 00:01:40,319
接下来是说

46
00:01:40,359 --> 00:01:42,799
我对每一个毛框

47
00:01:44,319 --> 00:01:46,319
都得去预测它是多少类

48
00:01:46,319 --> 00:01:47,759
就是number of class加1

49
00:01:48,640 --> 00:01:51,000
所以我的预测值

50
00:01:51,000 --> 00:01:53,759
就是每一个毛框乘以

51
00:01:53,800 --> 00:01:56,240
我有我的类加一数

52
00:01:57,800 --> 00:01:58,960
接下来就是说

53
00:01:58,960 --> 00:02:00,240
它不是个全连接

54
00:02:00,560 --> 00:02:02,439
跟我们之前的看到不一样

55
00:02:02,439 --> 00:02:03,120
之前我们说

56
00:02:03,120 --> 00:02:04,439
我们做一个预测的时候

57
00:02:04,480 --> 00:02:05,439
用的是

58
00:02:07,280 --> 00:02:08,040
一个

59
00:02:09,000 --> 00:02:09,960
Dense的layer

60
00:02:09,960 --> 00:02:11,640
就是一个全连接的层

61
00:02:12,840 --> 00:02:14,640
但是这里我们用的是卷积

62
00:02:15,000 --> 00:02:17,840
我们也看过用卷积做分类器

63
00:02:17,840 --> 00:02:18,560
就是在

64
00:02:20,879 --> 00:02:21,680
NIN里面

65
00:02:21,680 --> 00:02:23,200
就Network里面

66
00:02:23,800 --> 00:02:25,040
但是它的做法是说

67
00:02:25,040 --> 00:02:26,160
我的通道数

68
00:02:26,200 --> 00:02:27,920
就是等于number of class

69
00:02:28,360 --> 00:02:29,120
它的通道数

70
00:02:29,120 --> 00:02:29,800
就是我有多少类

71
00:02:29,840 --> 00:02:30,640
就是多少通道

72
00:02:30,680 --> 00:02:32,360
但是它的feature map

73
00:02:32,360 --> 00:02:34,120
已经是通过了一个

74
00:02:36,200 --> 00:02:38,160
已经是做了一次

75
00:02:38,400 --> 00:02:39,360
Global的pooling

76
00:02:39,360 --> 00:02:40,400
就是说它的

77
00:02:41,560 --> 00:02:43,800
输入的高和宽已经变成1了

78
00:02:43,840 --> 00:02:45,600
但这里并没有

79
00:02:46,040 --> 00:02:47,560
这里的输入的高宽

80
00:02:47,560 --> 00:02:48,560
其实是有的

81
00:02:48,840 --> 00:02:50,280
就是说为什么有

82
00:02:50,440 --> 00:02:51,240
是说你可以看到

83
00:02:51,240 --> 00:02:52,720
kernel size等于3

84
00:02:52,759 --> 00:02:55,000
就是说我每次会看三个像素

85
00:02:55,000 --> 00:02:56,280
然后piling的1

86
00:02:56,319 --> 00:02:57,639
那么这个组合我们知道

87
00:02:58,159 --> 00:02:59,360
我们不会改变

88
00:02:59,360 --> 00:03:00,919
我们的输入的高宽

89
00:03:02,120 --> 00:03:03,319
那么它这个是什么意思

90
00:03:03,840 --> 00:03:05,879
就是说我们记得是我们的毛框

91
00:03:06,000 --> 00:03:07,079
number of anchors

92
00:03:07,079 --> 00:03:07,800
这里是什么

93
00:03:08,479 --> 00:03:09,280
你的

94
00:03:09,520 --> 00:03:11,479
Shape的数

95
00:03:11,479 --> 00:03:12,800
就是说你的size的数

96
00:03:12,800 --> 00:03:14,159
加上你的

97
00:03:14,199 --> 00:03:15,879
Ratio的数减1

98
00:03:15,879 --> 00:03:17,400
就是这个是number of anchors

99
00:03:17,400 --> 00:03:18,199
是这个意思

100
00:03:18,240 --> 00:03:21,400
就是说以每一个像素为中心

101
00:03:21,400 --> 00:03:23,599
我生成了多少个毛框

102
00:03:24,520 --> 00:03:25,920
所以我真实的毛框

103
00:03:25,920 --> 00:03:29,000
就是说我的feature map的高和宽

104
00:03:29,000 --> 00:03:30,240
高乘以宽

105
00:03:30,640 --> 00:03:32,120
但它的每个像素

106
00:03:32,159 --> 00:03:34,520
再乘以你number of anchors

107
00:03:35,360 --> 00:03:36,640
然后你对每个anchors

108
00:03:36,640 --> 00:03:37,439
你还得预测

109
00:03:37,439 --> 00:03:38,719
说number of class加1

110
00:03:38,719 --> 00:03:40,000
就是说类别数加1

111
00:03:40,360 --> 00:03:41,680
所以你实际的预测值

112
00:03:41,680 --> 00:03:42,719
应该就是说

113
00:03:44,400 --> 00:03:45,879
H乘以W

114
00:03:46,159 --> 00:03:47,960
再乘以number of anchors

115
00:03:47,960 --> 00:03:49,680
再乘以number of class加1

116
00:03:49,960 --> 00:03:50,680
所以这个地方

117
00:03:50,680 --> 00:03:52,159
我们用了一个卷积

118
00:03:52,920 --> 00:03:54,000
2D就是说

119
00:03:54,000 --> 00:03:56,840
我们对于每一个输入的像素

120
00:03:58,640 --> 00:04:00,319
然后对它的通道数

121
00:04:00,319 --> 00:04:01,560
变成number of anchors

122
00:04:01,560 --> 00:04:02,920
乘以number of class加1

123
00:04:02,920 --> 00:04:03,840
意味着就是说

124
00:04:03,840 --> 00:04:04,599
我们

125
00:04:04,920 --> 00:04:06,040
它的就是说

126
00:04:06,040 --> 00:04:09,520
我们对它的输入的每一个像素

127
00:04:09,640 --> 00:04:11,480
它的通道数输出通道

128
00:04:11,480 --> 00:04:12,240
对应的就是你

129
00:04:12,240 --> 00:04:14,360
以你像素为中心的

130
00:04:14,360 --> 00:04:15,159
这些毛框

131
00:04:15,159 --> 00:04:16,199
它的预测值

132
00:04:17,639 --> 00:04:18,000
OK

133
00:04:18,000 --> 00:04:19,680
所以你的输出最后是

134
00:04:20,000 --> 00:04:21,199
你有一个高和宽

135
00:04:21,199 --> 00:04:22,759
跟输入的高宽是一样的

136
00:04:22,800 --> 00:04:24,360
然后你还有一个通道数

137
00:04:24,360 --> 00:04:26,439
通道数是你每一个像素

138
00:04:26,439 --> 00:04:27,720
你生成多个毛框

139
00:04:27,720 --> 00:04:29,959
以及对毛框要预测多少值

140
00:04:30,920 --> 00:04:32,040
所以看到是说

141
00:04:32,040 --> 00:04:34,519
你的卷积的输出里面

142
00:04:34,960 --> 00:04:37,360
这是不管是你的高和宽

143
00:04:37,360 --> 00:04:38,480
那个两个维度

144
00:04:38,480 --> 00:04:40,040
还是你的通道数里面

145
00:04:40,040 --> 00:04:41,480
全部是你的预测

146
00:04:41,960 --> 00:04:44,560
这是因为目标检测里面

147
00:04:44,560 --> 00:04:46,639
我们要做的预测值是比较多的

148
00:04:47,480 --> 00:04:47,759
OK

149
00:04:47,759 --> 00:04:49,519
这是一个核心的

150
00:04:49,519 --> 00:04:52,759
一个跟之前图片分类

151
00:04:52,759 --> 00:04:53,639
一个不同的地方

152
00:04:53,639 --> 00:04:55,039
就是说我们稍微讲慢一点

153
00:04:55,039 --> 00:04:56,159
让大家理解一下

154
00:04:56,159 --> 00:04:59,000
就是说我们要对每一个像素

155
00:05:00,159 --> 00:05:01,000
做预测

156
00:05:01,240 --> 00:05:02,439
做比较多的预测

157
00:05:02,599 --> 00:05:03,039
OK

158
00:05:03,039 --> 00:05:04,719
所以这是class predictor

159
00:05:06,079 --> 00:05:07,039
同样道理的话

160
00:05:07,039 --> 00:05:08,959
我们要一个box的predictor

161
00:05:08,959 --> 00:05:11,599
就是叫BB box

162
00:05:11,599 --> 00:05:12,759
就是bonded box

163
00:05:12,920 --> 00:05:14,079
就是说它的predictor

164
00:05:14,079 --> 00:05:15,319
其实是说去预测

165
00:05:15,360 --> 00:05:16,639
跟真实的bonded box

166
00:05:16,639 --> 00:05:18,079
那个offset

167
00:05:19,000 --> 00:05:20,000
offset是多少

168
00:05:20,000 --> 00:05:20,719
是一个4

169
00:05:20,719 --> 00:05:21,159
对吧

170
00:05:21,560 --> 00:05:22,480
4个数字

171
00:05:22,879 --> 00:05:24,240
就是说我这个anchor

172
00:05:24,279 --> 00:05:25,360
化学的anchor

173
00:05:25,360 --> 00:05:26,800
到我真实的bonded box

174
00:05:26,800 --> 00:05:27,319
那个偏移

175
00:05:27,319 --> 00:05:28,360
就是4个值

176
00:05:28,600 --> 00:05:29,879
所以你的预测是什么

177
00:05:30,240 --> 00:05:32,079
对每一个anchor box

178
00:05:32,399 --> 00:05:33,279
就毛框

179
00:05:33,319 --> 00:05:35,319
那么我的预测值是4

180
00:05:35,360 --> 00:05:36,279
所以你的预测值

181
00:05:36,279 --> 00:05:37,399
在这个地方是乘以4

182
00:05:37,439 --> 00:05:37,959
对不对

183
00:05:38,159 --> 00:05:40,120
我给大家换个行

184
00:05:40,159 --> 00:05:41,839
可能看得清楚一点

185
00:05:42,360 --> 00:05:46,440
就是说我的通道数据

186
00:05:46,440 --> 00:05:48,320
变成了我的

187
00:05:48,320 --> 00:05:48,920
每个

188
00:05:48,920 --> 00:05:50,480
以每个像素为中心

189
00:05:50,680 --> 00:05:52,200
毛框大小乘以4

190
00:05:52,960 --> 00:05:53,920
同样道理的话

191
00:05:53,920 --> 00:05:55,840
我对每一个输入的

192
00:05:55,840 --> 00:05:57,240
那个feature map里的像素

193
00:05:57,240 --> 00:05:58,000
都得做预测

194
00:05:58,200 --> 00:05:59,680
所以我们的kernels

195
00:05:59,680 --> 00:06:00,200
是等于3

196
00:06:00,200 --> 00:06:00,840
padding的1

197
00:06:00,840 --> 00:06:02,120
使得我的输入

198
00:06:02,440 --> 00:06:04,240
输出高宽和输入的高宽

199
00:06:04,240 --> 00:06:05,000
是一样的

200
00:06:06,120 --> 00:06:06,720
OK

201
00:06:06,760 --> 00:06:09,760
这就是两个核心的预测程

202
00:06:10,599 --> 00:06:11,800
一个是预测

203
00:06:12,000 --> 00:06:13,240
每个毛框的类别

204
00:06:13,240 --> 00:06:13,959
一个是预测

205
00:06:13,959 --> 00:06:16,439
每个毛框到真实毛框的偏移

206
00:06:18,159 --> 00:06:18,399
好

207
00:06:18,399 --> 00:06:19,360
我们就讲了

208
00:06:19,360 --> 00:06:21,000
这两个比较重要的概念

209
00:06:21,000 --> 00:06:22,599
然后接下来就说

210
00:06:23,879 --> 00:06:25,079
看一下是说

211
00:06:25,360 --> 00:06:28,159
我们要连接多尺度的预测

212
00:06:28,159 --> 00:06:30,079
就是我们不是在某一个层

213
00:06:30,079 --> 00:06:31,519
就是预测完就完事了

214
00:06:31,560 --> 00:06:32,800
我们还要做

215
00:06:33,839 --> 00:06:35,519
就是说我们其实要做

216
00:06:35,920 --> 00:06:37,759
在多个层之间的做法

217
00:06:37,879 --> 00:06:38,599
所以我们看一下

218
00:06:38,599 --> 00:06:39,399
这个是怎么做的

219
00:06:40,639 --> 00:06:41,879
首先我们定一个很简单

220
00:06:41,879 --> 00:06:42,680
叫做forward

221
00:06:42,680 --> 00:06:44,399
就是给一个block

222
00:06:44,399 --> 00:06:45,360
就是给一个network

223
00:06:45,360 --> 00:06:45,959
这么一块

224
00:06:46,079 --> 00:06:46,879
给了一个input

225
00:06:46,879 --> 00:06:48,159
然后把那个输出返回来

226
00:06:48,159 --> 00:06:49,120
就是称一下

227
00:06:51,800 --> 00:06:54,159
然后我们

228
00:06:55,639 --> 00:06:56,439
干个什么事情

229
00:06:56,560 --> 00:06:57,360
就是说

230
00:06:57,399 --> 00:06:59,480
我们假设生成两个

231
00:06:59,480 --> 00:07:00,839
不一样的feature map

232
00:07:00,839 --> 00:07:01,599
就是feature map

233
00:07:01,599 --> 00:07:02,399
反正你不管怎么样

234
00:07:02,399 --> 00:07:03,800
你的batch size是不变的

235
00:07:03,839 --> 00:07:05,319
这是你就是2

236
00:07:05,439 --> 00:07:06,599
然后你的通道数

237
00:07:06,920 --> 00:07:09,199
你的高宽都会可能发生变化

238
00:07:09,279 --> 00:07:10,560
比如说这个feature map

239
00:07:10,560 --> 00:07:11,599
是20×20

240
00:07:11,639 --> 00:07:12,839
这个是10×10

241
00:07:13,279 --> 00:07:14,560
然后我的

242
00:07:15,000 --> 00:07:16,279
我是用的

243
00:07:16,439 --> 00:07:18,120
class predict的话

244
00:07:18,319 --> 00:07:19,240
叫class predict

245
00:07:19,240 --> 00:07:21,240
你的8就是你这个8对应的

246
00:07:21,279 --> 00:07:22,120
然后你的5

247
00:07:24,439 --> 00:07:26,120
就是你每一个

248
00:07:27,000 --> 00:07:30,279
像素要生成的毛框数

249
00:07:30,319 --> 00:07:31,000
然后你的10

250
00:07:31,000 --> 00:07:32,079
就是你的类别了

251
00:07:33,120 --> 00:07:34,800
然后当然是你这么做出来之后

252
00:07:34,800 --> 00:07:35,399
你的结果

253
00:07:35,399 --> 00:07:37,800
你能看到是一个2×55

254
00:07:38,600 --> 00:07:41,160
55就是你5×11

255
00:07:41,360 --> 00:07:42,639
就是每个毛框要

256
00:07:42,680 --> 00:07:43,920
每个像素为中心

257
00:07:43,920 --> 00:07:45,199
要生成5个毛框

258
00:07:45,240 --> 00:07:47,160
然后你的类别数是10

259
00:07:47,160 --> 00:07:48,360
所以你就加一个背景

260
00:07:48,360 --> 00:07:49,160
那变成11

261
00:07:49,199 --> 00:07:51,480
所以是说对每一个像素

262
00:07:51,639 --> 00:07:52,960
就是说对每一个

263
00:07:53,120 --> 00:07:54,319
输入里面的像素

264
00:07:54,360 --> 00:07:55,160
就20×20

265
00:07:55,160 --> 00:07:56,240
这400个像素

266
00:07:56,280 --> 00:07:59,199
我都会去做55个预测

267
00:07:59,560 --> 00:08:00,680
所以这个是在

268
00:08:00,879 --> 00:08:02,879
这一个尺度下面

269
00:08:02,879 --> 00:08:03,600
我的

270
00:08:03,720 --> 00:08:05,680
就是这个类别的预测的输出

271
00:08:07,879 --> 00:08:09,520
然后接下来就是说

272
00:08:09,520 --> 00:08:11,840
假设我把在另外一个尺度里面

273
00:08:11,840 --> 00:08:12,360
另外一个尺度

274
00:08:12,360 --> 00:08:13,840
我的通道数有变化

275
00:08:13,879 --> 00:08:15,600
我的高宽还减半了

276
00:08:16,400 --> 00:08:18,960
然后我可能还我的毛框数还不一样

277
00:08:19,040 --> 00:08:19,879
就是变成3

278
00:08:20,160 --> 00:08:22,000
当然number class一般是不变的

279
00:08:22,480 --> 00:08:23,400
所以看到是说

280
00:08:23,480 --> 00:08:25,240
这个地方就变成了一个33

281
00:08:25,920 --> 00:08:27,600
然后这里变成10和10

282
00:08:28,319 --> 00:08:29,199
所以就是说

283
00:08:29,199 --> 00:08:33,159
我在不同的尺度下面的预测

284
00:08:33,680 --> 00:08:35,039
除了第一个维度

285
00:08:35,039 --> 00:08:36,199
就是你的

286
00:08:37,839 --> 00:08:40,279
小批量里面多个图片之外

287
00:08:40,519 --> 00:08:42,319
另外三个都会发生变化

288
00:08:42,839 --> 00:08:45,000
所以我们要想办法把它弄在一起

289
00:08:45,839 --> 00:08:46,519
怎么弄一起

290
00:08:48,759 --> 00:08:50,039
我们干了一个这么事情

291
00:08:50,679 --> 00:08:52,079
首先我们把它flatten掉

292
00:08:52,079 --> 00:08:53,599
就是说我们把4D的东西

293
00:08:53,599 --> 00:08:54,480
变成一个2D

294
00:08:55,079 --> 00:08:56,079
2D我们怎么变

295
00:08:57,079 --> 00:08:58,679
我们首先把它

296
00:08:58,719 --> 00:09:01,799
把通道数丢到最后

297
00:09:02,959 --> 00:09:04,319
就通道数放到最后

298
00:09:04,360 --> 00:09:05,800
就是说这个permute

299
00:09:06,840 --> 00:09:07,400
就是说

300
00:09:08,160 --> 00:09:11,320
批量大小为保持高宽的往前挪一下

301
00:09:11,320 --> 00:09:12,520
把通道数留到最后

302
00:09:12,520 --> 00:09:13,520
因为为什么

303
00:09:13,520 --> 00:09:15,400
PyTorch和M3它的通道数

304
00:09:15,400 --> 00:09:17,040
都是放在第二位的

305
00:09:17,960 --> 00:09:19,480
01位就是那个1

306
00:09:20,000 --> 00:09:21,000
TensorFlow当然是不一样

307
00:09:21,000 --> 00:09:22,120
可能会放在最后

308
00:09:22,280 --> 00:09:23,480
所以我们在这个地方

309
00:09:23,480 --> 00:09:25,200
把通道数挪到最后

310
00:09:26,440 --> 00:09:27,640
然后再把它flatten掉

311
00:09:27,640 --> 00:09:28,400
flatten的意思

312
00:09:28,400 --> 00:09:29,040
就start

313
00:09:29,440 --> 00:09:30,520
dim等于1的意思

314
00:09:30,520 --> 00:09:32,800
就是说把后面这三个维度

315
00:09:32,920 --> 00:09:34,520
就把它拉成一个向量

316
00:09:34,560 --> 00:09:37,400
就变成一个2D的矩阵

317
00:09:37,440 --> 00:09:38,400
然后2D的矩阵

318
00:09:38,400 --> 00:09:40,000
你的高就是你的

319
00:09:41,080 --> 00:09:43,520
你的高就是你的批量大小

320
00:09:43,520 --> 00:09:45,600
你的宽就是你后面的所有了

321
00:09:48,480 --> 00:09:50,680
之所以我们要把通道维持放到最后

322
00:09:50,680 --> 00:09:51,800
是因为我们

323
00:09:53,280 --> 00:09:56,000
我们其实就是这样子的看的话

324
00:09:56,000 --> 00:09:58,400
因为对每一个像素

325
00:09:58,600 --> 00:09:59,760
它的每一个预测

326
00:09:59,760 --> 00:10:01,560
在后面是一个连续值

327
00:10:01,720 --> 00:10:02,480
就你不然的话

328
00:10:02,480 --> 00:10:04,440
对每个像通道数放在中间的话

329
00:10:04,440 --> 00:10:05,840
你把它一拉的话

330
00:10:05,840 --> 00:10:07,160
那么对每个像素

331
00:10:07,200 --> 00:10:07,880
你的预测

332
00:10:08,040 --> 00:10:08,680
那个类别预测

333
00:10:08,680 --> 00:10:10,040
它就不再是连续了

334
00:10:10,040 --> 00:10:12,320
它就是会被拉得比较开

335
00:10:12,360 --> 00:10:13,840
这就是不那么好用

336
00:10:14,800 --> 00:10:16,560
就是说当然也是

337
00:10:16,600 --> 00:10:18,520
你不拉也没关系

338
00:10:18,560 --> 00:10:20,040
就你后面注意一下也行

339
00:10:21,000 --> 00:10:23,000
接下来就是说拉成一个矩阵之后

340
00:10:23,000 --> 00:10:24,200
我们就可以concate了

341
00:10:25,240 --> 00:10:26,880
concate我们是在哪一位

342
00:10:27,040 --> 00:10:29,880
就是在你的宽上面concate

343
00:10:30,679 --> 00:10:32,600
就我们直接看一下例子

344
00:10:32,960 --> 00:10:35,439
就是我的y1和y2进来

345
00:10:35,439 --> 00:10:38,120
直接用这个函数的话

346
00:10:38,120 --> 00:10:38,639
就这个函数

347
00:10:38,639 --> 00:10:40,279
就是说你先把它flatten掉

348
00:10:40,279 --> 00:10:42,200
然后再把它concate起来

349
00:10:42,279 --> 00:10:46,519
它就变成了2×25300

350
00:10:47,240 --> 00:10:47,799
就说白了

351
00:10:47,799 --> 00:10:50,080
就是说我们把前面这两个

352
00:10:50,240 --> 00:10:52,480
就是说除了第一个位都是一样的

353
00:10:52,480 --> 00:10:52,639
是吧

354
00:10:52,639 --> 00:10:53,480
别的都不一样

355
00:10:53,519 --> 00:10:55,159
那我们就把它拉成一下向量

356
00:10:55,840 --> 00:10:57,240
然后把拉成一下向量之后

357
00:10:57,240 --> 00:11:00,120
然后就一直把它弄得特别长

358
00:11:00,639 --> 00:11:01,120
这样的话

359
00:11:01,120 --> 00:11:02,480
你不管你的维度是

360
00:11:02,480 --> 00:11:04,240
就是说你的尺度是多少

361
00:11:04,399 --> 00:11:06,039
你的超川数怎么样子

362
00:11:06,039 --> 00:11:08,680
我都能把你给你合成一个tensor

363
00:11:09,120 --> 00:11:10,639
合成一个tensor主要好处

364
00:11:10,639 --> 00:11:12,840
就是说后面的代码写起来会简单一点

365
00:11:12,879 --> 00:11:16,519
就不要说我对每一个分辨率

366
00:11:16,519 --> 00:11:18,240
还要做一个对应的loss

367
00:11:18,440 --> 00:11:19,799
怎么算起来比较麻烦

368
00:11:19,799 --> 00:11:21,000
就是我反正把你合在一起

369
00:11:21,000 --> 00:11:22,600
变成一个大的tensor

370
00:11:22,600 --> 00:11:24,480
里面所有东西都有了

371
00:11:25,480 --> 00:11:25,759
OK

372
00:11:25,759 --> 00:11:27,480
就是说这个函数感的事情

373
00:11:30,000 --> 00:11:30,320
好

374
00:11:30,320 --> 00:11:31,480
接下来我们来看一下

375
00:11:31,480 --> 00:11:33,920
就是说我们网络是怎么定义的

376
00:11:34,279 --> 00:11:35,240
当然是说你

377
00:11:35,240 --> 00:11:36,920
我们也知道说你的

378
00:11:36,960 --> 00:11:39,399
其实你的神经网络设计

379
00:11:39,480 --> 00:11:41,720
你可以取前面任何一个

380
00:11:41,759 --> 00:11:43,680
我们讲过的神经网络都行

381
00:11:43,879 --> 00:11:45,039
就比如说你用resnet

382
00:11:45,320 --> 00:11:46,800
或者你用谁都没关系

383
00:11:47,159 --> 00:11:49,480
通常是大家会用pre-trained模型

384
00:11:49,680 --> 00:11:51,120
就是说我说我有一个

385
00:11:51,120 --> 00:11:51,759
我用res

386
00:11:51,759 --> 00:11:53,680
在imagenet上pre-trained好的

387
00:11:53,680 --> 00:11:54,920
resnet拿过来

388
00:11:54,960 --> 00:11:56,120
作为我的backbone

389
00:11:56,120 --> 00:11:59,040
就作为我的目标检测算法

390
00:11:59,040 --> 00:12:00,520
里面的CNN的模型

391
00:12:01,520 --> 00:12:02,280
这里的话

392
00:12:02,280 --> 00:12:04,720
我们就是给大家看一眼

393
00:12:04,720 --> 00:12:05,960
就是我们做了一个

394
00:12:06,040 --> 00:12:08,680
最简单一个CNN的网络

395
00:12:08,880 --> 00:12:10,360
就给大家一个演示目的

396
00:12:10,520 --> 00:12:12,000
就是一个很小的网络

397
00:12:12,280 --> 00:12:13,680
这样子跑起来比较快一点

398
00:12:13,680 --> 00:12:14,280
主要是

399
00:12:14,560 --> 00:12:15,720
所以给大家就是说

400
00:12:15,720 --> 00:12:18,720
从头定一个自己的CNN的网络

401
00:12:19,520 --> 00:12:21,320
我们CNN网络主要干点事情

402
00:12:21,320 --> 00:12:21,840
什么样子

403
00:12:21,960 --> 00:12:25,759
就是一个叫做DoneSampleBlock

404
00:12:26,080 --> 00:12:28,120
每一次就是把你的高宽减半

405
00:12:29,000 --> 00:12:30,639
你要给定的超参数

406
00:12:30,639 --> 00:12:32,040
就是说你的输入的通道数

407
00:12:32,560 --> 00:12:34,320
和你的输出的通道数

408
00:12:35,879 --> 00:12:36,800
首先这个干嘛

409
00:12:37,000 --> 00:12:39,320
它就是里面有两块

410
00:12:39,320 --> 00:12:40,480
一个卷集

411
00:12:40,480 --> 00:12:42,399
我们首先看大概的思想

412
00:12:42,639 --> 00:12:43,920
就是说一个卷集

413
00:12:43,920 --> 00:12:44,600
加一个batchlong

414
00:12:44,600 --> 00:12:45,480
加一个relu

415
00:12:46,519 --> 00:12:48,120
然后把它重复两遍

416
00:12:48,720 --> 00:12:52,679
就是说这个是pen的操作

417
00:12:54,519 --> 00:12:55,440
重复两次

418
00:12:55,440 --> 00:12:57,799
就是卷集batchlong加relu

419
00:12:57,799 --> 00:12:58,840
然后repeat两次

420
00:12:58,840 --> 00:13:00,000
就跟resnet有点像

421
00:13:00,000 --> 00:13:00,440
对不对

422
00:13:01,200 --> 00:13:04,480
最后我加一个Maxpool2D

423
00:13:04,480 --> 00:13:07,240
就是给你的windowsize等于2

424
00:13:07,720 --> 00:13:08,519
windowsize等于2

425
00:13:08,519 --> 00:13:09,560
我们知道默认的话

426
00:13:09,560 --> 00:13:10,519
strategy会等于2

427
00:13:10,519 --> 00:13:12,360
就是说它会把高宽减半

428
00:13:12,519 --> 00:13:14,080
就用一个最大的持话程

429
00:13:14,080 --> 00:13:15,240
把高宽减半

430
00:13:15,879 --> 00:13:17,000
再仔细看一下参数

431
00:13:17,000 --> 00:13:17,960
最后你会发现说

432
00:13:18,080 --> 00:13:18,879
其实也挺简单的

433
00:13:18,879 --> 00:13:19,360
对不对

434
00:13:19,600 --> 00:13:20,919
就是说你的

435
00:13:22,360 --> 00:13:23,039
我的卷集

436
00:13:23,039 --> 00:13:23,840
第一个卷集

437
00:13:23,840 --> 00:13:26,799
就是把你的输入通道和输出通道

438
00:13:26,799 --> 00:13:27,759
然后你的kernel

439
00:13:27,759 --> 00:13:29,000
就是反等于3

440
00:13:29,559 --> 00:13:30,600
就kernel等于3

441
00:13:30,600 --> 00:13:31,399
然后pan等于1

442
00:13:31,399 --> 00:13:32,799
就是不改变高宽

443
00:13:32,960 --> 00:13:34,039
然后加一个batchlong

444
00:13:34,320 --> 00:13:36,600
batchlong也就是告诉你的通道数

445
00:13:36,600 --> 00:13:37,240
就行了

446
00:13:37,240 --> 00:13:38,080
加一个relu

447
00:13:38,919 --> 00:13:40,360
当然后面一个就卷集

448
00:13:40,360 --> 00:13:41,559
就不会改变通道了

449
00:13:41,559 --> 00:13:44,440
就是说inchannel就改成outchannel

450
00:13:44,440 --> 00:13:46,799
然后它就不对通道做变换了

451
00:13:47,279 --> 00:13:48,799
然后重复了加进去之后

452
00:13:48,799 --> 00:13:50,720
然后再加上一个maxpoolrd

453
00:13:51,120 --> 00:13:52,440
然后最后把它放到一个

454
00:13:52,440 --> 00:13:53,720
sequential的一个block里面

455
00:13:53,960 --> 00:13:55,039
这个函数就完事了

456
00:13:56,279 --> 00:13:57,240
所以大家可以看一下

457
00:13:57,240 --> 00:13:58,320
就是说这个函数的意义

458
00:13:58,320 --> 00:13:59,000
就是说

459
00:13:59,159 --> 00:14:01,360
我给你一个2×3×2

460
00:14:01,360 --> 00:14:02,200
是20的

461
00:14:02,200 --> 00:14:03,799
高宽是20的

462
00:14:04,000 --> 00:14:06,720
通道数是3的一个输入的话

463
00:14:06,919 --> 00:14:08,480
我假设给你一个

464
00:14:08,600 --> 00:14:10,639
我可以把你通道数变成10

465
00:14:11,000 --> 00:14:12,840
那么高宽就会

466
00:14:12,960 --> 00:14:14,000
同时也会被减半

467
00:14:14,000 --> 00:14:14,440
对吧

468
00:14:14,440 --> 00:14:16,200
所以你的输出就是一个2

469
00:14:16,200 --> 00:14:17,879
p量大小不变

470
00:14:17,960 --> 00:14:19,160
通道变10

471
00:14:19,200 --> 00:14:21,160
高宽也会从20变成10

472
00:14:21,160 --> 00:14:21,879
减半

473
00:14:22,120 --> 00:14:22,640
OK

474
00:14:22,640 --> 00:14:24,520
这就是downsample block

475
00:14:24,920 --> 00:14:25,480
这个快

476
00:14:25,480 --> 00:14:27,879
其实在不管在resnet以前

477
00:14:27,879 --> 00:14:28,759
都很常见

478
00:14:29,320 --> 00:14:31,600
就是变换一下通道数

479
00:14:31,600 --> 00:14:34,080
然后再把你高宽减半

480
00:14:34,080 --> 00:14:36,360
就是你认为是一个stage

481
00:14:39,840 --> 00:14:41,240
那么另外一个是说

482
00:14:41,240 --> 00:14:42,720
我们做一个

483
00:14:43,280 --> 00:14:44,480
BaseNet

484
00:14:44,480 --> 00:14:45,800
BaseNet是什么样子

485
00:14:45,800 --> 00:14:46,960
意思就是说

486
00:14:47,000 --> 00:14:48,480
从原始图片

487
00:14:48,480 --> 00:14:49,240
抽特征

488
00:14:49,240 --> 00:14:51,200
一直到第一次

489
00:14:51,200 --> 00:14:54,200
我们去对它的feature map做模框

490
00:14:54,280 --> 00:14:55,560
就是说中间那一节

491
00:14:55,560 --> 00:14:57,960
我们把它叫做BaseNet

492
00:14:58,680 --> 00:15:00,000
BaseNet也挺简单的

493
00:15:00,000 --> 00:15:02,280
它就是那么三个

494
00:15:02,280 --> 00:15:03,920
downsample block放在一起

495
00:15:04,920 --> 00:15:05,880
就是说downsample block

496
00:15:05,880 --> 00:15:07,280
我只要告诉你通道就行了

497
00:15:07,280 --> 00:15:07,720
对吧

498
00:15:07,760 --> 00:15:08,680
所以就是说

499
00:15:08,880 --> 00:15:09,920
说白了BaseNet

500
00:15:09,920 --> 00:15:11,480
就是说给你一个

501
00:15:11,520 --> 00:15:12,320
给你一个图片

502
00:15:12,560 --> 00:15:13,840
我会有三个

503
00:15:14,240 --> 00:15:15,680
downsample block放在一起

504
00:15:15,800 --> 00:15:16,360
先看一下

505
00:15:16,560 --> 00:15:17,360
看一下什么意思

506
00:15:17,880 --> 00:15:19,360
我告诉你number of filters

507
00:15:19,360 --> 00:15:21,080
就是你的channel数

508
00:15:21,200 --> 00:15:22,040
输入是3

509
00:15:22,680 --> 00:15:23,320
首先第一次

510
00:15:23,320 --> 00:15:25,480
我们把它增加到16

511
00:15:25,520 --> 00:15:27,480
再double到32

512
00:15:27,480 --> 00:15:29,040
再double到64

513
00:15:30,320 --> 00:15:31,360
然后就是说

514
00:15:31,360 --> 00:15:32,000
我们说白了

515
00:15:32,000 --> 00:15:32,640
就是

516
00:15:33,280 --> 00:15:34,880
构造三个这样子的

517
00:15:34,880 --> 00:15:36,200
downsample block

518
00:15:36,320 --> 00:15:37,920
就每一次就是

519
00:15:38,040 --> 00:15:40,800
第一个就是从3变到16

520
00:15:41,080 --> 00:15:42,920
第二个就是从16变到23

521
00:15:43,160 --> 00:15:45,000
第三个就是从32变到64

522
00:15:45,000 --> 00:15:47,279
最后出来的是一个64位的东西

523
00:15:47,840 --> 00:15:49,519
然后因为我有三次用了

524
00:15:49,679 --> 00:15:51,679
所以我的高宽从原始图片

525
00:15:51,679 --> 00:15:53,840
会减少8倍

526
00:15:55,240 --> 00:15:56,360
让我们看一下效果

527
00:15:56,480 --> 00:15:57,279
效果就是说

528
00:15:57,279 --> 00:15:58,879
你可以看一下

529
00:15:59,759 --> 00:16:00,840
就比如说我给你一个

530
00:16:00,840 --> 00:16:02,559
2×3×256×256的

531
00:16:02,559 --> 00:16:03,559
这样图片的话

532
00:16:03,799 --> 00:16:05,200
那么你出来之后

533
00:16:05,639 --> 00:16:07,399
就变成2×64

534
00:16:07,679 --> 00:16:09,399
64是因为我最后一个

535
00:16:09,399 --> 00:16:10,120
downsample block

536
00:16:10,120 --> 00:16:11,879
我把channel数变成64了

537
00:16:12,279 --> 00:16:14,200
然后你变成32×32

538
00:16:14,200 --> 00:16:16,240
是因为我们有三个downsample block

539
00:16:16,440 --> 00:16:18,360
所以是变成减了8倍

540
00:16:18,360 --> 00:16:20,759
就是256×8×32

541
00:16:21,360 --> 00:16:21,879
OK

542
00:16:21,879 --> 00:16:22,840
所以就是说

543
00:16:23,400 --> 00:16:24,759
那么你可以看到是说

544
00:16:24,759 --> 00:16:29,040
我们第一次去采算模框的地方

545
00:16:29,040 --> 00:16:33,640
就是一个32×32的一个feature map

546
00:16:34,640 --> 00:16:35,240
OK

547
00:16:35,720 --> 00:16:37,120
当然是说你的图片

548
00:16:37,320 --> 00:16:38,360
当然你的图片可以做

549
00:16:38,360 --> 00:16:41,320
跟哪里做512×512的话

550
00:16:41,360 --> 00:16:42,680
那么我们看到的

551
00:16:42,960 --> 00:16:44,800
就是一个64×64的

552
00:16:46,480 --> 00:16:46,800
OK

553
00:16:46,800 --> 00:16:48,080
这也是我们之前说的

554
00:16:48,080 --> 00:16:49,800
假设你的物体特别小的话

555
00:16:49,800 --> 00:16:51,400
那你就把输入的图片弄大一点

556
00:16:53,440 --> 00:16:55,040
那么接下来我们看一下

557
00:16:55,040 --> 00:16:57,160
我们的整个网络是怎么样子的

558
00:16:57,520 --> 00:16:59,360
就我们网络它的结构

559
00:16:59,360 --> 00:17:01,680
就是说它其实有还是一样

560
00:17:01,680 --> 00:17:02,920
它是有5个stage

561
00:17:02,920 --> 00:17:04,000
就跟之前我们一样

562
00:17:04,000 --> 00:17:05,000
都是有5个stage

563
00:17:06,680 --> 00:17:09,120
首先我们第一个stage干嘛

564
00:17:09,120 --> 00:17:10,360
第一个stage就是我的

565
00:17:10,360 --> 00:17:11,480
base的net

566
00:17:11,680 --> 00:17:12,519
就刚刚说的

567
00:17:12,519 --> 00:17:15,319
就把你变成一个32×32的高宽

568
00:17:15,559 --> 00:17:19,480
和你的通道数变64的

569
00:17:19,480 --> 00:17:20,879
一个feature map

570
00:17:22,480 --> 00:17:23,680
假设你接下来

571
00:17:23,680 --> 00:17:24,759
你是第二个

572
00:17:24,759 --> 00:17:26,039
你的stage是什么样子

573
00:17:26,039 --> 00:17:28,000
第二个stage就是一个

574
00:17:28,039 --> 00:17:29,079
Dunn-Summer block

575
00:17:29,079 --> 00:17:32,000
但是把通道数变成了128

576
00:17:32,000 --> 00:17:33,240
就增加了通道数

577
00:17:34,119 --> 00:17:37,160
第block2和3在这个地方

578
00:17:37,639 --> 00:17:38,799
就在AOS里面

579
00:17:39,159 --> 00:17:42,559
它还是两个Dunn-Summer block

580
00:17:42,559 --> 00:17:44,079
但是我的通道数就没变了

581
00:17:44,079 --> 00:17:44,960
因为为什么

582
00:17:45,000 --> 00:17:46,839
是因为我们数据级比较小

583
00:17:46,960 --> 00:17:49,759
就没必要做到特别大的通道数

584
00:17:49,759 --> 00:17:51,639
就是说我们就维持通道数

585
00:17:51,639 --> 00:17:52,799
128就不变了

586
00:17:52,839 --> 00:17:54,759
就没有做到256和512

587
00:17:55,599 --> 00:17:56,399
然后通常来说

588
00:17:56,399 --> 00:17:58,919
你的当你的数据级比较复杂的时候

589
00:17:58,919 --> 00:18:00,799
你可能还是会往上增的

590
00:18:02,319 --> 00:18:04,319
最后的时候

591
00:18:04,319 --> 00:18:06,359
我们就做一个max pool

592
00:18:06,559 --> 00:18:08,480
就是一个global的max pool

593
00:18:08,599 --> 00:18:10,440
然后把它变成一个1乘1

594
00:18:11,079 --> 00:18:11,759
就是说最后的

595
00:18:11,759 --> 00:18:13,039
最后我们在一个1乘1的

596
00:18:13,039 --> 00:18:14,799
就不管你的图片输出图片多大

597
00:18:14,920 --> 00:18:16,519
最后我们把它做一个

598
00:18:16,519 --> 00:18:17,240
最后一个block

599
00:18:17,240 --> 00:18:18,480
我们把feature map压到

600
00:18:18,480 --> 00:18:20,920
压到一个1乘1的上面

601
00:18:21,720 --> 00:18:23,279
所以基本上可以看到是说

602
00:18:23,480 --> 00:18:25,839
我们这个网络就5个stage

603
00:18:26,120 --> 00:18:28,640
里面其实就都是Dunn-Summer block

604
00:18:28,880 --> 00:18:30,120
但是不一样的是说

605
00:18:30,120 --> 00:18:31,319
第1个stage的时候

606
00:18:32,240 --> 00:18:33,599
我们去做

607
00:18:34,759 --> 00:18:35,720
目标检测的时候

608
00:18:35,720 --> 00:18:37,519
已经是三个Dunn-Summer block

609
00:18:37,639 --> 00:18:38,879
接下来还是

610
00:18:38,879 --> 00:18:40,240
接下来的三个

611
00:18:40,240 --> 00:18:42,519
也仍然是三个Dunn-Summer block

612
00:18:42,920 --> 00:18:44,079
最后是一个

613
00:18:45,559 --> 00:18:47,599
全局的max pool

614
00:18:48,680 --> 00:18:51,519
所以我们有5个模块的话

615
00:18:51,519 --> 00:18:54,240
那么我们会在5个尺度上

616
00:18:54,240 --> 00:18:55,599
去做目标检测

617
00:18:56,119 --> 00:18:57,359
就每个block

618
00:18:57,359 --> 00:19:00,200
就是每个block的后面

619
00:19:00,200 --> 00:19:01,839
我们都会去做一次

620
00:19:02,000 --> 00:19:05,000
就从32x32到

621
00:19:05,440 --> 00:19:07,160
基本上就一直

622
00:19:07,759 --> 00:19:08,759
接下来减5次

623
00:19:09,000 --> 00:19:09,839
都可以过去

624
00:19:10,359 --> 00:19:10,880
OK

625
00:19:11,440 --> 00:19:13,839
所以这个是一个

626
00:19:13,839 --> 00:19:15,799
完整的一个SSD的模型

627
00:19:16,039 --> 00:19:17,000
当然我们这个模型

628
00:19:17,000 --> 00:19:18,279
是我们手动构造的

629
00:19:18,599 --> 00:19:19,599
你可以选用

630
00:19:19,599 --> 00:19:22,200
任何卷迹神级网络都可以

631
00:19:22,240 --> 00:19:23,119
因为你用resnet

632
00:19:23,119 --> 00:19:24,720
其实也就是5个stage了

633
00:19:24,799 --> 00:19:26,000
就是说你可以把它套过来

634
00:19:26,000 --> 00:19:26,920
都没关系了

635
00:19:29,079 --> 00:19:29,480
好

636
00:19:29,480 --> 00:19:30,160
接下来就是说

637
00:19:30,160 --> 00:19:31,640
我们对每个

638
00:19:31,960 --> 00:19:33,320
快每个stage

639
00:19:33,320 --> 00:19:35,759
来定义一下前项计算

640
00:19:35,960 --> 00:19:37,360
就跟之前会有一点不一样

641
00:19:37,360 --> 00:19:38,560
是因为你前项计算

642
00:19:38,560 --> 00:19:39,720
相对说比较复杂一点

643
00:19:40,080 --> 00:19:42,040
不再就是一个block

644
00:19:42,040 --> 00:19:42,840
传

645
00:19:42,840 --> 00:19:44,200
就我们之前

646
00:19:44,200 --> 00:19:44,920
我们的block

647
00:19:44,920 --> 00:19:46,720
就是给个x进去

648
00:19:46,720 --> 00:19:48,000
就block这个本身

649
00:19:48,000 --> 00:19:49,400
是一个network本身的话

650
00:19:49,400 --> 00:19:50,680
就是一堆卷迹的话

651
00:19:50,720 --> 00:19:52,160
那么我们的前项计算

652
00:19:52,160 --> 00:19:53,440
以前就是给个x进去

653
00:19:53,440 --> 00:19:54,360
出来一个y就行了

654
00:19:54,759 --> 00:19:55,680
但现在不一样

655
00:19:55,680 --> 00:19:57,440
现在我们得处理这些毛框

656
00:19:57,840 --> 00:19:58,120
好

657
00:19:58,120 --> 00:19:58,640
我们来看一下

658
00:19:58,640 --> 00:19:59,480
这是怎么做的

659
00:20:00,480 --> 00:20:03,360
首先我们的输入参数

660
00:20:03,559 --> 00:20:04,680
对每一个block

661
00:20:04,680 --> 00:20:06,120
就会每一个

662
00:20:07,400 --> 00:20:08,480
每一个分辨率

663
00:20:08,599 --> 00:20:10,599
就是多尺度上的一个分辨率上

664
00:20:10,640 --> 00:20:11,360
来说

665
00:20:11,360 --> 00:20:13,839
我们给定我们当前的输入

666
00:20:14,000 --> 00:20:16,120
给定我们当前网络那一块

667
00:20:16,720 --> 00:20:18,839
那么我们接下来还要说

668
00:20:19,000 --> 00:20:22,000
这个anchor

669
00:20:22,279 --> 00:20:23,200
就是这个毛框

670
00:20:23,200 --> 00:20:24,160
它要多少

671
00:20:24,160 --> 00:20:25,240
那些size是什么

672
00:20:25,240 --> 00:20:26,920
就是说大小是什么样子的

673
00:20:26,960 --> 00:20:29,200
就在这个分辨率下面

674
00:20:29,200 --> 00:20:30,400
size是什么样子的

675
00:20:30,400 --> 00:20:31,480
ratio是什么样子的

676
00:20:31,480 --> 00:20:33,240
那么你的class predictor

677
00:20:33,240 --> 00:20:34,519
什么叫box predictor

678
00:20:34,519 --> 00:20:35,240
是什么样子

679
00:20:36,279 --> 00:20:36,799
就这两个

680
00:20:36,799 --> 00:20:38,120
就是我们之前构造的东西

681
00:20:39,000 --> 00:20:39,319
好

682
00:20:39,319 --> 00:20:39,960
我们来看一下

683
00:20:39,960 --> 00:20:40,640
具体怎么做的

684
00:20:41,559 --> 00:20:42,759
首先跟之前一样

685
00:20:42,759 --> 00:20:44,680
当时我们要算一个y

686
00:20:45,120 --> 00:20:47,640
就是它的feature map出来

687
00:20:47,640 --> 00:20:49,200
那是说

688
00:20:49,240 --> 00:20:52,440
这个stage的feature map

689
00:20:52,799 --> 00:20:53,440
y

690
00:20:54,200 --> 00:20:55,400
接下来是说

691
00:20:55,960 --> 00:20:57,360
给定这个feature map之后

692
00:20:57,360 --> 00:20:59,160
给定它的高宽之后

693
00:20:59,160 --> 00:21:00,120
然后告诉我说

694
00:21:00,120 --> 00:21:01,759
在这个尺度下面

695
00:21:01,759 --> 00:21:03,640
我的那些毛框的超参数

696
00:21:03,640 --> 00:21:04,600
是什么样子

697
00:21:04,800 --> 00:21:07,160
然后我去生成一些

698
00:21:07,160 --> 00:21:09,080
把毛框全部生成出来

699
00:21:10,560 --> 00:21:11,680
当我们放在这个地方

700
00:21:11,680 --> 00:21:12,000
就是说

701
00:21:12,040 --> 00:21:13,680
其实你可以把它写出去

702
00:21:13,680 --> 00:21:14,120
没关系

703
00:21:14,120 --> 00:21:14,759
因为

704
00:21:15,600 --> 00:21:16,640
因为其实毛框

705
00:21:16,640 --> 00:21:19,320
只是要的是y的高和宽

706
00:21:19,320 --> 00:21:20,720
它不关心你y里面

707
00:21:20,720 --> 00:21:22,040
具体的值是什么样子

708
00:21:22,440 --> 00:21:23,600
所以你这个东西

709
00:21:23,600 --> 00:21:25,200
可以提前生成出来

710
00:21:25,200 --> 00:21:25,880
是没关系的

711
00:21:25,880 --> 00:21:27,600
这样子你的性能会快一点点

712
00:21:28,360 --> 00:21:29,160
但我们写在这里

713
00:21:29,160 --> 00:21:29,960
就是简单一点

714
00:21:31,040 --> 00:21:31,440
好

715
00:21:31,440 --> 00:21:33,880
有了毛框之后

716
00:21:34,480 --> 00:21:36,240
接下来我们要干的事情是说

717
00:21:36,240 --> 00:21:37,280
对每一个y

718
00:21:37,960 --> 00:21:40,440
我们要去算我们的

719
00:21:43,880 --> 00:21:45,800
每一个毛框

720
00:21:45,800 --> 00:21:48,240
它的内别

721
00:21:49,480 --> 00:21:50,880
当然注意到一点是说

722
00:21:50,880 --> 00:21:51,360
这个地方

723
00:21:51,360 --> 00:21:54,200
我们并不需要把毛框传进去

724
00:21:55,680 --> 00:21:56,080
理解吗

725
00:21:56,080 --> 00:21:56,680
就是说

726
00:21:56,680 --> 00:21:59,080
我知道知道我有多少个毛框就行了

727
00:21:59,519 --> 00:22:00,320
虽然这个地方

728
00:22:00,320 --> 00:22:00,880
我们这个函数

729
00:22:00,880 --> 00:22:01,920
没有写的特别好

730
00:22:02,080 --> 00:22:02,640
这个东西

731
00:22:02,640 --> 00:22:03,480
其实你需要把

732
00:22:04,440 --> 00:22:05,200
number of毛框

733
00:22:05,200 --> 00:22:06,039
就是size

734
00:22:06,039 --> 00:22:08,120
加上这个东西的length

735
00:22:08,120 --> 00:22:09,039
加上它的length

736
00:22:09,039 --> 00:22:09,560
减去1

737
00:22:09,560 --> 00:22:10,880
要把参数传进去的

738
00:22:11,360 --> 00:22:12,120
我们就偷懒

739
00:22:12,120 --> 00:22:16,360
反正没写在这个函数里面

740
00:22:18,000 --> 00:22:19,039
就sorry

741
00:22:19,039 --> 00:22:20,360
不是没写在函数里面

742
00:22:20,360 --> 00:22:21,360
是我们在构造时候

743
00:22:21,360 --> 00:22:22,039
已经传进去了

744
00:22:22,039 --> 00:22:22,720
所以这个地方

745
00:22:22,720 --> 00:22:24,000
我们在之后构造的时候

746
00:22:24,000 --> 00:22:24,480
我们会有

747
00:22:24,759 --> 00:22:26,920
所以这里就是你看不出来它的联系

748
00:22:27,160 --> 00:22:27,839
就是说

749
00:22:27,839 --> 00:22:29,160
它其实是不关心

750
00:22:29,160 --> 00:22:30,799
你到底毛框长什么样子

751
00:22:30,799 --> 00:22:33,079
就我只要知道有多少个毛框就行了

752
00:22:33,079 --> 00:22:34,079
我就做预测

753
00:22:34,240 --> 00:22:35,680
它其实看到的是

754
00:22:36,160 --> 00:22:38,240
看到的是整个外

755
00:22:39,200 --> 00:22:40,440
就之前我们有说

756
00:22:40,640 --> 00:22:42,920
你毛框怎么画怎么画

757
00:22:42,960 --> 00:22:44,480
其实你可能会觉得说

758
00:22:44,480 --> 00:22:45,880
我可能只会去看

759
00:22:45,880 --> 00:22:47,400
我跟你画一圈里面

760
00:22:47,400 --> 00:22:50,880
毛框里面那些feature是长什么样子

761
00:22:51,160 --> 00:22:52,720
其实在这个地方不是的

762
00:22:52,839 --> 00:22:53,960
这个地方是说

763
00:22:54,480 --> 00:22:55,799
你不管我毛框怎么样子

764
00:22:55,799 --> 00:22:58,759
我看到的是整个你的feature map

765
00:22:59,519 --> 00:23:01,480
只是说之后你算lost的时候

766
00:23:01,480 --> 00:23:04,039
让我去调整

767
00:23:04,039 --> 00:23:05,920
使得我尽量去看你的

768
00:23:05,960 --> 00:23:08,039
尝试尽量去看你的东西

769
00:23:08,079 --> 00:23:09,920
尽量去看你在毛框里面的东西

770
00:23:09,960 --> 00:23:11,880
但这个地方我是不需要去管

771
00:23:11,880 --> 00:23:13,240
你毛框到底是什么东西

772
00:23:13,480 --> 00:23:15,039
只是在the for的时候

773
00:23:15,039 --> 00:23:15,960
我是不用管的

774
00:23:16,000 --> 00:23:17,000
是在backhoe的时候

775
00:23:17,000 --> 00:23:17,960
你叫lost function

776
00:23:17,960 --> 00:23:20,000
所以我强迫你去看

777
00:23:20,880 --> 00:23:21,400
OK

778
00:23:22,320 --> 00:23:23,920
所以我们就直接拿到了

779
00:23:23,920 --> 00:23:25,200
class的predict

780
00:23:25,200 --> 00:23:25,960
和你的

781
00:23:26,000 --> 00:23:28,720
就帮你到你的真实别人

782
00:23:28,720 --> 00:23:31,320
可能offset的predict

783
00:23:31,960 --> 00:23:32,519
OK

784
00:23:32,640 --> 00:23:35,040
所以我们的for会返回4个东西

785
00:23:36,240 --> 00:23:37,759
就一个是你当前的

786
00:23:37,759 --> 00:23:39,320
就是说你的feature map

787
00:23:39,320 --> 00:23:41,000
就是你的卷积层的输出

788
00:23:41,759 --> 00:23:42,320
第二个是说

789
00:23:42,320 --> 00:23:44,040
在你的卷积层的输出上面

790
00:23:44,040 --> 00:23:45,640
我生成的那些毛框

791
00:23:46,759 --> 00:23:48,080
这个地方是说

792
00:23:48,120 --> 00:23:50,759
对每一个毛框

793
00:23:51,519 --> 00:23:53,800
它的类别的预测

794
00:23:54,200 --> 00:23:56,080
和它的毛框

795
00:23:56,560 --> 00:23:59,040
到真实别人框

796
00:23:59,040 --> 00:23:59,840
那个offset

797
00:23:59,880 --> 00:24:01,200
就偏移的预测

798
00:24:01,560 --> 00:24:02,240
OK

799
00:24:02,240 --> 00:24:03,040
就是我的for的

800
00:24:03,040 --> 00:24:04,480
会出来4个东西

801
00:24:04,680 --> 00:24:05,960
就跟之前是不一样的

802
00:24:06,080 --> 00:24:07,320
之前只有一个y

803
00:24:07,480 --> 00:24:09,080
我们现在多了三个东西出来了

804
00:24:10,440 --> 00:24:11,040
OK

805
00:24:11,320 --> 00:24:13,040
所以这个就是一个核心函数

806
00:24:13,200 --> 00:24:15,000
理解一下block到底在干嘛

807
00:24:16,759 --> 00:24:17,000
好

808
00:24:17,000 --> 00:24:18,040
接下来就是我们看一下

809
00:24:18,040 --> 00:24:19,280
我们的超参数

810
00:24:20,279 --> 00:24:22,720
因为我们有5个stage

811
00:24:23,399 --> 00:24:24,160
有5个stage

812
00:24:24,319 --> 00:24:25,599
我们对每一个stage

813
00:24:25,599 --> 00:24:27,079
就是说每一个块

814
00:24:27,240 --> 00:24:29,319
要去设置它的毛框

815
00:24:29,319 --> 00:24:33,799
那些大小和你的高宽比

816
00:24:35,160 --> 00:24:37,119
然后基本上可以看到是说

817
00:24:37,119 --> 00:24:37,799
我换个行

818
00:24:37,799 --> 00:24:38,399
就是说

819
00:24:38,440 --> 00:24:39,240
这个就是说

820
00:24:39,240 --> 00:24:40,200
第一个stage

821
00:24:40,200 --> 00:24:41,799
就是说最下面那一个层

822
00:24:41,799 --> 00:24:43,160
就是说你看这边是32层

823
00:24:43,160 --> 00:24:44,920
32那个feature map的层

824
00:24:45,240 --> 00:24:47,920
那么我们用的size是0.2

825
00:24:48,920 --> 00:24:49,960
就当然是比较小

826
00:24:50,120 --> 00:24:50,560
0.2

827
00:24:50,560 --> 00:24:51,920
就是说你可以认为是

828
00:24:51,960 --> 00:24:55,000
看到是20%的整个图片

829
00:24:57,120 --> 00:24:58,440
先不管后面这个值

830
00:24:58,880 --> 00:25:00,640
我们先看下一个stage

831
00:25:00,759 --> 00:25:03,400
下一个stage就是说是0.37

832
00:25:03,600 --> 00:25:05,080
然后是0.54

833
00:25:05,080 --> 00:25:08,400
然后就是说最后是0.71

834
00:25:08,600 --> 00:25:09,560
0.88

835
00:25:10,960 --> 00:25:12,680
就是说这几个值

836
00:25:12,680 --> 00:25:14,680
就基本上你看到是我在

837
00:25:15,680 --> 00:25:18,360
基本上是均匀的往上加

838
00:25:18,480 --> 00:25:20,120
就是0.2加上0.17

839
00:25:20,120 --> 00:25:21,039
等于0.37

840
00:25:21,039 --> 00:25:22,039
再加上0.17

841
00:25:22,039 --> 00:25:22,680
等于0.54

842
00:25:22,680 --> 00:25:23,519
再加0.17

843
00:25:23,519 --> 00:25:24,519
再加0.17

844
00:25:24,519 --> 00:25:25,680
就每次加了0.17

845
00:25:25,680 --> 00:25:26,360
就是说

846
00:25:26,640 --> 00:25:27,880
所谓的0.17

847
00:25:27,880 --> 00:25:29,360
也就是你反正选的

848
00:25:29,680 --> 00:25:30,560
就是说你要在

849
00:25:30,560 --> 00:25:32,560
反正你要在0和1之间取

850
00:25:32,560 --> 00:25:33,000
对吧

851
00:25:33,039 --> 00:25:35,480
你要在0和1之间取很多数值

852
00:25:35,920 --> 00:25:38,720
所以我们这里就是最小是0.2

853
00:25:39,000 --> 00:25:40,320
最大当然是0.96

854
00:25:40,759 --> 00:25:42,480
但我们这里取的是0.88

855
00:25:42,519 --> 00:25:44,120
就反正是你取个0.2

856
00:25:44,120 --> 00:25:44,800
取个0.88

857
00:25:44,800 --> 00:25:47,000
然后中间均匀的把它切出来

858
00:25:48,760 --> 00:25:50,600
这个值是怎么来的

859
00:25:50,880 --> 00:25:53,560
这个就是它乘以它

860
00:25:53,560 --> 00:25:54,760
然后开根号

861
00:25:56,000 --> 00:25:56,680
OK

862
00:25:57,160 --> 00:25:58,480
基本上你可以认为这个值

863
00:25:58,600 --> 00:26:01,240
就是它们之间的一个均值了

864
00:26:01,520 --> 00:26:04,880
但是它是不是一个等比的

865
00:26:04,880 --> 00:26:06,520
是一个等比的均值了

866
00:26:06,760 --> 00:26:08,240
所以就是说这个值

867
00:26:08,240 --> 00:26:10,480
也就是它和它值的

868
00:26:11,680 --> 00:26:13,120
乘起来开根号

869
00:26:13,840 --> 00:26:14,760
就基本上可以看到

870
00:26:14,760 --> 00:26:16,160
就是说你可以认为这些size

871
00:26:16,280 --> 00:26:17,640
就是从0.2开始

872
00:26:17,640 --> 00:26:20,000
然后慢慢变到0.96

873
00:26:20,000 --> 00:26:20,680
就0.96

874
00:26:20,680 --> 00:26:22,400
就是说我的模框要

875
00:26:22,920 --> 00:26:25,320
覆盖掉96%这个图片

876
00:26:25,360 --> 00:26:26,600
就已经是比较大了

877
00:26:28,200 --> 00:26:28,520
OK

878
00:26:28,520 --> 00:26:29,400
这就是size

879
00:26:29,800 --> 00:26:30,680
也可以看到是说

880
00:26:30,680 --> 00:26:32,080
越到下一层的话

881
00:26:32,080 --> 00:26:33,680
你的feature map越大

882
00:26:33,680 --> 00:26:35,960
那么你的size取的是相对比较小

883
00:26:36,000 --> 00:26:38,120
这样去看比较小的图片

884
00:26:38,360 --> 00:26:39,200
你越到后面

885
00:26:39,200 --> 00:26:41,520
最后一个就是1乘1的一个像素了

886
00:26:41,599 --> 00:26:43,720
那么我就用的是0.88和0.96

887
00:26:43,720 --> 00:26:44,680
这两个比较大的

888
00:26:44,680 --> 00:26:46,480
去看一个global的

889
00:26:46,480 --> 00:26:48,359
一个全局的一个大的物体

890
00:26:49,400 --> 00:26:51,920
Ratio通常说你不用太关心

891
00:26:51,920 --> 00:26:54,400
Ratio一般我就固定住是1 2和0.5

892
00:26:54,680 --> 00:26:58,079
这个是大家常用的组合

893
00:26:58,440 --> 00:26:59,879
所以大家就不用管了

894
00:27:00,960 --> 00:27:02,319
然后你number of anchors

895
00:27:02,599 --> 00:27:03,079
可以看到

896
00:27:04,079 --> 00:27:07,480
我们这里是size等于2

897
00:27:07,680 --> 00:27:09,079
Ratio等于3

898
00:27:09,240 --> 00:27:10,519
减去1就是4

899
00:27:10,839 --> 00:27:12,319
就每一个像素

900
00:27:12,879 --> 00:27:13,480
为中心

901
00:27:13,480 --> 00:27:14,920
我们生成4个毛框

902
00:27:14,920 --> 00:27:17,599
这就是我们超参数的定义

903
00:27:23,480 --> 00:27:24,079
OK

904
00:27:24,839 --> 00:27:25,079
好

905
00:27:25,079 --> 00:27:26,200
我们就可以定义

906
00:27:26,200 --> 00:27:28,599
我们的完整的网络了

907
00:27:29,599 --> 00:27:30,480
完整的网络

908
00:27:30,480 --> 00:27:32,279
我们叫做tiny SSD

909
00:27:32,440 --> 00:27:33,960
就是它不是

910
00:27:34,160 --> 00:27:35,480
跟SSD之间的

911
00:27:35,960 --> 00:27:38,319
还是有一点点完全不一样的

912
00:27:39,039 --> 00:27:40,879
整个模型长得稍微简单一点

913
00:27:41,039 --> 00:27:42,240
所以我们叫做tiny版本

914
00:27:42,240 --> 00:27:43,879
因为我们只要圈一个很小的函数

915
00:27:45,759 --> 00:27:48,279
然后我们可以看到一些东西

916
00:27:48,279 --> 00:27:48,839
就是说

917
00:27:50,159 --> 00:27:51,200
我们只要告诉你说

918
00:27:51,200 --> 00:27:52,359
number of class等于几

919
00:27:52,720 --> 00:27:53,079
就是说

920
00:27:53,079 --> 00:27:54,279
我们这个地方

921
00:27:54,279 --> 00:27:55,240
当然是等于1了

922
00:27:55,519 --> 00:27:57,519
你可以说做多类别的类别

923
00:27:57,519 --> 00:27:58,399
不一样也没关系

924
00:27:59,079 --> 00:28:00,159
接下来就是说

925
00:28:00,439 --> 00:28:01,480
Index to channels

926
00:28:01,480 --> 00:28:03,200
就是说你每一个block

927
00:28:03,480 --> 00:28:04,720
就你不是有5个stage

928
00:28:04,879 --> 00:28:05,359
5个stage

929
00:28:05,359 --> 00:28:07,399
每个stage它的输出是什么样子

930
00:28:07,560 --> 00:28:08,960
我们64 128

931
00:28:08,960 --> 00:28:10,200
就后面都是128

932
00:28:10,920 --> 00:28:11,840
就是你的channel数

933
00:28:12,560 --> 00:28:13,680
然后另外一个就是说

934
00:28:13,800 --> 00:28:16,440
我们看着就比较麻烦

935
00:28:16,560 --> 00:28:17,080
就是说

936
00:28:17,080 --> 00:28:19,000
我们就是set一个attribute

937
00:28:19,400 --> 00:28:20,840
就是说setattribute

938
00:28:20,840 --> 00:28:21,160
就是说

939
00:28:21,160 --> 00:28:23,480
你可以通过self.block

940
00:28:23,720 --> 00:28:25,280
下方叫0来访问这个东西

941
00:28:25,280 --> 00:28:25,560
就是说

942
00:28:25,560 --> 00:28:27,920
我们把这些block这些东西

943
00:28:28,040 --> 00:28:29,960
全部就每一个stage

944
00:28:29,960 --> 00:28:31,720
我们要定义它的网络

945
00:28:31,800 --> 00:28:33,000
就是getblock的函数

946
00:28:33,160 --> 00:28:34,240
记得我们之前定义的

947
00:28:34,640 --> 00:28:35,400
然后以及说

948
00:28:35,400 --> 00:28:36,440
对每一个stage

949
00:28:36,440 --> 00:28:39,039
我们要定义我们的class predictor

950
00:28:39,880 --> 00:28:41,840
然后我们的bundlebox predictor

951
00:28:42,480 --> 00:28:43,160
然后你就说

952
00:28:43,160 --> 00:28:44,400
你告诉你的channel数

953
00:28:44,519 --> 00:28:45,360
你number of anchors

954
00:28:45,360 --> 00:28:46,080
你number of class

955
00:28:46,080 --> 00:28:46,480
这些东西

956
00:28:46,480 --> 00:28:49,680
我们都根据我们这个东西来选

957
00:28:50,799 --> 00:28:51,799
可以看到是

958
00:28:52,080 --> 00:28:54,840
基本上是没什么特别不一样的

959
00:28:55,160 --> 00:28:56,000
唯一的是说

960
00:28:56,000 --> 00:28:58,640
我们做5次的预测

961
00:28:58,720 --> 00:28:59,799
在5个尺度上

962
00:28:59,920 --> 00:29:01,039
所以对每个尺度

963
00:29:01,039 --> 00:29:02,880
我们都得去定义

964
00:29:02,880 --> 00:29:04,559
它的class predictor

965
00:29:04,559 --> 00:29:06,000
你的bundlebox predictor

966
00:29:07,160 --> 00:29:07,519
好

967
00:29:07,519 --> 00:29:08,360
接下来我们看一下

968
00:29:08,360 --> 00:29:09,320
我们的forward函数

969
00:29:09,920 --> 00:29:11,640
我们是完整的forward函数

970
00:29:13,880 --> 00:29:15,320
就完整的forward函数的话

971
00:29:15,320 --> 00:29:16,240
你可以看到是说

972
00:29:16,519 --> 00:29:17,039
我的

973
00:29:17,039 --> 00:29:19,279
首先我们初始化这个东西先不管

974
00:29:19,840 --> 00:29:21,400
我们有5个stage

975
00:29:22,680 --> 00:29:23,720
然后对每一个stage

976
00:29:23,720 --> 00:29:24,799
我们iterate一次

977
00:29:24,920 --> 00:29:25,799
就是说

978
00:29:26,039 --> 00:29:27,720
我们对每个stage

979
00:29:27,720 --> 00:29:29,799
就是run block forward函数

980
00:29:29,799 --> 00:29:31,080
就我们之前定义的

981
00:29:31,759 --> 00:29:34,279
你的x就是你当前的输入

982
00:29:34,599 --> 00:29:37,000
然后我们把这个block拿出来

983
00:29:37,839 --> 00:29:39,079
然后把size

984
00:29:39,160 --> 00:29:40,759
这个是超算数也拿出来

985
00:29:41,000 --> 00:29:43,440
然后把class predictor拿出来

986
00:29:43,440 --> 00:29:44,839
把box predictor拿出来

987
00:29:44,839 --> 00:29:45,119
就是说

988
00:29:45,119 --> 00:29:47,319
这个都是我们之前在init函数上定义的

989
00:29:48,480 --> 00:29:50,240
然后就是说

990
00:29:50,240 --> 00:29:51,680
对于每一个stage

991
00:29:51,680 --> 00:29:52,599
我们把你的

992
00:29:52,599 --> 00:29:53,519
除了你的x

993
00:29:53,519 --> 00:29:55,039
我是不断的overwrite的话

994
00:29:55,200 --> 00:29:56,279
你所有的anchor

995
00:29:56,599 --> 00:29:57,839
你的class predictor

996
00:29:58,039 --> 00:29:59,000
你的bundlebox

997
00:29:59,000 --> 00:30:02,160
那个offset prediction

998
00:30:02,559 --> 00:30:03,799
我都存起来了

999
00:30:04,279 --> 00:30:05,559
就都存在那里面

1000
00:30:07,000 --> 00:30:07,319
OK

1001
00:30:07,319 --> 00:30:09,200
所以这里面都是一些list

1002
00:30:10,000 --> 00:30:12,279
然后把5个stagerun完之后

1003
00:30:12,920 --> 00:30:15,799
我把所有的anchors

1004
00:30:16,160 --> 00:30:17,759
全部把你并在一起

1005
00:30:18,440 --> 00:30:19,839
我的class predictor

1006
00:30:21,079 --> 00:30:23,319
就是我们之前concat的函数

1007
00:30:23,559 --> 00:30:26,039
就是把你变成一个矩阵

1008
00:30:26,039 --> 00:30:27,119
然后把你放在一起

1009
00:30:27,799 --> 00:30:29,720
然后我们还要reshape一次

1010
00:30:29,720 --> 00:30:30,480
就是说

1011
00:30:31,319 --> 00:30:33,359
我们把你reshape一个3D的话

1012
00:30:33,360 --> 00:30:34,880
这样子我们可以做之后做

1013
00:30:36,800 --> 00:30:39,120
就是说把最后类拿出来

1014
00:30:39,280 --> 00:30:39,960
就是说

1015
00:30:40,000 --> 00:30:41,440
最后那个地方是

1016
00:30:42,560 --> 00:30:44,080
做softmax比较方便

1017
00:30:44,080 --> 00:30:46,520
就是说我们不是对每一个anchor box

1018
00:30:46,520 --> 00:30:47,720
会预测number of class

1019
00:30:47,720 --> 00:30:48,480
加一个类

1020
00:30:49,320 --> 00:30:51,800
所以我们就把最后一个维度存成

1021
00:30:52,160 --> 00:30:53,240
对每一个类别

1022
00:30:53,560 --> 00:30:54,320
预测值

1023
00:30:54,400 --> 00:30:56,240
中间就变成一个3D的东西

1024
00:30:56,520 --> 00:30:58,640
所以我们在这样子是可以方便

1025
00:30:58,640 --> 00:31:00,040
我们做softmax

1026
00:31:00,320 --> 00:31:01,280
但bundlebox

1027
00:31:01,280 --> 00:31:02,160
我就是也是一样的

1028
00:31:02,160 --> 00:31:02,960
把它弄出来

1029
00:31:03,600 --> 00:31:06,000
所以这个函数

1030
00:31:06,240 --> 00:31:08,240
就是最后也返回的是

1031
00:31:08,280 --> 00:31:10,640
我的x会不断的overwrite

1032
00:31:10,640 --> 00:31:12,920
但是我最后我不需要我的

1033
00:31:13,120 --> 00:31:16,640
整个卷积那一个层的输出

1034
00:31:16,640 --> 00:31:17,560
我是不需要了

1035
00:31:17,680 --> 00:31:19,600
我需要的是每一个层

1036
00:31:19,640 --> 00:31:21,160
它的那些anchors

1037
00:31:21,960 --> 00:31:24,760
它的对每一个你毛框

1038
00:31:24,760 --> 00:31:27,240
它的类别的定义预测

1039
00:31:27,240 --> 00:31:28,960
和它的offset的预测

1040
00:31:29,160 --> 00:31:30,720
这个才是我真正的要的

1041
00:31:31,240 --> 00:31:31,760
OK

1042
00:31:31,759 --> 00:31:33,480
所以我把所有东西都把你空开了

1043
00:31:33,480 --> 00:31:33,879
在一起

1044
00:31:33,879 --> 00:31:34,879
然后把它丢出来

1045
00:31:35,519 --> 00:31:36,599
这样子的话

1046
00:31:36,599 --> 00:31:39,160
这也就是整个模型的forward

1047
00:31:39,160 --> 00:31:40,559
还是给一个图片进来

1048
00:31:41,319 --> 00:31:42,400
我输出什么

1049
00:31:42,799 --> 00:31:43,440
当然可以看到

1050
00:31:43,440 --> 00:31:45,200
跟之前的图片分类是不一样的

1051
00:31:45,559 --> 00:31:46,440
图片分类的话

1052
00:31:46,440 --> 00:31:47,759
我们拿到的是

1053
00:31:48,039 --> 00:31:49,799
基本上卷积值

1054
00:31:49,960 --> 00:31:51,440
到最后的输出

1055
00:31:51,480 --> 00:31:53,039
在这个地方我们拿到是

1056
00:31:53,079 --> 00:31:54,279
每一层

1057
00:31:54,319 --> 00:31:56,680
它跑的那些东西输出

1058
00:31:56,680 --> 00:31:57,799
然后把它合并起来

1059
00:31:57,799 --> 00:31:59,119
最后拿到三个东西

1060
00:31:59,559 --> 00:32:01,519
这也是一个比较重要的区别

1061
00:32:01,799 --> 00:32:04,039
OK

1062
00:32:04,039 --> 00:32:06,759
这就是我们的整个网络的定义

1063
00:32:07,400 --> 00:32:08,400
这样子的话

1064
00:32:08,400 --> 00:32:09,960
我们整个网络就比较完整了

1065
00:32:11,400 --> 00:32:12,799
那么接下来就是我们看一下

1066
00:32:12,799 --> 00:32:13,720
长什么样子

1067
00:32:14,319 --> 00:32:16,599
就是我们创建一个

1068
00:32:16,799 --> 00:32:17,640
Tiny SSD

1069
00:32:17,640 --> 00:32:19,119
Number Cluster E

1070
00:32:19,640 --> 00:32:20,759
让我们创建一个说

1071
00:32:20,920 --> 00:32:22,160
我们是256x256

1072
00:32:22,160 --> 00:32:23,559
然后channel数等于3

1073
00:32:23,720 --> 00:32:25,359
PID大小是32

1074
00:32:25,960 --> 00:32:28,400
然后我们就是把它丢进去算一下

1075
00:32:28,920 --> 00:32:31,400
看一下

1076
00:32:31,400 --> 00:32:32,120
就是说

1077
00:32:32,160 --> 00:32:33,120
首先

1078
00:32:33,920 --> 00:32:35,280
anchors等于多少

1079
00:32:36,000 --> 00:32:37,960
anchors是等于1的

1080
00:32:37,960 --> 00:32:38,560
这是为什么

1081
00:32:38,560 --> 00:32:40,280
是因为你不管你图片

1082
00:32:40,280 --> 00:32:42,360
因为我们是没有根据图片来设置

1083
00:32:42,360 --> 00:32:42,759
anchor

1084
00:32:42,759 --> 00:32:44,040
所以就是说

1085
00:32:44,040 --> 00:32:45,560
不管是谁哪个图片

1086
00:32:45,560 --> 00:32:47,120
我们都是以像素为中心

1087
00:32:47,120 --> 00:32:48,160
只要你的大小是一样

1088
00:32:48,160 --> 00:32:48,920
所以都一样

1089
00:32:48,960 --> 00:32:50,440
所以anchors它都没有

1090
00:32:50,440 --> 00:32:52,400
第一个通道是等于1的

1091
00:32:52,400 --> 00:32:53,880
不管你pid多大

1092
00:32:54,960 --> 00:32:55,680
就是说

1093
00:32:55,680 --> 00:32:56,600
然后就是说

1094
00:32:56,600 --> 00:32:58,600
这个是5个stage

1095
00:32:58,600 --> 00:33:01,240
就5个尺度下面

1096
00:33:01,240 --> 00:33:02,760
所有的anchor box

1097
00:33:02,760 --> 00:33:03,600
把它并起来

1098
00:33:03,600 --> 00:33:05,440
就是5444

1099
00:33:05,440 --> 00:33:06,440
44个

1100
00:33:06,920 --> 00:33:07,640
然后后面那个4

1101
00:33:07,640 --> 00:33:08,760
当然是我一个anchor box

1102
00:33:08,760 --> 00:33:09,880
要4个值来定义

1103
00:33:12,760 --> 00:33:15,200
那么接下来我的class predictor

1104
00:33:15,800 --> 00:33:17,320
首先可以看到这个是2

1105
00:33:17,320 --> 00:33:19,640
这是因为我们的输入的类别数是1

1106
00:33:19,920 --> 00:33:21,920
所以加上一个背景类是2

1107
00:33:22,640 --> 00:33:24,320
然后这个是pid大小

1108
00:33:24,639 --> 00:33:26,000
这个是anchor

1109
00:33:26,480 --> 00:33:27,839
就是多少个毛框

1110
00:33:28,279 --> 00:33:29,720
对每一个毛框

1111
00:33:30,119 --> 00:33:32,079
就是5444个毛框

1112
00:33:32,079 --> 00:33:33,159
每一个毛框

1113
00:33:33,159 --> 00:33:34,480
我们预测两个值

1114
00:33:35,519 --> 00:33:36,079
对吧

1115
00:33:36,679 --> 00:33:39,079
你要么是我们的

1116
00:33:39,279 --> 00:33:43,439
真的就是里面包含了我们的香蕉

1117
00:33:43,480 --> 00:33:45,240
要么就是背景

1118
00:33:46,319 --> 00:33:47,839
然后这个是你说

1119
00:33:48,079 --> 00:33:49,559
bounty box offset

1120
00:33:49,720 --> 00:33:51,639
这个地方我们没有把它reshape出来

1121
00:33:51,639 --> 00:33:52,960
它其实就是54

1122
00:33:53,000 --> 00:33:55,600
就是5444×4

1123
00:33:55,600 --> 00:33:56,799
就对每一个毛框

1124
00:33:56,799 --> 00:33:57,880
我会做4个预测

1125
00:33:57,880 --> 00:33:58,319
对吧

1126
00:33:58,440 --> 00:34:00,319
跟真实的bounty box那个片译

1127
00:34:00,319 --> 00:34:01,440
就是4个数字

1128
00:34:01,480 --> 00:34:04,480
所以毛框总数×4

1129
00:34:04,480 --> 00:34:07,039
就等于是21776个

1130
00:34:07,279 --> 00:34:07,880
OK

1131
00:34:07,880 --> 00:34:09,400
所以能看到是它的输出

1132
00:34:09,400 --> 00:34:10,880
是长成这个样子的

1133
00:34:12,240 --> 00:34:13,760
然后这个相对来说复杂一点

1134
00:34:13,920 --> 00:34:16,639
比我们之前的所有的图片分类

1135
00:34:19,159 --> 00:34:19,519
好

1136
00:34:19,519 --> 00:34:20,920
然后最后我们来看一下

1137
00:34:20,920 --> 00:34:21,760
我们怎么来训练

1138
00:34:22,440 --> 00:34:24,480
其实我们说我们之前数据

1139
00:34:24,480 --> 00:34:25,640
已经讲过了

1140
00:34:25,760 --> 00:34:27,520
就不再给大家重复了

1141
00:34:27,520 --> 00:34:28,240
就是说

1142
00:34:29,200 --> 00:34:30,600
Bite size我们取个32

1143
00:34:30,600 --> 00:34:34,920
就把banana数据给漏了出来

1144
00:34:34,920 --> 00:34:37,560
banana是我们自己准备的一个数据

1145
00:34:37,560 --> 00:34:39,680
就是给一堆图片

1146
00:34:39,680 --> 00:34:42,240
然后里面随机放一些香蕉进去

1147
00:34:42,280 --> 00:34:44,080
然后每一个图片放了一个香蕉

1148
00:34:44,080 --> 00:34:45,040
然后把它读进来

1149
00:34:45,120 --> 00:34:47,200
就跟之前图片分类不一样的是说

1150
00:34:47,200 --> 00:34:48,000
这里的标号

1151
00:34:48,200 --> 00:34:51,680
就是每个标号是一个图片

1152
00:34:51,679 --> 00:34:53,359
它会有对应的是里面

1153
00:34:53,359 --> 00:34:57,440
有可能有多个的标注的边缘框

1154
00:34:57,559 --> 00:34:58,839
但这里我们是一个

1155
00:35:00,440 --> 00:35:02,159
然后我们就可以初始化

1156
00:35:02,159 --> 00:35:04,079
我们用GPU来训练

1157
00:35:04,319 --> 00:35:05,279
这个模型也

1158
00:35:05,719 --> 00:35:06,519
courage比较小

1159
00:35:06,599 --> 00:35:08,079
但是它不会特别快

1160
00:35:08,079 --> 00:35:09,639
因为我们的毛框比较多

1161
00:35:09,919 --> 00:35:11,839
然后是我们把nandwork出来

1162
00:35:11,960 --> 00:35:13,559
我们用SGD来训练

1163
00:35:13,960 --> 00:35:14,519
OK

1164
00:35:14,559 --> 00:35:16,319
所以数据集和

1165
00:35:17,239 --> 00:35:18,799
模型初始化优化算法

1166
00:35:18,799 --> 00:35:19,480
我们都定了

1167
00:35:19,480 --> 00:35:20,759
都是最简单的

1168
00:35:22,119 --> 00:35:25,719
但接下来我们要定的是一个损失函数

1169
00:35:27,480 --> 00:35:28,679
就损失函数挺重要

1170
00:35:29,879 --> 00:35:33,639
因为我们这个地方有一个累的预测

1171
00:35:33,639 --> 00:35:35,759
和一个bundle box的预测

1172
00:35:38,039 --> 00:35:39,239
然后可以看到是说

1173
00:35:39,239 --> 00:35:40,639
我们来仔细看一下这个函数

1174
00:35:42,879 --> 00:35:44,039
首先累的预测

1175
00:35:44,039 --> 00:35:44,599
它很简单

1176
00:35:44,599 --> 00:35:46,119
你的损失就是一个cross entropy

1177
00:35:47,319 --> 00:35:48,960
就是分类的cross entropy

1178
00:35:48,960 --> 00:35:51,159
我们reduction区的没有做reduction

1179
00:35:51,159 --> 00:35:52,960
就是说你不要把我这些东西加起来

1180
00:35:53,480 --> 00:35:56,599
这是为主要是因为我们之前给大家实现的时候

1181
00:35:56,599 --> 00:35:57,920
都是没有把这些loss

1182
00:35:58,359 --> 00:36:00,879
每个样本上loss给你做平均

1183
00:36:01,039 --> 00:36:04,279
所以是一个保留的每一个样本的一个loss

1184
00:36:05,399 --> 00:36:06,639
bundle box loss

1185
00:36:06,639 --> 00:36:08,399
我们取的是L1 loss

1186
00:36:10,399 --> 00:36:15,039
就是说我对你真实的offset

1187
00:36:15,039 --> 00:36:17,960
我的offset定义和真实的offset里面

1188
00:36:17,960 --> 00:36:20,279
它的做减法

1189
00:36:20,320 --> 00:36:21,480
然后取绝对值

1190
00:36:22,240 --> 00:36:24,160
之所以没有用L2 loss

1191
00:36:24,160 --> 00:36:25,640
就是我们的regression

1192
00:36:26,240 --> 00:36:28,280
之前介绍regression的L2 loss

1193
00:36:28,280 --> 00:36:31,480
主要的原因是说很有可能我的预测

1194
00:36:32,240 --> 00:36:33,920
我可能预测的特别远

1195
00:36:33,920 --> 00:36:36,519
就是说你的值会比较大

1196
00:36:36,519 --> 00:36:38,800
所以你的做平方的话会特别大

1197
00:36:38,800 --> 00:36:42,800
所以L1就是说当你预测特别不靠谱的时候

1198
00:36:42,800 --> 00:36:46,160
它也不会给你一个特别大的一个损失

1199
00:36:46,160 --> 00:36:48,440
所以这个是用L1的一个原因

1200
00:36:49,440 --> 00:36:49,880
好

1201
00:36:49,880 --> 00:36:51,519
我们来看一下我们怎么算loss

1202
00:36:52,679 --> 00:36:56,720
首先你的是我对每个cluster prediction

1203
00:36:56,720 --> 00:36:58,119
然后我的cluster label

1204
00:36:58,119 --> 00:36:59,400
这是真实label

1205
00:36:59,400 --> 00:37:01,320
bundle box的offset

1206
00:37:01,320 --> 00:37:02,559
就是偏移的prediction

1207
00:37:02,559 --> 00:37:04,039
我才会有它的label

1208
00:37:04,039 --> 00:37:05,400
这两个东西怎么来的

1209
00:37:05,400 --> 00:37:07,440
这两个东西我们之前有说过

1210
00:37:07,440 --> 00:37:10,440
在上个星期课里面有说过是怎么出来的

1211
00:37:11,280 --> 00:37:15,920
然后这还有是bundle box的mask

1212
00:37:16,920 --> 00:37:17,280
好

1213
00:37:17,280 --> 00:37:18,880
我们等会讲这mask是个什么东西

1214
00:37:20,320 --> 00:37:23,280
首先我们来看我们是拿到我们的batch size

1215
00:37:23,280 --> 00:37:24,400
我们多少类

1216
00:37:25,800 --> 00:37:29,639
然后我们的cluster prediction

1217
00:37:30,599 --> 00:37:34,400
然后我们有一个reshape的地方

1218
00:37:35,159 --> 00:37:37,320
就之前我们把它变成3D的对吧

1219
00:37:37,720 --> 00:37:39,360
所以在这个地方

1220
00:37:39,880 --> 00:37:41,280
我们把就是说

1221
00:37:41,280 --> 00:37:44,280
我们知道每一个毛框是一个样本

1222
00:37:44,280 --> 00:37:45,360
在做分类的时候

1223
00:37:45,480 --> 00:37:46,599
不是每张图片

1224
00:37:46,599 --> 00:37:48,640
所以-1的意思是说

1225
00:37:48,640 --> 00:37:52,440
我把前面的批量大小为

1226
00:37:52,440 --> 00:37:55,200
和中间的毛框个数为

1227
00:37:55,680 --> 00:37:56,800
把它放在一个了

1228
00:37:57,800 --> 00:37:58,880
然后这样子的话

1229
00:37:58,880 --> 00:38:01,200
我们就是对每个毛框变成一个样本

1230
00:38:01,400 --> 00:38:02,720
label要同样做一下

1231
00:38:02,720 --> 00:38:04,079
这样子的一个reshape

1232
00:38:04,079 --> 00:38:05,440
然后放进cross entropy

1233
00:38:05,440 --> 00:38:06,440
可以算到一个

1234
00:38:06,440 --> 00:38:09,039
对毛框分类的一个loss

1235
00:38:10,880 --> 00:38:13,599
接下来bundle box的loss

1236
00:38:13,599 --> 00:38:14,840
就是l1的loss

1237
00:38:14,840 --> 00:38:15,760
我们这里做的是什么

1238
00:38:16,120 --> 00:38:16,880
可以看一下

1239
00:38:16,880 --> 00:38:20,160
就我们成了一个bundle box的mask

1240
00:38:20,680 --> 00:38:22,920
就我的预测时和我的真实标注

1241
00:38:22,960 --> 00:38:24,640
我们都成了一个mask

1242
00:38:24,880 --> 00:38:26,039
mask是什么意思

1243
00:38:26,760 --> 00:38:28,240
mask是说

1244
00:38:28,240 --> 00:38:30,079
你当你bundle box

1245
00:38:30,079 --> 00:38:31,079
我们这个毛框

1246
00:38:31,200 --> 00:38:34,760
我们觉得它里面就是一个背景框的时候

1247
00:38:35,600 --> 00:38:37,840
我们就不要去预测那一个

1248
00:38:38,160 --> 00:38:39,200
它的偏移了

1249
00:38:39,200 --> 00:38:39,800
因为背景框

1250
00:38:39,800 --> 00:38:41,000
我也不知道偏移到哪里去

1251
00:38:41,000 --> 00:38:41,480
对吧

1252
00:38:41,600 --> 00:38:43,640
所以mask是说

1253
00:38:43,639 --> 00:38:45,920
当你毛框

1254
00:38:46,079 --> 00:38:47,879
对应的是背景框的时候

1255
00:38:47,879 --> 00:38:49,039
mask等于0

1256
00:38:49,559 --> 00:38:50,920
不然的话它等于1

1257
00:38:50,960 --> 00:38:52,079
所以这个乘以mask

1258
00:38:52,079 --> 00:38:53,199
就会把那些

1259
00:38:53,920 --> 00:38:56,079
毛框对应的是背景框的东西

1260
00:38:56,079 --> 00:38:56,839
全部拿掉

1261
00:38:56,879 --> 00:39:00,799
就只要算毛框里面有框住

1262
00:39:00,799 --> 00:39:02,319
我们的物体的时候

1263
00:39:02,400 --> 00:39:04,759
它去真的去做惩罚

1264
00:39:05,199 --> 00:39:05,799
OK

1265
00:39:05,960 --> 00:39:07,119
最后是两个误差

1266
00:39:07,239 --> 00:39:09,119
两个损失

1267
00:39:09,119 --> 00:39:09,960
我们就加

1268
00:39:10,039 --> 00:39:11,920
当然你可以加全

1269
00:39:12,079 --> 00:39:13,639
我们就简单的就没加全了

1270
00:39:14,840 --> 00:39:16,639
然后最后我们说

1271
00:39:16,639 --> 00:39:20,480
我们可以做class的evaluation

1272
00:39:20,720 --> 00:39:21,559
就跟之前是一样

1273
00:39:21,599 --> 00:39:22,440
class evaluation

1274
00:39:22,440 --> 00:39:24,320
就是说等于是说分类精度

1275
00:39:24,440 --> 00:39:25,880
这就是一个分类精度的问题

1276
00:39:26,039 --> 00:39:27,200
就跟之前是一样的

1277
00:39:28,039 --> 00:39:29,440
最后的bundle box的话

1278
00:39:29,440 --> 00:39:30,880
也就是做的一个

1279
00:39:34,360 --> 00:39:36,400
把它的label和它的label

1280
00:39:36,400 --> 00:39:37,480
就是L1的loss

1281
00:39:37,840 --> 00:39:39,920
把它一减去个绝对值

1282
00:39:39,920 --> 00:39:42,920
但是也是乘以了一个bundle box mask

1283
00:39:42,920 --> 00:39:44,360
就是我们只关心那些

1284
00:39:44,360 --> 00:39:45,760
非背景毛框的

1285
00:39:45,760 --> 00:39:47,039
它的预测的错误

1286
00:39:47,280 --> 00:39:47,720
OK

1287
00:39:47,720 --> 00:39:50,079
所以这个函数干这个事情

1288
00:39:51,519 --> 00:39:53,800
就是说跟之前没区别

1289
00:39:53,800 --> 00:39:54,599
就是你可以认为

1290
00:39:54,599 --> 00:39:56,280
就是说它就是一个分类问题

1291
00:39:56,280 --> 00:39:57,320
加上一个回归问题

1292
00:39:57,320 --> 00:39:58,680
两个问题在一起

1293
00:39:59,039 --> 00:40:00,039
就一个分类loss

1294
00:40:00,039 --> 00:40:01,119
有个回归loss

1295
00:40:01,200 --> 00:40:02,599
我们要把loss加起来

1296
00:40:02,639 --> 00:40:04,119
然后做evaluation的时候

1297
00:40:04,119 --> 00:40:06,320
我们就看一下分类的loss

1298
00:40:06,320 --> 00:40:07,599
是等于多少

1299
00:40:07,599 --> 00:40:09,200
然后回归的loss等于多少

1300
00:40:09,200 --> 00:40:11,160
就是说有两个evaluation的函数

1301
00:40:12,480 --> 00:40:13,040
OK

1302
00:40:14,560 --> 00:40:14,840
好

1303
00:40:14,840 --> 00:40:15,800
模型训练

1304
00:40:16,400 --> 00:40:17,600
这模型训练跟之前

1305
00:40:17,720 --> 00:40:18,800
没什么太多区别

1306
00:40:19,920 --> 00:40:21,320
可以看到是说

1307
00:40:22,280 --> 00:40:24,920
电动就是画画我们的图

1308
00:40:25,040 --> 00:40:25,760
动态图

1309
00:40:26,080 --> 00:40:28,480
然后可以看到是

1310
00:40:28,920 --> 00:40:30,200
把你的xy

1311
00:40:30,320 --> 00:40:32,200
全部放到我们的GPU上

1312
00:40:32,480 --> 00:40:33,680
然后我们就是

1313
00:40:33,680 --> 00:40:34,960
run一个forward的函数

1314
00:40:35,000 --> 00:40:35,920
就拿到anchor

1315
00:40:36,240 --> 00:40:37,080
class prediction

1316
00:40:37,599 --> 00:40:38,519
那个bounded box

1317
00:40:38,519 --> 00:40:39,799
the offset prediction

1318
00:40:40,000 --> 00:40:40,920
然后

1319
00:40:41,799 --> 00:40:42,840
然后有个target

1320
00:40:42,840 --> 00:40:43,480
记得这个函数

1321
00:40:43,480 --> 00:40:43,960
对吧

1322
00:40:44,079 --> 00:40:44,799
就这个函数

1323
00:40:46,599 --> 00:40:47,360
它干个什么

1324
00:40:50,480 --> 00:40:51,519
这个函数干个什么事情

1325
00:40:51,599 --> 00:40:52,199
就是

1326
00:40:53,239 --> 00:40:54,239
把你的anchors

1327
00:40:54,239 --> 00:40:55,599
你的y拉进去之后

1328
00:40:56,039 --> 00:40:58,039
就生成我的bounded box的label

1329
00:40:58,239 --> 00:40:59,000
我的mask

1330
00:40:59,519 --> 00:41:00,719
和我的class predict

1331
00:41:01,039 --> 00:41:02,279
那个label

1332
00:41:02,799 --> 00:41:04,119
这个算法就是我们知道

1333
00:41:04,119 --> 00:41:06,000
就是说把所有的模框

1334
00:41:06,000 --> 00:41:09,039
和你的真实的标注框

1335
00:41:09,039 --> 00:41:10,519
然后一一的对应起来

1336
00:41:10,760 --> 00:41:11,800
就是每次找最近的

1337
00:41:11,800 --> 00:41:12,679
然后这样子对

1338
00:41:12,800 --> 00:41:14,440
我们上周有讲过

1339
00:41:15,639 --> 00:41:16,360
然后这样子的话

1340
00:41:16,360 --> 00:41:17,079
就是说

1341
00:41:17,800 --> 00:41:19,440
这个就是生成的预测

1342
00:41:19,719 --> 00:41:21,239
这个就是把我们的

1343
00:41:21,280 --> 00:41:21,880
模框

1344
00:41:21,880 --> 00:41:23,639
加上我们的真实的

1345
00:41:23,639 --> 00:41:25,000
这个y就是标注的

1346
00:41:25,000 --> 00:41:25,920
那些bounded box

1347
00:41:26,800 --> 00:41:27,880
根据你的模框

1348
00:41:27,880 --> 00:41:29,039
生成你的模框

1349
00:41:29,039 --> 00:41:30,400
要去预测的东西

1350
00:41:31,119 --> 00:41:32,800
最后来计算损失

1351
00:41:33,199 --> 00:41:34,920
然后算损失

1352
00:41:34,920 --> 00:41:36,000
里面就两个损失

1353
00:41:36,119 --> 00:41:37,320
就是分类误差

1354
00:41:37,320 --> 00:41:39,400
加上你的回归误差

1355
00:41:39,440 --> 00:41:42,039
然后再当然是在backward

1356
00:41:42,960 --> 00:41:43,920
但然后在

1357
00:41:44,880 --> 00:41:45,480
算的时候

1358
00:41:45,480 --> 00:41:46,240
我当然会去说

1359
00:41:46,400 --> 00:41:47,880
我这个分类误差是多少

1360
00:41:47,880 --> 00:41:48,559
回归误差多少

1361
00:41:48,800 --> 00:41:50,159
后面都是一些print函数了

1362
00:41:51,159 --> 00:41:51,480
OK

1363
00:41:51,480 --> 00:41:52,519
所以整体来讲

1364
00:41:52,519 --> 00:41:53,680
就是个这样子的东西

1365
00:41:54,159 --> 00:41:56,159
可以看到是跟图片分类的问题

1366
00:41:56,159 --> 00:41:56,800
是什么区别

1367
00:41:58,360 --> 00:41:59,240
分类的话

1368
00:41:59,599 --> 00:42:00,680
主要区别是说

1369
00:42:01,119 --> 00:42:02,119
本来我们这个地方

1370
00:42:02,119 --> 00:42:04,559
就是一个py对吧

1371
00:42:04,599 --> 00:42:05,719
就predict y

1372
00:42:06,360 --> 00:42:07,119
现在不是了

1373
00:42:07,119 --> 00:42:08,840
我们不能直接去predict y

1374
00:42:08,840 --> 00:42:10,079
就这个y是什么

1375
00:42:10,239 --> 00:42:11,799
这个y是你的真实的

1376
00:42:12,199 --> 00:42:13,679
物体的bounded box

1377
00:42:14,000 --> 00:42:15,000
这边缘框

1378
00:42:15,400 --> 00:42:16,880
我们不能直接预测它

1379
00:42:16,920 --> 00:42:18,799
所以我们预测的是

1380
00:42:19,159 --> 00:42:20,039
一堆模框

1381
00:42:20,039 --> 00:42:21,199
以及对每个模框

1382
00:42:21,199 --> 00:42:22,920
它的类别的预测

1383
00:42:22,920 --> 00:42:24,719
和它的到真实边缘框

1384
00:42:24,960 --> 00:42:25,920
偏移的预测

1385
00:42:25,960 --> 00:42:27,199
所以这是我的输出

1386
00:42:27,559 --> 00:42:29,759
然后我们要把这三个东西

1387
00:42:29,759 --> 00:42:31,400
跟真实的y做对比

1388
00:42:31,880 --> 00:42:33,000
所以我们下个函数

1389
00:42:33,000 --> 00:42:34,360
就说给定真实y

1390
00:42:34,360 --> 00:42:35,519
给定我身上的模框

1391
00:42:35,519 --> 00:42:36,480
去生成说

1392
00:42:36,480 --> 00:42:38,519
怎么样把这些模框

1393
00:42:38,680 --> 00:42:40,360
映射到我的真实边框

1394
00:42:40,360 --> 00:42:41,440
一一对应起来

1395
00:42:41,480 --> 00:42:42,160
然后说

1396
00:42:42,680 --> 00:42:43,079
这样子

1397
00:42:43,079 --> 00:42:44,640
我能对每个模框

1398
00:42:44,640 --> 00:42:45,360
变成一个样本

1399
00:42:45,360 --> 00:42:46,280
拿到它的

1400
00:42:47,640 --> 00:42:48,720
类别编号

1401
00:42:49,599 --> 00:42:50,559
是不是它

1402
00:42:51,160 --> 00:42:53,400
只圈住背景

1403
00:42:53,440 --> 00:42:54,640
以及是

1404
00:42:54,720 --> 00:42:55,280
不

1405
00:42:55,280 --> 00:42:56,160
这个是你得到

1406
00:42:56,160 --> 00:42:58,120
真实边界框的偏移

1407
00:42:58,240 --> 00:42:59,160
以及是说

1408
00:42:59,160 --> 00:43:01,120
是不是只有背景

1409
00:43:01,160 --> 00:43:04,320
和它对应的物体的类别

1410
00:43:05,280 --> 00:43:06,120
所以

1411
00:43:06,440 --> 00:43:08,120
做过这两次变换之后

1412
00:43:08,120 --> 00:43:08,880
这三个

1413
00:43:08,880 --> 00:43:10,800
这几个东西是可以算loss的

1414
00:43:11,120 --> 00:43:12,519
就这个就是一个

1415
00:43:13,079 --> 00:43:15,280
这个都是简单的分类的loss

1416
00:43:15,280 --> 00:43:16,920
就是在模框上面的loss

1417
00:43:16,960 --> 00:43:18,599
然后是模框上面的回归

1418
00:43:18,920 --> 00:43:19,320
OK

1419
00:43:19,320 --> 00:43:21,120
最后就是我们别的都是一样的

1420
00:43:21,960 --> 00:43:24,320
这就是我们这个地方

1421
00:43:24,599 --> 00:43:25,880
目标会检测

1422
00:43:25,880 --> 00:43:27,800
它跟图片分类不一样的地方

1423
00:43:30,320 --> 00:43:30,760
所以

1424
00:43:32,880 --> 00:43:33,720
我们

1425
00:43:35,160 --> 00:43:36,559
我们来看一下我们的

1426
00:43:36,840 --> 00:43:37,280
训练

1427
00:43:38,039 --> 00:43:38,760
就训练的话

1428
00:43:38,760 --> 00:43:40,160
我们就基本上run在这里

1429
00:43:40,160 --> 00:43:41,440
这个东西跑起来

1430
00:43:42,640 --> 00:43:43,320
跑起来还行

1431
00:43:43,519 --> 00:43:45,680
就是每秒钟也能跑个5000张图片

1432
00:43:45,840 --> 00:43:48,680
这是因为我们图片大小不大

1433
00:43:48,720 --> 00:43:49,920
然后另外一个

1434
00:43:49,920 --> 00:43:51,320
我们的网络确实比较简单

1435
00:43:51,760 --> 00:43:52,640
所以可以看到是说

1436
00:43:52,640 --> 00:43:53,840
我们会print一个

1437
00:43:54,280 --> 00:43:56,360
就class的arrow是

1438
00:43:56,760 --> 00:43:57,480
挺低的

1439
00:43:57,480 --> 00:43:59,559
然后bounded box的MAE

1440
00:43:59,559 --> 00:44:01,360
就是也是一个

1441
00:44:02,079 --> 00:44:03,840
就是你的边界框的预测

1442
00:44:03,840 --> 00:44:04,720
也还是挺低的

1443
00:44:05,160 --> 00:44:06,120
因为我们这个数据集

1444
00:44:06,120 --> 00:44:07,120
相对来说比较简单

1445
00:44:07,120 --> 00:44:08,800
所以我们基本上看到是

1446
00:44:09,599 --> 00:44:10,720
跳的还挺

1447
00:44:10,960 --> 00:44:12,480
我们有两个arrow画出来

1448
00:44:12,480 --> 00:44:14,920
就基本上还是收敛还是挺快的

1449
00:44:16,400 --> 00:44:16,920
OK

1450
00:44:18,680 --> 00:44:19,840
最后我们来预测一下

1451
00:44:20,480 --> 00:44:22,840
预测也跟之前会有一点的不一样

1452
00:44:23,480 --> 00:44:24,920
所以我们怎么预测

1453
00:44:24,920 --> 00:44:26,960
就是说我们就读一张图片进来

1454
00:44:27,240 --> 00:44:29,039
就是一个banana图片读进来

1455
00:44:29,440 --> 00:44:32,800
然后就是说net我们说

1456
00:44:32,880 --> 00:44:35,119
现在是预测模式

1457
00:44:35,800 --> 00:44:37,840
然后把x传到我的GPU上

1458
00:44:38,000 --> 00:44:39,239
拿到我的anchors

1459
00:44:39,239 --> 00:44:42,320
我的class prediction bounded box

1460
00:44:43,320 --> 00:44:45,199
然后我们要做一个softmax

1461
00:44:45,599 --> 00:44:48,239
去把我的prediction换成一个

1462
00:44:48,279 --> 00:44:49,400
softmax的

1463
00:44:49,400 --> 00:44:54,719
就是说到变成一个概率

1464
00:44:56,480 --> 00:44:57,679
然后接下来就是说

1465
00:44:57,679 --> 00:44:59,519
我们要做multi box prediction

1466
00:44:59,519 --> 00:45:00,599
就是为什么要干这些事情

1467
00:45:00,599 --> 00:45:03,119
因为记得我们要在里面run NMS

1468
00:45:04,199 --> 00:45:07,000
我们要根据你的每一个类别的

1469
00:45:07,000 --> 00:45:09,159
自信度和它的那些

1470
00:45:09,639 --> 00:45:12,000
等于是说把毛框和你的prediction

1471
00:45:12,000 --> 00:45:13,119
先给你加起来

1472
00:45:13,119 --> 00:45:13,519
对吧

1473
00:45:13,519 --> 00:45:14,319
就不是加起来

1474
00:45:14,319 --> 00:45:15,159
就是结合起来

1475
00:45:15,159 --> 00:45:17,399
就还原出我真实预测的

1476
00:45:17,399 --> 00:45:19,079
那一个边界框

1477
00:45:19,239 --> 00:45:22,279
然后再根据它的类别的自信度

1478
00:45:22,279 --> 00:45:23,559
来run NMS

1479
00:45:23,599 --> 00:45:24,799
就会得到output

1480
00:45:25,159 --> 00:45:27,319
output最后我们就是直接

1481
00:45:27,680 --> 00:45:30,000
说去掉的就不要

1482
00:45:30,000 --> 00:45:33,640
就是把只把剩下东西留出来

1483
00:45:33,640 --> 00:45:37,120
就是说把NMS去掉的东西

1484
00:45:37,120 --> 00:45:38,160
我就删掉

1485
00:45:38,160 --> 00:45:39,720
只剩下NMS留下东西

1486
00:45:39,720 --> 00:45:40,519
就是output

1487
00:45:40,640 --> 00:45:41,559
就是prediction

1488
00:45:41,559 --> 00:45:43,720
也是稍微复杂一点

1489
00:45:43,800 --> 00:45:47,160
然后因为相对来说

1490
00:45:47,320 --> 00:45:49,120
就比较比图片分类

1491
00:45:49,280 --> 00:45:50,080
这个地方

1492
00:45:51,000 --> 00:45:53,200
基本上就是要run一次NMS

1493
00:45:53,200 --> 00:45:54,480
NMS这个东西

1494
00:45:54,480 --> 00:45:56,159
在跑起来

1495
00:45:56,639 --> 00:45:58,320
在GPU跑起来不容易

1496
00:45:58,880 --> 00:45:59,679
你要知道

1497
00:45:59,679 --> 00:46:01,440
就是一个一堆iteration

1498
00:46:01,559 --> 00:46:02,159
就是

1499
00:46:02,519 --> 00:46:03,199
避来避去

1500
00:46:03,199 --> 00:46:04,480
我们有讲过说

1501
00:46:04,480 --> 00:46:05,320
在硬件来讲

1502
00:46:05,320 --> 00:46:05,920
有讲过说

1503
00:46:05,920 --> 00:46:07,800
GPU还真不适合做这个事情

1504
00:46:07,840 --> 00:46:11,119
所以NMS需要非常好的实现

1505
00:46:11,159 --> 00:46:13,679
才能保证说在GPU上run的比较快

1506
00:46:16,199 --> 00:46:16,800
OK

1507
00:46:17,079 --> 00:46:18,360
最后就是说我们就是

1508
00:46:19,119 --> 00:46:20,960
我们筛选出所有自信度

1509
00:46:21,119 --> 00:46:22,440
不低于0.9的边界框

1510
00:46:22,440 --> 00:46:23,559
然后做一下输出

1511
00:46:23,679 --> 00:46:26,880
我们就不给大家直接讲这个函数了

1512
00:46:26,880 --> 00:46:27,400
就说白了

1513
00:46:27,400 --> 00:46:28,719
就是把output拿过来

1514
00:46:28,759 --> 00:46:30,079
告诉我一个threshold

1515
00:46:30,199 --> 00:46:31,759
然后我们就是

1516
00:46:32,920 --> 00:46:34,279
NMS的threshold

1517
00:46:34,759 --> 00:46:36,000
然后我们就把它

1518
00:46:36,960 --> 00:46:38,320
不是NMS的threshold

1519
00:46:38,320 --> 00:46:39,400
是prediction的threshold

1520
00:46:39,400 --> 00:46:41,599
NMS里面已经给定了

1521
00:46:41,599 --> 00:46:42,440
应该是0.5

1522
00:46:42,759 --> 00:46:44,079
最后可以看到是说

1523
00:46:44,159 --> 00:46:45,079
给一张图片

1524
00:46:45,279 --> 00:46:48,400
然后我们有4个香蕉

1525
00:46:48,440 --> 00:46:49,960
然后我们run一次

1526
00:46:49,960 --> 00:46:52,239
然后把这个bondi box给画出来

1527
00:46:52,240 --> 00:46:53,240
就基本上是

1528
00:46:53,520 --> 00:46:54,880
因为我们这个图片很简单

1529
00:46:55,040 --> 00:46:56,040
其实基本上你看到是

1530
00:46:56,040 --> 00:46:57,640
我的预测值都是1.0

1531
00:46:58,080 --> 00:46:58,560
对吧

1532
00:46:58,600 --> 00:46:59,400
就是说

1533
00:46:59,520 --> 00:47:02,120
这框就是你我的预测的那一个

1534
00:47:02,360 --> 00:47:03,120
边界框

1535
00:47:03,120 --> 00:47:04,200
然后这个数字

1536
00:47:04,320 --> 00:47:06,520
就是我的对类别的预测度

1537
00:47:07,720 --> 00:47:08,200
OK

1538
00:47:08,480 --> 00:47:09,160
所以

1539
00:47:10,120 --> 00:47:13,040
这个就是一个完整的

1540
00:47:14,200 --> 00:47:16,280
SSD的目标检测实现

1541
00:47:17,400 --> 00:47:19,480
相对来说是比较复杂一点

1542
00:47:19,800 --> 00:47:21,480
比我们之前的

1543
00:47:21,960 --> 00:47:24,320
讲过的图片分类都要复杂很多

1544
00:47:24,920 --> 00:47:26,079
基本上可以看到

1545
00:47:26,360 --> 00:47:27,320
稍微回顾一下

1546
00:47:27,320 --> 00:47:28,119
就是说

1547
00:47:29,360 --> 00:47:31,320
首先我们的

1548
00:47:31,760 --> 00:47:32,719
一个关键是说

1549
00:47:32,719 --> 00:47:34,000
对每一个

1550
00:47:34,880 --> 00:47:36,079
不同的尺度下面

1551
00:47:36,719 --> 00:47:37,760
对每一个模框

1552
00:47:37,760 --> 00:47:38,559
它的

1553
00:47:39,039 --> 00:47:40,440
类别的预测

1554
00:47:40,480 --> 00:47:43,920
和它的到真实边界框偏移

1555
00:47:43,960 --> 00:47:45,280
我们是用了一个

1556
00:47:45,920 --> 00:47:47,119
Colonel Science Way 3的

1557
00:47:47,119 --> 00:47:49,159
一个conf2d来解决的

1558
00:47:49,760 --> 00:47:51,559
然后他去保证是说

1559
00:47:51,559 --> 00:47:53,000
因为他没有改变高宽

1560
00:47:53,000 --> 00:47:54,599
所以对每一个像素

1561
00:47:54,599 --> 00:47:56,039
我都是做预测

1562
00:47:56,079 --> 00:47:58,159
预测值全部在通道里面

1563
00:47:58,360 --> 00:48:00,599
这通道数是等于说

1564
00:48:00,639 --> 00:48:01,639
你在每一个像素

1565
00:48:01,639 --> 00:48:02,920
要生成的模框数

1566
00:48:02,960 --> 00:48:04,199
乘以每一个模框

1567
00:48:04,199 --> 00:48:05,480
需要预测的数值

1568
00:48:05,719 --> 00:48:07,880
要么是类别数加一

1569
00:48:07,880 --> 00:48:08,960
要么是等于4

1570
00:48:09,320 --> 00:48:09,679
OK

1571
00:48:09,679 --> 00:48:11,880
这个是第一点不一样的

1572
00:48:13,199 --> 00:48:15,000
第二点不一样的是说

1573
00:48:15,760 --> 00:48:17,880
我们一个图片进来之后

1574
00:48:17,880 --> 00:48:18,960
我们输出的东西

1575
00:48:18,960 --> 00:48:20,680
不再是你Y了

1576
00:48:20,960 --> 00:48:23,160
我们要的是你的那些模框

1577
00:48:23,400 --> 00:48:24,400
你的模框的预测

1578
00:48:24,400 --> 00:48:25,240
你的类别预测

1579
00:48:25,240 --> 00:48:26,840
你的偏移的预测

1580
00:48:27,039 --> 00:48:29,640
然后最后是把每不同的尺度

1581
00:48:29,640 --> 00:48:30,640
下面所有东西

1582
00:48:30,640 --> 00:48:32,039
都给你合在一起

1583
00:48:33,200 --> 00:48:34,599
合在一起的时候

1584
00:48:34,599 --> 00:48:35,880
然后你做loss的时候

1585
00:48:35,880 --> 00:48:37,559
就是类别预测

1586
00:48:37,559 --> 00:48:38,559
是类别的loss

1587
00:48:38,599 --> 00:48:40,039
你的偏移的预测

1588
00:48:40,039 --> 00:48:40,800
是一个回归的

1589
00:48:40,800 --> 00:48:41,880
L1的loss

1590
00:48:42,000 --> 00:48:43,640
但是加了一个mask在里面

1591
00:48:43,640 --> 00:48:44,720
就是说如果是背景内

1592
00:48:44,720 --> 00:48:46,079
我们就不算loss了

1593
00:48:47,079 --> 00:48:47,519
OK

1594
00:48:47,519 --> 00:48:48,480
这应该就是

1595
00:48:48,480 --> 00:48:49,599
当然在预测的时候

1596
00:48:49,599 --> 00:48:50,719
我们要做ms

1597
00:48:50,719 --> 00:48:52,400
就是这样子

1598
00:48:52,400 --> 00:48:55,239
我们能够把一些重复的模框去掉

1599
00:48:55,239 --> 00:48:57,199
得到比较干净的一个预测

1600
00:48:58,159 --> 00:48:59,199
那当然回过来

1601
00:48:59,199 --> 00:49:00,119
我们之前有讲过

1602
00:49:00,119 --> 00:49:02,360
是说我们在做forward的时候

1603
00:49:02,360 --> 00:49:02,960
你可以看到

1604
00:49:02,960 --> 00:49:04,599
是对模框的类别预测

1605
00:49:04,719 --> 00:49:05,559
我们根本就没看

1606
00:49:05,559 --> 00:49:06,880
模框是到底长什么样子

1607
00:49:06,880 --> 00:49:07,239
对吧

1608
00:49:07,239 --> 00:49:08,920
把整个东西拿进去

1609
00:49:08,960 --> 00:49:10,400
所以在什么时候会去看

1610
00:49:10,840 --> 00:49:12,239
就是在loss的时候

1611
00:49:12,759 --> 00:49:14,199
就是说我告诉你说

1612
00:49:14,720 --> 00:49:16,480
虽然我没告诉你

1613
00:49:16,480 --> 00:49:18,240
这个模框到底是在什么地方

1614
00:49:18,240 --> 00:49:20,280
但是我在之后的loss告诉你说

1615
00:49:20,280 --> 00:49:21,680
你对应的位置

1616
00:49:21,880 --> 00:49:23,200
通道数位置的预测

1617
00:49:23,200 --> 00:49:25,160
应该是一个某个类

1618
00:49:25,360 --> 00:49:27,560
所以使得你神经网络

1619
00:49:27,560 --> 00:49:29,240
尽量的把你的注意力

1620
00:49:29,240 --> 00:49:30,560
转到我模框

1621
00:49:30,560 --> 00:49:33,240
真正的圈的位置

1622
00:49:33,560 --> 00:49:35,320
以及说你要去predict

1623
00:49:35,320 --> 00:49:36,560
你offset对吧

1624
00:49:36,600 --> 00:49:39,160
所以他也是真正的让他去学会

1625
00:49:39,200 --> 00:49:40,840
就是说我没有告诉

1626
00:49:40,840 --> 00:49:42,200
神经网络说

1627
00:49:42,520 --> 00:49:44,880
你真的是在这一块区域里面去看

1628
00:49:44,880 --> 00:49:46,280
就没有给死他

1629
00:49:46,320 --> 00:49:48,240
是说我给你让你看所有区域

1630
00:49:48,240 --> 00:49:50,880
但是我在在loss里面告诉你说

1631
00:49:51,200 --> 00:49:53,040
这个区域很有可能是在这一块

1632
00:49:53,040 --> 00:49:54,720
所以你尽量去看他的地方

1633
00:49:55,320 --> 00:49:55,720
OK

1634
00:49:55,720 --> 00:49:57,560
这就是怎么样

1635
00:49:57,560 --> 00:49:58,360
模框的信息

1636
00:49:58,360 --> 00:50:00,000
怎么样是进入神经网络的

1637
00:50:00,000 --> 00:50:01,440
是通过loss进去的

1638
00:50:02,560 --> 00:50:03,160
OK

1639
00:50:03,280 --> 00:50:04,480
所以基本上

1640
00:50:04,880 --> 00:50:07,760
我们SSD的事情就讲完了

1641
00:50:08,320 --> 00:50:09,440
稍微是有点复杂

1642
00:50:09,960 --> 00:50:12,760
还是可能是我们相对来说

1643
00:50:12,760 --> 00:50:14,599
比较长的一个小节了

1644
00:50:14,639 --> 00:50:15,599
我们也尽量的

1645
00:50:15,599 --> 00:50:17,280
已经把大家给拆得很开了

1646
00:50:17,320 --> 00:50:18,880
我们已经拆成三个

1647
00:50:19,760 --> 00:50:21,320
三个notebook了

1648
00:50:21,639 --> 00:50:23,280
但是还是不得已

1649
00:50:23,280 --> 00:50:24,280
还是比较长

1650
00:50:24,480 --> 00:50:26,039
我们也有讲过说SSD

1651
00:50:26,039 --> 00:50:26,720
目前来说

1652
00:50:26,720 --> 00:50:28,720
它不再是一个特别主流的

1653
00:50:28,720 --> 00:50:30,240
一个目标检测算法

1654
00:50:30,240 --> 00:50:32,880
是因为他提出来之后

1655
00:50:32,880 --> 00:50:33,800
在过去一些年

1656
00:50:33,800 --> 00:50:36,159
确实没有跟上我们这些新的

1657
00:50:36,360 --> 00:50:38,039
小技术的进展

1658
00:50:38,079 --> 00:50:40,960
导致说实际使用中SSD

1659
00:50:40,960 --> 00:50:43,039
在精度可能拼不过

1660
00:50:43,079 --> 00:50:44,960
在同样的性能下

1661
00:50:44,960 --> 00:50:47,320
拼不过YOLO和精度

1662
00:50:47,320 --> 00:50:49,119
也可能远远的不如FastRCNN

1663
00:50:49,119 --> 00:50:50,000
这些模型

1664
00:50:50,679 --> 00:50:52,199
但反过来讲是因为

1665
00:50:52,880 --> 00:50:55,159
它是第一个

1666
00:50:55,880 --> 00:50:58,400
能够性能还不错

1667
00:50:58,400 --> 00:51:00,199
但是又能够用Python

1668
00:51:00,199 --> 00:51:02,400
给你实现出来的一个模型

1669
00:51:02,440 --> 00:51:03,639
所以我们把它用

1670
00:51:03,639 --> 00:51:05,400
给它作为一个样例

1671
00:51:06,119 --> 00:51:08,280
让大家去仔细的去理解说

1672
00:51:08,280 --> 00:51:09,880
到底目标检测里面

1673
00:51:09,880 --> 00:51:11,160
那些Bounty Box

1674
00:51:11,160 --> 00:51:12,320
是怎么做预测的

1675
00:51:12,320 --> 00:51:14,280
还是怎么样去弄的

1676
00:51:14,320 --> 00:51:16,880
就给大家一个直观上的感受

1677
00:51:17,720 --> 00:51:18,320
就是说

1678
00:51:18,320 --> 00:51:19,000
但反过来讲

1679
00:51:19,000 --> 00:51:21,039
这一套代码

1680
00:51:21,039 --> 00:51:23,599
不是给大家去用的

1681
00:51:23,880 --> 00:51:25,400
因为我们所有这些Bounty Box

1682
00:51:25,400 --> 00:51:26,480
都是用Python实现的

1683
00:51:26,480 --> 00:51:27,280
特别慢

1684
00:51:27,800 --> 00:51:29,000
你改成CI加实现

1685
00:51:29,000 --> 00:51:30,760
改成CUDA实现会快很多

1686
00:51:30,800 --> 00:51:33,599
所以在真实的场景下面

1687
00:51:33,759 --> 00:51:35,400
目标检测这一块

1688
00:51:35,559 --> 00:51:36,839
所有的尽量的代码

1689
00:51:36,839 --> 00:51:37,639
都是尽量的

1690
00:51:37,639 --> 00:51:39,960
大家是往C++和CUDA去写

1691
00:51:40,000 --> 00:51:41,519
这样子性能会好一点

1692
00:51:41,679 --> 00:51:43,799
而且我们这个地方

1693
00:51:43,839 --> 00:51:45,279
目标检测里面

1694
00:51:45,279 --> 00:51:47,119
有大量的trick

1695
00:51:47,480 --> 00:51:48,799
因为Bounty Box很恶心

1696
00:51:48,799 --> 00:51:49,639
就是说有可能很大

1697
00:51:49,639 --> 00:51:50,159
有可能很小

1698
00:51:50,159 --> 00:51:50,839
有可能重叠

1699
00:51:50,880 --> 00:51:51,880
就是说各种各样

1700
00:51:51,880 --> 00:51:53,039
heuristic在里面

1701
00:51:53,079 --> 00:51:55,279
所以他们会做大量

1702
00:51:55,279 --> 00:51:56,599
这样的细节上更新

1703
00:51:56,639 --> 00:51:58,239
所以这一块

1704
00:51:58,239 --> 00:52:01,119
大家尽量去用别人成熟的

1705
00:52:01,159 --> 00:52:03,839
一些目标检测的包

1706
00:52:04,480 --> 00:52:05,719
不像说

1707
00:52:05,719 --> 00:52:07,400
我觉得目标检测

1708
00:52:07,400 --> 00:52:08,039
跟图标分类

1709
00:52:08,039 --> 00:52:08,920
主要的一个区别

1710
00:52:08,920 --> 00:52:10,199
是目标检测里面

1711
00:52:10,239 --> 00:52:11,759
小细节太多了

1712
00:52:12,119 --> 00:52:13,239
自己写一个notebook

1713
00:52:13,239 --> 00:52:14,639
把所有东西搬过来的

1714
00:52:14,719 --> 00:52:16,199
概率真的不大

1715
00:52:16,440 --> 00:52:16,920
OK

1716
00:52:16,920 --> 00:52:19,119
所以这个地方

1717
00:52:19,119 --> 00:52:20,359
虽然看上去很简单

1718
00:52:20,359 --> 00:52:21,400
也算简单

1719
00:52:21,519 --> 00:52:22,279
我们的代码

1720
00:52:22,559 --> 00:52:23,719
真的就是一行一行

1721
00:52:23,719 --> 00:52:24,719
给大家实现了

1722
00:52:24,759 --> 00:52:26,440
但是大家说还是说

1723
00:52:26,480 --> 00:52:28,199
我们跟真实的

1724
00:52:28,759 --> 00:52:30,199
能够达到目标检测

1725
00:52:30,200 --> 00:52:31,360
最好性能的算法

1726
00:52:31,360 --> 00:52:33,040
比还是有一定差距的

1727
00:52:33,080 --> 00:52:34,280
因为我们很多细节

1728
00:52:34,280 --> 00:52:35,760
是没有加进来

1729
00:52:35,760 --> 00:52:37,200
是因为这样加进来的话

1730
00:52:37,200 --> 00:52:37,960
我们这个东西

1731
00:52:37,960 --> 00:52:39,440
可能讲个一两天

1732
00:52:39,480 --> 00:52:40,880
再讲两天讲不完

1733
00:52:41,280 --> 00:52:41,760
OK

1734
00:52:41,760 --> 00:52:44,000
这就是我们SSE的实现

