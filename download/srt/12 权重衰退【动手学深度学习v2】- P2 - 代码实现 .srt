1
00:00:00,000 --> 00:00:01,919
权重衰退

2
00:00:01,919 --> 00:00:04,799
这个叫做weight decay

3
00:00:04,799 --> 00:00:09,839
是我们最常见的来处理过拟核的一种方法

4
00:00:12,720 --> 00:00:15,320
就是我们在上一次有讲过

5
00:00:15,359 --> 00:00:18,240
我怎么控制一个模型的容量呢

6
00:00:18,760 --> 00:00:21,039
一个是说我把模型变得比较小

7
00:00:21,039 --> 00:00:22,879
就是里面参数比较少

8
00:00:23,359 --> 00:00:29,080
第二个是说我使得每个参数选择的值的范围比较小

9
00:00:31,000 --> 00:00:34,079
权重衰退就是通过

10
00:00:34,119 --> 00:00:38,320
控制你整个值的选择范围来进行的

11
00:00:38,759 --> 00:00:41,600
具体来说我们是一个这样子的过程

12
00:00:41,600 --> 00:00:42,679
我拿支笔

13
00:00:45,679 --> 00:00:47,920
就是说我们还是之前一样的

14
00:00:47,920 --> 00:00:50,960
我们优化的是我们最小化的损失函数

15
00:00:50,960 --> 00:00:52,400
就是L是我们的损失

16
00:00:52,519 --> 00:00:56,079
假设WB是我们的参数的话

17
00:00:56,359 --> 00:00:58,320
W是你的权重

18
00:00:58,320 --> 00:00:59,879
B是你的偏移

19
00:01:00,719 --> 00:01:04,079
但是我们在最小化的时候

20
00:01:04,079 --> 00:01:05,599
我们加入一个限制

21
00:01:06,120 --> 00:01:07,319
就subject to

22
00:01:07,879 --> 00:01:10,760
使得你W就是你的权重

23
00:01:10,760 --> 00:01:15,159
它的L too long是小于一个θ

24
00:01:15,200 --> 00:01:16,560
就小于一个值

25
00:01:18,560 --> 00:01:22,159
就是说使得你整个W的平方

26
00:01:22,159 --> 00:01:25,840
每个项的平方和是小于一个特定的值的

27
00:01:26,840 --> 00:01:28,680
那么就意味着说

28
00:01:28,960 --> 00:01:31,400
你的W的每一个元素的值

29
00:01:32,040 --> 00:01:36,400
都要小于θ的开根号

30
00:01:37,120 --> 00:01:38,359
如果θ选择很小

31
00:01:38,400 --> 00:01:39,920
那当然我的值就比较小了

32
00:01:40,800 --> 00:01:42,800
这就是一个我强行说

33
00:01:42,800 --> 00:01:45,159
我的每个值的不能太大

34
00:01:46,200 --> 00:01:49,879
这里的话我们通常不会限制偏移B

35
00:01:50,280 --> 00:01:53,840
就是说因为B对于我们来讲

36
00:01:53,840 --> 00:01:55,520
其实统计上来讲

37
00:01:55,520 --> 00:01:59,280
你偏移你是对你整个数据在零点的偏移

38
00:01:59,280 --> 00:02:00,719
所以你是不应该限制的

39
00:02:01,159 --> 00:02:02,439
在实际上来讲

40
00:02:02,480 --> 00:02:04,560
其实你限不限制都是一样的

41
00:02:04,560 --> 00:02:05,719
就是大家可以试一下

42
00:02:05,719 --> 00:02:08,480
把B也加进去或者不加进去

43
00:02:08,520 --> 00:02:12,280
可能对大家的实际结果不会产生太大影响

44
00:02:12,319 --> 00:02:13,719
所以数学上来讲

45
00:02:13,719 --> 00:02:17,159
我们一般是不会将B放进我们的限制里面

46
00:02:18,560 --> 00:02:20,360
这里一个可以看到是说

47
00:02:20,400 --> 00:02:21,759
你比较小的θ

48
00:02:21,759 --> 00:02:25,840
就意味着我的正折向会比较强

49
00:02:25,840 --> 00:02:29,399
就是我的对你这个值的限制会比较强

50
00:02:29,439 --> 00:02:31,759
最强的情况就是θ等于0

51
00:02:31,959 --> 00:02:32,439
那怎么样

52
00:02:32,439 --> 00:02:33,679
所有的W都等于0

53
00:02:33,799 --> 00:02:35,239
那只能选一个偏移

54
00:02:36,560 --> 00:02:37,439
如果一般来说

55
00:02:37,439 --> 00:02:38,560
我们会比较选一个

56
00:02:38,560 --> 00:02:41,759
比如说θ等于1或者0.1 0.01

57
00:02:42,479 --> 00:02:43,120
这样子的话

58
00:02:43,120 --> 00:02:44,319
使得我们整个

59
00:02:44,680 --> 00:02:46,039
如果你是选择1的话

60
00:02:46,039 --> 00:02:49,680
那么你W里面每一个值都不应该会超过1

61
00:02:50,680 --> 00:02:52,520
而且随着你的W

62
00:02:52,520 --> 00:02:54,520
如果里面元素很多的话

63
00:02:54,560 --> 00:02:56,000
那么你每个元素

64
00:02:56,000 --> 00:02:58,400
你也就相对来说会变得更小一点

65
00:02:58,960 --> 00:02:59,560
OK

66
00:02:59,599 --> 00:03:02,280
这个就是说我们做成一个硬性限制

67
00:03:02,439 --> 00:03:05,360
我们说硬性就是我们强行说

68
00:03:05,360 --> 00:03:07,439
你的W一定是小于这个值的

69
00:03:08,640 --> 00:03:09,520
但一般来说

70
00:03:09,520 --> 00:03:13,000
我们不会直接用这一个优化函数

71
00:03:13,000 --> 00:03:16,280
因为它的优化起来相对来说麻烦一点

72
00:03:16,319 --> 00:03:20,000
我们其实常用的是一个这样的一个函数

73
00:03:21,120 --> 00:03:22,400
对于每一个θ

74
00:03:22,400 --> 00:03:24,280
就是之前我们选定的每一个θ

75
00:03:24,280 --> 00:03:25,680
比如说θ等于0.1

76
00:03:25,680 --> 00:03:27,639
1 0.01

77
00:03:27,719 --> 00:03:28,439
都可以

78
00:03:28,879 --> 00:03:30,599
对每一个这样子的值

79
00:03:30,759 --> 00:03:32,680
我们都可以找到一个number

80
00:03:32,680 --> 00:03:34,080
就是另外一个值

81
00:03:34,680 --> 00:03:37,120
使得它之前的目标函数

82
00:03:37,120 --> 00:03:39,080
等价于下面一个目标函数

83
00:03:39,840 --> 00:03:42,039
就是说我把限制像挪掉

84
00:03:42,080 --> 00:03:44,199
但是我在整个目标函数里面

85
00:03:44,200 --> 00:03:47,280
加入了2分之num

86
00:03:48,080 --> 00:03:50,560
然后W对一个L2

87
00:03:51,160 --> 00:03:52,120
就是

88
00:03:54,880 --> 00:03:56,160
然后这一个可以证明

89
00:03:56,560 --> 00:03:59,360
就是说你可以通过拉格朗日诚子来证明

90
00:03:59,920 --> 00:04:03,720
所以就是说它跟这个就是优化整个这两项

91
00:04:03,720 --> 00:04:06,120
跟我们之前加限制是一样的

92
00:04:06,520 --> 00:04:08,680
我们之所以讲之前的硬性限制

93
00:04:08,680 --> 00:04:11,280
就是给大家直观的来理解说

94
00:04:11,280 --> 00:04:13,880
我这个θ是确实是把W限制在

95
00:04:13,879 --> 00:04:14,840
一个值里面

96
00:04:15,159 --> 00:04:16,079
但实际上来说

97
00:04:16,079 --> 00:04:18,519
我们通常用的是如下这个形式

98
00:04:18,600 --> 00:04:21,199
就是说这是我原始的损失函数

99
00:04:21,920 --> 00:04:23,680
现在我加了一项新的项

100
00:04:23,680 --> 00:04:24,879
这项叫做罚

101
00:04:24,879 --> 00:04:26,319
通常来说就是penalty

102
00:04:26,920 --> 00:04:30,199
就是说使得你的W不会特别大

103
00:04:30,959 --> 00:04:34,000
而且lambda是一个超参数

104
00:04:34,560 --> 00:04:38,959
lambda控制了整个正者项的重要程度

105
00:04:39,680 --> 00:04:41,800
就假设lambda等于0的时候

106
00:04:41,800 --> 00:04:42,959
它当然是没有作用了

107
00:04:43,000 --> 00:04:44,719
就是说整个这一项是等于0的

108
00:04:45,079 --> 00:04:47,319
就等价于之前的θ等于无穷大

109
00:04:48,359 --> 00:04:51,799
当你lambda渐渐的趋向无穷大的时候

110
00:04:51,799 --> 00:04:55,519
就等价于之前的θ趋向0

111
00:04:55,799 --> 00:04:58,959
使得你的最优解W心也会慢慢的变成0

112
00:05:00,039 --> 00:05:00,879
所以就是说

113
00:05:00,879 --> 00:05:03,839
假设我想把模型复杂度控制的比较低

114
00:05:03,839 --> 00:05:06,319
我想让模型不要太复杂的话

115
00:05:06,319 --> 00:05:09,719
我会通过增加lambda来满足我的需求

116
00:05:10,720 --> 00:05:11,480
Ok

117
00:05:11,480 --> 00:05:12,880
这个就是我们的

118
00:05:12,880 --> 00:05:16,000
所以这一块叫做柔性限制

119
00:05:16,000 --> 00:05:17,680
之前的叫硬性限制

120
00:05:17,960 --> 00:05:22,080
这是因为这是一个lambda不再是一个硬性的

121
00:05:22,080 --> 00:05:24,600
说你所有的值都给我小于某个值

122
00:05:24,600 --> 00:05:26,240
而是一个更平滑一点的

123
00:05:26,240 --> 00:05:28,400
就是有点像你比如说

124
00:05:28,400 --> 00:05:30,120
photoshop拉曲线的那种感觉

125
00:05:31,120 --> 00:05:31,600
Ok

126
00:05:32,480 --> 00:05:33,760
所以给大家演示一下

127
00:05:33,920 --> 00:05:37,480
具体是怎么样作用过去的

128
00:05:38,080 --> 00:05:39,720
我们看一下

129
00:05:39,720 --> 00:05:40,360
就是说

130
00:05:40,360 --> 00:05:42,800
首先我们假设我们有一个l在这里

131
00:05:43,400 --> 00:05:45,480
我假设这个滤线就是一个l

132
00:05:46,280 --> 00:05:49,400
那这个滤线画的是你整个l的等高线

133
00:05:51,040 --> 00:05:55,319
假设我就是想优化损失l的话

134
00:05:55,360 --> 00:05:58,120
那么我的最优点在这个地方

135
00:05:58,400 --> 00:05:59,280
这是我的最优解

136
00:05:59,280 --> 00:06:02,040
就是W的波浪号性

137
00:06:02,840 --> 00:06:03,800
因为你l是一个

138
00:06:03,800 --> 00:06:05,800
我假设其实这就是个二次函数了

139
00:06:06,000 --> 00:06:07,680
假设l是长这样子的话

140
00:06:07,680 --> 00:06:08,960
那么它的正中心

141
00:06:09,319 --> 00:06:10,199
这是最小值

142
00:06:10,199 --> 00:06:13,480
那么就是我的只优化我的损失的情况

143
00:06:15,199 --> 00:06:17,879
如果我加入了一个二分之l的这个项

144
00:06:18,639 --> 00:06:19,960
这个也是一个二次函数

145
00:06:20,360 --> 00:06:22,639
所以在这个函数里面

146
00:06:22,639 --> 00:06:25,400
我们其实就是一个W这两个值

147
00:06:25,519 --> 00:06:27,480
就是X1和一个X2的话

148
00:06:28,000 --> 00:06:30,800
那么对一个W的二次项的话

149
00:06:30,800 --> 00:06:31,639
你可以认为

150
00:06:31,759 --> 00:06:33,519
它其实是一个

151
00:06:33,519 --> 00:06:36,719
在原点为中心的一个等高线

152
00:06:36,719 --> 00:06:37,519
长成这样子

153
00:06:38,959 --> 00:06:40,360
那么首先我们看一下

154
00:06:40,360 --> 00:06:42,639
就是说原始的最优解这个点

155
00:06:43,159 --> 00:06:45,360
这个点现在就不会是特别优了

156
00:06:45,360 --> 00:06:48,439
因为这个点对于我的损失项来说

157
00:06:48,439 --> 00:06:50,039
也就是黄线来说

158
00:06:50,479 --> 00:06:51,680
它的值非常大

159
00:06:53,839 --> 00:06:56,839
而且我如果沿着这个方向走

160
00:06:56,839 --> 00:06:58,879
如果我沿着这个方向走的话

161
00:06:59,040 --> 00:07:02,639
那么我的l的值会变得大一点

162
00:07:02,639 --> 00:07:05,879
但是我的罚的项值会变小

163
00:07:08,240 --> 00:07:09,439
而且大家记不记得

164
00:07:09,439 --> 00:07:13,399
我们在损失函数的l2的损失函数讲过

165
00:07:13,399 --> 00:07:14,920
就l2的损失函数

166
00:07:14,920 --> 00:07:17,600
就是你平方损失函数的话

167
00:07:17,600 --> 00:07:19,560
在优化点附近的时候

168
00:07:19,560 --> 00:07:21,159
它对于我画一下

169
00:07:21,159 --> 00:07:26,279
就说假设这是我的l2的一个损失

170
00:07:26,440 --> 00:07:30,240
我在原点附近的时候

171
00:07:30,240 --> 00:07:32,600
我对我的值的拉伸是比较小的

172
00:07:32,600 --> 00:07:34,560
因为它的梯度相对来说比较小

173
00:07:34,800 --> 00:07:37,720
但是我对于在我的离原点比较远的时候

174
00:07:37,720 --> 00:07:38,800
我的值是很大的

175
00:07:38,800 --> 00:07:42,120
我对我整个往下拉的作用会越大

176
00:07:42,320 --> 00:07:45,360
所以在这个点的话

177
00:07:46,640 --> 00:07:48,960
我的罚对这个点的拉动力

178
00:07:49,000 --> 00:07:50,800
会比我的l会大

179
00:07:51,120 --> 00:07:53,840
所以意味着是说我会将它往下拉

180
00:07:54,240 --> 00:07:54,920
举个例子

181
00:07:54,960 --> 00:07:56,720
我们可能会拉到这个地方

182
00:07:58,800 --> 00:08:01,720
这个地方就是说形成一个平衡点

183
00:08:01,879 --> 00:08:04,480
如果你再往下面走一点点

184
00:08:04,759 --> 00:08:09,120
你的l就会说你那边减少了

185
00:08:09,120 --> 00:08:11,879
不足以弥补我的增加项

186
00:08:12,240 --> 00:08:13,639
你往这边走的话

187
00:08:13,759 --> 00:08:15,000
那么一样的

188
00:08:15,000 --> 00:08:20,879
我的罚的增加项比你的l的损失项要大

189
00:08:21,120 --> 00:08:23,000
所以在这个点形成一个平衡点

190
00:08:23,000 --> 00:08:25,360
总体上来看

191
00:08:25,360 --> 00:08:30,680
你可以看到是说我的罚的引入使得我的

192
00:08:30,680 --> 00:08:32,480
最优解往原点走了

193
00:08:34,200 --> 00:08:35,559
那么对于我的值来讲

194
00:08:35,559 --> 00:08:36,639
我的最优解值的话

195
00:08:36,639 --> 00:08:37,600
我这两个点

196
00:08:37,639 --> 00:08:39,559
我这个点对就值的话

197
00:08:39,559 --> 00:08:41,399
它的值会变得小一些

198
00:08:42,320 --> 00:08:43,679
就我的绝对值会变小

199
00:08:44,039 --> 00:08:45,440
一旦我绝对值变小的话

200
00:08:45,440 --> 00:08:47,960
如果我都是把我的最优解往这边拉的话

201
00:08:48,000 --> 00:08:49,559
那么对整个模型来讲

202
00:08:49,600 --> 00:08:51,279
我的模型复杂度就变低了

203
00:08:51,879 --> 00:08:56,120
这就是说如何理解我们加入罚

204
00:08:56,120 --> 00:08:59,199
就在柔性限制里面

205
00:08:59,240 --> 00:09:01,799
它对我整个损失是怎么影响的

206
00:09:07,039 --> 00:09:08,839
接下来我们来看一下

207
00:09:09,279 --> 00:09:11,720
它的参数更新的法则

208
00:09:13,839 --> 00:09:14,639
就是说

209
00:09:14,879 --> 00:09:17,759
就为什么它是叫做一个

210
00:09:17,759 --> 00:09:19,279
跳过了一下

211
00:09:19,319 --> 00:09:22,799
它为什么叫做一个权重衰退呢

212
00:09:23,519 --> 00:09:25,240
我们可以看一下这个的原因

213
00:09:26,000 --> 00:09:26,839
就我们回忆一下

214
00:09:26,839 --> 00:09:28,839
我们之前是怎么算t度的

215
00:09:29,799 --> 00:09:31,360
就现在我们有两个项

216
00:09:31,399 --> 00:09:32,759
就有个L一个项

217
00:09:33,039 --> 00:09:35,120
和我的罚在两个项里面

218
00:09:35,480 --> 00:09:37,439
我对它算t度的话

219
00:09:37,439 --> 00:09:40,000
我首先是对我第一个L项算t度

220
00:09:40,039 --> 00:09:40,399
对吧

221
00:09:40,399 --> 00:09:41,399
是这一项

222
00:09:42,199 --> 00:09:43,759
接下来对它算t度的话

223
00:09:43,759 --> 00:09:44,879
因为它是一个二次函数

224
00:09:45,360 --> 00:09:47,839
所以首先这个平方向没了

225
00:09:47,920 --> 00:09:50,600
然后它只剩一个w在里面

226
00:09:50,600 --> 00:09:52,800
然后二和二击销

227
00:09:52,800 --> 00:09:55,840
所以就变成了一个lambda加乘以w

228
00:09:58,759 --> 00:10:01,320
那么理解是在时间t的更新

229
00:10:01,320 --> 00:10:02,680
我这可以写一下

230
00:10:02,680 --> 00:10:05,200
就是wt加上1

231
00:10:05,200 --> 00:10:09,040
就应该等于wt减去你的学习率

232
00:10:09,040 --> 00:10:13,360
eta乘以我的w项

233
00:10:13,920 --> 00:10:16,840
那么我接下来就把我这个项带进来就行了

234
00:10:17,840 --> 00:10:18,639
带进来你可以看到

235
00:10:18,639 --> 00:10:21,680
首先这一个项就是我们保留住

236
00:10:22,040 --> 00:10:23,160
还是在留在这里

237
00:10:23,160 --> 00:10:25,879
就是eta乘以这个项留在这个地方

238
00:10:26,320 --> 00:10:27,800
那么接下来就是说

239
00:10:27,800 --> 00:10:31,160
eta乘以它乘以lambda和w

240
00:10:31,360 --> 00:10:33,600
就会这里我再补一下

241
00:10:33,600 --> 00:10:35,120
这是一个t在这个地方

242
00:10:35,399 --> 00:10:38,720
那么就会我们就把它和第一个项

243
00:10:38,759 --> 00:10:39,759
合并在一起

244
00:10:39,920 --> 00:10:40,960
那么它就变成一个

245
00:10:40,960 --> 00:10:43,040
1减去eta乘以lambda

246
00:10:45,040 --> 00:10:46,040
那么可以看到是说

247
00:10:46,039 --> 00:10:48,279
跟之前不一样的地方在哪里

248
00:10:48,279 --> 00:10:50,079
跟之前唯一的不一样的地方

249
00:10:50,079 --> 00:10:51,519
就是多了一个这样子的项

250
00:10:53,079 --> 00:10:55,120
我不要把它的发展解好

251
00:10:55,120 --> 00:10:56,839
那里就是说大家会显得

252
00:10:57,839 --> 00:10:58,839
迷糊一点

253
00:10:59,959 --> 00:11:01,199
这就是唯一多了项

254
00:11:01,360 --> 00:11:03,759
如果你没有加入奥斯法项的话

255
00:11:03,759 --> 00:11:05,279
这个地方是没有的

256
00:11:06,719 --> 00:11:07,679
通常来说

257
00:11:07,679 --> 00:11:10,639
我们的lambda乘以我们的学习率

258
00:11:10,639 --> 00:11:11,799
是小于1的

259
00:11:12,400 --> 00:11:14,040
如果大于1

260
00:11:14,040 --> 00:11:16,080
当然会抖动比较大

261
00:11:16,080 --> 00:11:17,720
一般来说是会小于1

262
00:11:17,840 --> 00:11:19,560
所以你可以看到是说

263
00:11:19,600 --> 00:11:21,120
跟之前的区别

264
00:11:21,160 --> 00:11:23,280
减去t度的负方向

265
00:11:23,280 --> 00:11:25,040
乘以学习率是没有变化的

266
00:11:26,040 --> 00:11:27,400
那么主要的变化在这个地方

267
00:11:27,960 --> 00:11:28,440
这个地方

268
00:11:28,440 --> 00:11:30,560
每一次我们对它更新的时候

269
00:11:30,600 --> 00:11:32,560
我先把wt

270
00:11:32,800 --> 00:11:35,120
乘以了一个小于1的一个正常数

271
00:11:36,000 --> 00:11:38,520
那就是说把它值先变小了一点点

272
00:11:38,720 --> 00:11:40,279
再在t度的

273
00:11:40,279 --> 00:11:42,679
沿着t度的方向再走一点点

274
00:11:44,639 --> 00:11:45,079
对吧

275
00:11:45,079 --> 00:11:48,519
所以为什么这个叫做权重衰退

276
00:11:48,519 --> 00:11:50,120
就是每一次更新的时候

277
00:11:50,120 --> 00:11:51,639
因为lambda的引入

278
00:11:51,679 --> 00:11:53,559
使得我们在更新前

279
00:11:53,559 --> 00:11:55,679
我们先把当前的权重

280
00:11:55,960 --> 00:11:57,799
做了一次放小

281
00:11:57,840 --> 00:12:00,120
所以认为这是有一次衰退了

282
00:12:01,879 --> 00:12:02,399
OK

283
00:12:04,079 --> 00:12:05,439
所以这就是

284
00:12:06,440 --> 00:12:10,000
我们的为什么叫做权重衰退

285
00:12:14,480 --> 00:12:15,720
我们总结一下

286
00:12:17,360 --> 00:12:18,640
权重衰退

287
00:12:18,640 --> 00:12:20,840
通过L2的正轴向

288
00:12:20,880 --> 00:12:23,440
使得模型参数不会过大

289
00:12:23,960 --> 00:12:25,920
从而控制模型的复杂度

290
00:12:26,440 --> 00:12:29,440
我们可以通过一个刚性的写法

291
00:12:29,440 --> 00:12:32,280
使得知道说我们限制w2的向

292
00:12:32,399 --> 00:12:36,519
总是比一个θ要小

293
00:12:36,720 --> 00:12:38,759
但是我们在真正的优化的时候

294
00:12:38,759 --> 00:12:41,279
我们是通过一个lambda

295
00:12:41,279 --> 00:12:43,879
来控制它的强度

296
00:12:44,199 --> 00:12:45,120
而且这个lambda

297
00:12:45,120 --> 00:12:47,240
因为等价于我们在更新的时候

298
00:12:47,279 --> 00:12:50,120
每一次对权重做了一次放小

299
00:12:50,159 --> 00:12:52,039
所以它就等价于说

300
00:12:52,079 --> 00:12:54,159
它是一个权重的衰退过程

301
00:12:54,839 --> 00:12:55,839
在这个地方

302
00:12:55,879 --> 00:12:57,600
我们的lambda

303
00:12:57,759 --> 00:13:01,360
是我们控制模型复杂度的一个超参数

