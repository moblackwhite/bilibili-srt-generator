1
00:00:00,000 --> 00:00:05,000
这里我们给大家介绍一下怎么样自定义一个层

2
00:00:05,000 --> 00:00:09,400
之前我们讲过说怎么样自定义一个神经网络

3
00:00:09,400 --> 00:00:11,800
和怎么样访问参数

4
00:00:11,800 --> 00:00:16,399
这里说我们再往下一点怎么自定义一个层

5
00:00:16,399 --> 00:00:20,800
自定义层跟自定义你的网络其实没本质区别

6
00:00:20,800 --> 00:00:24,800
为什么是因为你的层也是一个模具的一个子类

7
00:00:24,800 --> 00:00:27,000
比如说

8
00:00:27,800 --> 00:00:31,800
这里我们的做一个center的layer

9
00:00:31,800 --> 00:00:33,200
它是没有参数的

10
00:00:33,200 --> 00:00:34,600
首先这比较简单一点

11
00:00:35,399 --> 00:00:38,519
那么init的函数他也不用干什么事情

12
00:00:38,519 --> 00:00:39,399
他就把

13
00:00:39,399 --> 00:00:43,200
傅类的init调用一下

14
00:00:43,200 --> 00:00:45,400
所以你可以不用这个函数都没关系

15
00:00:45,400 --> 00:00:46,799
它会默认加上

16
00:00:48,000 --> 00:00:50,400
但是python3应该是

17
00:00:50,400 --> 00:00:52,200
python3才行

18
00:00:52,200 --> 00:00:53,799
那个

19
00:00:53,799 --> 00:00:56,600
2应该是2我还不知道

20
00:00:56,800 --> 00:00:58,000
所以建议你用3

21
00:00:59,399 --> 00:01:00,000
第二个是

22
00:01:01,000 --> 00:01:03,800
他就是跟之前的自定义的网络是一样的

23
00:01:03,800 --> 00:01:05,799
就是说你要定义那个forward的函数

24
00:01:06,400 --> 00:01:07,200
他forward干嘛

25
00:01:07,200 --> 00:01:09,799
他就把自己的均值给减掉

26
00:01:09,799 --> 00:01:12,000
就把你的输入减掉你的均值

27
00:01:12,000 --> 00:01:14,400
使得他的均值变成0

28
00:01:15,599 --> 00:01:17,000
所以我们用起来

29
00:01:17,000 --> 00:01:20,599
他跟我们构造一个python自己的layer

30
00:01:20,599 --> 00:01:22,799
或者一个自定义的module是一样的

31
00:01:22,799 --> 00:01:26,000
就定义他一个类的实例

32
00:01:26,000 --> 00:01:27,799
然后把一个tensor放进去

33
00:01:28,400 --> 00:01:29,799
然后可以看到是说

34
00:01:29,799 --> 00:01:32,000
他的均值就变成0了

35
00:01:32,000 --> 00:01:33,599
这就是这个layer干的事情对吧

36
00:01:36,799 --> 00:01:38,200
当然你可以这个layer

37
00:01:38,200 --> 00:01:40,400
这个layer可以做成一个

38
00:01:40,799 --> 00:01:42,400
简单的一个层

39
00:01:43,000 --> 00:01:44,400
参加比较复杂的网络

40
00:01:44,400 --> 00:01:46,599
比如说我们构造一个sequential的layer

41
00:01:46,599 --> 00:01:48,200
把线性层放进去

42
00:01:48,200 --> 00:01:50,400
把center的layer也是一个

43
00:01:50,400 --> 00:01:52,000
自定义层放进去

44
00:01:52,000 --> 00:01:53,599
跟别的layer

45
00:01:53,599 --> 00:01:55,000
跟别的自定义的

46
00:01:55,599 --> 00:01:57,400
pytorch定义的那些layer

47
00:01:57,400 --> 00:01:59,200
跟自定义的网络没有本质区别

48
00:01:59,200 --> 00:01:59,799
用起来

49
00:02:00,400 --> 00:02:03,799
然后就是说我随一个随机输进去

50
00:02:03,799 --> 00:02:05,599
Y的均值

51
00:02:05,599 --> 00:02:06,599
那就是应该是等于0

52
00:02:07,000 --> 00:02:08,599
那这里不会等于真的等于0

53
00:02:08,599 --> 00:02:11,000
这就有点浮点计算的误差

54
00:02:13,400 --> 00:02:14,800
那另外一个是说

55
00:02:14,800 --> 00:02:18,599
我的层如果想要带有参数会怎么样

56
00:02:19,400 --> 00:02:21,199
带有参数其实也是

57
00:02:21,199 --> 00:02:23,599
记得我们之前的参数都是

58
00:02:23,799 --> 00:02:26,599
parameter类的实例

59
00:02:26,599 --> 00:02:28,599
所以你的参数

60
00:02:29,799 --> 00:02:31,799
就是调用相应的parameter

61
00:02:32,599 --> 00:02:33,199
这个类

62
00:02:34,199 --> 00:02:35,000
就这里我们看一下

63
00:02:35,000 --> 00:02:37,199
我们定一个我们自己的线性层

64
00:02:38,000 --> 00:02:39,000
线性层我们知道

65
00:02:39,000 --> 00:02:41,199
我们需要一个输入的维度

66
00:02:41,199 --> 00:02:42,000
输出的维度

67
00:02:42,000 --> 00:02:43,799
这就是我们init还是要干的事情

68
00:02:45,199 --> 00:02:47,199
然后我们有两个参数

69
00:02:48,000 --> 00:02:49,199
一个是一个

70
00:02:51,799 --> 00:02:52,400
init

71
00:02:53,000 --> 00:02:55,400
大小乘以输出大

72
00:02:55,400 --> 00:02:55,599
不

73
00:02:55,599 --> 00:02:59,400
输入大小乘以输出大小的一个矩阵

74
00:02:59,800 --> 00:03:01,800
然后我们用的是一个随机数

75
00:03:01,800 --> 00:03:02,400
最简单

76
00:03:02,400 --> 00:03:04,599
我们就是这就我们就完成了初始化了

77
00:03:04,599 --> 00:03:06,800
我们用的是最简单的

78
00:03:06,800 --> 00:03:09,800
正义负义之间的均匀分布做初始化

79
00:03:10,800 --> 00:03:14,400
然后我们把随机参数放进n的parameter里面

80
00:03:15,000 --> 00:03:16,000
他就会完成了说

81
00:03:16,000 --> 00:03:18,200
我要把你的t度加上需要有t度

82
00:03:18,200 --> 00:03:19,599
就干那么点事情

83
00:03:19,599 --> 00:03:22,200
以及给你一个合适的名字

84
00:03:23,200 --> 00:03:24,200
同样的话

85
00:03:24,200 --> 00:03:25,599
对于bias的话

86
00:03:25,599 --> 00:03:28,200
那我们这里其实是用的random做bias

87
00:03:28,200 --> 00:03:30,400
就是我们你可以把它换成zero

88
00:03:30,400 --> 00:03:31,599
一般是用zero

89
00:03:31,800 --> 00:03:33,000
所以我们也是一样的

90
00:03:33,000 --> 00:03:35,400
就构造初始化我们的参数之后

91
00:03:35,400 --> 00:03:36,800
我们放进我们的parameter里面

92
00:03:36,800 --> 00:03:38,000
就得到parameter了

93
00:03:38,200 --> 00:03:39,800
就是说所有就是说加t度

94
00:03:39,800 --> 00:03:40,800
加名字这种事情

95
00:03:40,800 --> 00:03:42,200
都在这个里面完成了

96
00:03:43,200 --> 00:03:46,400
那么用定义起来跟之前也区别不大

97
00:03:46,400 --> 00:03:49,200
就是说我们拿一个x的话

98
00:03:49,200 --> 00:03:50,400
唯一的是说

99
00:03:50,400 --> 00:03:53,480
你要知道是通过点data去访问

100
00:03:53,480 --> 00:03:54,400
它对应的参数

101
00:03:54,400 --> 00:03:57,000
就是说我们拿到weights的点data

102
00:03:57,000 --> 00:03:59,200
然后跟我的x做一次矩阵乘

103
00:03:59,200 --> 00:04:03,800
然后再加上我们的偏移的数值

104
00:04:04,000 --> 00:04:07,400
然后再做一个我们这里跟之前不一样

105
00:04:07,400 --> 00:04:09,200
我们直接把relu做在这个地方

106
00:04:09,200 --> 00:04:11,000
然后再把relu做出去

107
00:04:11,400 --> 00:04:12,800
然后可以看到是说

108
00:04:12,800 --> 00:04:14,599
这里的定义跟之前是一样的

109
00:04:14,599 --> 00:04:17,199
就跟我们的module linear

110
00:04:17,199 --> 00:04:18,600
其实用起来差不多

111
00:04:18,800 --> 00:04:21,200
输入是3 5输出是3

112
00:04:21,200 --> 00:04:22,800
然后给拿到我们的weights

113
00:04:23,200 --> 00:04:23,600
OK

114
00:04:24,000 --> 00:04:25,200
可以看到是说

115
00:04:25,200 --> 00:04:27,600
这就是我们的parameter了

116
00:04:28,000 --> 00:04:29,400
就parameter可以看到

117
00:04:29,400 --> 00:04:31,400
我们是require square等于true

118
00:04:31,400 --> 00:04:33,000
因为我们要做更新

119
00:04:34,000 --> 00:04:34,400
OK

120
00:04:34,400 --> 00:04:38,200
这就是说怎么样定一个自带参数的

121
00:04:38,200 --> 00:04:39,200
一个自定义层

122
00:04:39,200 --> 00:04:43,400
就通过n.parameter把你的初始化的

123
00:04:43,400 --> 00:04:44,800
值包起来就行了

124
00:04:48,600 --> 00:04:50,400
然后我们给例子

125
00:04:50,400 --> 00:04:52,800
就是说自定义的那一个层

126
00:04:52,800 --> 00:04:55,800
我们可以输入一个随机的矩阵

127
00:04:55,800 --> 00:04:57,000
拿到一个输出对吧

128
00:04:57,400 --> 00:04:58,600
同样的道理的话

129
00:04:58,600 --> 00:05:00,800
我们可以构造我们自己的实例

130
00:05:00,800 --> 00:05:02,600
放进sequential里面

131
00:05:02,600 --> 00:05:05,600
参与到复杂网络的构造

132
00:05:06,000 --> 00:05:07,800
这跟之前用的是没什么区别的

133
00:05:11,400 --> 00:05:11,800
好

134
00:05:11,800 --> 00:05:13,000
这个就是说

135
00:05:13,000 --> 00:05:16,000
我们要怎么样做自定义的层

136
00:05:16,000 --> 00:05:18,400
跟我们自定义的网络是没区别的

137
00:05:18,600 --> 00:05:20,800
就是通过继承nn.module

138
00:05:21,400 --> 00:05:22,600
而唯一的是说

139
00:05:22,600 --> 00:05:25,000
我们如果要定义自带参数的话

140
00:05:25,000 --> 00:05:27,200
要把它放进nn.parameter的

141
00:05:27,200 --> 00:05:28,200
那个类里面

