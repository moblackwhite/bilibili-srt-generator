1
00:00:00,000 --> 00:00:03,359
就是我们来真的来讲一个在开口上

2
00:00:03,359 --> 00:00:06,600
一个简单的房价预测的一个问题

3
00:00:06,919 --> 00:00:09,640
然后怎么样来用我们之前学到的一些

4
00:00:09,640 --> 00:00:11,599
简单知识来做竞赛

5
00:00:12,599 --> 00:00:16,000
首先我们定义一些些函数

6
00:00:16,000 --> 00:00:17,719
我们就不讲这个函数了

7
00:00:17,719 --> 00:00:19,000
就是下载一个

8
00:00:19,080 --> 00:00:23,120
就是在某个地方下载一个这样子的函数

9
00:00:23,120 --> 00:00:25,640
然后把它放在本地并返回文件名

10
00:00:25,640 --> 00:00:28,519
我们就不讲这个是怎么算的了

11
00:00:29,480 --> 00:00:32,600
接下来是说我们开口开过的话

12
00:00:32,600 --> 00:00:34,519
我不知道国内能不能访问

13
00:00:34,519 --> 00:00:37,320
大家可以说一下

14
00:00:37,320 --> 00:00:37,960
就是说

15
00:00:39,879 --> 00:00:41,840
另外一个我们这是个很小数据

16
00:00:41,879 --> 00:00:44,000
我们就放在我们自己的一个小地方

17
00:00:44,000 --> 00:00:45,320
所以大家可以去

18
00:00:45,359 --> 00:00:47,480
我们把它注册成开口house

19
00:00:47,480 --> 00:00:49,200
train开口housetest

20
00:00:49,320 --> 00:00:50,679
就是说大家可以通过

21
00:00:50,719 --> 00:00:53,239
然后就是说从download这个函数

22
00:00:53,239 --> 00:00:55,000
给定这个文件名就可以下载了

23
00:00:55,239 --> 00:00:58,200
就实际上真正大家做开口竞赛的时候

24
00:00:58,200 --> 00:00:59,920
还得去他的官网上下数据

25
00:00:59,920 --> 00:01:01,760
大一点数据就放在官网上了

26
00:01:01,960 --> 00:01:03,120
下载之后

27
00:01:03,120 --> 00:01:04,920
他会返回本地的文件名

28
00:01:04,960 --> 00:01:06,240
然后我们就用pandas

29
00:01:06,240 --> 00:01:07,159
我们之前记得

30
00:01:07,560 --> 00:01:09,960
读入叫read一个csv文件

31
00:01:10,000 --> 00:01:12,040
就得到一个train和一个test data

32
00:01:12,719 --> 00:01:16,159
我们可以然后就是这个地方

33
00:01:16,200 --> 00:01:17,760
来打印一下我们的

34
00:01:18,040 --> 00:01:19,920
就train你可以看到是一个

35
00:01:19,960 --> 00:01:22,879
有1460个样本

36
00:01:22,920 --> 00:01:24,800
然后我的维度是81

37
00:01:24,920 --> 00:01:26,320
因为它有个标号

38
00:01:26,760 --> 00:01:28,760
然后我的test就是没有标号了

39
00:01:28,760 --> 00:01:29,720
就是少一个维度

40
00:01:29,720 --> 00:01:31,280
但是样本数也差不多

41
00:01:31,280 --> 00:01:32,480
也是1500左右

42
00:01:34,400 --> 00:01:34,960
好

43
00:01:36,120 --> 00:01:38,080
然后我们来看一下这个数据长什么样子

44
00:01:39,760 --> 00:01:41,680
就是train data

45
00:01:41,680 --> 00:01:44,400
就是说我们把前面的4行

46
00:01:44,520 --> 00:01:47,760
然后前面4列和最后3列打印出来

47
00:01:48,240 --> 00:01:50,720
看一下是说第一列是ID

48
00:01:50,920 --> 00:01:52,520
就是开口上一般来说

49
00:01:52,520 --> 00:01:53,360
第一列是ID

50
00:01:53,360 --> 00:01:56,080
或者总有一列是ID

51
00:01:56,079 --> 00:01:58,560
ID是一个不能参加训练的东西

52
00:01:58,560 --> 00:02:00,560
因为它就是每个样本有个ID

53
00:02:00,560 --> 00:02:02,280
如果你和ID的话

54
00:02:02,280 --> 00:02:04,280
就是就记住了整个样本

55
00:02:04,640 --> 00:02:07,840
所以有一般ID是用来提交

56
00:02:07,840 --> 00:02:09,599
但提交结果用的

57
00:02:10,560 --> 00:02:11,879
当然是说

58
00:02:12,400 --> 00:02:13,319
可以看一下

59
00:02:13,319 --> 00:02:14,639
大家可以去点那个link

60
00:02:14,639 --> 00:02:16,439
去看一下这里面到底是什么意思

61
00:02:16,520 --> 00:02:17,520
就是zoom是什么

62
00:02:17,520 --> 00:02:19,079
就是房子在哪个地方

63
00:02:19,240 --> 00:02:23,039
就是lot就是说你的房子前面有多大

64
00:02:23,239 --> 00:02:25,000
然后你的类型

65
00:02:25,319 --> 00:02:26,199
你的condition

66
00:02:26,439 --> 00:02:27,120
就是说

67
00:02:27,400 --> 00:02:29,120
最后的话就是一个sell price

68
00:02:29,120 --> 00:02:30,840
就是你那个房子卖了多少钱

69
00:02:31,399 --> 00:02:33,680
所以就整个意思是说

70
00:02:33,680 --> 00:02:35,919
我要根据我这些特征

71
00:02:36,199 --> 00:02:37,079
里面有文本

72
00:02:37,239 --> 00:02:37,879
有文本

73
00:02:37,879 --> 00:02:38,879
有数字来预测

74
00:02:38,879 --> 00:02:40,199
最后我的卖了多少钱

75
00:02:40,199 --> 00:02:41,959
就卖的这个钱是我要预测的

76
00:02:44,919 --> 00:02:47,319
然后因为它的第一个特征是ID

77
00:02:47,439 --> 00:02:48,719
所以我们要把它删掉

78
00:02:49,159 --> 00:02:51,000
就是我们把train data

79
00:02:51,280 --> 00:02:53,280
然后把第一列干掉

80
00:02:53,439 --> 00:02:55,080
把test data第一列拿掉

81
00:02:55,080 --> 00:02:56,120
然后把它合并起来

82
00:02:56,120 --> 00:02:56,879
放成一个

83
00:02:56,879 --> 00:02:58,360
成为一个all features里面

84
00:02:59,319 --> 00:03:01,879
然后用pandas的concate来实现这个函数

85
00:03:06,319 --> 00:03:08,280
那接下来我们要干的事情是说

86
00:03:08,439 --> 00:03:09,400
我们有讲过

87
00:03:09,560 --> 00:03:12,199
我们因为你那个数值有大有小

88
00:03:12,199 --> 00:03:13,920
我们第一个要干的事情是说

89
00:03:13,920 --> 00:03:15,039
让每一列

90
00:03:15,199 --> 00:03:16,560
如果是数值的话

91
00:03:16,599 --> 00:03:17,280
均值为0

92
00:03:17,280 --> 00:03:18,199
方程为1

93
00:03:19,200 --> 00:03:21,160
首先我们通过也就是说

94
00:03:21,240 --> 00:03:23,960
你所有的feature的data type

95
00:03:23,960 --> 00:03:25,560
如果不是一个object的话

96
00:03:25,560 --> 00:03:26,520
那么就是一个数值

97
00:03:26,520 --> 00:03:27,840
我们就这么假设了

98
00:03:28,040 --> 00:03:29,680
所以我们就知道说

99
00:03:29,720 --> 00:03:32,120
哪一些特征是一些数值的特征

100
00:03:32,120 --> 00:03:33,560
哪一些是文本

101
00:03:33,560 --> 00:03:34,440
我们等会处理

102
00:03:36,240 --> 00:03:37,680
那么对数值特征的话

103
00:03:37,680 --> 00:03:39,840
那就是说我们对每一个

104
00:03:39,880 --> 00:03:41,080
apply一个这样的操作

105
00:03:41,080 --> 00:03:42,200
把它这一列

106
00:03:42,400 --> 00:03:43,480
减去它的均值

107
00:03:43,480 --> 00:03:44,520
除以它的方叉

108
00:03:46,080 --> 00:03:47,680
所以注意到这个地方

109
00:03:47,680 --> 00:03:50,520
我们是把训练和测试级放在一起

110
00:03:50,520 --> 00:03:52,280
去算均值算方叉

111
00:03:52,280 --> 00:03:54,480
因为我们做比赛

112
00:03:54,480 --> 00:03:56,560
比赛反正你有已经有测试级了

113
00:03:56,560 --> 00:03:57,319
你就这么做

114
00:03:57,360 --> 00:03:59,719
实际情况你不一定能够这么做

115
00:03:59,760 --> 00:04:03,000
实际情况可能你得先在训练级算均值

116
00:04:03,000 --> 00:04:05,400
然后把它用到测试级上去

117
00:04:07,200 --> 00:04:08,800
所以这一行就是说

118
00:04:08,800 --> 00:04:11,760
我们把每一个数值特征均值变成0

119
00:04:11,760 --> 00:04:12,800
方叉变成1

120
00:04:13,600 --> 00:04:14,640
然后最后一个干嘛

121
00:04:14,719 --> 00:04:15,760
最后一个就是

122
00:04:15,800 --> 00:04:16,480
好吧

123
00:04:17,520 --> 00:04:18,600
最后就是说

124
00:04:19,920 --> 00:04:23,240
这个东西是说把你的lot number

125
00:04:23,439 --> 00:04:24,040
改成0

126
00:04:24,040 --> 00:04:26,640
因为我的实际数据里面有很多

127
00:04:26,640 --> 00:04:29,759
没有missing的data

128
00:04:29,759 --> 00:04:31,560
就是你没有可能采样

129
00:04:31,560 --> 00:04:32,560
没有采样的data

130
00:04:32,600 --> 00:04:34,120
我把它全部变成0

131
00:04:34,360 --> 00:04:37,160
这意思是因为你的均值已经是0了

132
00:04:37,520 --> 00:04:38,480
所以我把它变成0

133
00:04:38,480 --> 00:04:39,759
就变成均值的样子

134
00:04:40,360 --> 00:04:40,840
OK

135
00:04:40,840 --> 00:04:47,360
那么另外一个处理这种

136
00:04:47,360 --> 00:04:51,760
那种字符串怎么做

137
00:04:51,760 --> 00:04:54,480
字符串的话就是要one-hot encoding

138
00:04:55,000 --> 00:04:57,160
就是你假设我

139
00:04:57,440 --> 00:05:00,040
这一列里面有5个不同的值

140
00:05:00,600 --> 00:05:01,320
5个不同值

141
00:05:01,400 --> 00:05:02,640
我就创建5个feature

142
00:05:02,640 --> 00:05:07,920
如果你当前只是跟第二个feature是一样的话

143
00:05:07,920 --> 00:05:09,240
那就是一别的是0

144
00:05:09,560 --> 00:05:11,639
所以在pandas里面有个这函数

145
00:05:11,639 --> 00:05:12,600
要get a dummy

146
00:05:12,960 --> 00:05:14,759
来帮你转成这个函数

147
00:05:14,879 --> 00:05:16,319
然后dummy is not a number

148
00:05:16,319 --> 00:05:17,120
意思是说

149
00:05:17,160 --> 00:05:19,639
假设你这个是missing data

150
00:05:19,639 --> 00:05:20,759
是NA的话

151
00:05:21,040 --> 00:05:22,360
那就要unknow的话

152
00:05:22,400 --> 00:05:25,560
那么我可以把你也加上一个

153
00:05:25,680 --> 00:05:28,879
特别类叫说没有这一个特征

154
00:05:29,439 --> 00:05:31,439
所以可以看到是说做完之后

155
00:05:31,439 --> 00:05:32,560
你的feature会比较大

156
00:05:32,560 --> 00:05:34,720
就是说最后有300个特征出来

157
00:05:34,759 --> 00:05:36,199
之前我们大概是80个

158
00:05:36,199 --> 00:05:38,840
去掉ID之后应该是79个

159
00:05:38,880 --> 00:05:41,080
所以里面那一些离散值的话

160
00:05:41,080 --> 00:05:43,000
我们把它做成one-hot encoding

161
00:05:43,880 --> 00:05:46,840
最后能拿到331个特征

162
00:05:47,920 --> 00:05:49,040
那么这样子的话

163
00:05:49,040 --> 00:05:50,960
我们就可以把它变成一个

164
00:05:51,000 --> 00:05:53,160
touch的一个pencil了

165
00:05:53,280 --> 00:05:54,320
所以到目前为止

166
00:05:54,360 --> 00:05:57,360
我们都是之前在pandas那一章有讲过的

167
00:05:57,840 --> 00:06:01,720
就是说我们把nchain选出来

168
00:06:01,720 --> 00:06:02,440
value选出来

169
00:06:02,440 --> 00:06:04,360
它是一个numpy的一个结构

170
00:06:04,520 --> 00:06:05,640
唯一的不一样的是说

171
00:06:05,640 --> 00:06:06,640
我的data type

172
00:06:06,719 --> 00:06:08,560
它默认的python

173
00:06:08,560 --> 00:06:10,680
应该是默认numpy是float64

174
00:06:10,719 --> 00:06:12,159
所以我们变成float32

175
00:06:15,919 --> 00:06:16,240
好

176
00:06:16,240 --> 00:06:17,399
接下来是说

177
00:06:18,240 --> 00:06:19,439
我们要做训练了

178
00:06:19,639 --> 00:06:21,800
我们这种用了一个非常简单的模型

179
00:06:22,319 --> 00:06:24,639
loss我们还是用MLC

180
00:06:24,759 --> 00:06:26,479
然后我们的infeature

181
00:06:26,479 --> 00:06:27,519
说就是331

182
00:06:27,519 --> 00:06:29,399
然后我们用了一个非常简单的模型

183
00:06:29,399 --> 00:06:32,039
就是一个单层的线性回归

184
00:06:32,439 --> 00:06:33,599
这是我们get net

185
00:06:36,639 --> 00:06:38,519
然后我们就是说

186
00:06:39,079 --> 00:06:40,919
我们之前我们知道

187
00:06:40,919 --> 00:06:42,599
我们去怎么做我们的误差

188
00:06:42,639 --> 00:06:43,279
就是

189
00:06:43,479 --> 00:06:46,279
真实值减去预测值

190
00:06:46,319 --> 00:06:47,879
但是这个东西不是特别好

191
00:06:47,879 --> 00:06:48,519
是为什么

192
00:06:48,519 --> 00:06:49,839
对房价来讲

193
00:06:49,879 --> 00:06:50,800
房价的值

194
00:06:50,800 --> 00:06:52,519
有可能卖100万一个房

195
00:06:52,519 --> 00:06:53,879
有可能卖10万一个房

196
00:06:54,519 --> 00:06:57,039
所以如果你是直接这么做的话

197
00:06:57,079 --> 00:06:57,959
那就是

198
00:06:59,240 --> 00:07:00,879
100万的房的预差

199
00:07:00,959 --> 00:07:03,360
误差可能就权重更大一点

200
00:07:03,639 --> 00:07:06,079
那么小房子的误差

201
00:07:06,079 --> 00:07:07,439
可能就显得小一点

202
00:07:07,599 --> 00:07:08,839
一般来解决这个方法

203
00:07:08,839 --> 00:07:10,839
是说我们估计一个相对误差

204
00:07:10,959 --> 00:07:12,359
就我们关心的是说

205
00:07:12,359 --> 00:07:13,519
我们的真实值

206
00:07:13,560 --> 00:07:14,839
减去预测值

207
00:07:14,839 --> 00:07:15,759
除以真实值

208
00:07:15,759 --> 00:07:17,240
那就相对误差是误差

209
00:07:17,240 --> 00:07:19,680
10%还是100%

210
00:07:19,680 --> 00:07:21,879
还是5%

211
00:07:22,799 --> 00:07:24,000
所以要怎么做

212
00:07:24,360 --> 00:07:25,159
我就取个log

213
00:07:25,680 --> 00:07:26,319
就一般来说

214
00:07:26,319 --> 00:07:27,279
我就是对于

215
00:07:27,719 --> 00:07:28,879
因为你有除法在里面

216
00:07:28,879 --> 00:07:30,240
我就取个log就行了

217
00:07:30,319 --> 00:07:32,479
所以一般是log RMSE

218
00:07:32,519 --> 00:07:33,599
就这个是我们

219
00:07:33,600 --> 00:07:35,720
对于这种比较大的值

220
00:07:35,720 --> 00:07:38,080
正的值做回归的时候

221
00:07:38,080 --> 00:07:39,840
我们通常用log这个函数

222
00:07:40,520 --> 00:07:42,160
你可以看到这个意思是说

223
00:07:42,320 --> 00:07:43,840
对一个network

224
00:07:43,879 --> 00:07:44,920
它的输出

225
00:07:45,200 --> 00:07:46,080
首先我们把

226
00:07:46,080 --> 00:07:47,520
如果是一个infinity的话

227
00:07:47,520 --> 00:07:48,480
我们就变成

228
00:07:48,520 --> 00:07:51,160
因为log的infinity会出问题

229
00:07:51,160 --> 00:07:51,600
对吧

230
00:07:52,920 --> 00:07:54,120
然后呢

231
00:07:55,280 --> 00:07:56,560
接下来就是说

232
00:07:56,879 --> 00:07:57,720
把它的

233
00:07:58,760 --> 00:07:59,840
把它的

234
00:08:00,400 --> 00:08:01,800
预测的做log

235
00:08:01,879 --> 00:08:03,360
然后label也做个log

236
00:08:03,360 --> 00:08:05,520
然后再丢到RMSE里面

237
00:08:05,720 --> 00:08:07,560
然后再开根号就行了

238
00:08:07,720 --> 00:08:09,040
所以就是等于是说

239
00:08:09,040 --> 00:08:09,960
我们把我们的

240
00:08:10,319 --> 00:08:13,040
预测值和我们的label都做个log

241
00:08:13,040 --> 00:08:14,960
然后再按照正常的做

242
00:08:15,560 --> 00:08:16,360
信息回归

243
00:08:17,000 --> 00:08:18,240
就是这个函数干的事情

244
00:08:20,400 --> 00:08:21,480
所以训练函数

245
00:08:21,480 --> 00:08:22,199
跟我们之前

246
00:08:22,199 --> 00:08:23,639
其实是没什么本质区别

247
00:08:23,680 --> 00:08:25,560
我们就不太讲了

248
00:08:25,800 --> 00:08:27,800
就是说你可以看到是

249
00:08:27,840 --> 00:08:29,080
我们可能唯一区别

250
00:08:29,080 --> 00:08:30,759
是我们用了一个addon这个函数

251
00:08:30,800 --> 00:08:32,800
我们之前一直用了STD

252
00:08:32,799 --> 00:08:34,079
我们还没有解释addon

253
00:08:34,240 --> 00:08:35,719
addon你可认为是一个

254
00:08:35,759 --> 00:08:37,599
比较平滑的STD

255
00:08:37,679 --> 00:08:39,279
他的唯一的好处是说

256
00:08:39,279 --> 00:08:41,159
他对学习率没那么敏感

257
00:08:41,519 --> 00:08:43,199
就是说STD就是说

258
00:08:43,199 --> 00:08:44,240
学习率可能没调好

259
00:08:44,240 --> 00:08:45,399
就出问题

260
00:08:45,439 --> 00:08:46,120
addon来讲

261
00:08:46,120 --> 00:08:46,839
他的学习率

262
00:08:46,839 --> 00:08:48,719
可能他的使用范围会宽一点

263
00:08:49,679 --> 00:08:51,479
另外一个我们有一个weight decay

264
00:08:51,479 --> 00:08:52,279
就是说我们

265
00:08:52,319 --> 00:08:54,479
昨天有讲weight decay的做法

266
00:08:54,879 --> 00:08:56,679
所以别的东西都差不多

267
00:08:57,199 --> 00:08:58,759
别的都是一个标准的模块

268
00:08:58,759 --> 00:08:59,919
我就不仔细讲了

269
00:08:59,919 --> 00:09:01,120
大家可以去看一下

270
00:09:03,799 --> 00:09:06,120
另外一个是我们实现了一个

271
00:09:06,120 --> 00:09:07,319
k 者交叉验证

272
00:09:07,319 --> 00:09:08,959
我们上个星期有讲过

273
00:09:09,279 --> 00:09:11,839
就是说假设给定k

274
00:09:11,879 --> 00:09:13,399
给定第几折

275
00:09:13,439 --> 00:09:14,919
训练数据在里面

276
00:09:15,039 --> 00:09:17,159
可以看一下这个是怎么实现的

277
00:09:17,279 --> 00:09:18,879
其实也比较简单了

278
00:09:19,599 --> 00:09:20,639
就k肯定大于1的

279
00:09:20,639 --> 00:09:21,079
首先

280
00:09:22,240 --> 00:09:23,479
他每一折的大小

281
00:09:23,599 --> 00:09:25,799
就是你的样本数除以k

282
00:09:27,120 --> 00:09:28,079
然后每一次

283
00:09:29,079 --> 00:09:30,399
每一次我就是说

284
00:09:30,399 --> 00:09:32,199
我来把它切成k下

285
00:09:32,800 --> 00:09:33,800
那就说我的index

286
00:09:33,800 --> 00:09:35,080
就是等于是我的

287
00:09:35,120 --> 00:09:36,200
折的大小

288
00:09:36,200 --> 00:09:37,880
乘以当前的j

289
00:09:38,120 --> 00:09:40,360
然后j加1就是为折的大小

290
00:09:40,480 --> 00:09:42,000
就如果你是100个样本的话

291
00:09:42,000 --> 00:09:42,720
做5折的话

292
00:09:42,720 --> 00:09:43,640
每一折就是25

293
00:09:44,840 --> 00:09:46,040
然后接下来就是说

294
00:09:46,040 --> 00:09:48,360
我们把对应的那一个部分取出来

295
00:09:50,000 --> 00:09:52,320
如果j是等于i的话

296
00:09:52,320 --> 00:09:54,680
意味着说i就是当前第几折

297
00:09:54,720 --> 00:09:57,120
那么就把这一折做成validation dataset

298
00:09:57,120 --> 00:09:58,600
就是做成一个验证集

299
00:09:58,760 --> 00:10:02,520
那就是我把它做成一个验证集

300
00:10:02,800 --> 00:10:03,280
不然的话

301
00:10:03,280 --> 00:10:04,800
它应该是作为测试级

302
00:10:04,840 --> 00:10:07,360
而且测试级就是k-1个的

303
00:10:07,400 --> 00:10:10,080
把它并起来

304
00:10:10,400 --> 00:10:12,160
就如果它是train是none的话

305
00:10:12,280 --> 00:10:14,200
就是他还没有第一次看到

306
00:10:14,200 --> 00:10:15,120
就把它存起来

307
00:10:15,160 --> 00:10:15,720
不然的话

308
00:10:15,720 --> 00:10:18,040
就是我把当前存的xtrain

309
00:10:18,040 --> 00:10:18,800
和part

310
00:10:18,800 --> 00:10:19,880
给你concate起来

311
00:10:20,840 --> 00:10:23,680
就最后我能返回一个训练集

312
00:10:23,960 --> 00:10:25,400
和一个验证集

313
00:10:26,680 --> 00:10:28,600
就是说我给定我的x和y

314
00:10:28,640 --> 00:10:29,640
我给定一个

315
00:10:29,920 --> 00:10:32,640
k折的k和当前第几折

316
00:10:32,639 --> 00:10:34,279
我返回它对应的训练集

317
00:10:34,279 --> 00:10:36,639
和对应的验证集

318
00:10:37,360 --> 00:10:38,679
这是这个函数干的事情

319
00:10:43,319 --> 00:10:43,559
好

320
00:10:43,559 --> 00:10:44,720
那么这个函数是干嘛

321
00:10:44,840 --> 00:10:46,559
这个函数就是做k折交叉验证

322
00:10:47,559 --> 00:10:48,720
我们可以稍微讲一下

323
00:10:49,279 --> 00:10:49,879
就说白了

324
00:10:49,879 --> 00:10:51,879
就是说我们要做k次

325
00:10:51,919 --> 00:10:53,679
假定给k的话做k次

326
00:10:53,840 --> 00:10:57,039
每一次就是拿到第i折

327
00:10:57,240 --> 00:10:58,600
把这个数据拿出来

328
00:10:59,279 --> 00:11:01,279
里面就包含了训练集和验证集

329
00:11:01,279 --> 00:11:01,720
对吧

330
00:11:01,720 --> 00:11:05,040
然后我们在初始化一个network

331
00:11:05,360 --> 00:11:06,200
然后就去train

332
00:11:06,800 --> 00:11:08,360
就是把这个东西丢进去

333
00:11:08,360 --> 00:11:09,519
就里面包含了训练集

334
00:11:09,519 --> 00:11:10,759
验证集丢去train

335
00:11:10,840 --> 00:11:13,000
train之后会拿到一个train的loss

336
00:11:13,000 --> 00:11:14,240
一个validation的loss

337
00:11:15,240 --> 00:11:16,840
然后就是说我们把它求和

338
00:11:16,840 --> 00:11:19,759
当然这一些一些pro的函数

339
00:11:19,759 --> 00:11:20,360
我就不讲了

340
00:11:20,360 --> 00:11:21,639
最后的最后就是说

341
00:11:21,680 --> 00:11:22,920
把每一折

342
00:11:22,920 --> 00:11:25,160
它的train的loss求和

343
00:11:25,160 --> 00:11:26,080
然后做平均

344
00:11:26,120 --> 00:11:28,440
把validation的loss求和

345
00:11:28,480 --> 00:11:29,080
求的和

346
00:11:29,080 --> 00:11:29,879
然后做平均

347
00:11:29,920 --> 00:11:31,440
那就是k折的做法

348
00:11:32,320 --> 00:11:34,160
所以这意思是说

349
00:11:34,800 --> 00:11:37,320
给定我的各种超参数

350
00:11:37,519 --> 00:11:39,680
就是april calendar rate这些东西

351
00:11:39,720 --> 00:11:42,279
那么我就做一次k折交叉验证

352
00:11:42,279 --> 00:11:46,399
返回我的平均的损失

353
00:11:46,399 --> 00:11:48,840
和平均的验证集的损失

354
00:11:49,279 --> 00:11:50,480
就这个函数干的事情

355
00:11:51,360 --> 00:11:52,000
大家可以看一下

356
00:11:52,160 --> 00:11:53,639
这个假设我做一次会怎么样

357
00:11:53,639 --> 00:11:54,960
最次因为我们可以化

358
00:11:55,360 --> 00:11:55,920
化的话

359
00:11:55,920 --> 00:11:57,680
就是可以看到是说

360
00:11:57,720 --> 00:11:59,279
这个是第一折

361
00:11:59,279 --> 00:12:00,040
应该是第一折

362
00:12:00,040 --> 00:12:01,440
它的化的曲线

363
00:12:02,120 --> 00:12:05,320
然后这个是x还是我的epoc

364
00:12:05,360 --> 00:12:06,879
y是我的loss

365
00:12:07,360 --> 00:12:09,160
可以看到是我的train和validation

366
00:12:09,160 --> 00:12:10,399
还是重合的比较好的

367
00:12:10,399 --> 00:12:10,800
对吧

368
00:12:10,920 --> 00:12:12,560
就是我没有太多over fitting

369
00:12:12,879 --> 00:12:15,000
但是我只能看到

370
00:12:15,000 --> 00:12:15,720
我没有over fitting

371
00:12:15,720 --> 00:12:16,920
但是我不能知道

372
00:12:16,920 --> 00:12:18,360
是说我到底好还是坏

373
00:12:18,600 --> 00:12:20,040
然后可以看到是每一折

374
00:12:20,040 --> 00:12:21,160
你的train的log

375
00:12:21,160 --> 00:12:22,680
你的IMSE

376
00:12:22,960 --> 00:12:24,639
然后validation的log

377
00:12:24,639 --> 00:12:26,120
IMSE是长什么样子

378
00:12:27,160 --> 00:12:29,519
最后你的平均的loss

379
00:12:29,519 --> 00:12:31,120
就是这个是我们care的东西

380
00:12:31,279 --> 00:12:32,399
训练不是我们care的

381
00:12:32,399 --> 00:12:33,480
我们care的是这个东西

382
00:12:35,159 --> 00:12:35,919
就是说

383
00:12:36,120 --> 00:12:38,159
我们调一个超参数在这个地方

384
00:12:38,440 --> 00:12:39,360
k等于5

385
00:12:39,360 --> 00:12:40,560
number of block100

386
00:12:40,560 --> 00:12:42,519
lr等于5

387
00:12:42,519 --> 00:12:43,039
比较大

388
00:12:43,039 --> 00:12:44,360
weight dk等于0

389
00:12:44,360 --> 00:12:45,480
batch size64

390
00:12:45,519 --> 00:12:46,320
模型大小

391
00:12:46,320 --> 00:12:48,480
我们就应该是线性模型

392
00:12:48,480 --> 00:12:50,480
我们就不用调别的东西

393
00:12:50,799 --> 00:12:51,639
所以的话

394
00:12:51,679 --> 00:12:52,399
就是说

395
00:12:52,440 --> 00:12:53,279
这里干的事情

396
00:12:53,279 --> 00:12:54,039
就是说

397
00:12:54,039 --> 00:12:56,080
我们给定一个超参数

398
00:12:56,799 --> 00:12:59,039
然后放到k值里面训练一下

399
00:12:59,159 --> 00:12:59,839
然后看一下

400
00:12:59,839 --> 00:13:03,120
最后看一下我的平均的验证的

401
00:13:03,159 --> 00:13:05,319
logIMSE

402
00:13:06,120 --> 00:13:07,240
然后我们要干的事情

403
00:13:07,240 --> 00:13:07,879
就是说

404
00:13:07,919 --> 00:13:09,079
同学们要干的事情

405
00:13:09,079 --> 00:13:09,719
就是

406
00:13:09,879 --> 00:13:11,159
不断的换

407
00:13:11,919 --> 00:13:13,519
不断的调这些参数

408
00:13:13,519 --> 00:13:14,719
和调我们之前network

409
00:13:14,719 --> 00:13:15,679
network我们还没说

410
00:13:15,679 --> 00:13:18,079
network是我们希望一个最简单

411
00:13:18,079 --> 00:13:18,559
线性网络

412
00:13:18,559 --> 00:13:21,480
你可以换别的mlp什么东西

413
00:13:22,399 --> 00:13:23,839
不断去调它

414
00:13:23,879 --> 00:13:25,719
最后看你最后的

415
00:13:26,159 --> 00:13:28,240
验证级的平均IMSE

416
00:13:28,240 --> 00:13:29,120
长什么样子

417
00:13:29,799 --> 00:13:30,680
然后

418
00:13:31,080 --> 00:13:33,519
比如说调个10下20下

419
00:13:33,519 --> 00:13:36,639
然后把最好的超参数给留下来

420
00:13:36,680 --> 00:13:37,759
这就是调参

421
00:13:40,919 --> 00:13:43,039
最后就提交你的结果了

422
00:13:43,039 --> 00:13:44,639
假设你的参数已经调好了

423
00:13:44,680 --> 00:13:45,720
那我们再在

424
00:13:45,919 --> 00:13:48,399
完整的训练级上训练一次

425
00:13:48,919 --> 00:13:49,680
就是说

426
00:13:49,680 --> 00:13:50,799
还是把network拿到

427
00:13:50,799 --> 00:13:51,560
然后把这些

428
00:13:51,560 --> 00:13:52,279
假设这个里面

429
00:13:52,279 --> 00:13:55,000
就是你调好的那些超参数了

430
00:13:55,080 --> 00:13:57,519
最后在完整的训练级上

431
00:13:57,519 --> 00:13:58,240
再训练一次

432
00:13:58,240 --> 00:13:59,559
因为我们这个数据比较小

433
00:13:59,720 --> 00:14:01,159
就是你训练一次没问题

434
00:14:01,319 --> 00:14:01,919
然后可以

435
00:14:01,919 --> 00:14:02,759
当然也可以换一下

436
00:14:03,120 --> 00:14:04,120
因为没有验证级了

437
00:14:04,120 --> 00:14:04,840
这时候

438
00:14:05,240 --> 00:14:05,960
所以你可以看一下

439
00:14:05,960 --> 00:14:07,480
我的训练是不是正常

440
00:14:07,559 --> 00:14:09,000
最后的最后就是说

441
00:14:09,000 --> 00:14:10,000
你要做预测

442
00:14:10,039 --> 00:14:10,840
有个测试机

443
00:14:10,840 --> 00:14:12,399
测试机是没有标注的

444
00:14:12,519 --> 00:14:14,079
你把测试机拿进去

445
00:14:14,120 --> 00:14:15,759
然后再创建一个pandas

446
00:14:16,279 --> 00:14:19,199
把它存成一个submission.csv文件

447
00:14:19,439 --> 00:14:21,000
然后存在这个文件

448
00:14:21,000 --> 00:14:22,879
最后是你用这个文件去提交

449
00:14:23,120 --> 00:14:24,279
你可以去开口上提交

450
00:14:24,279 --> 00:14:25,600
然后看到你的分数

451
00:14:25,679 --> 00:14:27,159
就是说看到你的排名

452
00:14:27,159 --> 00:14:29,759
这个是整个Nordpork看的事情

