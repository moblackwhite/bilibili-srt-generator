1
00:00:00,000 --> 00:00:07,259
问题二是全卷机能解决输入大小变化的情况

2
00:00:07,259 --> 00:00:10,660
有什么办法解决输入Channel数动态变化的情况吗

3
00:00:10,660 --> 00:00:12,259
只能下采样

4
00:00:14,560 --> 00:00:15,560
呃

5
00:00:17,460 --> 00:00:18,059
呃

6
00:00:18,059 --> 00:00:20,140
我不是那么理解这个意思啊

7
00:00:20,140 --> 00:00:23,620
就是说你输入通道和输出通道你可以输入

8
00:00:23,620 --> 00:00:24,339
你不能变啊

9
00:00:24,339 --> 00:00:25,940
输入反正给定了你的东西

10
00:00:25,940 --> 00:00:27,900
输出你可以设成任何值

11
00:00:28,200 --> 00:00:30,000
假设你的输入通道是10的话

12
00:00:30,000 --> 00:00:31,400
输出我可以输出1

13
00:00:31,400 --> 00:00:33,160
我也可以输出100都没关系

14
00:00:34,320 --> 00:00:36,079
但是确实你不能任意设啊

15
00:00:36,079 --> 00:00:37,960
任意通常来讲

16
00:00:37,960 --> 00:00:40,600
我们会保证啊

17
00:00:40,620 --> 00:00:41,760
怎么说呢

18
00:00:41,760 --> 00:00:42,920
假设我的

19
00:00:46,320 --> 00:00:46,920
怎么说呢

20
00:00:46,920 --> 00:00:52,800
假设我的输入和输出的高宽没有变的情况下

21
00:00:52,800 --> 00:00:56,320
通常我是不会去动那个通道数的值

22
00:00:57,219 --> 00:01:04,219
但是假设我的我把输入和输出的高宽都减半的情况下

23
00:01:04,219 --> 00:01:07,460
通常我就会把我的输出的通道数给加一倍

24
00:01:09,700 --> 00:01:10,219
就理解吗

25
00:01:10,219 --> 00:01:12,740
就是说我把空间信息压缩了

26
00:01:12,760 --> 00:01:15,579
把这些提出来的那些信息啊

27
00:01:15,579 --> 00:01:18,060
在更多的通道里面把你存下来

28
00:01:18,060 --> 00:01:20,019
就是这样直观上是这么理解的

29
00:01:24,460 --> 00:01:25,379
问题21

30
00:01:26,540 --> 00:01:31,100
网络越深Padding越多是不是影响性能

31
00:01:31,100 --> 00:01:31,660
我首先啊

32
00:01:31,660 --> 00:01:34,780
性能这个包计算性能和模型性能啊

33
00:01:34,780 --> 00:01:37,180
计算性能的话

34
00:01:37,180 --> 00:01:38,420
还好啦

35
00:01:38,440 --> 00:01:40,300
就是反正就加了一点点嘛

36
00:01:40,300 --> 00:01:41,300
就不会那么的大

37
00:01:41,300 --> 00:01:43,620
就一点点增加

38
00:01:43,620 --> 00:01:46,700
你我觉得你可能会是说模型性能

39
00:01:46,720 --> 00:01:48,660
就是说我我放很多零进来

40
00:01:50,100 --> 00:01:51,460
就你放很多零

41
00:01:51,460 --> 00:01:53,660
其实不会影响了

42
00:01:53,719 --> 00:01:57,879
就零不会对你的输出造成影响

43
00:01:57,879 --> 00:01:58,640
理解吗

44
00:01:58,640 --> 00:02:02,959
就说零和我的卷积一成就得到一个零

45
00:02:02,959 --> 00:02:04,879
但偏差是有偏差了

46
00:02:04,899 --> 00:02:08,000
所以你最后你很多零进来

47
00:02:08,000 --> 00:02:10,039
反正出来就是等加一个偏差者

48
00:02:10,039 --> 00:02:11,120
等加一个常数了

49
00:02:11,120 --> 00:02:12,840
所以这个东西对神经网络来讲

50
00:02:12,859 --> 00:02:13,759
他无所谓

51
00:02:13,759 --> 00:02:16,079
给一次对常数对于他来讲

52
00:02:16,079 --> 00:02:17,759
他完全会忽略掉这个事情

53
00:02:17,780 --> 00:02:22,639
所以Padding很多Padding是不会影响太多

54
00:02:22,640 --> 00:02:24,380
影响了你的模型的精度

55
00:02:24,380 --> 00:02:25,700
他当然会影响你的性能

56
00:02:25,700 --> 00:02:26,740
如果你拍了很多很多

57
00:02:26,760 --> 00:02:28,220
你当然计算就变复杂了

58
00:02:31,620 --> 00:02:34,820
问题二十二每个通道的卷积和都不一样吗

59
00:02:34,820 --> 00:02:38,380
同一层不同通道的卷积和大家必须一样吗

60
00:02:38,380 --> 00:02:39,460
啊

61
00:02:39,480 --> 00:02:42,620
每个通道的卷积和是不一样的

62
00:02:42,620 --> 00:02:45,100
不同的通道的卷积和是一样的

63
00:02:47,820 --> 00:02:48,100
对

64
00:02:49,220 --> 00:02:51,340
所以你如果说

65
00:02:51,360 --> 00:02:54,800
你可以选择你可以用不同的卷积和

66
00:02:54,819 --> 00:02:57,759
但是那个就是我们之后会介绍是Google

67
00:02:57,759 --> 00:02:59,400
GoogleNet是这么用的

68
00:02:59,420 --> 00:03:04,080
但是一般来讲不同的通道的卷积和大小是一样的

69
00:03:05,719 --> 00:03:08,000
这是因为计算上的好处

70
00:03:08,020 --> 00:03:09,280
就说你如果不一样的话

71
00:03:09,280 --> 00:03:11,759
你得写上两个卷积操作

72
00:03:11,780 --> 00:03:12,039
对吧

73
00:03:12,039 --> 00:03:12,560
你如果不一样

74
00:03:12,580 --> 00:03:14,319
你得把它分开

75
00:03:14,340 --> 00:03:15,159
你现在一样的话

76
00:03:15,159 --> 00:03:17,439
你放在一起做一次运算就过去了

77
00:03:17,439 --> 00:03:20,480
就是说计算上更加方便

78
00:03:20,500 --> 00:03:22,660
他不是说我们写成这样子

79
00:03:22,660 --> 00:03:26,740
纯粹是因为计算下的计算上的效率更高

80
00:03:26,740 --> 00:03:29,700
并不是说你不能这么做啊

81
00:03:29,700 --> 00:03:30,860
是说我这么做的话

82
00:03:30,860 --> 00:03:32,700
我一个操作就过去了

83
00:03:32,720 --> 00:03:37,140
然后再用GPU或CPU做运算时候效率更好而已

84
00:03:40,340 --> 00:03:45,460
问题23计算卷积是BIOS的有无对结果影响大吗

85
00:03:45,460 --> 00:03:46,900
BIOS的作用怎么理解

86
00:03:48,340 --> 00:03:49,400
BIOS就是说

87
00:03:49,400 --> 00:03:53,099
偏移这个东西它是有一些用的

88
00:03:53,099 --> 00:03:55,300
但是它现在作用会变得越来越低

89
00:03:55,300 --> 00:04:01,020
我们之后会说我们有Batch Normalization时的作用变低

90
00:04:01,040 --> 00:04:02,420
但是偏移绝对是有用的

91
00:04:02,420 --> 00:04:03,379
首先啊

92
00:04:03,379 --> 00:04:07,939
统计上来讲偏移是说当你的数据都往上的时候

93
00:04:07,939 --> 00:04:10,500
假设举个例子

94
00:04:10,520 --> 00:04:14,540
你的当你的数据它的均值不为零的时候

95
00:04:14,540 --> 00:04:15,379
你这个偏移

96
00:04:15,379 --> 00:04:18,340
它其实就会去等价你的均值的负数

97
00:04:18,340 --> 00:04:20,000
就偏移干的小

98
00:04:20,000 --> 00:04:22,920
就是说能处理说你的数据都是证书很大

99
00:04:22,920 --> 00:04:23,660
这时候都是很小

100
00:04:23,660 --> 00:04:26,240
负数偏移会干这个事情啊

101
00:04:26,240 --> 00:04:27,000
实际上来说

102
00:04:27,000 --> 00:04:31,080
当然因为我们会做大量的一些均匀化的操作

103
00:04:31,080 --> 00:04:34,840
所以偏移的对于实际的啊

104
00:04:34,840 --> 00:04:37,480
没那么大的影响啊

105
00:04:37,480 --> 00:04:41,800
但我觉得你可以说不要偏移这个没关系啊

106
00:04:41,800 --> 00:04:45,440
但是你加上点也不会给你的计算带来特别大的

107
00:04:46,420 --> 00:04:48,939
几乎不会对基层性能产生影响

108
00:04:48,939 --> 00:04:51,060
而且偏移反正也很少嘛

109
00:04:51,079 --> 00:04:53,699
很小的一个数值对你来讲也无所谓

110
00:04:53,719 --> 00:04:55,019
有它也挺好的

111
00:04:55,019 --> 00:04:58,139
所以一般来说就默认就放在那个地方

112
00:05:03,579 --> 00:05:05,540
就核的参数怎么选啊

113
00:05:05,540 --> 00:05:07,459
下面是一堆问题

114
00:05:07,459 --> 00:05:09,100
核的参数是学出来的

115
00:05:09,100 --> 00:05:10,459
不是选出来的

116
00:05:10,459 --> 00:05:13,339
我们之前有讲说针对锐化的效果

117
00:05:13,340 --> 00:05:15,760
就是说我告诉大家说啊

118
00:05:15,760 --> 00:05:20,560
不同的核的参数的值会导致有不同的效果

119
00:05:20,560 --> 00:05:25,080
但是那个值具体叫哪一个是我们学出来的

120
00:05:25,080 --> 00:05:27,440
我们当后我们还没讲具体啊

121
00:05:27,440 --> 00:05:30,480
卷迹神经网络是怎么训练的啊

122
00:05:30,500 --> 00:05:33,080
但是我们确实是学出来的

123
00:05:33,080 --> 00:05:34,520
不需要大家去写的

124
00:05:38,520 --> 00:05:41,160
如果是一个RGB图像加上深度

125
00:05:41,180 --> 00:05:42,080
就是比如说深度

126
00:05:42,139 --> 00:05:43,300
就是说你的深度摄像头啊

127
00:05:43,300 --> 00:05:48,139
不同的深度的那个图片相当于输入是一个四通道

128
00:05:48,139 --> 00:05:51,139
做卷迹和RGB三通道是同样做法吗

129
00:05:51,139 --> 00:05:51,699
不是的

130
00:05:51,699 --> 00:05:55,539
就是说我们这一节介绍的是二维卷迹

131
00:05:57,019 --> 00:06:02,219
就通道数不算是一个你的通道数是一个外东西

132
00:06:02,240 --> 00:06:07,099
所以二维卷迹是说你只有高宽两个啊

133
00:06:07,099 --> 00:06:10,259
你那个输入那个图片就高宽两个channel

134
00:06:11,199 --> 00:06:12,000
然后呢

135
00:06:12,000 --> 00:06:15,599
你所谓的深度图就是多了一个深度

136
00:06:15,599 --> 00:06:17,279
这一个维度的话

137
00:06:17,279 --> 00:06:19,519
那你就用3D卷迹

138
00:06:19,519 --> 00:06:21,439
我们上一节课有讲

139
00:06:21,459 --> 00:06:24,279
大家可以进去看一下上节课那个录像

140
00:06:24,279 --> 00:06:27,639
就说对你的3D的卷迹是什么样子的

141
00:06:27,639 --> 00:06:30,800
3D卷迹同样有一个输出输出输入通道

142
00:06:30,819 --> 00:06:31,959
所以呢

143
00:06:31,980 --> 00:06:32,920
这样子的话

144
00:06:32,920 --> 00:06:36,879
你的输入就会变成一个输出输入通道

145
00:06:36,899 --> 00:06:40,199
乘以深度乘以宽乘以高

146
00:06:41,139 --> 00:06:44,620
然后你的核会变成一个5D的一个涨量

147
00:06:44,620 --> 00:06:47,300
你的输出同样是一个4D的东西

148
00:06:47,300 --> 00:06:47,659
OK

149
00:06:47,659 --> 00:06:48,979
这就是啊

150
00:06:48,979 --> 00:06:50,779
这个叫3D三维卷迹

151
00:06:53,500 --> 00:06:54,259
问题26

152
00:06:55,420 --> 00:06:58,259
不是每个核对应一个输入通道

153
00:06:58,259 --> 00:06:59,899
然后得到一个输出通道吗

154
00:06:59,899 --> 00:07:03,019
然后用多少核就输出多少通道吗

155
00:07:03,019 --> 00:07:03,899
啊

156
00:07:03,899 --> 00:07:06,819
三维卷迹是指用三个核吗

157
00:07:07,719 --> 00:07:15,279
就一个核卷迹核卷迹核二维的二维卷迹的卷迹核是个二维的一个矩阵

158
00:07:15,279 --> 00:07:16,639
我们之前讲过

159
00:07:16,659 --> 00:07:20,000
所以你的输入通道确实每一个是有个二维的

160
00:07:20,019 --> 00:07:21,920
假设你是图片输入的话

161
00:07:21,939 --> 00:07:24,360
那么二维图片输入的话

162
00:07:24,360 --> 00:07:26,279
那么就是说你就有个高宽了

163
00:07:26,279 --> 00:07:27,439
RGB就是通道了

164
00:07:27,439 --> 00:07:28,319
我先不管

165
00:07:28,339 --> 00:07:33,000
那么就是说你的你会一个你会得到一个输出通道

166
00:07:33,000 --> 00:07:33,519
对吧

167
00:07:33,519 --> 00:07:36,079
一个输入通道有自己的核

168
00:07:36,079 --> 00:07:38,659
然后会得到一个输出通道啊

169
00:07:38,659 --> 00:07:39,979
然后用了多少核

170
00:07:39,979 --> 00:07:40,419
就是说

171
00:07:41,939 --> 00:07:46,779
你还有外面还有一个输出通道的核就是你个4D的东西

172
00:07:46,779 --> 00:07:51,180
所以就是说会输出你的CO就是你的输出的通道

173
00:07:52,259 --> 00:07:55,339
三维的卷迹核是指你

174
00:07:57,819 --> 00:07:59,459
三维的卷迹核

175
00:07:59,459 --> 00:08:02,740
那么就是说你不再是有个H乘W

176
00:08:02,740 --> 00:08:04,779
你是H乘W再乘一个什么

177
00:08:04,779 --> 00:08:05,500
乘一个D吧

178
00:08:06,120 --> 00:08:08,360
那就是让你还有个输入通道

179
00:08:08,360 --> 00:08:10,040
输出通道就是五维嘛

180
00:08:10,060 --> 00:08:10,800
所以是这样子的

181
00:08:16,360 --> 00:08:20,560
高频和低频细节的学习有什么讲究吗

182
00:08:20,560 --> 00:08:22,560
例如开始注重高频部分

183
00:08:22,579 --> 00:08:24,480
接下来注重低频

184
00:08:24,480 --> 00:08:27,399
我觉得怎么说呢

185
00:08:27,399 --> 00:08:28,120
一般来说

186
00:08:28,120 --> 00:08:33,240
我觉得我们通常来说不去做太多人工的干预说

187
00:08:33,240 --> 00:08:35,039
你这个特征是高频的

188
00:08:35,299 --> 00:08:36,819
高频就是说一些很

189
00:08:39,099 --> 00:08:41,500
对信号处理的一个一个讲法

190
00:08:41,519 --> 00:08:44,459
就图片里面倒不那么讲高频低频的东西

191
00:08:44,459 --> 00:08:45,299
但反过来讲

192
00:08:45,299 --> 00:08:45,980
通常来说

193
00:08:45,980 --> 00:08:49,019
你可认为有些通道可能会去

194
00:08:49,019 --> 00:08:51,339
假设高频低频都有用的情况下

195
00:08:51,339 --> 00:08:53,620
有些通道会去学习高频的一些特征

196
00:08:54,579 --> 00:08:56,779
有些通道会去学习低频的特征

197
00:08:56,779 --> 00:08:59,459
你是不要去太多注重这个事情

198
00:08:59,459 --> 00:09:00,379
就把数据溜进去

199
00:09:00,379 --> 00:09:03,819
让全球神经网络自己去找出来是什么情况

200
00:09:05,039 --> 00:09:09,939
问题是吧

201
00:09:09,939 --> 00:09:12,539
怎么理解不识别空间信息

202
00:09:12,539 --> 00:09:14,659
就是我讲的是一层一的卷集合

203
00:09:14,659 --> 00:09:16,219
怎么不识别空间信息

204
00:09:16,219 --> 00:09:19,779
是因为你每一层一的卷集合

205
00:09:19,799 --> 00:09:23,459
你的每一个输出的那个元素

206
00:09:24,579 --> 00:09:28,339
他其实只看了对应的那个

207
00:09:28,360 --> 00:09:31,699
后来直接回到这个PPT吧

208
00:09:32,400 --> 00:09:34,000
就说

209
00:09:35,480 --> 00:09:39,200
我说不看空间信息说每一个他的一个输出啊

210
00:09:39,200 --> 00:09:43,240
他只看了对应的那个输入的他那个像素

211
00:09:43,259 --> 00:09:47,680
他没有看边上这任何边上这一圈东西只看了自己啊

212
00:09:47,700 --> 00:09:53,040
所以就是说他根本就没有看说这个像素跟他边上像素的关系是什么样子

213
00:09:53,040 --> 00:09:55,920
所以就说他没有去识别空间的模式

214
00:09:55,919 --> 00:10:01,379
所以这个就是一层一卷集层不识别空间信息的一个这个原因的由来

215
00:10:08,059 --> 00:10:08,659
问题29

216
00:10:08,659 --> 00:10:12,979
是不是可以三层三层三和一层一层n的卷集层叠加

217
00:10:13,000 --> 00:10:17,740
分别来进行空间信息检测和输出通道调整啊

218
00:10:17,740 --> 00:10:18,099
是的

219
00:10:18,120 --> 00:10:18,659
恭喜你

220
00:10:18,659 --> 00:10:19,500
你又在

221
00:10:20,819 --> 00:10:23,860
五年之后得到了非常有名的一个模型

222
00:10:24,840 --> 00:10:27,840
mobile net的一个设计思路

223
00:10:27,860 --> 00:10:31,800
就是说我先不先就是这个叫depth wise convolution

224
00:10:31,800 --> 00:10:32,919
就是说啊

225
00:10:32,919 --> 00:10:35,560
假设你生啊

226
00:10:35,560 --> 00:10:38,360
假设你五年之前就来做深度学习的话

227
00:10:38,379 --> 00:10:39,680
你现在已经工程名就了

228
00:10:41,680 --> 00:10:43,200
这个是mobile net

229
00:10:43,220 --> 00:10:45,840
我们可能没有讲mobile net的东西啊

230
00:10:45,860 --> 00:10:49,360
就是说mobile net是说我不做通道的融合

231
00:10:49,360 --> 00:10:54,500
我先对每一个输入通道直接做三层三的卷集

232
00:10:55,659 --> 00:10:57,740
就不像之前那样把它加起来

233
00:10:57,759 --> 00:10:59,300
再做个输出通道

234
00:10:59,320 --> 00:11:00,139
然后呢

235
00:11:00,159 --> 00:11:03,759
做完之后再对每一个再做空间融合

236
00:11:03,759 --> 00:11:06,460
这样子的好处是说

237
00:11:06,460 --> 00:11:09,100
唯一的好处是说我的计算链会比较小

238
00:11:09,100 --> 00:11:14,940
我的可以适合比如mobile net就是给手移动端用的卷集神经网络

239
00:11:14,960 --> 00:11:17,139
他的计算复杂度非常低

240
00:11:17,139 --> 00:11:21,600
他的效果当然现在也可以做到很不错的效果

241
00:11:21,600 --> 00:11:22,720
这个是可以这么做的

242
00:11:24,519 --> 00:11:32,960
所以我们大家问问题都把那个常见的一些通道给常见的经典的算法都给大家想出来了

243
00:11:32,980 --> 00:11:33,879
我们这个挺厉害的

244
00:11:37,199 --> 00:11:39,159
所以我觉得大家如果你有这种想法

245
00:11:39,159 --> 00:11:41,840
你现在真的去做研究吧

246
00:11:41,840 --> 00:11:44,519
随着你的说不定你可以再学点别的东西

247
00:11:44,519 --> 00:11:45,720
要冒出一点新的想法

248
00:11:45,720 --> 00:11:46,319
没人做

249
00:11:46,319 --> 00:11:47,039
赶紧把它做了

250
00:11:47,779 --> 00:11:49,980
说不定就Citation上万

251
00:11:53,379 --> 00:11:55,579
卷集能获取未知信息吗

252
00:11:55,599 --> 00:11:58,079
感觉卷集就是把网络信息提取出来

253
00:11:58,079 --> 00:12:01,539
变于函数融合卷集能有未知信息了

254
00:12:01,559 --> 00:12:02,099
就是说

255
00:12:04,659 --> 00:12:10,620
卷集你的输出的那个卷集是对位置非常敏感的

256
00:12:10,620 --> 00:12:14,579
你对于就就是说输出里面的I行的接力

257
00:12:15,560 --> 00:12:18,200
就是对应的输入图片

258
00:12:18,200 --> 00:12:19,600
I行的接力

259
00:12:19,620 --> 00:12:23,200
那个元素附近那一块东西的那些信息

260
00:12:23,220 --> 00:12:29,240
所以是说卷集的输出的那些信息是位置信息放在你输出的元素

261
00:12:29,240 --> 00:12:32,000
在你那个举着里面的那个位置决定了

262
00:12:32,000 --> 00:12:34,040
我们甚至之后会讲说怎么样通过

263
00:12:35,080 --> 00:12:40,960
持话层使得你不要那么去获取对新位置那么敏感

264
00:12:40,980 --> 00:12:41,320
OK

265
00:12:41,340 --> 00:12:43,400
卷集绝对是能获取未知信息的

266
00:12:45,280 --> 00:12:49,560
多通道时每个科学到不同的参数

267
00:12:49,560 --> 00:12:50,879
这样理解没错吧

268
00:12:50,879 --> 00:12:54,000
那么卷集层的参数是怎么共享的

269
00:12:55,800 --> 00:12:58,080
通道之间是不共享参数的

270
00:12:59,280 --> 00:12:59,879
你见吧

271
00:12:59,879 --> 00:13:03,080
就是说每个通道你希望他能学习不一样的东西

272
00:13:03,100 --> 00:13:05,320
每个通道去识别一个

273
00:13:05,340 --> 00:13:09,160
你可认为每个通道去识别一个特定的模式

274
00:13:10,120 --> 00:13:13,800
他们之间是不那么去共享参数的

275
00:13:13,820 --> 00:13:23,700
就是说我实现我去识别红拆红通道里面的一个这个方向的边和绿通道一个这个方向的边

276
00:13:23,700 --> 00:13:26,620
你就不那么好去共享参数吧

277
00:13:26,640 --> 00:13:27,180
对吧

278
00:13:27,180 --> 00:13:29,300
所以就说他们之间是不共享参数的

279
00:13:32,140 --> 00:13:34,140
问题在事儿

280
00:13:34,140 --> 00:13:36,540
计算复杂度是不是一层的复杂度

281
00:13:37,780 --> 00:13:39,180
如果是一层的话

282
00:13:39,640 --> 00:13:45,040
你的输入的mh是不是也可以用nh再计算得出

283
00:13:45,060 --> 00:13:48,960
然后最后的复杂度应该是可以去掉两个边对吧

284
00:13:48,960 --> 00:13:51,800
就说当然是的

285
00:13:51,800 --> 00:13:54,240
就是说我们计算复杂度有讲

286
00:13:54,240 --> 00:13:57,440
我们的是一个计算复杂度

287
00:13:57,440 --> 00:13:58,440
我来切换过来

288
00:14:00,440 --> 00:14:02,280
我的计算复杂度是一个

289
00:14:04,080 --> 00:14:07,160
mh乘nw的东西

290
00:14:07,219 --> 00:14:10,620
那你可以换成nhnw

291
00:14:10,639 --> 00:14:14,179
我们知道mh和mw是怎么通过nh

292
00:14:14,179 --> 00:14:16,659
那个ph啊

293
00:14:16,659 --> 00:14:19,620
那个和那个stride的那个sh算出来的

294
00:14:19,639 --> 00:14:21,500
那你可以替换了是可以做的

295
00:14:21,500 --> 00:14:23,059
但是这样写方便一点

296
00:14:23,059 --> 00:14:26,419
因为你前面还有个复杂的公式怎么去运算呢

297
00:14:26,419 --> 00:14:32,500
但是我觉得这个公式就是说你可以去理解每一个输出的像素元素

298
00:14:32,500 --> 00:14:36,339
你需要多少个就每一个输出的一个元素

299
00:14:36,360 --> 00:14:39,120
你需要多少个东西来算出来

300
00:14:39,120 --> 00:14:41,320
这样子其实公式上简单一点

301
00:14:44,800 --> 00:14:45,480
啊

302
00:14:45,480 --> 00:14:47,639
343跟之前是一样的

303
00:14:47,639 --> 00:14:50,360
你nh和nw当然是相关的

304
00:14:50,360 --> 00:14:53,120
因为他和mh和mw是相关的

305
00:14:53,139 --> 00:14:56,639
就是说输入的宽高宽和输出的高宽是相关的

306
00:14:59,160 --> 00:15:00,519
问题啊

307
00:15:00,519 --> 00:15:04,840
34就检测图像文例的时候

308
00:15:04,860 --> 00:15:07,660
经过一次卷积操作就可以得到想要的信息吗

309
00:15:07,660 --> 00:15:09,379
还需要多多次啊

310
00:15:09,399 --> 00:15:10,460
另外和是怎么确定的

311
00:15:10,480 --> 00:15:12,860
训练出来是经验得到的啊

312
00:15:12,879 --> 00:15:14,340
检测文理的时候

313
00:15:15,540 --> 00:15:17,019
你你就是说我

314
00:15:17,019 --> 00:15:22,420
我是说我们希望卷积和能够去识别各种你想要的文理

315
00:15:22,420 --> 00:15:24,100
但实际上他是怎么做的

316
00:15:24,100 --> 00:15:26,180
是一他自己学出来了

317
00:15:26,200 --> 00:15:30,060
他的和参数是自己通过数据学出来的啊

318
00:15:30,080 --> 00:15:33,100
所以你无法控制他到底去识别谁

319
00:15:33,100 --> 00:15:36,399
你也无法说通过一次卷积操作还是多次

320
00:15:36,399 --> 00:15:38,000
通常来说是通过多次

321
00:15:38,019 --> 00:15:39,960
这是为什么要深度升级网络了

322
00:15:41,040 --> 00:15:44,920
就每一个卷积层就会识别一点点信息

323
00:15:44,920 --> 00:15:48,680
然后下一层的就根据前面那些信息做一步的经验

324
00:15:48,680 --> 00:15:51,240
然后慢慢慢慢就很多很多层慢慢的过去

325
00:15:51,240 --> 00:15:52,560
我们之后会讲了这东西

326
00:15:55,399 --> 00:15:58,920
问题35是一个pychain训练模型的时候

327
00:15:58,920 --> 00:16:00,399
怎么没有

328
00:16:03,480 --> 00:16:06,639
就是说你模型参数是说你训练完之后

329
00:16:06,639 --> 00:16:07,960
你得存在磁盘上

330
00:16:07,960 --> 00:16:10,560
就是每次要save和load这两个操作

331
00:16:10,560 --> 00:16:14,440
就你最好是没存在上面

332
00:16:14,440 --> 00:16:17,480
然后我们之前有讲过怎么把一个模型存到磁盘

333
00:16:17,500 --> 00:16:18,920
然后再读回来

334
00:16:18,920 --> 00:16:20,040
嗯

335
00:16:20,040 --> 00:16:27,120
然后jupiter和pychain训练模型哪个推荐jupiter是一个互动的一个就interactive

336
00:16:27,120 --> 00:16:31,519
就是说你就是写一行就会出一行结果的一个东西啊

337
00:16:31,539 --> 00:16:32,340
然后pychain呢

338
00:16:32,360 --> 00:16:34,259
很多时候我从来没有用过pychain

339
00:16:34,279 --> 00:16:35,980
其实说实话好像那个东西收费的

340
00:16:35,980 --> 00:16:38,779
我记得所以看收费我就觉得哎

341
00:16:38,779 --> 00:16:39,659
算了

342
00:16:39,679 --> 00:16:40,980
我以前用emacs居多

343
00:16:40,980 --> 00:16:43,500
现在用VS code就偷懒了

344
00:16:43,519 --> 00:16:44,740
用VS code居多

345
00:16:44,740 --> 00:16:48,620
但是pychain我觉得跟emacs和VS code一样

346
00:16:48,620 --> 00:16:50,460
都是用来开发

347
00:16:51,379 --> 00:16:54,419
比较做大的开发的时候用的

348
00:16:54,439 --> 00:16:56,500
就是你要写一个完整的py文件

349
00:16:56,500 --> 00:16:58,579
jupiter很多时候就是写一些啊

350
00:16:58,579 --> 00:16:59,419
调试用的

351
00:16:59,419 --> 00:17:00,579
写些简单的代码用的

352
00:17:02,419 --> 00:17:04,819
所以就是说你看你个人喜好吧

353
00:17:04,819 --> 00:17:06,180
我反正啊

354
00:17:06,180 --> 00:17:07,779
jupiter也用啊

355
00:17:07,799 --> 00:17:08,619
VS code也用

356
00:17:10,660 --> 00:17:12,019
问题36啊

357
00:17:12,019 --> 00:17:14,859
我们时间下好

358
00:17:14,859 --> 00:17:17,460
我们干脆快速过一下

359
00:17:17,460 --> 00:17:19,740
假设输入通道是三通道啊

360
00:17:19,759 --> 00:17:20,819
设置时通道

361
00:17:20,839 --> 00:17:21,339
那么

362
00:17:25,059 --> 00:17:26,660
假设你的输入是三通道

363
00:17:26,660 --> 00:17:29,139
那么你代码里面输入通道必须写成三通道

364
00:17:29,160 --> 00:17:30,099
你不能写成别的

365
00:17:30,099 --> 00:17:30,619
写成别的

366
00:17:30,620 --> 00:17:31,880
就是啊

367
00:17:34,280 --> 00:17:35,560
写成别的肯定不行

368
00:17:35,560 --> 00:17:38,040
但是你的输出通道可以设成10对的

369
00:17:38,060 --> 00:17:39,040
我觉得这个是对的

370
00:17:39,060 --> 00:17:41,040
最后的啊

371
00:17:41,060 --> 00:17:42,000
你这个是对的

372
00:17:42,020 --> 00:17:42,640
我觉得没错

373
00:17:45,040 --> 00:17:49,360
feature map的数量feature map一般来就是对feature map

374
00:17:49,380 --> 00:17:53,440
你可以认为就是你的输出的高和宽

375
00:17:53,460 --> 00:17:56,840
有时候你的feature map会讲你的输出的通道数

376
00:17:56,840 --> 00:18:00,160
但feature map所谓的feature map就是你的卷迹的输出了

377
00:18:00,180 --> 00:18:00,940
就是feature map

378
00:18:03,460 --> 00:18:05,620
输入通道动态变化是怎么处理的

379
00:18:05,620 --> 00:18:11,180
输入通道不能动态的输入通道必须是你输入都是一个RGB图片了

380
00:18:11,180 --> 00:18:13,300
你不能RGB转灰度

381
00:18:13,300 --> 00:18:16,620
就是你得输入通道是不能动态变的啊

382
00:18:18,779 --> 00:18:19,940
就这个我没有讲过

383
00:18:19,960 --> 00:18:22,580
为什么卷迹和的都是奇数

384
00:18:22,580 --> 00:18:24,220
没有偶数啊

385
00:18:24,220 --> 00:18:25,500
你可以有偶数没关系

386
00:18:25,519 --> 00:18:26,980
就是说效果是一样的

387
00:18:26,980 --> 00:18:29,060
只是说奇数在排令起来方便一点

388
00:18:31,140 --> 00:18:33,180
3D卷迹是处理视频吧

389
00:18:33,200 --> 00:18:35,700
也可以处理RGB加深度可以的3D

390
00:18:35,700 --> 00:18:38,420
RGB加深度是可以用3D卷迹来做的啊

391
00:18:38,440 --> 00:18:40,180
甚至可以用2D卷迹都可以做

392
00:18:40,180 --> 00:18:41,900
就每一个深度做一个2D卷迹

393
00:18:41,920 --> 00:18:43,740
然后再用一个RN啊

394
00:18:43,740 --> 00:18:46,259
或者是就把它空开了起来都OK

395
00:18:46,259 --> 00:18:47,420
就是说啊

396
00:18:47,440 --> 00:18:48,420
都是OK的

397
00:18:48,420 --> 00:18:51,019
但我们这一次应该是不会讲3D卷迹啊

398
00:18:51,040 --> 00:18:53,900
3D卷迹在视频里面用的比较多

399
00:18:53,900 --> 00:18:57,980
但是也是一个比较活跃的一个研究方向了

400
00:18:58,000 --> 00:19:01,920
所以目前来说3D卷迹啊

401
00:19:01,940 --> 00:19:07,519
稍微比2D卷迹的效果好一点点

402
00:19:07,519 --> 00:19:09,279
但是计算复杂度高很多

403
00:19:09,279 --> 00:19:12,000
所以也就是为什么整个视频领域

404
00:19:12,019 --> 00:19:13,400
他大家都做的比较痛苦

405
00:19:13,400 --> 00:19:14,759
因为计算量太大了

