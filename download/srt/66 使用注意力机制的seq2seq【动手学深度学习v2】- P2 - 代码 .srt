1
00:00:00,000 --> 00:00:04,400
使用注意力机制的seek to seek

2
00:00:04,400 --> 00:00:07,799
就是说注意力机制在这里面

3
00:00:07,799 --> 00:00:10,919
在NLP的应用也是最早的工作之一

4
00:00:10,919 --> 00:00:14,000
就是说怎么样把tension用过来

5
00:00:14,000 --> 00:00:19,120
然后这个是我记得应该是最早工作之一

6
00:00:19,120 --> 00:00:24,039
就是说也是我们之所以讲它也是

7
00:00:24,039 --> 00:00:25,760
因为我们之前讲过seek to seek

8
00:00:25,760 --> 00:00:27,679
然后我先接下来讲说

9
00:00:27,679 --> 00:00:30,120
把注意力拿进来会长什么样子

10
00:00:30,120 --> 00:00:34,280
另外一个也是说给大家真的看一下

11
00:00:34,280 --> 00:00:36,880
key query value

12
00:00:36,880 --> 00:00:38,200
到底是什么东西

13
00:00:38,480 --> 00:00:41,119
就是说当然取决于应用的不一样

14
00:00:41,119 --> 00:00:42,640
它的东西是很不一样的

15
00:00:42,920 --> 00:00:43,240
OK

16
00:00:43,240 --> 00:00:44,960
但我们先讲一个例子

17
00:00:47,359 --> 00:00:51,039
动机是说在机器翻译的时候

18
00:00:51,039 --> 00:00:56,760
每个生成的词可能源自于句子中间的

19
00:00:56,759 --> 00:00:57,679
不同的词

20
00:00:59,359 --> 00:00:59,799
你看

21
00:00:59,799 --> 00:01:04,480
Hello world句号翻译法语的时候

22
00:01:04,480 --> 00:01:06,359
第一个词翻译

23
00:01:06,359 --> 00:01:10,599
它应该是个算我不懂法语

24
00:01:10,599 --> 00:01:12,480
我可能也是乱标的

25
00:01:13,159 --> 00:01:16,879
就是说第一个词应该是它比较重要

26
00:01:16,879 --> 00:01:17,280
对吧

27
00:01:19,159 --> 00:01:21,519
我猜这个词应该没有word这个词的意思

28
00:01:21,519 --> 00:01:24,000
那么就是句号肯定也不管对吧

29
00:01:24,079 --> 00:01:26,840
所以你去翻它这个词的时候

30
00:01:26,959 --> 00:01:29,319
你应该是说去找到它的相似

31
00:01:29,319 --> 00:01:30,159
这应该是它

32
00:01:30,920 --> 00:01:31,799
这样子的话

33
00:01:31,799 --> 00:01:34,159
就是说你应该去把你的关注点

34
00:01:34,159 --> 00:01:35,079
看在这个词

35
00:01:35,079 --> 00:01:37,319
而不需要去真的看很厚的东西

36
00:01:38,640 --> 00:01:40,359
当然你要翻到

37
00:01:40,359 --> 00:01:42,960
我猜这个词是世界的意思

38
00:01:43,120 --> 00:01:43,879
在法语里面

39
00:01:44,000 --> 00:01:46,120
那么就是说你翻这个词的时候

40
00:01:46,480 --> 00:01:49,039
应该去看的是对应的是这个词

41
00:01:49,680 --> 00:01:51,240
最后你要翻句号的时候

42
00:01:51,240 --> 00:01:52,599
当时你看到是这个句号

43
00:01:52,599 --> 00:01:52,840
对吧

44
00:01:52,840 --> 00:01:53,719
你就翻译过来

45
00:01:55,000 --> 00:01:57,200
所以就是说你在合理的时候

46
00:01:57,200 --> 00:01:59,000
特别是你比较长的句子的时候

47
00:01:59,719 --> 00:02:00,719
你在翻的时候

48
00:02:00,719 --> 00:02:01,680
你后面那一节

49
00:02:01,680 --> 00:02:03,200
就是我说一段很长的话

50
00:02:03,200 --> 00:02:04,480
让你一句很长的话

51
00:02:04,480 --> 00:02:05,359
让你翻译的话

52
00:02:05,359 --> 00:02:09,000
那么你把所有东西压到一起

53
00:02:09,000 --> 00:02:11,520
很有可能你看到的

54
00:02:11,960 --> 00:02:13,840
可能就里面东西就

55
00:02:14,639 --> 00:02:16,280
可能太

56
00:02:16,560 --> 00:02:17,800
东西在里面太挤了

57
00:02:17,800 --> 00:02:19,280
然后你可能看不出来

58
00:02:19,280 --> 00:02:20,520
到底哪一块是前面

59
00:02:20,520 --> 00:02:21,400
哪一块是后面的

60
00:02:21,960 --> 00:02:24,520
而且你在语言翻译的时候

61
00:02:24,520 --> 00:02:26,039
你多多少少也知道说

62
00:02:26,159 --> 00:02:27,000
大家如果都是

63
00:02:27,680 --> 00:02:29,520
中文和英文会有点不一样

64
00:02:29,520 --> 00:02:29,960
会跳

65
00:02:30,040 --> 00:02:32,719
但是你可能西方语言之间

66
00:02:32,840 --> 00:02:34,000
可能真的就是

67
00:02:34,439 --> 00:02:36,240
句子那些词的相对位置

68
00:02:36,319 --> 00:02:38,360
都是比较相对来说比较像的

69
00:02:38,439 --> 00:02:41,719
所以你去说我在翻句子

70
00:02:42,120 --> 00:02:43,599
target句子哪个部位的时候

71
00:02:43,599 --> 00:02:45,360
我去看对应部位的原句子

72
00:02:45,360 --> 00:02:46,840
总是可能是没错的

73
00:02:47,640 --> 00:02:48,280
但是

74
00:02:48,840 --> 00:02:50,480
seek to seek做不了这个事情

75
00:02:51,480 --> 00:02:53,640
seek to seek传过去的东西

76
00:02:53,640 --> 00:02:54,920
是你最后的

77
00:02:55,760 --> 00:02:58,560
最后词的隐藏状态传过去了

78
00:02:58,879 --> 00:03:01,080
他只用了最后的东西

79
00:03:01,080 --> 00:03:02,439
就seek to seek里面

80
00:03:04,240 --> 00:03:05,960
seek to seek是只用了

81
00:03:06,000 --> 00:03:07,599
最后词输出的东西

82
00:03:08,040 --> 00:03:09,360
然后他根据这个东西

83
00:03:09,360 --> 00:03:11,120
直接去往下走

84
00:03:11,400 --> 00:03:14,240
所以他看不到前面那些词输

85
00:03:14,280 --> 00:03:15,719
当然你可以说我前面那些词

86
00:03:15,719 --> 00:03:16,599
已经在里面了

87
00:03:16,960 --> 00:03:19,200
但是因为你

88
00:03:20,080 --> 00:03:22,040
那就是假设你已经存了很多东西

89
00:03:22,040 --> 00:03:23,000
但是你要从这里

90
00:03:23,000 --> 00:03:24,640
还原出你的位置的信息

91
00:03:25,600 --> 00:03:27,200
所以这里的动机是说

92
00:03:27,320 --> 00:03:31,880
我想要去在翻译对应的词的时候

93
00:03:31,880 --> 00:03:33,360
去让我的注意力

94
00:03:33,360 --> 00:03:36,240
关注在原句子中对应的部分

95
00:03:36,280 --> 00:03:37,560
这个就是说

96
00:03:37,560 --> 00:03:38,680
把注意力机制

97
00:03:38,720 --> 00:03:41,720
放在里面的一个动机

98
00:03:43,240 --> 00:03:43,600
好

99
00:03:43,600 --> 00:03:44,880
具体看一下怎么做的

100
00:03:47,400 --> 00:03:48,000
具体看一下

101
00:03:48,199 --> 00:03:50,759
就是说大体上来说是什么意思

102
00:03:52,439 --> 00:03:55,120
我在做

103
00:03:56,199 --> 00:03:58,159
我在在解码器

104
00:03:58,439 --> 00:04:00,759
解码器的RN的输入的时候

105
00:04:01,879 --> 00:04:03,719
一块当时来自embedding

106
00:04:03,719 --> 00:04:06,000
另外一块当时还说前面的RN

107
00:04:06,000 --> 00:04:08,439
它的state还是做了

108
00:04:08,599 --> 00:04:09,920
但是context

109
00:04:10,120 --> 00:04:11,159
就是上下文

110
00:04:11,439 --> 00:04:12,159
记不记得

111
00:04:12,159 --> 00:04:13,360
在seek to seek里面

112
00:04:13,400 --> 00:04:15,120
我的上下文就是

113
00:04:15,240 --> 00:04:16,639
RN的

114
00:04:16,920 --> 00:04:18,879
最后一个时刻的

115
00:04:18,920 --> 00:04:20,120
最后一层的输出

116
00:04:20,120 --> 00:04:21,199
作为上下文

117
00:04:21,680 --> 00:04:24,600
跟embedding并在一起传进去了

118
00:04:25,759 --> 00:04:26,720
现在说

119
00:04:27,240 --> 00:04:29,720
用最后一个时刻

120
00:04:29,879 --> 00:04:30,759
作为上下文

121
00:04:30,759 --> 00:04:33,199
作为context传进去不好

122
00:04:33,240 --> 00:04:34,280
我应该是说

123
00:04:34,280 --> 00:04:35,519
根据我的

124
00:04:35,560 --> 00:04:37,639
现在预测值的不一样

125
00:04:37,639 --> 00:04:38,600
去选择

126
00:04:38,600 --> 00:04:39,639
而不是最后

127
00:04:39,639 --> 00:04:41,600
可是可能是前面几个时刻

128
00:04:41,600 --> 00:04:43,879
它对应的那些隐藏传的

129
00:04:43,879 --> 00:04:46,120
隐藏的状态作为输入

130
00:04:46,319 --> 00:04:46,639
就是说

131
00:04:46,639 --> 00:04:48,319
比如说我在翻译第一个的时候

132
00:04:48,439 --> 00:04:49,120
翻译就是说

133
00:04:49,879 --> 00:04:50,480
hello的

134
00:04:50,480 --> 00:04:52,079
就是法语的第一个词的时候

135
00:04:52,079 --> 00:04:54,759
我不应该去把RN

136
00:04:54,759 --> 00:04:55,519
最后个时刻

137
00:04:55,519 --> 00:04:56,480
也就是句号

138
00:04:56,480 --> 00:04:57,839
它对应的state

139
00:04:57,959 --> 00:04:59,560
传到这一来

140
00:04:59,719 --> 00:05:00,800
而是

141
00:05:01,279 --> 00:05:01,920
把前面

142
00:05:01,920 --> 00:05:02,839
我就回到前面的图

143
00:05:03,120 --> 00:05:03,879
就是说

144
00:05:04,439 --> 00:05:06,040
在做它的预测的时候

145
00:05:06,800 --> 00:05:09,240
context信息不应该是用它

146
00:05:09,439 --> 00:05:11,519
而是应该用它

147
00:05:11,560 --> 00:05:12,199
对吧

148
00:05:12,279 --> 00:05:13,240
用它这个词

149
00:05:13,240 --> 00:05:15,079
对应的隐藏状态

150
00:05:15,079 --> 00:05:16,199
就最后它的输出

151
00:05:16,360 --> 00:05:17,879
就是说它的RN的输出

152
00:05:17,920 --> 00:05:19,800
用它作为你的context

153
00:05:19,920 --> 00:05:21,719
加上这个东西的embedding

154
00:05:21,759 --> 00:05:23,199
然后把这两个东西的合并

155
00:05:23,199 --> 00:05:23,959
全放进来

156
00:05:24,599 --> 00:05:26,079
在算它的时候

157
00:05:26,120 --> 00:05:27,759
你应该是去

158
00:05:28,079 --> 00:05:31,039
把word的RN的输出

159
00:05:31,360 --> 00:05:32,839
和你这个东西

160
00:05:32,839 --> 00:05:34,480
这个词的embedding的东西

161
00:05:34,480 --> 00:05:36,439
并且去做这个事情

162
00:05:37,360 --> 00:05:37,959
OK

163
00:05:37,959 --> 00:05:39,399
So attention就是说

164
00:05:39,439 --> 00:05:41,399
多多少少允许你干这个事情

165
00:05:41,680 --> 00:05:42,280
它怎么做

166
00:05:42,720 --> 00:05:43,520
就是说

167
00:05:43,520 --> 00:05:45,560
它把编码器

168
00:05:46,680 --> 00:05:49,040
对每个词的输出

169
00:05:49,040 --> 00:05:50,600
作为key和value

170
00:05:50,600 --> 00:05:52,240
就key和value是一个东西

171
00:05:52,600 --> 00:05:53,280
就是说

172
00:05:53,280 --> 00:05:55,960
假设你的编码器

173
00:05:55,960 --> 00:05:56,200
就是说

174
00:05:56,200 --> 00:05:58,320
你的英语句是成为3的话

175
00:05:58,640 --> 00:06:01,320
那么你就会有三个key value pair

176
00:06:02,320 --> 00:06:04,560
这个key和value是一个东西

177
00:06:04,640 --> 00:06:05,800
它是等价的

178
00:06:06,320 --> 00:06:07,840
然后它是什么

179
00:06:08,160 --> 00:06:10,680
它就是你第i个词

180
00:06:10,680 --> 00:06:12,680
它的RN的输出

181
00:06:14,000 --> 00:06:14,639
OK

182
00:06:16,160 --> 00:06:17,720
所以之前我们seq2seq

183
00:06:17,720 --> 00:06:18,160
是用的

184
00:06:18,160 --> 00:06:19,720
只用了最后key

185
00:06:20,079 --> 00:06:21,000
最后key value

186
00:06:21,079 --> 00:06:21,840
现在我们用的是

187
00:06:21,840 --> 00:06:23,439
把所有东西都拿过来

188
00:06:23,840 --> 00:06:25,639
他们作为key value

189
00:06:26,960 --> 00:06:28,560
放进了tension里面

190
00:06:30,360 --> 00:06:31,199
Query是什么

191
00:06:32,759 --> 00:06:35,280
Query是RNN

192
00:06:35,280 --> 00:06:36,199
在这个东西

193
00:06:36,199 --> 00:06:37,920
解码器的RN

194
00:06:38,520 --> 00:06:41,680
在对上一个词的预测

195
00:06:41,680 --> 00:06:42,280
作为输入

196
00:06:42,280 --> 00:06:43,040
做query

197
00:06:43,680 --> 00:06:44,319
就是说

198
00:06:44,319 --> 00:06:44,840
就说白了

199
00:06:44,840 --> 00:06:45,360
就告诉你说

200
00:06:45,560 --> 00:06:46,120
OK

201
00:06:46,120 --> 00:06:47,720
现在我要开始翻译

202
00:06:47,720 --> 00:06:49,400
我现在我的词是

203
00:06:53,680 --> 00:06:54,120
OK

204
00:06:54,120 --> 00:06:57,759
现在我要我拿进来的词是

205
00:07:02,759 --> 00:07:03,280
怎么说

206
00:07:03,360 --> 00:07:04,840
就是说

207
00:07:04,840 --> 00:07:08,240
上一次我的预测是

208
00:07:08,240 --> 00:07:09,640
比如说hello的话

209
00:07:10,080 --> 00:07:11,720
那么接下来就是说

210
00:07:11,720 --> 00:07:14,040
我要去找说

211
00:07:14,040 --> 00:07:15,280
我要翻译下一个词了

212
00:07:15,280 --> 00:07:16,960
我说作为现在我看到是这个词

213
00:07:16,960 --> 00:07:18,120
我接下来是下一个词

214
00:07:18,120 --> 00:07:20,080
就是说用这个词去

215
00:07:20,120 --> 00:07:21,720
在里面去查说

216
00:07:21,720 --> 00:07:24,120
他应该去找到

217
00:07:24,120 --> 00:07:27,280
他应该去找到hello的英语的词

218
00:07:27,280 --> 00:07:28,200
然后把附近的

219
00:07:28,480 --> 00:07:29,440
我知道我要翻这个词

220
00:07:29,440 --> 00:07:31,240
我把附近那些东西给你圈出来

221
00:07:32,280 --> 00:07:32,840
OK

222
00:07:32,840 --> 00:07:34,000
所以他其实干这个事情

223
00:07:34,000 --> 00:07:34,720
因为但是你

224
00:07:34,720 --> 00:07:35,279
你

225
00:07:35,480 --> 00:07:37,079
当然你虽然我要翻

226
00:07:37,079 --> 00:07:38,319
我要去

227
00:07:38,639 --> 00:07:41,040
预测你hello world

228
00:07:41,040 --> 00:07:41,680
那个world的时候

229
00:07:41,680 --> 00:07:43,360
我当时最好是我能拿到world

230
00:07:43,360 --> 00:07:43,959
那个embedded

231
00:07:43,959 --> 00:07:44,399
然后去

232
00:07:44,399 --> 00:07:45,800
但是你world还没预测出来

233
00:07:45,800 --> 00:07:46,079
对吧

234
00:07:46,079 --> 00:07:46,839
所以你没办法

235
00:07:46,839 --> 00:07:48,399
你只能拿到上一个词

236
00:07:48,480 --> 00:07:51,680
就是说你对这个东西的输出作为

237
00:07:51,680 --> 00:07:52,920
输出作为query

238
00:07:53,120 --> 00:07:54,920
去跟在里面去match

239
00:07:55,279 --> 00:07:56,319
为什么你是输出

240
00:07:56,480 --> 00:07:57,279
是因为

241
00:07:57,759 --> 00:07:59,759
你可以假设RNN的输出

242
00:07:59,759 --> 00:08:02,199
它都是在同一个语义空间里面

243
00:08:02,399 --> 00:08:03,920
所以你需要用它输出

244
00:08:03,920 --> 00:08:05,520
你不能用inviting的输入

245
00:08:05,520 --> 00:08:06,840
因为你可以认为

246
00:08:06,840 --> 00:08:07,960
因为你的key value

247
00:08:07,960 --> 00:08:09,240
也是RNN的输出

248
00:08:09,240 --> 00:08:12,600
所以你key和query做匹配的时候

249
00:08:12,879 --> 00:08:15,199
你最好也是用同样一个RNN的输出

250
00:08:15,199 --> 00:08:15,520
这样子

251
00:08:15,520 --> 00:08:17,680
它在一个差不多在一个语义空间里面

252
00:08:17,680 --> 00:08:18,600
这样比较好

253
00:08:19,720 --> 00:08:20,920
然后这样子的话

254
00:08:21,080 --> 00:08:22,240
然后这样子就拿到

255
00:08:22,240 --> 00:08:23,360
就上一个时刻的输出

256
00:08:24,160 --> 00:08:25,360
做完这个之后

257
00:08:25,360 --> 00:08:27,400
就会得到这一个

258
00:08:27,400 --> 00:08:28,240
Rotation to us

259
00:08:28,240 --> 00:08:31,120
成为这个时刻的输入进放进来

260
00:08:31,840 --> 00:08:32,240
OK

261
00:08:32,240 --> 00:08:34,919
就替代了我们在seq to seq

262
00:08:34,919 --> 00:08:36,600
用的context variable

263
00:08:37,440 --> 00:08:37,840
OK

264
00:08:37,840 --> 00:08:38,840
这就是说

265
00:08:38,960 --> 00:08:43,120
在把attention放到seq to seq里面

266
00:08:43,159 --> 00:08:46,080
它的道理是key value和query是什么

267
00:08:46,480 --> 00:08:48,320
key value就是在编码器

268
00:08:48,320 --> 00:08:50,639
对每一个词的RNN的输出

269
00:08:51,360 --> 00:08:53,440
query就是你的解码器

270
00:08:53,440 --> 00:08:55,759
对上一个词的预测输出

271
00:08:56,720 --> 00:08:57,240
OK

272
00:08:57,360 --> 00:08:59,200
然后这样子它的value

273
00:08:59,320 --> 00:09:02,640
就是会作为一个叫做上下文的

274
00:09:02,640 --> 00:09:04,920
那个向量和你的输入

275
00:09:04,920 --> 00:09:05,680
embedded输入

276
00:09:05,680 --> 00:09:07,360
合并起来进入的RNN

277
00:09:08,480 --> 00:09:10,600
所以它对于我们之前seq to seq的

278
00:09:10,600 --> 00:09:11,480
改进是说

279
00:09:11,520 --> 00:09:12,400
之前seq to seq

280
00:09:12,400 --> 00:09:13,400
永远是这个地方

281
00:09:13,520 --> 00:09:16,440
永远是上一个RNN里面

282
00:09:16,440 --> 00:09:18,120
最后那一个词的输出

283
00:09:18,160 --> 00:09:19,480
现在我允许说

284
00:09:19,480 --> 00:09:20,800
我现在把所有的词拿出来

285
00:09:20,800 --> 00:09:22,320
然后对它做一个weight

286
00:09:22,320 --> 00:09:23,800
做一个加全的平均

287
00:09:23,840 --> 00:09:25,320
然后根据你翻的词不同

288
00:09:25,320 --> 00:09:28,040
可能一开始我用前面的那些输出

289
00:09:28,039 --> 00:09:29,079
会到越到后面

290
00:09:29,079 --> 00:09:30,919
用后面那些词的输出

291
00:09:31,599 --> 00:09:32,120
OK

292
00:09:32,120 --> 00:09:33,159
所以这就是

293
00:09:34,759 --> 00:09:35,480
比较简单

294
00:09:35,759 --> 00:09:36,360
对吧

295
00:09:36,399 --> 00:09:37,039
就讲通了

296
00:09:37,039 --> 00:09:39,439
你还是比较好理解的

297
00:09:40,399 --> 00:09:41,360
总结一下

298
00:09:42,360 --> 00:09:45,159
seq to seq是通过说隐藏状态

299
00:09:45,159 --> 00:09:46,399
当然是可以传递信息的

300
00:09:46,559 --> 00:09:49,159
另外一个是一个上下文的向量

301
00:09:49,279 --> 00:09:52,759
用最后一个时刻的编码器

302
00:09:52,759 --> 00:09:54,480
最后一个时刻的隐藏状态

303
00:09:54,480 --> 00:09:55,879
作为上下文传入

304
00:09:56,000 --> 00:09:57,360
但是注意力机制

305
00:09:57,360 --> 00:09:59,639
可以根据编码器RNN的输出

306
00:10:01,120 --> 00:10:02,519
解码器RNN的输出

307
00:10:02,519 --> 00:10:03,720
来匹配到

308
00:10:03,720 --> 00:10:06,120
合适的编码器RNN的输出

309
00:10:06,120 --> 00:10:07,480
使得能够

310
00:10:07,680 --> 00:10:09,960
不仅仅是只能去

311
00:10:09,960 --> 00:10:11,440
真的把前面那些东西

312
00:10:12,360 --> 00:10:13,879
更有效的传递信息

