1
00:00:00,000 --> 00:00:16,000
导数的作用主要是进行梯度下降,但容易陷入局部最优解。请问是不是可以通过Leopold函数或者其他方法来使得下降得到全局最优解?

2
00:00:16,000 --> 00:00:29,000
这个问题就是说,如果你是突函数的话,你可以拿到最优解,如果你不是突函数的话,其实你不管用谁函,几乎是拿不到最优解的。

3
00:00:29,000 --> 00:00:35,000
当然理论上数学是可以,但是从计算上来说,几乎是拿不到最优解的。

4
00:00:35,000 --> 00:00:40,000
这个真的是一个不幸的消息。

5
00:00:40,000 --> 00:00:50,000
而且机器学习几乎是不会处理突函数,就是说,如果你这个问题能得到最优解的话,那就是一个P的问题。

6
00:00:50,000 --> 00:00:54,000
我们机器学习不关心P问题,我们只关心NP的问题。

7
00:00:54,000 --> 00:00:57,000
所以大家不要去纠结最优解这个事情。

8
00:00:57,000 --> 00:01:02,000
一个向量的单位向量对其自身求导是多少?

9
00:01:02,000 --> 00:01:17,000
其实我不是看得懂这个计法是什么样子,就是说,你它除以它自己,然后OK,它X除以X,然后,但我们这里不展开了,好不好?

10
00:01:17,000 --> 00:01:21,000
我们可以,我可以offline跟大家算一下这个会长什么样子。

11
00:01:21,000 --> 00:01:27,000
我们现在不好,没有白板,我们不好写这个东西。

12
00:01:27,000 --> 00:01:38,000
PyTorch和M3的区采用的是自动微分和计算图,对的,我们马上就会讲自动微分和计算图,就是说,不会让你自己去求导。

13
00:01:38,000 --> 00:01:47,000
但是呢,就是说,这是基础数学,我希望大家能够知道导数大概是怎么算的,至少你的形状能够搞清楚。

14
00:01:47,000 --> 00:01:57,000
就是说,你不需要知道整个是算是怎么算出来的,但是你能大概理解导数的形状跟你的input的形状是怎么样一个变化的关系,我觉得这个比较重要。

