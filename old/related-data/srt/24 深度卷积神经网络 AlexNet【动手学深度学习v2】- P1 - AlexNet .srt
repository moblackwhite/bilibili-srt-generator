1
00:00:00,000 --> 00:00:00,600
好

2
00:00:00,600 --> 00:00:03,320
我们今天先来讲AlexNet

3
00:00:04,719 --> 00:00:08,120
AlexNet真的是引起了整个这一次

4
00:00:08,120 --> 00:00:10,240
深度学习热潮的第一个网络

5
00:00:10,240 --> 00:00:15,679
这个是2012年的左右的时候的一个网络

6
00:00:15,679 --> 00:00:21,559
真的是从它开始到今天一直是深度学习

7
00:00:21,559 --> 00:00:24,879
不断的一个火热的一个状态

8
00:00:24,920 --> 00:00:27,719
所以我们今天先来讲一讲网络是怎么样子的

9
00:00:30,000 --> 00:00:35,920
首先我们来看一下

10
00:00:35,960 --> 00:00:39,200
就是深度学习之前的网络是长什么样子的

11
00:00:40,399 --> 00:00:45,480
在2000年的时候

12
00:00:45,679 --> 00:00:49,679
最火的积极学习模型其实是何方法

13
00:00:50,359 --> 00:00:52,359
这个是2010年出版

14
00:00:52,359 --> 00:00:55,320
2001年出版的Lenny with kernels这本书

15
00:00:56,119 --> 00:01:01,000
这个是积极学习在2000年初期的时候

16
00:01:01,000 --> 00:01:02,480
最主流的一个算法

17
00:01:02,719 --> 00:01:06,840
它的核心是说你首先提取我的特征

18
00:01:07,000 --> 00:01:10,319
就是我们在之前有讲过怎么特征提取

19
00:01:10,680 --> 00:01:12,599
然后这里有一个关键是说

20
00:01:12,599 --> 00:01:16,200
你用何函数来计算相关性

21
00:01:16,560 --> 00:01:20,240
也就是说我怎么判断在高维空间里面

22
00:01:20,240 --> 00:01:22,079
两个点是如何相关的

23
00:01:22,480 --> 00:01:23,799
当然是线性模型的话

24
00:01:23,799 --> 00:01:24,960
你就是做了一机了

25
00:01:25,120 --> 00:01:26,560
如果你用何方法的话

26
00:01:26,560 --> 00:01:28,920
你可以通过变换空间

27
00:01:28,920 --> 00:01:31,080
把空间拉成我们想要的样子

28
00:01:32,320 --> 00:01:35,760
然后通过何函数计算了之后

29
00:01:35,760 --> 00:01:37,680
你就会变成一个突厥化问题

30
00:01:37,720 --> 00:01:39,400
这是convex的问题

31
00:01:39,560 --> 00:01:43,280
我们比如说线性模型是一个突厥化问题

32
00:01:43,320 --> 00:01:46,880
所以它有很好的理论解

33
00:01:47,240 --> 00:01:49,160
你可以把闲事解写出来

34
00:01:49,320 --> 00:01:50,440
因为是突厥化

35
00:01:50,440 --> 00:01:52,120
所以你有比较好的定理

36
00:01:52,480 --> 00:01:56,160
整个何方法它最大的一个特色

37
00:01:56,160 --> 00:02:00,640
就是它有一套完整的泛函那边过来的数学定理

38
00:02:00,719 --> 00:02:03,600
能够计算它的模型的复杂度

39
00:02:03,640 --> 00:02:05,719
然后能计算在什么样的情况下

40
00:02:05,719 --> 00:02:06,960
会发生什么样的事情

41
00:02:07,680 --> 00:02:09,800
这是它最大的优美的地方

42
00:02:09,960 --> 00:02:14,319
也就是在2000年的时候

43
00:02:14,319 --> 00:02:18,840
为什么何方法能够替代掉深度学习

44
00:02:18,960 --> 00:02:20,480
那个时候还不叫深度学习

45
00:02:20,599 --> 00:02:22,519
就是替代掉神经网络

46
00:02:22,560 --> 00:02:26,399
成为当时候积极学习主流的一个网络

47
00:02:26,399 --> 00:02:28,039
也就是那时候发生的

48
00:02:28,120 --> 00:02:29,719
当然是2000年之后

49
00:02:29,719 --> 00:02:33,239
比如说在2006年的时候

50
00:02:33,239 --> 00:02:34,639
整个突优化

51
00:02:34,639 --> 00:02:36,280
整个优化问题的纠结

52
00:02:36,280 --> 00:02:39,919
也是整个积极学习最热门的一个方向

53
00:02:40,120 --> 00:02:43,120
但之后说我们在做各种政策上面

54
00:02:43,759 --> 00:02:44,959
直到2000

55
00:02:45,000 --> 00:02:48,599
2010年左右以后

56
00:02:48,599 --> 00:02:50,319
我们深度学习才开始起来

57
00:02:50,799 --> 00:02:52,799
这个是深度学习之前

58
00:02:52,799 --> 00:02:54,719
最为流行的一个积极学习算法

59
00:02:54,759 --> 00:02:58,919
当然我们说现在SVM还是被很广泛使用

60
00:02:58,919 --> 00:03:00,319
因为它不需要调参

61
00:03:00,399 --> 00:03:02,239
它也不是不需要调参

62
00:03:02,239 --> 00:03:04,039
它对调参确实不那么敏感

63
00:03:04,280 --> 00:03:09,000
所以通常来说大家闭着眼睛可以用SVM

64
00:03:09,000 --> 00:03:10,039
一点问题都没有

65
00:03:11,679 --> 00:03:12,879
另外一块就是说

66
00:03:12,879 --> 00:03:16,319
我们一直讲的是卷积神经网络

67
00:03:16,439 --> 00:03:17,560
卷积神经网络

68
00:03:17,560 --> 00:03:19,359
通常特别是2D的卷积

69
00:03:19,520 --> 00:03:21,480
通常是用在图片上面

70
00:03:21,600 --> 00:03:24,480
所谓的图片就是计算机视觉

71
00:03:25,360 --> 00:03:27,040
在2000年的时候

72
00:03:27,320 --> 00:03:28,960
计算机视觉关心的

73
00:03:28,960 --> 00:03:31,760
其实是从几何学那边过来

74
00:03:32,040 --> 00:03:33,680
这也是一本很经典的书

75
00:03:33,800 --> 00:03:35,840
Multiview Geometry

76
00:03:36,640 --> 00:03:38,280
在计算机世界上的应用

77
00:03:38,600 --> 00:03:40,160
他的核心思想是说

78
00:03:40,160 --> 00:03:42,880
我首先当然是这样做特征抽取

79
00:03:43,160 --> 00:03:45,160
然后比较核心的是说

80
00:03:45,160 --> 00:03:47,480
我想把整个几何问题

81
00:03:47,840 --> 00:03:49,360
整个计算机视觉问题

82
00:03:49,360 --> 00:03:51,360
描述成一个几何的问题

83
00:03:51,880 --> 00:03:54,280
比如说我有三个相机放在这里

84
00:03:54,640 --> 00:03:56,360
然后我可以通过相机的位置

85
00:03:56,360 --> 00:03:58,960
去缓况3D这样子的情况

86
00:04:00,040 --> 00:04:03,760
然后当然你有比较好的几何模型的话

87
00:04:03,760 --> 00:04:07,400
我可以建立图优化的一个目标函数

88
00:04:07,560 --> 00:04:09,480
或者当然你有可能是非图的了

89
00:04:10,560 --> 00:04:13,200
这里另外因为你用了图优化

90
00:04:13,200 --> 00:04:15,680
所以它确实有很漂亮的定义

91
00:04:15,800 --> 00:04:18,920
或者是说一些特殊的非图优化的情况

92
00:04:18,920 --> 00:04:20,720
它也有非常漂亮的定义

93
00:04:21,199 --> 00:04:23,000
它的最好的情况是说

94
00:04:23,000 --> 00:04:25,519
假设我因为我是一个几何模型

95
00:04:25,560 --> 00:04:28,040
假设我的假设被满足了

96
00:04:28,040 --> 00:04:29,920
确实是满足我的假设

97
00:04:29,920 --> 00:04:32,000
那我的效果会非常好

98
00:04:33,040 --> 00:04:35,240
就是我对这个世界做了一个比较简单的

99
00:04:35,240 --> 00:04:36,680
一个物理模型的假设

100
00:04:36,879 --> 00:04:39,480
一旦真的符合我这个物理模型

101
00:04:39,519 --> 00:04:40,639
我的效果会很好

102
00:04:41,360 --> 00:04:44,879
这也是现在很多学科

103
00:04:44,920 --> 00:04:46,079
他现在做的事情

104
00:04:46,079 --> 00:04:48,360
比如说当然我们说计算机

105
00:04:48,360 --> 00:04:53,240
视觉在20年前是做了一个比较好的物理上的

106
00:04:53,240 --> 00:04:53,800
假设

107
00:04:53,800 --> 00:04:54,719
但反过来讲

108
00:04:54,719 --> 00:04:57,000
就算现在有很多资领域

109
00:04:57,000 --> 00:04:59,040
比如说地球科学

110
00:04:59,439 --> 00:05:01,279
就是说气象预测

111
00:05:01,319 --> 00:05:04,360
气象预测还一样的是做了很多的物理

112
00:05:04,360 --> 00:05:04,959
假设

113
00:05:05,000 --> 00:05:09,159
也是最近在今年大家发现深度学习

114
00:05:09,199 --> 00:05:13,319
能够比这些做物理假设的模型效果更好

115
00:05:14,199 --> 00:05:15,079
这也是说

116
00:05:15,079 --> 00:05:18,599
当然10年前已经在计算机

117
00:05:18,599 --> 00:05:20,719
视觉上验证了它的效果

118
00:05:20,759 --> 00:05:23,439
在现在慢慢的在别的一些领域

119
00:05:23,480 --> 00:05:25,279
还要基于物理假设

120
00:05:25,279 --> 00:05:28,480
比如说药物的那些研究

121
00:05:28,519 --> 00:05:30,360
材料学

122
00:05:30,399 --> 00:05:32,839
当然是说地球学很多领域

123
00:05:32,839 --> 00:05:34,959
它是基于它的先验知识的模型

124
00:05:35,000 --> 00:05:37,959
深度学习在这里面也在慢慢的取得效果

125
00:05:38,959 --> 00:05:45,199
在10年前或者说15年前

126
00:05:45,239 --> 00:05:47,279
其实在计算机视觉里面

127
00:05:47,319 --> 00:05:49,359
最重要的是特征工程

128
00:05:49,959 --> 00:05:52,479
就是对你一张图片怎么抽取特征

129
00:05:53,039 --> 00:05:56,439
我们之前是直接把图片的原始的

130
00:05:56,439 --> 00:05:59,279
那一些像素信息拉进我们的模型

131
00:05:59,439 --> 00:06:00,599
但实际上来说

132
00:06:00,599 --> 00:06:03,159
假设你用的是比如说SVM的模型的话

133
00:06:03,199 --> 00:06:05,039
你直接把原始的像素拉进去

134
00:06:05,039 --> 00:06:06,560
效果会非常的差

135
00:06:07,560 --> 00:06:09,360
所以在过去的很多年

136
00:06:09,720 --> 00:06:11,680
计算机视觉的研究者

137
00:06:11,720 --> 00:06:13,319
提出了非常多的

138
00:06:13,319 --> 00:06:16,639
怎么样到图片抽取特征的一些算法

139
00:06:16,800 --> 00:06:19,199
比如说最有名的是SIFT的模型

140
00:06:19,840 --> 00:06:22,720
就是说他去看里面各个方向

141
00:06:22,840 --> 00:06:26,240
各个抽取一些这样子的一个小项量

142
00:06:26,240 --> 00:06:27,560
来描述图片

143
00:06:27,840 --> 00:06:30,040
如果你的特征工程抽的比较好的话

144
00:06:30,040 --> 00:06:33,040
那么之后就是有一个很简单的

145
00:06:33,319 --> 00:06:34,639
多分类模型就行了

146
00:06:35,039 --> 00:06:36,560
你简单用SVM就行了

147
00:06:37,039 --> 00:06:40,719
当然所以整个计算机视觉

148
00:06:40,919 --> 00:06:42,959
在深度学习之前

149
00:06:43,000 --> 00:06:44,599
大家其实不那么关心

150
00:06:44,599 --> 00:06:46,519
你的机器学习的模型什么样子

151
00:06:46,599 --> 00:06:48,319
就是说你不管你是用SVM也好

152
00:06:48,319 --> 00:06:48,919
用别的也好

153
00:06:48,919 --> 00:06:50,120
其实都问题不大

154
00:06:50,479 --> 00:06:52,120
最关键的是说

155
00:06:52,159 --> 00:06:54,399
怎么样做特征提取

156
00:06:54,639 --> 00:06:55,759
就原始图片

157
00:06:55,879 --> 00:06:57,479
怎么样抽取特征

158
00:06:57,519 --> 00:07:00,360
使得我的机器学习比较好的去学习

159
00:07:01,120 --> 00:07:02,319
所以整个你可以认为

160
00:07:02,319 --> 00:07:03,639
整个计算机视觉

161
00:07:03,680 --> 00:07:06,240
在针对不一样

162
00:07:06,240 --> 00:07:07,240
不同的问题

163
00:07:07,240 --> 00:07:08,759
来抽取不一样的特征

164
00:07:11,399 --> 00:07:12,759
然后我们再来看一下

165
00:07:12,759 --> 00:07:15,599
就是说在过去几十年

166
00:07:15,599 --> 00:07:17,079
我们60年里面

167
00:07:17,159 --> 00:07:20,519
整个发展趋势是什么样子

168
00:07:20,599 --> 00:07:23,000
以及为什么深度学习能够崛起

169
00:07:24,039 --> 00:07:25,599
首先你看到是说

170
00:07:25,719 --> 00:07:27,839
我们每一列就是10年

171
00:07:27,839 --> 00:07:30,680
从1970年开始到2020年

172
00:07:31,319 --> 00:07:32,719
然后你有三行

173
00:07:33,200 --> 00:07:34,160
三行的话

174
00:07:34,160 --> 00:07:35,960
每一行就是

175
00:07:36,800 --> 00:07:40,240
第一行是你的样本的个数

176
00:07:41,120 --> 00:07:43,320
第二行是你的内存的大小

177
00:07:43,880 --> 00:07:46,160
第三行是你的CPU的能力

178
00:07:46,840 --> 00:07:48,440
就是说或者说你不是CPU

179
00:07:48,440 --> 00:07:49,920
就是你的计存单元的能力

180
00:07:51,320 --> 00:07:52,200
首先你看一下

181
00:07:52,200 --> 00:07:55,680
就是说在70年代的时候

182
00:07:55,680 --> 00:07:58,280
当然你的样本大概就100个的样子

183
00:07:58,720 --> 00:08:00,560
你的内存1KB

184
00:08:00,839 --> 00:08:02,920
然后你的CPU当然是很弱

185
00:08:02,920 --> 00:08:03,120
对

186
00:08:03,120 --> 00:08:04,680
可能大家都无法理解说

187
00:08:04,680 --> 00:08:06,519
当年是什么样的情况

188
00:08:06,879 --> 00:08:08,839
或者你回到90年代

189
00:08:09,000 --> 00:08:10,759
90年代也就是我们的

190
00:08:11,240 --> 00:08:13,639
昨天有讲过的Nernet的年代

191
00:08:14,000 --> 00:08:16,280
你可以看到是说我的样本是

192
00:08:17,600 --> 00:08:18,279
1万个吧

193
00:08:18,319 --> 00:08:19,800
1万个左右是比较好的

194
00:08:19,800 --> 00:08:21,759
就是M list的数据集

195
00:08:21,920 --> 00:08:23,319
我的内存是10兆

196
00:08:23,639 --> 00:08:25,079
所以这个内存其实是放不下

197
00:08:25,079 --> 00:08:26,040
我的数据集的

198
00:08:26,519 --> 00:08:27,840
然后我的CPU的话

199
00:08:27,840 --> 00:08:29,319
大概就是10

200
00:08:29,480 --> 00:08:31,759
每次每秒钟的运算1000万次

201
00:08:33,240 --> 00:08:34,759
就是说跟现在比

202
00:08:35,000 --> 00:08:36,639
其实是非常差的

203
00:08:36,639 --> 00:08:37,319
比较远的

204
00:08:37,960 --> 00:08:39,519
现在你看到是说

205
00:08:39,519 --> 00:08:41,720
我的数据现在可以很

206
00:08:42,159 --> 00:08:44,039
到一个11个亿的规模

207
00:08:44,039 --> 00:08:44,919
是可以到了

208
00:08:44,919 --> 00:08:46,120
因为比较假设说

209
00:08:46,120 --> 00:08:47,879
你是用比如说社交网络的话

210
00:08:47,879 --> 00:08:49,279
那就是你10个亿的人

211
00:08:49,840 --> 00:08:51,159
你的内存很容易

212
00:08:51,159 --> 00:08:53,159
就是好一点的机型是100G

213
00:08:54,080 --> 00:08:54,840
你CPU的话

214
00:08:55,039 --> 00:08:56,159
基本上你可以用

215
00:08:56,480 --> 00:08:58,439
我们不再用CPU来做计算

216
00:08:58,600 --> 00:09:00,880
我们是用比如说8个P3的

217
00:09:02,000 --> 00:09:03,760
就是Volta的GPU来做的话

218
00:09:03,760 --> 00:09:05,000
那就是一个P了

219
00:09:06,680 --> 00:09:07,800
所以可以看到是说

220
00:09:07,800 --> 00:09:09,760
你的数据在过去

221
00:09:09,760 --> 00:09:11,240
从1980年到现

222
00:09:11,440 --> 00:09:12,880
从1970年开始算

223
00:09:13,400 --> 00:09:14,200
算到现在的话

224
00:09:14,200 --> 00:09:16,240
你大概是一路这么增长下来

225
00:09:16,240 --> 00:09:19,480
大概是增长了1000次的样子

226
00:09:19,840 --> 00:09:20,640
1000倍的样子

227
00:09:22,400 --> 00:09:23,600
但你看你的计算

228
00:09:24,440 --> 00:09:26,000
所以你的计算这里说

229
00:09:26,000 --> 00:09:28,040
你就是在这一块

230
00:09:28,439 --> 00:09:29,199
在这个地方

231
00:09:30,079 --> 00:09:31,360
是有比较大的突破

232
00:09:31,360 --> 00:09:33,240
就在最近的10年里面

233
00:09:33,240 --> 00:09:35,839
因为GPU在这一块的兴起

234
00:09:35,839 --> 00:09:37,039
导致我的计算

235
00:09:37,039 --> 00:09:38,599
是比我的数据增加快了

236
00:09:38,599 --> 00:09:39,959
我的计算可以翻到了

237
00:09:39,959 --> 00:09:41,639
10万倍的样子

238
00:09:42,480 --> 00:09:44,480
就是说我的计算能力

239
00:09:44,480 --> 00:09:47,000
其实涨得比数据的涨得要快

240
00:09:48,480 --> 00:09:51,639
所以因为计算和数据的

241
00:09:52,519 --> 00:09:53,799
不一样的速率

242
00:09:53,799 --> 00:09:56,000
导致了我们很多模型的区别

243
00:09:56,000 --> 00:09:59,159
当你在90年代的时候

244
00:09:59,159 --> 00:10:00,480
90年代的时候

245
00:10:00,480 --> 00:10:02,120
当你数据也不够大

246
00:10:02,120 --> 00:10:06,000
然后你计算也还差比较均匀的时候

247
00:10:06,200 --> 00:10:08,039
大家其实是用神经网络的

248
00:10:08,799 --> 00:10:13,759
因为神经网络其实是一个比较便宜的

249
00:10:13,799 --> 00:10:16,759
相对来说比较便宜的一个框架

250
00:10:16,759 --> 00:10:18,159
因为它我们要知道

251
00:10:18,159 --> 00:10:19,000
卷积神经网络

252
00:10:19,000 --> 00:10:20,960
它的模型其实是比较小的

253
00:10:21,960 --> 00:10:23,759
虽然它的计算点比较大

254
00:10:23,759 --> 00:10:26,159
但是因为你用的是随机提速下降

255
00:10:26,200 --> 00:10:29,360
所以你的内存要求也不那么高

256
00:10:29,919 --> 00:10:33,840
所以你是也是能跑的

257
00:10:35,840 --> 00:10:39,639
当然到了2000年左右的时候

258
00:10:39,799 --> 00:10:41,799
你的内存其实还不错

259
00:10:41,799 --> 00:10:43,279
然后你的CPU也不错

260
00:10:43,279 --> 00:10:46,240
然后你的数据有增加

261
00:10:46,240 --> 00:10:48,319
但是也还是规模的情况下

262
00:10:48,360 --> 00:10:51,159
你核方法是比较合适的一个方法

263
00:10:51,159 --> 00:10:52,240
是因为一它简单

264
00:10:52,240 --> 00:10:53,240
二它有理论

265
00:10:53,240 --> 00:10:55,680
第三是我们能够跑它

266
00:10:55,960 --> 00:10:58,159
就是说核方法对这样子的数据集

267
00:10:58,159 --> 00:11:02,399
我能够真的能够把它的核矩阵给你算出来

268
00:11:02,600 --> 00:11:06,000
然后也是在这样子的计算量下是比较好的

269
00:11:07,360 --> 00:11:10,360
但现在来说我们又回到了神经网络

270
00:11:10,399 --> 00:11:13,000
是因为我的计算量更多了

271
00:11:13,039 --> 00:11:16,360
我可以构造更加深的一些网络

272
00:11:17,560 --> 00:11:20,000
就是说虽然我的数据涨的没那么快

273
00:11:20,039 --> 00:11:22,680
但是我的计算量已经比以前翻的

274
00:11:22,680 --> 00:11:24,280
比数据涨是要快的话

275
00:11:24,320 --> 00:11:27,560
那么我可以去更多的去挖掘

276
00:11:27,560 --> 00:11:28,920
我数据里面的信息

277
00:11:29,360 --> 00:11:32,720
也就是说我去构造更加深的神经网络

278
00:11:32,720 --> 00:11:34,960
用计算来换取我的精度

279
00:11:35,400 --> 00:11:41,680
所以就是说可以认为是数据和你的硬件

280
00:11:41,680 --> 00:11:44,160
他们之间的就计算能力和你的数据

281
00:11:44,160 --> 00:11:45,440
所要的算法能力

282
00:11:45,480 --> 00:11:48,760
他们之间的不同阶段的

283
00:11:48,760 --> 00:11:50,920
它的一个发展的程度

284
00:11:50,919 --> 00:11:53,000
导致大家对网络的选取

285
00:11:53,000 --> 00:11:55,000
是有自己的个偏好的

286
00:11:55,879 --> 00:11:59,719
所以说不定再过10年

287
00:11:59,719 --> 00:12:01,240
何方法这一块又兴起了

288
00:12:01,240 --> 00:12:02,399
或者有新的网络兴起

289
00:12:02,399 --> 00:12:03,559
这是不知道的

290
00:12:03,719 --> 00:12:05,519
但是反正历史就是这样子

291
00:12:05,559 --> 00:12:08,719
就是因为你跟每个不同主因的

292
00:12:08,719 --> 00:12:09,879
不同的发展

293
00:12:09,919 --> 00:12:13,639
导致说你在流行的方法上

294
00:12:13,639 --> 00:12:14,959
大家主流用的方法上

295
00:12:14,959 --> 00:12:16,399
会有不一样的地方在那里

296
00:12:17,519 --> 00:12:20,079
所以现在我们是处于神经网络的第一

297
00:12:20,080 --> 00:12:22,080
差不多是第一个10年快要结束

298
00:12:22,080 --> 00:12:24,920
当年第一个神经网络

299
00:12:24,920 --> 00:12:27,240
也就是持续了10年20年

300
00:12:27,440 --> 00:12:30,879
然后在80 90年代的末期的时候

301
00:12:30,879 --> 00:12:34,560
大家也去专门去造各种芯片

302
00:12:34,560 --> 00:12:37,879
就是当时候我们用的是

303
00:12:37,920 --> 00:12:39,440
当时候最好的一个芯片

304
00:12:39,560 --> 00:12:40,800
就是一个vector machine

305
00:12:40,800 --> 00:12:42,200
我都忘了它叫什么名字了

306
00:12:42,200 --> 00:12:43,520
这个公司可能已经

307
00:12:43,560 --> 00:12:45,879
应该是DC那个公司的芯片

308
00:12:46,080 --> 00:12:49,160
然后当时候勒昆他们真的去做了很多

309
00:12:50,159 --> 00:12:52,559
芯片来去跑卷进神经网络

310
00:12:52,600 --> 00:12:54,240
现在大家也是一样的

311
00:12:54,240 --> 00:12:55,919
我们去造大量的芯片

312
00:12:55,919 --> 00:12:57,639
在手机里面跑神经网络

313
00:12:57,639 --> 00:12:59,559
在服务器端跑

314
00:13:00,199 --> 00:13:03,279
就是说但是你无法预测说过了这一段

315
00:13:03,279 --> 00:13:04,959
会不会有新的模型出来

316
00:13:05,399 --> 00:13:07,639
使得我们CPU又能跑了

317
00:13:07,719 --> 00:13:08,600
说不定

318
00:13:09,159 --> 00:13:09,559
OK

319
00:13:09,559 --> 00:13:13,799
这就是我们可以简单的把不同的

320
00:13:13,839 --> 00:13:16,240
种类的模型的兴起

321
00:13:16,240 --> 00:13:18,600
和你的数据大小和硬件的计算能力

322
00:13:18,600 --> 00:13:20,320
他们之间做一些关联

323
00:13:22,800 --> 00:13:23,440
OK

324
00:13:23,480 --> 00:13:24,480
所以我们来看一下

325
00:13:24,600 --> 00:13:25,240
数据

326
00:13:25,240 --> 00:13:27,240
首先数据是非常重要的一个事情

327
00:13:28,560 --> 00:13:32,159
就是说这次深度神经网络冷起来

328
00:13:32,159 --> 00:13:35,200
数据首先是起到一个非常大的作用

329
00:13:35,519 --> 00:13:38,120
这里我们不得不提到一个数据集

330
00:13:38,120 --> 00:13:39,279
叫做ImageNet

331
00:13:40,240 --> 00:13:43,000
ImageNet是一个2010年时候做的事情

332
00:13:43,160 --> 00:13:45,960
就是李飞飞老师在斯坦福

333
00:13:45,960 --> 00:13:52,519
跟Princeton的李凯老师

334
00:13:52,560 --> 00:13:54,240
他们合作做了一个数据集

335
00:13:54,960 --> 00:13:57,560
就是说他还是要做一个物体分类的

336
00:13:57,560 --> 00:14:00,360
一个任务

337
00:14:01,440 --> 00:14:05,160
但是他跟当年我们之前有讲过

338
00:14:05,160 --> 00:14:06,600
M list的比的话

339
00:14:06,600 --> 00:14:08,600
你可以看到他是有比较大的区别的

340
00:14:09,080 --> 00:14:10,720
首先图片上来说

341
00:14:10,759 --> 00:14:14,680
他不再是做简单的黑白数字的手写识别了

342
00:14:14,840 --> 00:14:18,040
他是做一个自然物体的彩色图片

343
00:14:18,960 --> 00:14:20,800
他图片是相对来说比较大的

344
00:14:20,840 --> 00:14:23,280
当时候基本上是Google下载图片

345
00:14:23,360 --> 00:14:25,440
所以它的平均大小是

346
00:14:25,600 --> 00:14:27,800
宽是469个像素

347
00:14:27,840 --> 00:14:29,680
高是387个像素

348
00:14:30,960 --> 00:14:32,120
另外一个主要的区别是

349
00:14:32,120 --> 00:14:33,760
它的样本数是比较大的

350
00:14:33,760 --> 00:14:35,360
它有120万个样本

351
00:14:35,680 --> 00:14:37,920
但是说整个ImageNet是比较大的

352
00:14:37,920 --> 00:14:40,120
它是有1000个万个样本

353
00:14:40,160 --> 00:14:42,360
但是用来做竞赛的数据集

354
00:14:42,440 --> 00:14:45,320
它是采取了其中的1000个类

355
00:14:46,120 --> 00:14:46,960
就是1000个类

356
00:14:46,960 --> 00:14:51,240
然后每个类保证应该是至少有5000张照片

357
00:14:51,519 --> 00:14:56,399
所以导致基本上是你的样本数是

358
00:14:56,399 --> 00:14:58,399
其实没有5000张照片

359
00:14:58,600 --> 00:15:00,919
就是平均它就是一个

360
00:15:00,919 --> 00:15:03,039
当然有一些类东西很多

361
00:15:03,039 --> 00:15:04,039
有些类东西很少

362
00:15:04,039 --> 00:15:08,840
它最后是取得比较数据还比较多的类

363
00:15:08,840 --> 00:15:09,600
1000个类

364
00:15:09,639 --> 00:15:12,000
然后这样子你有120万个样本

365
00:15:12,840 --> 00:15:15,320
你可以看到跟你的M list比

366
00:15:15,320 --> 00:15:18,440
它的主要区别是你的类现在多了100倍

367
00:15:18,560 --> 00:15:21,680
你的样本多了1000倍

368
00:15:21,720 --> 00:15:23,279
然后你的大小更大了

369
00:15:23,960 --> 00:15:26,680
所以是说因为你有这么大的数据集

370
00:15:27,000 --> 00:15:30,960
然后所以允许你使用更深的神级网络

371
00:15:30,960 --> 00:15:33,320
来抽取里面更复杂的信息

372
00:15:34,720 --> 00:15:35,240
OK

373
00:15:35,440 --> 00:15:40,600
所以在应该是第三次的ImageNet的竞赛的时候

374
00:15:41,080 --> 00:15:42,680
应该是2012年那一年

375
00:15:42,680 --> 00:15:47,480
就AlexNet拿到了ImageNet竞赛的冠军

376
00:15:49,120 --> 00:15:53,159
就是说AlexNet它本质上是一个更深更大的

377
00:15:53,159 --> 00:15:53,800
LearnNet

378
00:15:54,560 --> 00:15:57,600
它跟LearnNet在架构上没有太多本质的区别

379
00:15:57,800 --> 00:15:59,840
我们等会会看到它的具体的实现

380
00:16:01,759 --> 00:16:04,120
然后它主要的改进在这个地方

381
00:16:05,000 --> 00:16:08,040
它主要的改进是说我们加入了丢弃法

382
00:16:08,080 --> 00:16:09,160
丢弃法我们有讲过

383
00:16:09,600 --> 00:16:11,360
大家如果没听的话

384
00:16:11,360 --> 00:16:12,199
可以去看一下

385
00:16:12,199 --> 00:16:13,079
并且看一下视频

386
00:16:13,919 --> 00:16:16,559
另外一个是说它的激活函数

387
00:16:16,559 --> 00:16:21,039
从LearnNet的sigmoid改成了relu

388
00:16:22,360 --> 00:16:24,240
我们之前有讲过relu这个函数

389
00:16:24,799 --> 00:16:27,000
在昨天我们QA的环节里面

390
00:16:27,000 --> 00:16:29,480
有同学问说relu效果不是很好

391
00:16:29,519 --> 00:16:32,639
实际上我们改用relu之后

392
00:16:32,679 --> 00:16:34,360
你可以看到确实效果有

393
00:16:34,399 --> 00:16:36,759
即使在LearnNet

394
00:16:36,879 --> 00:16:40,240
在Fashion Analyst的数据上

395
00:16:40,279 --> 00:16:42,560
你也能看到进度的一点点提升

396
00:16:43,840 --> 00:16:45,480
第三个是说我们LearnNet

397
00:16:45,480 --> 00:16:49,960
它用的是主要是的平均尺划

398
00:16:50,000 --> 00:16:52,759
所以AlexNet取的是max pooling

399
00:16:54,080 --> 00:16:57,600
所以你可认为说丢弃法是让你做模型的控制

400
00:16:57,639 --> 00:16:58,840
因为你模型更大了

401
00:16:58,840 --> 00:17:01,440
所以我用丢弃法来做一些政策

402
00:17:01,519 --> 00:17:02,960
那么relu和max pooling

403
00:17:02,960 --> 00:17:05,360
你可认为是我让我的relu

404
00:17:05,360 --> 00:17:07,920
让你的sigmoid的激活函数

405
00:17:07,920 --> 00:17:10,600
比它最大的是说它的梯度

406
00:17:10,600 --> 00:17:11,720
它确实更大

407
00:17:12,680 --> 00:17:15,079
而且我们之前有讲过relu在零点处

408
00:17:15,079 --> 00:17:19,039
它的一阶倒确实是更加好一点

409
00:17:19,039 --> 00:17:20,880
它能让你支撑更深的模型

410
00:17:21,480 --> 00:17:23,960
第二个是说用的是max pooling

411
00:17:24,000 --> 00:17:25,840
max pooling取的是最大值

412
00:17:25,880 --> 00:17:27,960
使得你的输出的值比较大

413
00:17:28,000 --> 00:17:29,680
你的梯度相对来说比较大

414
00:17:30,319 --> 00:17:31,960
使得训练更加容易一点

415
00:17:32,920 --> 00:17:34,640
当然就是说

416
00:17:34,680 --> 00:17:38,279
它不仅仅是一个让它更大更深

417
00:17:38,319 --> 00:17:40,840
它更多的是一个观念上的一个改变

418
00:17:42,079 --> 00:17:42,920
就是说

419
00:17:43,120 --> 00:17:44,400
Nernet大家还是认为

420
00:17:44,400 --> 00:17:46,200
这就是一个机器学习的模型

421
00:17:46,240 --> 00:17:47,519
但是对AlexNet

422
00:17:47,559 --> 00:17:50,360
因为它应该增大了几十倍的样子

423
00:17:50,400 --> 00:17:54,160
但是它量变引起了质变

424
00:17:54,440 --> 00:17:57,640
它对整个计算机视觉的改变是说

425
00:17:57,680 --> 00:17:59,680
把人的观念改变了

426
00:18:00,680 --> 00:18:02,320
具体来说是说

427
00:18:02,320 --> 00:18:03,720
我们之前有讲过

428
00:18:03,720 --> 00:18:06,519
你如果用的是在深度学习

429
00:18:06,519 --> 00:18:08,080
神经网络之前的话

430
00:18:08,120 --> 00:18:09,960
那么你首先对照图片

431
00:18:10,000 --> 00:18:11,720
你做你的人工特征提取

432
00:18:12,720 --> 00:18:14,160
计算机视觉的研究者

433
00:18:14,160 --> 00:18:16,960
主要是关心你怎么样去做的特征提取

434
00:18:18,920 --> 00:18:21,799
如果大家参加过我们第一次竞赛的话

435
00:18:21,799 --> 00:18:24,480
你会发现特征提取是非常关键的

436
00:18:24,480 --> 00:18:26,320
我们的房价识别

437
00:18:26,759 --> 00:18:28,519
接下来就是用一个比较

438
00:18:28,559 --> 00:18:31,200
标准的机器学习模型

439
00:18:31,960 --> 00:18:34,480
所以人的专家的信息

440
00:18:34,480 --> 00:18:35,720
对整个问题的理解

441
00:18:35,720 --> 00:18:38,240
都放在人工特征提取这一块

442
00:18:38,480 --> 00:18:41,000
这就是说机器视觉的专家

443
00:18:41,039 --> 00:18:44,639
怎么样把对我问题的理解

444
00:18:45,119 --> 00:18:48,399
转换成我的标准的机器学习算法的

445
00:18:48,399 --> 00:18:50,000
理解的一些数值

446
00:18:52,119 --> 00:18:54,159
但是深度学习神经网络

447
00:18:54,840 --> 00:18:56,320
你可以认为他最后一层

448
00:18:56,320 --> 00:18:56,960
我们有讲过

449
00:18:56,960 --> 00:18:59,240
就是一个softmax回归

450
00:18:59,240 --> 00:19:00,720
最后一层就是

451
00:19:01,400 --> 00:19:03,400
然后之前的所有层

452
00:19:03,440 --> 00:19:07,200
你可以认为是我通过CNN来学习

453
00:19:07,200 --> 00:19:08,040
我的特征

454
00:19:09,759 --> 00:19:13,400
我们昨天仍然是在ql环节有讲过

455
00:19:13,440 --> 00:19:16,000
说你CNN确实在不同的通道

456
00:19:16,040 --> 00:19:18,920
他去尝试去学习不同的图片

457
00:19:18,920 --> 00:19:21,240
面学习不同的一些模式

458
00:19:21,279 --> 00:19:22,800
使得抽取出来

459
00:19:22,799 --> 00:19:26,559
使得最后的softmax是能够好的做分类的

460
00:19:27,200 --> 00:19:29,240
因为他这里主要的好处是说

461
00:19:29,440 --> 00:19:31,359
你前面是一个独立的

462
00:19:31,359 --> 00:19:35,039
就是我觉得你SVN应该要什么样的特征

463
00:19:35,039 --> 00:19:35,720
比较好

464
00:19:35,759 --> 00:19:38,119
但这里它是一个一起训练的过程

465
00:19:39,319 --> 00:19:40,599
你最后的分类器

466
00:19:40,639 --> 00:19:42,759
和我的特征提取的模型

467
00:19:42,799 --> 00:19:44,279
是在一起训练的

468
00:19:45,039 --> 00:19:46,639
所以就意味着是说

469
00:19:47,319 --> 00:19:49,559
我CNN学出来的东西

470
00:19:49,599 --> 00:19:52,039
很有可能就是你softmax想要的

471
00:19:52,319 --> 00:19:55,200
我通过我的很深的神经网络

472
00:19:55,240 --> 00:19:58,639
把整个原始的那些pixel

473
00:19:58,680 --> 00:20:00,559
能够map到一个空间

474
00:20:00,559 --> 00:20:03,440
使得你的softmax回归很好去进行分类

475
00:20:04,879 --> 00:20:05,680
所以这个

476
00:20:06,000 --> 00:20:07,799
所以就是说有两点

477
00:20:07,799 --> 00:20:08,839
第一点是说

478
00:20:08,879 --> 00:20:11,000
构造CNN相对来说

479
00:20:11,480 --> 00:20:12,200
简单

480
00:20:12,639 --> 00:20:14,519
就不需要了解太多的

481
00:20:14,519 --> 00:20:16,960
这些计算机视觉的一些专业的知识

482
00:20:17,720 --> 00:20:20,480
而且比较容易跨到不同的问题上

483
00:20:20,480 --> 00:20:21,440
不同的学科

484
00:20:21,759 --> 00:20:22,640
第二点是说

485
00:20:22,640 --> 00:20:24,360
因为我跟这两个模型

486
00:20:24,360 --> 00:20:25,759
其实是在一起训练的

487
00:20:26,600 --> 00:20:27,799
从模型角度来讲

488
00:20:27,799 --> 00:20:28,680
它其实就是一个

489
00:20:29,680 --> 00:20:31,480
然后这样子的话

490
00:20:31,480 --> 00:20:33,320
它其实更加高效一点

491
00:20:33,759 --> 00:20:34,320
OK

492
00:20:34,360 --> 00:20:38,279
所以这里就是一个主要的深度学习

493
00:20:38,559 --> 00:20:40,400
对传统一点的

494
00:20:40,400 --> 00:20:42,640
之前的机器学习的改变

495
00:20:42,680 --> 00:20:46,120
就是说我们不再去想说

496
00:20:46,120 --> 00:20:47,920
怎么样人工抽取特征

497
00:20:47,960 --> 00:20:50,360
而是到一个端到端的一个学习

498
00:20:50,400 --> 00:20:51,800
就从原始的pixel

499
00:20:51,800 --> 00:20:53,600
原始的字符串

500
00:20:53,600 --> 00:20:55,240
原始的所有的信号

501
00:20:55,280 --> 00:20:57,640
到最终的一个无药的分类

502
00:20:57,640 --> 00:20:58,880
或者是一个预测

503
00:20:58,920 --> 00:21:00,240
直接通过深度学习

504
00:21:00,240 --> 00:21:02,040
神经网络一路过去

505
00:21:02,400 --> 00:21:05,800
这就是深度学习最大的一个卖点了

506
00:21:08,840 --> 00:21:09,200
OK

507
00:21:09,200 --> 00:21:10,760
我们接下来来看一下

508
00:21:10,760 --> 00:21:14,120
整个AlexNet的架构是长什么样子

509
00:21:14,760 --> 00:21:15,480
我们有讲过

510
00:21:15,480 --> 00:21:17,040
它其实就是一个更深的

511
00:21:17,040 --> 00:21:18,280
更大的LearnNet

512
00:21:18,519 --> 00:21:20,160
我们在这里就是

513
00:21:20,200 --> 00:21:22,319
把他们两个做一个对比

514
00:21:23,359 --> 00:21:24,960
首先我们看到是说

515
00:21:25,839 --> 00:21:28,319
这一个就是AlexNet和LearnNet

516
00:21:28,799 --> 00:21:30,599
这个是对图片进来

517
00:21:31,599 --> 00:21:35,639
AlexNet图片进去是一个224×224

518
00:21:35,879 --> 00:21:37,160
就是我们虽然大一点

519
00:21:37,160 --> 00:21:38,960
但是我们会把它变得小一点点

520
00:21:39,599 --> 00:21:40,440
然后乘以3

521
00:21:40,440 --> 00:21:41,799
因为它是RGB的图片

522
00:21:41,839 --> 00:21:43,319
如果是LearnNet的话

523
00:21:43,440 --> 00:21:44,279
就是一个

524
00:21:44,639 --> 00:21:46,480
我们知道是一个32×32

525
00:21:46,839 --> 00:21:48,079
channel数是等于1

526
00:21:48,199 --> 00:21:49,039
就是灰度图

527
00:21:50,439 --> 00:21:53,480
所以首先我们看第一个卷积层

528
00:21:55,399 --> 00:21:57,359
LearnNet第一个卷积层是这个地方

529
00:21:57,359 --> 00:21:59,319
就是5×5的卷积窗口

530
00:21:59,319 --> 00:22:00,159
我们昨天有讲

531
00:22:00,599 --> 00:22:02,480
然后我的输出的通道数是6

532
00:22:02,480 --> 00:22:03,399
然后PAD了

533
00:22:03,599 --> 00:22:05,199
PAD应该不应该是2

534
00:22:05,359 --> 00:22:06,119
这里不需要2了

535
00:22:06,119 --> 00:22:08,240
因为我的输入已经32×32了

536
00:22:09,720 --> 00:22:12,919
然后在AlexNet

537
00:22:14,079 --> 00:22:17,159
它用了一个更大的一个核窗口

538
00:22:17,200 --> 00:22:18,400
11×11

539
00:22:19,400 --> 00:22:21,320
这是因为你的图片更大了

540
00:22:21,320 --> 00:22:24,320
一个5×5的窗口能看的东西就变少了

541
00:22:25,000 --> 00:22:26,400
它需要一个更大的窗口

542
00:22:26,400 --> 00:22:28,600
去看更多的一块方块

543
00:22:30,400 --> 00:22:33,880
第二个是说你的通道数增加比较大

544
00:22:33,880 --> 00:22:36,120
从6变成了96

545
00:22:37,040 --> 00:22:39,360
我觉得说我这里面图片里面

546
00:22:39,360 --> 00:22:41,320
更多的一些模式

547
00:22:41,320 --> 00:22:43,960
我想去在第一层就给你试探

548
00:22:43,960 --> 00:22:45,440
去尝试识别出来

549
00:22:45,440 --> 00:22:47,200
所以它用的比较大的通道数

550
00:22:48,480 --> 00:22:51,360
然后当然是说我的stripe等于4

551
00:22:51,360 --> 00:22:53,360
因为如果你不做等于4的话

552
00:22:53,720 --> 00:22:58,039
相对来说是你当时候是2012年的时候

553
00:22:58,039 --> 00:22:59,720
当时GPU还真的没那么好用

554
00:22:59,720 --> 00:23:03,400
也就4个两GB或者4GB的内存

555
00:23:03,480 --> 00:23:05,920
所以而且计算其实不是那么快的

556
00:23:06,600 --> 00:23:08,920
所以如果你的stripe不够大的话

557
00:23:09,120 --> 00:23:11,960
那么你的后面的计算就会变得特别难

558
00:23:12,120 --> 00:23:13,799
所以他在第一步用的是

559
00:23:13,799 --> 00:23:15,919
每一次就跳4个像素

560
00:23:16,519 --> 00:23:21,119
所以Alexandr和Nernet在第一层卷积层的一个比较

561
00:23:22,720 --> 00:23:25,039
接下来就卷积层之后

562
00:23:25,039 --> 00:23:27,319
我们知道是用的是持话层

563
00:23:28,079 --> 00:23:33,319
首先看到是说Alexandr用的是3×3的持话层

564
00:23:33,839 --> 00:23:36,240
就窗口比Nernet2×2

565
00:23:36,759 --> 00:23:37,839
Stripe是一样的

566
00:23:37,839 --> 00:23:39,440
就不服都是2

567
00:23:39,720 --> 00:23:42,359
Nernet就是说我的窗口是2

568
00:23:42,400 --> 00:23:45,280
每次看下一个我是不重叠的

569
00:23:46,280 --> 00:23:49,000
Alexandr就是说我用一个3×3

570
00:23:49,280 --> 00:23:52,360
你可以认为2×2和3×3主要的区别是说

571
00:23:52,360 --> 00:23:53,480
如果是2×2的话

572
00:23:53,480 --> 00:23:56,360
我允许一个像素往一边移一点点

573
00:23:57,120 --> 00:23:57,920
就是一个

574
00:23:58,560 --> 00:24:04,000
如果你的一个模式在一个像素往一边移一点点

575
00:24:04,040 --> 00:24:05,840
其实不会影响我的输出

576
00:24:05,840 --> 00:24:08,160
反正我就把你同样输出出去了

577
00:24:08,480 --> 00:24:09,600
如果是3×3的话

578
00:24:09,720 --> 00:24:11,720
就允许我说往左移一下

579
00:24:11,720 --> 00:24:13,120
往右移一下都OK

580
00:24:14,360 --> 00:24:15,280
Stripe等于2

581
00:24:15,280 --> 00:24:16,360
就是大家都是等于2

582
00:24:16,360 --> 00:24:20,920
就是一样的把输入和输出的高宽全部减半

583
00:24:21,840 --> 00:24:26,480
所以这里可以认为是说Alexandr比Nernet用了

584
00:24:26,520 --> 00:24:29,040
稍微大一点点的一个持话窗口

585
00:24:29,320 --> 00:24:31,560
另外一个是他用的max pooling

586
00:24:31,720 --> 00:24:33,920
而不是Nernet的average pooling

587
00:24:35,280 --> 00:24:35,560
OK

588
00:24:35,560 --> 00:24:39,320
这个就是第一个卷积层和持话层的区别

589
00:24:40,600 --> 00:24:42,240
接下来我们看后面的

590
00:24:42,240 --> 00:24:44,000
后面的就是说Nernet

591
00:24:44,000 --> 00:24:46,680
我们知道后面他又接了一个卷积层

592
00:24:46,680 --> 00:24:48,640
它是一个5×5的卷积层

593
00:24:48,640 --> 00:24:50,640
然后你的通道数是16

594
00:24:51,280 --> 00:24:55,760
接下来接了一个同样的均值的持话层

595
00:24:56,760 --> 00:24:58,480
那么看一下Alexandr是什么样子

596
00:24:59,800 --> 00:25:01,000
Alexandr是一样的

597
00:25:01,000 --> 00:25:02,920
他用了一个5×5的卷积

598
00:25:03,560 --> 00:25:05,720
然后你的pad等于2

599
00:25:06,760 --> 00:25:07,640
就pad等于2

600
00:25:07,640 --> 00:25:11,600
大家知道就是让你的输入和输出的尺寸是一样的

601
00:25:12,520 --> 00:25:14,280
那么接下来就看到是说

602
00:25:14,840 --> 00:25:15,480
这个地方

603
00:25:17,120 --> 00:25:19,160
他用的是256

604
00:25:20,480 --> 00:25:22,640
就是说你的输出通道是256

605
00:25:23,840 --> 00:25:24,759
刚刚是96

606
00:25:24,920 --> 00:25:26,920
现在直接跳到256

607
00:25:26,920 --> 00:25:29,160
跟你的Nernet的16比

608
00:25:29,360 --> 00:25:32,200
也是翻了个十几倍的样子

609
00:25:33,280 --> 00:25:34,360
所以你可以认为

610
00:25:34,800 --> 00:25:39,320
这一块主要的区别是我用了更大的输出通道

611
00:25:39,320 --> 00:25:40,120
还是一样的

612
00:25:40,120 --> 00:25:41,520
我觉得我能够

613
00:25:41,520 --> 00:25:44,640
我应该去识别更多的模式在里面

614
00:25:44,840 --> 00:25:46,880
所以你就需要有更大的输出通道

615
00:25:47,680 --> 00:25:50,080
那么接下来的持话层是一样的

616
00:25:50,080 --> 00:25:51,440
就是说他用了3×3

617
00:25:51,440 --> 00:25:52,640
稍微大一点点

618
00:25:52,680 --> 00:25:54,760
然后用的是最大持话层

619
00:25:55,800 --> 00:25:58,160
同样的你的不符等于2

620
00:25:58,160 --> 00:26:00,600
就是说把我的输入的高宽减半

621
00:26:01,720 --> 00:26:03,480
所以这个是第二个卷积层

622
00:26:04,520 --> 00:26:08,160
接下来AlexNet又新加了三个卷积层

623
00:26:10,720 --> 00:26:13,560
所以就是说你比Nernet卷积层多了三个

624
00:26:14,000 --> 00:26:14,840
他是这么用的

625
00:26:16,040 --> 00:26:17,840
他是先用一个3×3的

626
00:26:17,840 --> 00:26:19,680
后面都是用3×3的卷积层

627
00:26:19,880 --> 00:26:20,640
π等于1

628
00:26:20,640 --> 00:26:22,640
就是说输入和输出还是长一样

629
00:26:22,960 --> 00:26:25,600
然后他这里增加到了384

630
00:26:26,400 --> 00:26:28,960
就连续把三个卷积层放在一起

631
00:26:29,720 --> 00:26:32,600
最后再做一次持话层

632
00:26:32,800 --> 00:26:35,000
用持话层跟之前是一样的设计

633
00:26:35,800 --> 00:26:38,200
所以就是说他又增加了第三个单元

634
00:26:38,200 --> 00:26:40,720
这个单元是先用三个卷积层

635
00:26:40,720 --> 00:26:42,960
再用一次持话层

636
00:26:44,680 --> 00:26:45,160
OK

637
00:26:47,240 --> 00:26:51,080
接下来就是说我们知道Nernet在两个卷积层之后

638
00:26:51,080 --> 00:26:53,120
是用了两个隐藏层

639
00:26:53,120 --> 00:26:55,800
再到最后你的softmax回归做输出

640
00:26:56,240 --> 00:26:58,600
所以那就是第一个隐藏层

641
00:26:58,600 --> 00:26:59,600
大概是120

642
00:26:59,760 --> 00:27:00,800
接下来是84

643
00:27:00,799 --> 00:27:02,960
然后最后是10做输出

644
00:27:03,720 --> 00:27:05,519
Alexandr跟他是一样的

645
00:27:05,639 --> 00:27:07,119
用了两个隐藏层

646
00:27:07,319 --> 00:27:13,119
但是隐藏层的大小从1直接变到了4096

647
00:27:13,319 --> 00:27:14,240
4000

648
00:27:14,639 --> 00:27:16,240
这是一个非常大的一个数字了

649
00:27:16,240 --> 00:27:18,720
因为你要那么大是为什么

650
00:27:18,720 --> 00:27:21,359
是因为你有要做1000类的输出在这个地方

651
00:27:22,039 --> 00:27:25,319
所以通常说你这个数字总得比1000要大一点点

652
00:27:25,319 --> 00:27:28,000
所以他取的是两个4096

653
00:27:28,919 --> 00:27:29,480
OK

654
00:27:30,480 --> 00:27:34,559
所以基本上整个AlexNet的一个架构

655
00:27:34,839 --> 00:27:35,960
回顾一下

656
00:27:35,960 --> 00:27:38,640
就是我的前面两个卷积层

657
00:27:38,680 --> 00:27:39,640
窗口更大

658
00:27:39,640 --> 00:27:40,759
通道数更多

659
00:27:40,880 --> 00:27:43,160
再增加了三个卷积层

660
00:27:43,960 --> 00:27:47,039
然后在最后的全连接层

661
00:27:47,079 --> 00:27:49,839
我的隐藏层大小更大

662
00:27:50,360 --> 00:27:53,680
所以就是为什么说我这是一个更胖的

663
00:27:53,680 --> 00:27:56,720
也是稍微深那么一点点的一个Nernet

664
00:27:56,880 --> 00:27:59,279
OK

665
00:27:59,279 --> 00:28:00,880
这就是AlexNet的架构

666
00:28:02,000 --> 00:28:04,440
当然它有一些更多的细节在的地方

667
00:28:05,319 --> 00:28:07,519
就是说我们之前有说过

668
00:28:07,559 --> 00:28:09,640
我们没有画我的激活层

669
00:28:09,799 --> 00:28:12,600
激活层是从Nernet的SigmaWide变成RedLoop

670
00:28:12,799 --> 00:28:13,839
我们之前有讲过

671
00:28:13,839 --> 00:28:16,160
RedLoop确实可以减缓T度的消失

672
00:28:16,160 --> 00:28:17,960
是因为你的T度总是比较大

673
00:28:18,279 --> 00:28:19,799
特别在值比较大的时候

674
00:28:19,799 --> 00:28:21,759
在正向T度总是唯一的

675
00:28:22,640 --> 00:28:26,160
而且它确实它的函数

676
00:28:26,160 --> 00:28:27,120
我们也介绍过

677
00:28:27,120 --> 00:28:29,640
在零点处它的一阶导数

678
00:28:29,640 --> 00:28:30,720
它是等于1

679
00:28:30,720 --> 00:28:33,160
所以相对来说比较容易数值稳定

680
00:28:34,160 --> 00:28:35,200
然后第二个是说

681
00:28:35,200 --> 00:28:39,640
它在隐藏全连接层的隐藏层之后

682
00:28:39,640 --> 00:28:41,920
就是两个4096的隐藏层之后

683
00:28:41,960 --> 00:28:43,400
加入了Dropout层

684
00:28:43,400 --> 00:28:47,160
就丢弃层来做我的模型的一个政策化

685
00:28:48,960 --> 00:28:51,480
另外一个也是一个非常重要的是说

686
00:28:51,519 --> 00:28:53,680
它做了数据的增强

687
00:28:54,680 --> 00:28:58,000
就是说它觉得120万张图片不够大

688
00:28:59,279 --> 00:29:01,440
而且它怎么样做图片来讲

689
00:29:01,440 --> 00:29:02,480
就是说你怎么样做

690
00:29:02,640 --> 00:29:05,000
就是说我假设我的原始图片

691
00:29:05,000 --> 00:29:06,400
是这是猫的话

692
00:29:06,960 --> 00:29:08,840
每一次我假设我去

693
00:29:09,000 --> 00:29:10,640
这次我要读它进去

694
00:29:10,640 --> 00:29:11,880
因为我是随机T度下降

695
00:29:12,039 --> 00:29:13,880
每次我随机采样一个样子回来

696
00:29:14,480 --> 00:29:16,400
假设我采样的这是猫了

697
00:29:16,640 --> 00:29:17,560
那么我会说

698
00:29:17,560 --> 00:29:20,120
我不会把猫直接作用过去

699
00:29:20,160 --> 00:29:23,400
我会去做很多这样子的数据的变化

700
00:29:23,400 --> 00:29:26,240
包括这里我随机的截取

701
00:29:26,840 --> 00:29:29,000
随机的去重新去取一块

702
00:29:29,560 --> 00:29:30,519
截取一块

703
00:29:31,000 --> 00:29:31,759
做进去

704
00:29:32,640 --> 00:29:35,600
然后当然是说我随机的把亮度调高一点

705
00:29:35,600 --> 00:29:36,519
调低一点

706
00:29:36,560 --> 00:29:37,720
然后甚至把你的

707
00:29:38,480 --> 00:29:44,080
你的Hue色温给你调的蓝一点

708
00:29:44,240 --> 00:29:45,280
随机调一调

709
00:29:46,280 --> 00:29:48,360
就是说他的想法是说

710
00:29:48,360 --> 00:29:49,759
我想让

711
00:29:49,800 --> 00:29:51,960
因为我们知道我们的卷积这个东西

712
00:29:51,960 --> 00:29:54,079
对位置是比较敏感的

713
00:29:54,559 --> 00:29:56,600
而且对于那些光照这些东西

714
00:29:56,600 --> 00:29:57,600
都会比较敏感

715
00:29:57,720 --> 00:29:59,880
那么我如何让你不敏感

716
00:30:00,079 --> 00:30:02,640
我就是在数图里面

717
00:30:02,680 --> 00:30:06,039
增加大量的变种

718
00:30:06,960 --> 00:30:08,440
最好的情况下是说

719
00:30:08,440 --> 00:30:09,319
你的预测

720
00:30:09,319 --> 00:30:11,559
假设你的预测猫形状会发生变化

721
00:30:11,559 --> 00:30:13,480
或者颜色框上会发生变化

722
00:30:13,519 --> 00:30:14,799
那我在训练的时候

723
00:30:14,799 --> 00:30:16,759
我就给你去模拟这种变化出来

724
00:30:17,079 --> 00:30:19,240
使得你都能处理过

725
00:30:19,480 --> 00:30:20,440
反过来讲

726
00:30:20,480 --> 00:30:23,120
因为我们知道神经网络是非常是

727
00:30:23,279 --> 00:30:25,440
能够去记住你所有的数据

728
00:30:25,600 --> 00:30:27,519
那么我这样子做变化之后

729
00:30:27,519 --> 00:30:29,400
那么你记住数据的

730
00:30:29,920 --> 00:30:31,640
能力就会变低了

731
00:30:31,960 --> 00:30:34,279
因为我不是每次都给你一只同样的猫

732
00:30:34,759 --> 00:30:35,039
OK

733
00:30:35,039 --> 00:30:36,720
这就是另外一个

734
00:30:36,720 --> 00:30:38,120
我们会在之后

735
00:30:38,120 --> 00:30:39,799
在详细的有一节课

736
00:30:39,799 --> 00:30:41,360
专门来讲数据增强

737
00:30:41,400 --> 00:30:42,759
因为这个太重要了

738
00:30:42,759 --> 00:30:44,000
对计算机视觉来讲

739
00:30:46,720 --> 00:30:46,960
好

740
00:30:46,960 --> 00:30:48,480
我们来接下来我们来看一下

741
00:30:48,480 --> 00:30:51,319
就是说我们这两个模型

742
00:30:51,319 --> 00:30:53,079
它的复杂度的对比

743
00:30:54,440 --> 00:30:56,559
首先我们来对比一下参数的个数

744
00:30:56,559 --> 00:30:58,640
首先

745
00:30:58,640 --> 00:31:00,360
learnnet它确实是不大的

746
00:31:00,360 --> 00:31:03,279
就是说你第一个卷积层就是150个

747
00:31:03,480 --> 00:31:06,039
可以学习的一个参数

748
00:31:06,200 --> 00:31:08,279
第二个大概是2400两次

749
00:31:08,279 --> 00:31:09,200
后面的

750
00:31:09,440 --> 00:31:11,000
全年阶层大那么一点点

751
00:31:12,120 --> 00:31:14,120
然后可以看一下我的AlexNet

752
00:31:14,759 --> 00:31:16,240
AlexNet就基本上是说

753
00:31:16,240 --> 00:31:17,680
你看到第一个卷积层

754
00:31:17,680 --> 00:31:20,320
因为我用的7x7的核

755
00:31:20,320 --> 00:31:22,120
而且我的通道数增加了

756
00:31:22,160 --> 00:31:24,400
而且你的输入通道数从1变成3了

757
00:31:24,400 --> 00:31:27,440
所以你从150直接的变成了35000

758
00:31:28,279 --> 00:31:29,279
第二个会比较大

759
00:31:29,880 --> 00:31:31,960
快到600k了

760
00:31:32,240 --> 00:31:34,720
然后三和五就是新增的

761
00:31:34,720 --> 00:31:37,400
每一个就是因为你的通道数都是一样

762
00:31:37,400 --> 00:31:39,000
然后和大小是一样

763
00:31:39,000 --> 00:31:40,560
所以它都是三种

764
00:31:41,960 --> 00:31:44,799
然后你的全年阶层就是

765
00:31:45,319 --> 00:31:47,879
最后全年阶层当然比较大一点

766
00:31:47,879 --> 00:31:49,440
就是26兆16兆

767
00:31:49,480 --> 00:31:52,359
最后你是你的模型的大小

768
00:31:52,359 --> 00:31:54,119
大概就是46兆的样子

769
00:31:54,119 --> 00:31:55,159
这是你的AlexNet

770
00:31:55,519 --> 00:31:58,000
你有4600万个可以学习的参数

771
00:31:58,399 --> 00:32:00,879
learnnet就是60万个

772
00:32:01,159 --> 00:32:03,879
所以你可以看到是AlexNet

773
00:32:03,919 --> 00:32:06,319
在参数的个数上

774
00:32:06,319 --> 00:32:07,599
可以学习的个数上

775
00:32:07,599 --> 00:32:10,240
是比learnnet多10倍的样子

776
00:32:11,240 --> 00:32:12,879
但考虑到你的imageNet

777
00:32:12,880 --> 00:32:15,440
你的图片的imageNet

778
00:32:15,440 --> 00:32:17,520
大概是120万张图片

779
00:32:17,520 --> 00:32:18,080
然后更大

780
00:32:18,080 --> 00:32:19,960
大概算下来就是100G的

781
00:32:19,960 --> 00:32:20,800
在磁盘上存

782
00:32:21,360 --> 00:32:23,840
learnnet大概存下来可能就10兆的样子

783
00:32:23,880 --> 00:32:26,640
所以你的学习数据增加的更大

784
00:32:26,680 --> 00:32:29,400
所以你图片也就增加了10倍

785
00:32:29,400 --> 00:32:30,760
其实不算很大了

786
00:32:31,200 --> 00:32:34,440
这是因为确实卷积层是比较省参数的

787
00:32:34,440 --> 00:32:35,680
一个层

788
00:32:36,960 --> 00:32:38,800
那么它主要的变化在什么地方

789
00:32:38,880 --> 00:32:41,040
主要的变化是你的计算术

790
00:32:41,040 --> 00:32:42,120
就是你的flops

791
00:32:42,360 --> 00:32:44,440
这每秒就是你需要的

792
00:32:45,360 --> 00:32:47,720
整个一个往前算的话

793
00:32:47,720 --> 00:32:50,720
你需要的一个浮点计算数

794
00:32:51,680 --> 00:32:53,640
可以看到是说我们就不详细讲了

795
00:32:53,640 --> 00:32:54,680
可以看到是说

796
00:32:54,720 --> 00:32:57,360
你的整个大概是一个G的样子

797
00:32:58,520 --> 00:33:01,960
就是你需要10一次计算

798
00:33:02,760 --> 00:33:05,120
learnnet是400万

799
00:33:05,160 --> 00:33:06,640
所以这个地方是很大的

800
00:33:06,840 --> 00:33:08,400
就是说AlexNet

801
00:33:08,840 --> 00:33:11,600
在他的图片上做一次前项运算

802
00:33:11,640 --> 00:33:13,640
比learnnet在他的数据集上

803
00:33:13,640 --> 00:33:15,480
就是小一点数据集上

804
00:33:15,520 --> 00:33:17,720
是贵了250倍的样子

805
00:33:20,160 --> 00:33:23,240
所以说这是一个非常巨大的一个数字了

806
00:33:23,480 --> 00:33:25,760
就是说我一个模型比另外一个模型

807
00:33:26,360 --> 00:33:28,840
要多算250次的计算

808
00:33:28,880 --> 00:33:30,160
那真的就是

809
00:33:31,840 --> 00:33:34,120
这两个模型是有很大很大的区别了

810
00:33:34,880 --> 00:33:35,240
OK

811
00:33:35,240 --> 00:33:37,760
所以你可以认为是

812
00:33:37,760 --> 00:33:39,520
虽然AlexNet

813
00:33:39,519 --> 00:33:42,079
只在学习的参数上多了10倍

814
00:33:42,119 --> 00:33:43,759
但是因为卷积升级网络

815
00:33:43,759 --> 00:33:46,480
它那个都是参数都是乘在一起的

816
00:33:46,519 --> 00:33:49,119
所以导致你最终多了250倍

817
00:33:50,440 --> 00:33:53,559
所以他们不在一个scale上面

818
00:33:53,920 --> 00:33:56,680
但反过来讲AlexNet也是一个

819
00:33:56,720 --> 00:33:57,799
从现在角度来看

820
00:33:57,799 --> 00:33:59,759
是一个非常便宜的一个

821
00:33:59,759 --> 00:34:01,079
深度升级网络了

822
00:34:02,079 --> 00:34:04,839
后面的升级网络比这个贵太多

823
00:34:06,079 --> 00:34:06,639
OK

824
00:34:06,680 --> 00:34:07,960
所以我们总结一下

825
00:34:08,960 --> 00:34:10,400
总结一下就是说

826
00:34:10,920 --> 00:34:13,679
AlexNet就是一个更大

827
00:34:14,199 --> 00:34:15,440
就更胖

828
00:34:15,800 --> 00:34:16,440
更深

829
00:34:16,440 --> 00:34:19,400
就是它多了三个卷积层的一个Nernet

830
00:34:19,440 --> 00:34:21,480
但是它的思想上跟Nernet

831
00:34:21,480 --> 00:34:23,320
就整个架构是没区别的

832
00:34:23,720 --> 00:34:25,199
一些卷积层

833
00:34:25,320 --> 00:34:28,000
然后再加上我的全连接层

834
00:34:29,360 --> 00:34:31,400
它比Nernet多了参数

835
00:34:31,400 --> 00:34:32,400
个数多了10倍

836
00:34:32,400 --> 00:34:34,880
计算度要多了260倍

837
00:34:35,680 --> 00:34:38,240
它新加入了一些小技巧

838
00:34:38,400 --> 00:34:40,400
使得我的训练更加容易点

839
00:34:40,680 --> 00:34:41,160
丢弃法

840
00:34:41,800 --> 00:34:42,360
redo

841
00:34:42,680 --> 00:34:44,240
最大池化层

842
00:34:44,480 --> 00:34:46,000
然后和数据增强

843
00:34:47,039 --> 00:34:48,840
然后AlexNet它迎向了

844
00:34:48,840 --> 00:34:51,240
2012年的ImageNet的竞赛后

845
00:34:51,280 --> 00:34:54,160
标志着新的一轮升级网络

846
00:34:54,200 --> 00:34:56,640
也就是说深度学习的朝来开始

847
00:34:57,000 --> 00:34:59,039
就是说给大家我这么做

848
00:34:59,039 --> 00:35:00,480
能赢下来效果很好

849
00:35:00,480 --> 00:35:01,880
大家纷纷的去

850
00:35:01,960 --> 00:35:05,160
在接下来的几年的ImageNet竞赛里面

851
00:35:05,160 --> 00:35:07,559
大家纷纷用深度神级网络

852
00:35:07,559 --> 00:35:08,640
去赢下了冠军

853
00:35:08,640 --> 00:35:11,160
基本上前面几名都是ImageNet

854
00:35:11,800 --> 00:35:13,880
都是深度神级网络所爆版的

855
00:35:14,720 --> 00:35:15,200
OK

