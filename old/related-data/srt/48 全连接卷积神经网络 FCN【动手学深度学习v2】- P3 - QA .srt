1
00:00:00,000 --> 00:00:02,000
好,接下来我们来看一下问题

2
00:00:02,000 --> 00:00:04,000
问题一

3
00:00:04,000 --> 00:00:10,000
如果只考虑目标检测,只考虑精度,不考虑速度,有推荐的吗?

4
00:00:10,000 --> 00:00:14,000
我觉得如果你考虑的话,你就考虑RCN系列

5
00:00:14,000 --> 00:00:18,000
RCN系列就是说你可以去看一下Detection 2

6
00:00:18,000 --> 00:00:20,000
比如说这个包,我觉得实际上是比较不错的

7
00:00:20,000 --> 00:00:23,000
可以看一下里面实现了大量的RCN系列的算法

8
00:00:23,000 --> 00:00:26,000
具体用哪一个你应该去看一下

9
00:00:26,000 --> 00:00:29,000
他们自己做的评测

10
00:00:29,000 --> 00:00:36,000
就是说现在的这些模型跟你诺本众的精度完全不在一个尺度上面

11
00:00:36,000 --> 00:00:40,000
现在实现的模型都大量的用了新的技术在里面

12
00:00:40,000 --> 00:00:43,000
所以使得远远的比诺本众的结果要好

13
00:00:43,000 --> 00:00:46,000
所以你还是以现在的实现为主

14
00:00:46,000 --> 00:00:48,000
问题二

15
00:00:48,000 --> 00:00:53,000
如果有相似场景两万张图片,自己预训练新的大马能做Auto Grow吗?

16
00:00:53,000 --> 00:00:55,000
Auto Grow能做目标检测

17
00:00:55,000 --> 00:00:57,000
这是可以的,你可以去试一下

18
00:00:57,000 --> 00:01:00,000
另外一块是说两万张图片,如果你觉得够了

19
00:01:00,000 --> 00:01:02,000
你就可以自己预训练

20
00:01:02,000 --> 00:01:06,000
但反过来讲,我觉得你用一下预训的模型做反应tooling

21
00:01:06,000 --> 00:01:08,000
可能总是不会差的

22
00:01:08,000 --> 00:01:11,000
就不会让你变差,很有可能会让你变好

23
00:01:11,000 --> 00:01:13,000
问题三

24
00:01:13,000 --> 00:01:20,000
网络中介的1x1卷集将7x7x512压缩到7x7x21

25
00:01:20,000 --> 00:01:24,000
这样子的损失,东西会不会造成损失吗?

26
00:01:24,000 --> 00:01:26,000
这个问题很好

27
00:01:26,000 --> 00:01:31,000
这个问题确实说我们1x1的卷集做的比较狠

28
00:01:31,000 --> 00:01:34,000
就在没有增大我的空间的解析度的情况下

29
00:01:34,000 --> 00:01:37,000
我把通道数一下就压到了21

30
00:01:37,000 --> 00:01:40,000
我们之所以这么做不是从精度上考虑

31
00:01:40,000 --> 00:01:42,000
我们主要是从速度上考虑

32
00:01:42,000 --> 00:01:46,000
因为我们想,你想我们一秒钟

33
00:01:46,000 --> 00:01:49,000
4个GPU也就是处理100个样板

34
00:01:49,000 --> 00:01:52,000
跑一轮起码要十几秒,也就是十秒

35
00:01:52,000 --> 00:01:54,000
然后我们跑个五轮也就几分钟了

36
00:01:54,000 --> 00:01:58,000
我们平常可能就一个GPU跑一跑就十分钟了

37
00:01:58,000 --> 00:02:02,000
所以主要是从速度上让notebook跑起来比较快

38
00:02:02,000 --> 00:02:05,000
但是确实精度上会有比较大的损失

39
00:02:05,000 --> 00:02:09,000
大家可以尝试去把1x1的卷集通道数设高一点

40
00:02:09,000 --> 00:02:11,000
会好一点

41
00:02:14,000 --> 00:02:16,000
问题四和五都是Padding

42
00:02:16,000 --> 00:02:18,000
Padding这个东西我再想一想

43
00:02:18,000 --> 00:02:22,000
我还没想好怎么画转制卷集的Padding

44
00:02:23,000 --> 00:02:25,000
我想想怎么画出来

45
00:02:25,000 --> 00:02:27,000
然后给大家来解释一下

46
00:02:29,000 --> 00:02:33,000
问题六七八六七是一个东西

47
00:02:33,000 --> 00:02:38,000
你为什么不用多个小的kernel的转制卷集是一步到位呢

48
00:02:38,000 --> 00:02:40,000
这个问题特别好

49
00:02:40,000 --> 00:02:42,000
我们讲的是最原始的算法

50
00:02:42,000 --> 00:02:44,000
最简单的算法

51
00:02:44,000 --> 00:02:45,000
确实后面有一系列改进

52
00:02:45,000 --> 00:02:46,000
比如说unet

53
00:02:46,000 --> 00:02:48,000
它的核心思想是说

54
00:02:48,000 --> 00:02:50,000
你不是一层一层卷集做过来吗

55
00:02:50,000 --> 00:02:51,000
一层一层减少

56
00:02:51,000 --> 00:02:53,000
那么我就把它倒过来

57
00:02:53,000 --> 00:02:57,000
然后把所有的卷集换成转制卷集

58
00:02:57,000 --> 00:02:59,000
就是按照同样的顺序一层一层把它变大

59
00:02:59,000 --> 00:03:01,000
就是一层一层变小

60
00:03:01,000 --> 00:03:03,000
然后一层一层变大

61
00:03:03,000 --> 00:03:04,000
做一个对称的模型

62
00:03:04,000 --> 00:03:06,000
所以他们发现效果比较好

63
00:03:06,000 --> 00:03:09,000
据说后面还有大量的工作

64
00:03:09,000 --> 00:03:14,000
确实是这样渐变效果确实可能会更好一点

65
00:03:15,000 --> 00:03:17,000
所以大家可以去研究一下这些工作

66
00:03:17,000 --> 00:03:18,000
可以看一下它

67
00:03:18,000 --> 00:03:21,000
当然unet里面还有一些细节的实现

68
00:03:21,000 --> 00:03:22,000
也没那么简单

69
00:03:22,000 --> 00:03:25,000
直接用一层一层过去就好了

70
00:03:27,000 --> 00:03:30,000
问题八九十

71
00:03:30,000 --> 00:03:32,000
其实是核心思想

72
00:03:32,000 --> 00:03:35,000
就是说你在

73
00:03:35,000 --> 00:03:37,000
你为什么用插子

74
00:03:37,000 --> 00:03:40,000
插子这个东西主要是用来初始化的

75
00:03:40,000 --> 00:03:42,000
就让你后面训练快

76
00:03:42,000 --> 00:03:44,000
就跟你做fine tuning是差不多一个效果

77
00:03:44,000 --> 00:03:48,000
你可以使用三次插子或什么插子都OK

78
00:03:48,000 --> 00:03:49,000
我觉得不重要

79
00:03:49,000 --> 00:03:51,000
插子的效果不重要

80
00:03:51,000 --> 00:03:54,000
只是给你一个也还不错的初始值

81
00:03:54,000 --> 00:03:56,000
让你去后面进行迭代

82
00:03:56,000 --> 00:03:58,000
你用随机也可以

83
00:03:58,000 --> 00:04:00,000
你用随机值可能效果也不差

84
00:04:00,000 --> 00:04:03,000
就说你就可能需要多训练一些时间而已

85
00:04:07,000 --> 00:04:08,000
问题十二

86
00:04:08,000 --> 00:04:11,000
FCM跟SOLTA模型比后续有哪些改进

87
00:04:11,000 --> 00:04:12,000
这个问题比较大

88
00:04:12,000 --> 00:04:14,000
我们就是unit

89
00:04:14,000 --> 00:04:16,000
我们就比如说是刚刚说过了一次

90
00:04:16,000 --> 00:04:19,000
就不要做一个巨大的一个全时卷积出去

91
00:04:19,000 --> 00:04:21,000
另外一块还有比如说deep lab

92
00:04:21,000 --> 00:04:23,000
现在是可以做到V3了

93
00:04:23,000 --> 00:04:24,000
可以大量模型

94
00:04:24,000 --> 00:04:26,000
我觉得你可以去看一看

95
00:04:26,000 --> 00:04:27,000
自己了解一下

96
00:04:27,000 --> 00:04:30,000
我们就没那么多时间给大家一一去讲了

97
00:04:30,000 --> 00:04:32,000
可能得花一节课

98
00:04:34,000 --> 00:04:35,000
问题十三

99
00:04:35,000 --> 00:04:37,000
如果想导入pre-trained的模型

100
00:04:37,000 --> 00:04:40,000
目标模型是不是和pre-trained的模型一致

101
00:04:40,000 --> 00:04:42,000
至少是你想要用weight的那些

102
00:04:42,000 --> 00:04:45,000
用它的全重的那些块必须是一致的

103
00:04:45,000 --> 00:04:47,000
别的地方你可以自己做

104
00:04:47,000 --> 00:04:50,000
这个是怎么样pre-trained的模型

